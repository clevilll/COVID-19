{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-based Surveying the Impact of Environmental, Climatic, Economic and Demographic Conditions on the Epidemic Outbreak Rate of COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Mehryar{\\,}Majd$, $Ramin{\\,}Mousa$ \\& $Arsalan{\\,}Mousazadeh$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Abstract:__ This study aims to have an analytical and predictive approach to the growth rate and spread of the first wave of COVID-19 infection and mainly focuses on its dependency on other global factors in affected countries via Artificial Intelligence-based processing of fatality data/statistics. Fatality, infected, and recovered cases in the form of the time-series data was acquired through the World Health Organization (WHO) & the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). Recorded health data subsequently was analyzed by several Deep Neural Network (DNN) models to create a better intuition of epidemic outbreak rate of COVID-19. Monitoring spreading trend changes becomes more feasible via continuous observation of statistical pattern and integrating the other datasets with more global features count as factors influencing the local conditions on historical data conveys pivotal information concerning learning the pattern of epidemic progression. In this study, attention-based Sequence-to-Sequence (Seq2Seq) models empowered by Long-Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) units, were deployed to predict mortality rate. Ultimately these analyses are utilized to monitor infection behaviour on time-series data and were subsequently assessed for their performance to predict the behaviour of the first wave of COVID-19 outbreak rate intensely. Demographic & environmental conditions have likely been influenced significantly to shape the reliable predictive learning algorithms for long-duration risk of COVID-19 pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction along with other data __weather data__, __economic data__\n",
    "__Data Cleaning & Preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "df_covid_19 = pd.read_csv(\"novel-corona-virus/covid_19_data.csv\")\n",
    "df_covid_19['Date'] = pd.to_datetime(df_covid_19['ObservationDate'])\n",
    "df_covid_19['Outbreak'] = 'COVID_2019'\n",
    "df_sars_03 = pd.read_csv(\"novel-corona-virus/sars_2003_complete_dataset_clean.csv\")\n",
    "df_sars_03['Date'] = pd.to_datetime(df_sars_03['Date'])\n",
    "df_sars_03['Province/State'] = None\n",
    "df_sars_03['Outbreak'] = 'SARS_2003'\n",
    "df_sars_03.rename({'Cumulative number of case(s)':'Confirmed', 'Number of deaths':'Deaths', 'Number recovered':'Recovered', 'Country':'Country/Region'},axis=1,inplace=True)\n",
    "templ_cols = ['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed', 'Deaths', 'Recovered']\n",
    "df = pd.concat([df_covid_19[templ_cols], df_sars_03[templ_cols]])\n",
    "#df=df_covid_19\n",
    "df = df.reset_index(drop=True)\n",
    "df['Confirmed'] = df['Confirmed'].fillna(0)\n",
    "df['Province/State'] = df['Province/State'].fillna('Others')\n",
    "df = df.sort_values(['Country/Region','Province/State','Date'])\n",
    "t = df.groupby(['Outbreak','Country/Region','Province/State']).agg({'Confirmed':'max'})\n",
    "t = t.loc[t['Confirmed'] >=0]\n",
    "df = pd.merge(df,t,left_on=['Outbreak','Country/Region','Province/State'], right_index=True)\n",
    "\n",
    "country_data = pd.read_csv(\"novel-corona-virus/countries of the world.csv\")\n",
    "country_data['Country'] = country_data['Country'].str.strip()\n",
    "df.loc[df['Country/Region']=='US','Country/Region'] = 'United States'\n",
    "df.loc[df['Country/Region']=='Mainland China','Country/Region'] = 'China'\n",
    "df.loc[df['Country/Region']=='Viet Nam','Country/Region'] = 'Vietnam'\n",
    "df.loc[df['Country/Region']=='UK','Country/Region'] = 'United Kingdom'\n",
    "df.loc[df['Country/Region']=='South Korea','Country/Region'] = 'Korea, South'\n",
    "df.loc[df['Country/Region']=='Taiwan, China','Country/Region'] = 'Taiwan'\n",
    "df.loc[df['Country/Region']=='Hong Kong SAR, China','Country/Region'] = 'Hong Kong'\n",
    "df = pd.merge(df, country_data, how='left', left_on=['Country/Region'], right_on=['Country'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[df['Region'].isnull(), 'Region'] = 'Others'\n",
    "df.loc[df['Country'].isnull(), 'Country'] = 'Undefined'\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Week'] = df['Date'].dt.week\n",
    "df = df.fillna(0)\n",
    "df=df.drop('Other (%)',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "from fastnumbers import fast_real\n",
    "Literacy=[]\n",
    "Pop,Pho,Agric=[],[],[]\n",
    "Coa,Clim,Bir,Dea=[],[],[],[]\n",
    "Net,Inf,Arab,Crop,Ind,Serv=[],[],[],[],[],[]\n",
    "for index ,row in df.iterrows():\n",
    "    a=str(row['Literacy (%)']).replace(',','.')\n",
    "    Literacy.append(fast_real(a))\n",
    "    #----------\n",
    "    a=str(row['Pop. Density (per sq. mi.)']).replace(',','.')\n",
    "    Pop.append(fast_real(a))\n",
    "    #----------\n",
    "    a=str(row['Coastline (coast/area ratio)']).replace(',','.')\n",
    "    Coa.append(fast_real(a))\n",
    "    #-----------\n",
    "    a=str(row['Net migration']).replace(',','.')\n",
    "    Net.append(fast_real(a))\n",
    "    #-----------\n",
    "    a=str(row['Infant mortality (per 1000 births)']).replace(',','.')\n",
    "    Inf.append(fast_real(a))\n",
    "    #\n",
    "    #\n",
    "    a=str(row['Phones (per 1000)']).replace(',','.')\n",
    "    Pho.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Arable (%)']).replace(',','.')\n",
    "    Arab.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Crops (%)']).replace(',','.')\n",
    "    Crop.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Climate']).replace(',','.')\n",
    "    Clim.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Birthrate']).replace(',','.')\n",
    "    Bir.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Deathrate']).replace(',','.')\n",
    "    Dea.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Agriculture']).replace(',','.')\n",
    "    Agric.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Industry']).replace(',','.')\n",
    "    Ind.append(fast_real(a))\n",
    "    #\n",
    "    a=str(row['Service']).replace(',','.')\n",
    "    Serv.append(fast_real(a))\n",
    "df['Literacy (%)']=Literacy\n",
    "df['Pop. Density (per sq. mi.)']=Pop\n",
    "df['Coastline (coast/area ratio)']=Coa\n",
    "df['Net migration']=Net\n",
    "df['Infant mortality (per 1000 births)']=Inf\n",
    "df['Phones (per 1000)']=Pho\n",
    "df['Arable (%)']=Arab\n",
    "df['Crops (%)']=Crop\n",
    "df['Climate']=Clim\n",
    "df['Birthrate']=Bir\n",
    "df['Deathrate']=Dea\n",
    "df['Agriculture']=Agric\n",
    "df['Industry']=Ind\n",
    "df['Service']=Serv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outbreak</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed_x</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Confirmed_y</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>...</th>\n",
       "      <th>Arable (%)</th>\n",
       "      <th>Crops (%)</th>\n",
       "      <th>Climate</th>\n",
       "      <th>Birthrate</th>\n",
       "      <th>Deathrate</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Service</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>Others</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>Others</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "      <td>...</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "      <td>...</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "      <td>...</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outbreak Province/State  Country/Region       Date  Confirmed_x  Deaths  \\\n",
       "0         0         Others               0 2020-02-28          1.0     0.0   \n",
       "1         0         Others               1 2020-03-10          2.0     0.0   \n",
       "2         0         Others               2 2020-02-24          1.0     0.0   \n",
       "3         0         Others               2 2020-02-25          1.0     0.0   \n",
       "4         0         Others               2 2020-02-26          1.0     0.0   \n",
       "\n",
       "   Recovered  Confirmed_y      Country                         Region  ...  \\\n",
       "0        0.0          1.0    Undefined                         Others  ...   \n",
       "1        0.0          2.0    Undefined                         Others  ...   \n",
       "2        0.0         21.0  Afghanistan  ASIA (EX. NEAR EAST)           ...   \n",
       "3        0.0         21.0  Afghanistan  ASIA (EX. NEAR EAST)           ...   \n",
       "4        0.0         21.0  Afghanistan  ASIA (EX. NEAR EAST)           ...   \n",
       "\n",
       "   Arable (%)  Crops (%)  Climate  Birthrate  Deathrate  Agriculture  \\\n",
       "0        0.00       0.00      0.0        0.0       0.00         0.00   \n",
       "1        0.00       0.00      0.0        0.0       0.00         0.00   \n",
       "2       12.13       0.22      1.0       46.6      20.34         0.38   \n",
       "3       12.13       0.22      1.0       46.6      20.34         0.38   \n",
       "4       12.13       0.22      1.0       46.6      20.34         0.38   \n",
       "\n",
       "   Industry  Service  Month  Week  \n",
       "0      0.00     0.00      2     9  \n",
       "1      0.00     0.00      3    11  \n",
       "2      0.24     0.38      2     9  \n",
       "3      0.24     0.38      2     9  \n",
       "4      0.24     0.38      2     9  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country/Region'] = df['Country/Region'].astype('category')\n",
    "df['Outbreak'] = df['Outbreak'].astype('category')\n",
    "df['Country/Region'] = df['Country/Region'].cat.codes\n",
    "df['Outbreak'] = df['Outbreak'].cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()\n",
    "new_df=df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['Outbreak','Country/Region', 'Industry','Confirmed_x','Deaths','Recovered']\n",
    "df=df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM,GRU\n",
    "from keras.layers import Dense\n",
    "def load_data(data, time_step=2, after_day=1, validate_percent=0.67):\n",
    "    seq_length = time_step + after_day\n",
    "    result = []\n",
    "    for index in range(len(data) - seq_length + 1):\n",
    "        result.append(data[index: index + seq_length])\n",
    "    result = np.array(result)\n",
    "    print('total data: ', result.shape)\n",
    "\n",
    "    train_size = int(len(result) * validate_percent)\n",
    "    train = result[:train_size, :]\n",
    "    validate = result[train_size:, :]\n",
    "\n",
    "    x_train = train[:, :time_step]\n",
    "    y_train = train[:, time_step:]\n",
    "    x_validate = validate[:, :time_step]\n",
    "    y_validate = validate[:, time_step:]\n",
    "    \n",
    "     \n",
    "\n",
    "    return [x_train, y_train, x_validate, y_validate]\n",
    "def base_model(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "\n",
    "def seq2seq(feature_len=1, after_day=1, input_shape=(8, 1)):\n",
    "    '''\n",
    "    Encoder:\n",
    "    X = Input sequence\n",
    "    C = LSTM(X); The context vector\n",
    "\n",
    "    Decoder:\n",
    "    y(t) = LSTM(s(t-1), y(t-1)); where s is the hidden state of the LSTM(h and c)\n",
    "    y(0) = LSTM(s0, C); C is the context vector from the encoder.\n",
    "    '''\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=input_shape) # (timesteps, feature)\n",
    "    encoder = LSTM(units=100, return_state=True,  name='encoder')\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    states = [state_h, state_c]\n",
    "\n",
    "    # Decoder\n",
    "    reshapor = Reshape((1, 100), name='reshapor')\n",
    "    decoder = LSTM(units=100, return_sequences=True, return_state=True, name='decoder')\n",
    "\n",
    "    # Densor\n",
    "    #tdensor = TimeDistributed(Dense(units=200, activation='linear', name='time_densor'))\n",
    "    densor_output = Dense(units=feature_len, activation='linear', name='output')\n",
    "\n",
    "    inputs = reshapor(encoder_outputs)\n",
    "    #inputs = tdensor(inputs)\n",
    "    all_outputs = []\n",
    "\n",
    "\n",
    "\n",
    "    for _ in range(after_day):\n",
    "        outputs, h, c = decoder(inputs, initial_state=states)\n",
    "\n",
    "        #inputs = tdensor(outputs)\n",
    "        inputs = outputs\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "        outputs = densor_output(outputs)\n",
    "        all_outputs.append(outputs)\n",
    "\n",
    "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "    model = Model(inputs=encoder_inputs, outputs=decoder_outputs)\n",
    "\n",
    "    return model\n",
    "def normalize_data(data, scaler, feature_len):\n",
    "    minmaxscaler = scaler.fit(data)\n",
    "    normalize_data = minmaxscaler.transform(data)\n",
    "    return normalize_data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rad/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/rad/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 6s 834us/step - loss: 0.0479 - acc: 0.6699 - rmse: 0.1935 - mse: 0.0479 - r_square: 0.3655 - val_loss: 0.0435 - val_acc: 0.9823 - val_rmse: 0.1958 - val_mse: 0.0435 - val_r_square: 0.6792\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 293us/step - loss: 0.0298 - acc: 0.7813 - rmse: 0.1481 - mse: 0.0298 - r_square: 0.6068 - val_loss: 0.0310 - val_acc: 0.8365 - val_rmse: 0.1704 - val_mse: 0.0310 - val_r_square: 0.7718\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0201 - acc: 0.8515 - rmse: 0.1151 - mse: 0.0201 - r_square: 0.7260 - val_loss: 0.0173 - val_acc: 0.8365 - val_rmse: 0.1249 - val_mse: 0.0173 - val_r_square: 0.8747\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 3s 368us/step - loss: 0.0142 - acc: 0.9285 - rmse: 0.0913 - mse: 0.0142 - r_square: 0.8080 - val_loss: 0.0119 - val_acc: 0.8365 - val_rmse: 0.1028 - val_mse: 0.0119 - val_r_square: 0.9139\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 280us/step - loss: 0.0119 - acc: 0.9181 - rmse: 0.0811 - mse: 0.0119 - r_square: 0.8322 - val_loss: 0.0076 - val_acc: 0.8365 - val_rmse: 0.0786 - val_mse: 0.0076 - val_r_square: 0.9465\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0097 - acc: 0.9217 - rmse: 0.0695 - mse: 0.0097 - r_square: 0.8643 - val_loss: 0.0056 - val_acc: 0.8365 - val_rmse: 0.0607 - val_mse: 0.0056 - val_r_square: 0.9620\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0086 - acc: 0.9335 - rmse: 0.0614 - mse: 0.0086 - r_square: 0.8777 - val_loss: 0.0047 - val_acc: 0.8365 - val_rmse: 0.0535 - val_mse: 0.0047 - val_r_square: 0.9698\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0088 - acc: 0.9016 - rmse: 0.0641 - mse: 0.0088 - r_square: 0.8793 - val_loss: 0.0048 - val_acc: 0.8900 - val_rmse: 0.0598 - val_mse: 0.0048 - val_r_square: 0.9662\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0084 - acc: 0.9112 - rmse: 0.0616 - mse: 0.0084 - r_square: 0.8822 - val_loss: 0.0048 - val_acc: 0.9555 - val_rmse: 0.0601 - val_mse: 0.0048 - val_r_square: 0.9654\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0073 - acc: 0.9249 - rmse: 0.0531 - mse: 0.0073 - r_square: 0.8996 - val_loss: 0.0029 - val_acc: 0.9665 - val_rmse: 0.0418 - val_mse: 0.0029 - val_r_square: 0.9806\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0072 - acc: 0.9445 - rmse: 0.0531 - mse: 0.0072 - r_square: 0.9017 - val_loss: 0.0025 - val_acc: 0.8375 - val_rmse: 0.0373 - val_mse: 0.0025 - val_r_square: 0.9840\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0069 - acc: 0.9437 - rmse: 0.0497 - mse: 0.0069 - r_square: 0.9063 - val_loss: 0.0025 - val_acc: 0.8397 - val_rmse: 0.0379 - val_mse: 0.0025 - val_r_square: 0.9842\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0067 - acc: 0.9445 - rmse: 0.0485 - mse: 0.0067 - r_square: 0.9112 - val_loss: 0.0026 - val_acc: 0.8382 - val_rmse: 0.0390 - val_mse: 0.0026 - val_r_square: 0.9837\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0067 - acc: 0.9333 - rmse: 0.0500 - mse: 0.0067 - r_square: 0.9115 - val_loss: 0.0029 - val_acc: 0.8401 - val_rmse: 0.0442 - val_mse: 0.0029 - val_r_square: 0.9811\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0065 - acc: 0.9245 - rmse: 0.0479 - mse: 0.0065 - r_square: 0.9131 - val_loss: 0.0021 - val_acc: 0.8646 - val_rmse: 0.0331 - val_mse: 0.0021 - val_r_square: 0.9870\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 3s 434us/step - loss: 0.0063 - acc: 0.9258 - rmse: 0.0467 - mse: 0.0063 - r_square: 0.9149 - val_loss: 0.0017 - val_acc: 0.8774 - val_rmse: 0.0259 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 3s 382us/step - loss: 0.0064 - acc: 0.9408 - rmse: 0.0481 - mse: 0.0064 - r_square: 0.9144 - val_loss: 0.0025 - val_acc: 0.8365 - val_rmse: 0.0392 - val_mse: 0.0025 - val_r_square: 0.9845\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 350us/step - loss: 0.0065 - acc: 0.9414 - rmse: 0.0487 - mse: 0.0065 - r_square: 0.9154 - val_loss: 0.0026 - val_acc: 0.8366 - val_rmse: 0.0381 - val_mse: 0.0026 - val_r_square: 0.9846\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 293us/step - loss: 0.0064 - acc: 0.9440 - rmse: 0.0489 - mse: 0.0064 - r_square: 0.9162 - val_loss: 0.0031 - val_acc: 0.8374 - val_rmse: 0.0429 - val_mse: 0.0031 - val_r_square: 0.9814\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 294us/step - loss: 0.0069 - acc: 0.9371 - rmse: 0.0531 - mse: 0.0069 - r_square: 0.9101 - val_loss: 0.0030 - val_acc: 0.8377 - val_rmse: 0.0426 - val_mse: 0.0030 - val_r_square: 0.9819\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0071 - acc: 0.9270 - rmse: 0.0567 - mse: 0.0071 - r_square: 0.9064 - val_loss: 0.0031 - val_acc: 0.8397 - val_rmse: 0.0472 - val_mse: 0.0031 - val_r_square: 0.9798\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 339us/step - loss: 0.0077 - acc: 0.8987 - rmse: 0.0610 - mse: 0.0077 - r_square: 0.9019 - val_loss: 0.0061 - val_acc: 0.9929 - val_rmse: 0.0725 - val_mse: 0.0061 - val_r_square: 0.9570\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 349us/step - loss: 0.0077 - acc: 0.8760 - rmse: 0.0615 - mse: 0.0077 - r_square: 0.8995 - val_loss: 0.0045 - val_acc: 0.9925 - val_rmse: 0.0600 - val_mse: 0.0045 - val_r_square: 0.9686\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 3s 406us/step - loss: 0.0077 - acc: 0.8765 - rmse: 0.0630 - mse: 0.0077 - r_square: 0.8951 - val_loss: 0.0020 - val_acc: 0.8630 - val_rmse: 0.0308 - val_mse: 0.0020 - val_r_square: 0.9878\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 3s 365us/step - loss: 0.0069 - acc: 0.9067 - rmse: 0.0534 - mse: 0.0069 - r_square: 0.9056 - val_loss: 0.0018 - val_acc: 0.8623 - val_rmse: 0.0274 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0065 - acc: 0.9039 - rmse: 0.0504 - mse: 0.0065 - r_square: 0.9116 - val_loss: 0.0020 - val_acc: 0.8365 - val_rmse: 0.0307 - val_mse: 0.0020 - val_r_square: 0.9881\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 273us/step - loss: 0.0060 - acc: 0.9305 - rmse: 0.0435 - mse: 0.0060 - r_square: 0.9170 - val_loss: 0.0016 - val_acc: 0.8500 - val_rmse: 0.0247 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0055 - acc: 0.9449 - rmse: 0.0392 - mse: 0.0055 - r_square: 0.9250 - val_loss: 0.0017 - val_acc: 0.8640 - val_rmse: 0.0268 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0053 - acc: 0.9563 - rmse: 0.0357 - mse: 0.0053 - r_square: 0.9288 - val_loss: 0.0016 - val_acc: 0.8772 - val_rmse: 0.0258 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0052 - acc: 0.9562 - rmse: 0.0353 - mse: 0.0052 - r_square: 0.9306 - val_loss: 0.0017 - val_acc: 0.9407 - val_rmse: 0.0268 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0052 - acc: 0.9575 - rmse: 0.0346 - mse: 0.0052 - r_square: 0.9313 - val_loss: 0.0017 - val_acc: 0.9411 - val_rmse: 0.0266 - val_mse: 0.0017 - val_r_square: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 277us/step - loss: 0.0052 - acc: 0.9544 - rmse: 0.0342 - mse: 0.0052 - r_square: 0.9312 - val_loss: 0.0017 - val_acc: 0.9414 - val_rmse: 0.0264 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0052 - acc: 0.9561 - rmse: 0.0347 - mse: 0.0052 - r_square: 0.9308 - val_loss: 0.0017 - val_acc: 0.9414 - val_rmse: 0.0269 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0052 - acc: 0.9547 - rmse: 0.0340 - mse: 0.0052 - r_square: 0.9308 - val_loss: 0.0017 - val_acc: 0.9423 - val_rmse: 0.0271 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0051 - acc: 0.9560 - rmse: 0.0339 - mse: 0.0051 - r_square: 0.9331 - val_loss: 0.0017 - val_acc: 0.9419 - val_rmse: 0.0265 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9548 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9337 - val_loss: 0.0017 - val_acc: 0.9421 - val_rmse: 0.0262 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9540 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9340 - val_loss: 0.0017 - val_acc: 0.9426 - val_rmse: 0.0272 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9539 - rmse: 0.0332 - mse: 0.0050 - r_square: 0.9343 - val_loss: 0.0017 - val_acc: 0.9421 - val_rmse: 0.0268 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0051 - acc: 0.9527 - rmse: 0.0336 - mse: 0.0051 - r_square: 0.9334 - val_loss: 0.0018 - val_acc: 0.9421 - val_rmse: 0.0284 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0051 - acc: 0.9536 - rmse: 0.0335 - mse: 0.0051 - r_square: 0.9331 - val_loss: 0.0017 - val_acc: 0.9421 - val_rmse: 0.0271 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0051 - acc: 0.9501 - rmse: 0.0341 - mse: 0.0051 - r_square: 0.9326 - val_loss: 0.0018 - val_acc: 0.9421 - val_rmse: 0.0288 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9507 - rmse: 0.0340 - mse: 0.0050 - r_square: 0.9345 - val_loss: 0.0018 - val_acc: 0.9423 - val_rmse: 0.0279 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9489 - rmse: 0.0340 - mse: 0.0050 - r_square: 0.9349 - val_loss: 0.0018 - val_acc: 0.9423 - val_rmse: 0.0285 - val_mse: 0.0018 - val_r_square: 0.9887\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0050 - acc: 0.9472 - rmse: 0.0344 - mse: 0.0050 - r_square: 0.9348 - val_loss: 0.0018 - val_acc: 0.9424 - val_rmse: 0.0290 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0050 - acc: 0.9466 - rmse: 0.0347 - mse: 0.0050 - r_square: 0.9348 - val_loss: 0.0019 - val_acc: 0.9426 - val_rmse: 0.0298 - val_mse: 0.0019 - val_r_square: 0.9883\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0050 - acc: 0.9455 - rmse: 0.0352 - mse: 0.0050 - r_square: 0.9347 - val_loss: 0.0019 - val_acc: 0.9431 - val_rmse: 0.0299 - val_mse: 0.0019 - val_r_square: 0.9883\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0050 - acc: 0.9449 - rmse: 0.0356 - mse: 0.0050 - r_square: 0.9344 - val_loss: 0.0019 - val_acc: 0.9430 - val_rmse: 0.0303 - val_mse: 0.0019 - val_r_square: 0.9882\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9442 - rmse: 0.0360 - mse: 0.0051 - r_square: 0.9342 - val_loss: 0.0019 - val_acc: 0.9434 - val_rmse: 0.0301 - val_mse: 0.0019 - val_r_square: 0.9884\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0051 - acc: 0.9451 - rmse: 0.0364 - mse: 0.0051 - r_square: 0.9334 - val_loss: 0.0018 - val_acc: 0.9424 - val_rmse: 0.0295 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0053 - acc: 0.9442 - rmse: 0.0366 - mse: 0.0053 - r_square: 0.9302 - val_loss: 0.0018 - val_acc: 0.9434 - val_rmse: 0.0289 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0052 - acc: 0.9496 - rmse: 0.0366 - mse: 0.0052 - r_square: 0.9304 - val_loss: 0.0017 - val_acc: 0.9414 - val_rmse: 0.0265 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0052 - acc: 0.9483 - rmse: 0.0359 - mse: 0.0052 - r_square: 0.9307 - val_loss: 0.0016 - val_acc: 0.9413 - val_rmse: 0.0261 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0050 - acc: 0.9530 - rmse: 0.0348 - mse: 0.0050 - r_square: 0.9328 - val_loss: 0.0015 - val_acc: 0.9218 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 3s 444us/step - loss: 0.0049 - acc: 0.9533 - rmse: 0.0340 - mse: 0.0049 - r_square: 0.9338 - val_loss: 0.0015 - val_acc: 0.8900 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 3s 427us/step - loss: 0.0049 - acc: 0.9528 - rmse: 0.0334 - mse: 0.0049 - r_square: 0.9344 - val_loss: 0.0015 - val_acc: 0.9151 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0049 - acc: 0.9521 - rmse: 0.0323 - mse: 0.0049 - r_square: 0.9354 - val_loss: 0.0015 - val_acc: 0.8895 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9504 - rmse: 0.0335 - mse: 0.0050 - r_square: 0.9332 - val_loss: 0.0016 - val_acc: 0.9280 - val_rmse: 0.0244 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9520 - rmse: 0.0311 - mse: 0.0048 - r_square: 0.9364 - val_loss: 0.0016 - val_acc: 0.8849 - val_rmse: 0.0245 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 3s 382us/step - loss: 0.0048 - acc: 0.9526 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9357 - val_loss: 0.0015 - val_acc: 0.9404 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0048 - acc: 0.9529 - rmse: 0.0305 - mse: 0.0048 - r_square: 0.9375 - val_loss: 0.0016 - val_acc: 0.9147 - val_rmse: 0.0242 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 292us/step - loss: 0.0048 - acc: 0.9521 - rmse: 0.0315 - mse: 0.0048 - r_square: 0.9367 - val_loss: 0.0016 - val_acc: 0.9410 - val_rmse: 0.0241 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0048 - acc: 0.9508 - rmse: 0.0305 - mse: 0.0048 - r_square: 0.9377 - val_loss: 0.0016 - val_acc: 0.9279 - val_rmse: 0.0249 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0049 - acc: 0.9501 - rmse: 0.0318 - mse: 0.0049 - r_square: 0.9355 - val_loss: 0.0016 - val_acc: 0.9411 - val_rmse: 0.0253 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0048 - acc: 0.9509 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9379 - val_loss: 0.0016 - val_acc: 0.9403 - val_rmse: 0.0251 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0047 - acc: 0.9501 - rmse: 0.0308 - mse: 0.0047 - r_square: 0.9381 - val_loss: 0.0016 - val_acc: 0.9408 - val_rmse: 0.0244 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0047 - acc: 0.9475 - rmse: 0.0308 - mse: 0.0047 - r_square: 0.9383 - val_loss: 0.0016 - val_acc: 0.9408 - val_rmse: 0.0246 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0047 - acc: 0.9446 - rmse: 0.0312 - mse: 0.0047 - r_square: 0.9383 - val_loss: 0.0016 - val_acc: 0.9413 - val_rmse: 0.0242 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0048 - acc: 0.9458 - rmse: 0.0315 - mse: 0.0048 - r_square: 0.9375 - val_loss: 0.0017 - val_acc: 0.9411 - val_rmse: 0.0263 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0049 - acc: 0.9425 - rmse: 0.0326 - mse: 0.0049 - r_square: 0.9360 - val_loss: 0.0016 - val_acc: 0.9416 - val_rmse: 0.0245 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0048 - acc: 0.9453 - rmse: 0.0319 - mse: 0.0048 - r_square: 0.9374 - val_loss: 0.0017 - val_acc: 0.9036 - val_rmse: 0.0281 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0048 - acc: 0.9439 - rmse: 0.0324 - mse: 0.0048 - r_square: 0.9377 - val_loss: 0.0015 - val_acc: 0.9289 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9444 - rmse: 0.0324 - mse: 0.0048 - r_square: 0.9375 - val_loss: 0.0017 - val_acc: 0.8905 - val_rmse: 0.0265 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9415 - rmse: 0.0338 - mse: 0.0049 - r_square: 0.9371 - val_loss: 0.0016 - val_acc: 0.9417 - val_rmse: 0.0251 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0049 - acc: 0.9458 - rmse: 0.0337 - mse: 0.0049 - r_square: 0.9363 - val_loss: 0.0018 - val_acc: 0.8899 - val_rmse: 0.0302 - val_mse: 0.0018 - val_r_square: 0.9883\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0051 - acc: 0.9406 - rmse: 0.0355 - mse: 0.0051 - r_square: 0.9345 - val_loss: 0.0016 - val_acc: 0.9034 - val_rmse: 0.0253 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0052 - acc: 0.9451 - rmse: 0.0364 - mse: 0.0052 - r_square: 0.9314 - val_loss: 0.0020 - val_acc: 0.8643 - val_rmse: 0.0321 - val_mse: 0.0020 - val_r_square: 0.9874\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0050 - acc: 0.9431 - rmse: 0.0366 - mse: 0.0050 - r_square: 0.9348 - val_loss: 0.0016 - val_acc: 0.8643 - val_rmse: 0.0248 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9457 - rmse: 0.0332 - mse: 0.0049 - r_square: 0.9361 - val_loss: 0.0016 - val_acc: 0.8515 - val_rmse: 0.0262 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0051 - acc: 0.9293 - rmse: 0.0377 - mse: 0.0051 - r_square: 0.9341 - val_loss: 0.0016 - val_acc: 0.8634 - val_rmse: 0.0248 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9474 - rmse: 0.0329 - mse: 0.0048 - r_square: 0.9362 - val_loss: 0.0017 - val_acc: 0.8377 - val_rmse: 0.0270 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0051 - acc: 0.9305 - rmse: 0.0373 - mse: 0.0051 - r_square: 0.9332 - val_loss: 0.0014 - val_acc: 0.8381 - val_rmse: 0.0202 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9499 - rmse: 0.0323 - mse: 0.0048 - r_square: 0.9364 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9315 - rmse: 0.0365 - mse: 0.0050 - r_square: 0.9343 - val_loss: 0.0014 - val_acc: 0.8377 - val_rmse: 0.0192 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9512 - rmse: 0.0315 - mse: 0.0048 - r_square: 0.9370 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9299 - rmse: 0.0362 - mse: 0.0050 - r_square: 0.9342 - val_loss: 0.0013 - val_acc: 0.8377 - val_rmse: 0.0185 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0047 - acc: 0.9525 - rmse: 0.0312 - mse: 0.0047 - r_square: 0.9374 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0049 - acc: 0.9340 - rmse: 0.0357 - mse: 0.0049 - r_square: 0.9354 - val_loss: 0.0013 - val_acc: 0.8377 - val_rmse: 0.0181 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9514 - rmse: 0.0313 - mse: 0.0047 - r_square: 0.9373 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0231 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0051 - acc: 0.9334 - rmse: 0.0368 - mse: 0.0051 - r_square: 0.9332 - val_loss: 0.0013 - val_acc: 0.8377 - val_rmse: 0.0183 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9482 - rmse: 0.0316 - mse: 0.0048 - r_square: 0.9370 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9382 - rmse: 0.0372 - mse: 0.0050 - r_square: 0.9342 - val_loss: 0.0014 - val_acc: 0.8377 - val_rmse: 0.0184 - val_mse: 0.0014 - val_r_square: 0.9923\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9474 - rmse: 0.0328 - mse: 0.0048 - r_square: 0.9365 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0052 - acc: 0.9369 - rmse: 0.0395 - mse: 0.0052 - r_square: 0.9321 - val_loss: 0.0014 - val_acc: 0.8377 - val_rmse: 0.0201 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9463 - rmse: 0.0350 - mse: 0.0049 - r_square: 0.9345 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0056 - acc: 0.9353 - rmse: 0.0430 - mse: 0.0056 - r_square: 0.9270 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0052 - acc: 0.9437 - rmse: 0.0388 - mse: 0.0052 - r_square: 0.9291 - val_loss: 0.0014 - val_acc: 0.8377 - val_rmse: 0.0208 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0059 - acc: 0.9414 - rmse: 0.0467 - mse: 0.0059 - r_square: 0.9218 - val_loss: 0.0021 - val_acc: 0.8377 - val_rmse: 0.0353 - val_mse: 0.0021 - val_r_square: 0.9864\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0052 - acc: 0.9461 - rmse: 0.0409 - mse: 0.0052 - r_square: 0.9280 - val_loss: 0.0014 - val_acc: 0.8377 - val_rmse: 0.0202 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 253us/step - loss: 0.0061 - acc: 0.9436 - rmse: 0.0487 - mse: 0.0061 - r_square: 0.9203 - val_loss: 0.0030 - val_acc: 0.8377 - val_rmse: 0.0455 - val_mse: 0.0030 - val_r_square: 0.9804\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0056 - acc: 0.9497 - rmse: 0.0444 - mse: 0.0056 - r_square: 0.9251 - val_loss: 0.0017 - val_acc: 0.8377 - val_rmse: 0.0267 - val_mse: 0.0017 - val_r_square: 0.9899\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Activation, TimeDistributed, Dropout, Lambda, RepeatVector, Input, Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD,Adam\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],'k-*',label='train')\n",
    "plt.plot(history.history['val_loss'],'r-*', label='test')\n",
    "plt.legend()\n",
    "plt.title(\"LSTM loss during training Covid19 and Sars\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_6 (RepeatVecto (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 5s 691us/step - loss: 0.0146 - acc: 0.8163 - mse: 0.0146 - rmse: 0.0971 - r_square: 0.7896 - val_loss: 0.0091 - val_acc: 0.9931 - val_mse: 0.0091 - val_rmse: 0.0915 - val_r_square: 0.9337\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 248us/step - loss: 0.0156 - acc: 0.7868 - mse: 0.0156 - rmse: 0.1071 - r_square: 0.7202 - val_loss: 0.0061 - val_acc: 0.8862 - val_mse: 0.0061 - val_rmse: 0.0733 - val_r_square: 0.9572\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 238us/step - loss: 0.0140 - acc: 0.9144 - mse: 0.0140 - rmse: 0.0930 - r_square: 0.7898 - val_loss: 0.0068 - val_acc: 0.8636 - val_mse: 0.0068 - val_rmse: 0.0771 - val_r_square: 0.9510\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 238us/step - loss: 0.0139 - acc: 0.9328 - mse: 0.0139 - rmse: 0.0965 - r_square: 0.7802 - val_loss: 0.0068 - val_acc: 0.9942 - val_mse: 0.0068 - val_rmse: 0.0771 - val_r_square: 0.9508\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 247us/step - loss: 0.0133 - acc: 0.8884 - mse: 0.0133 - rmse: 0.0939 - r_square: 0.7962 - val_loss: 0.0038 - val_acc: 0.8630 - val_mse: 0.0038 - val_rmse: 0.0537 - val_r_square: 0.9748\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 237us/step - loss: 0.0114 - acc: 0.9010 - mse: 0.0114 - rmse: 0.0817 - r_square: 0.8413 - val_loss: 0.0053 - val_acc: 0.8365 - val_mse: 0.0053 - val_rmse: 0.0629 - val_r_square: 0.9660\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0085 - acc: 0.9464 - mse: 0.0085 - rmse: 0.0676 - r_square: 0.8862 - val_loss: 0.0023 - val_acc: 0.8371 - val_mse: 0.0023 - val_rmse: 0.0310 - val_r_square: 0.9869\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 240us/step - loss: 0.0087 - acc: 0.9238 - mse: 0.0087 - rmse: 0.0668 - r_square: 0.8701 - val_loss: 0.0034 - val_acc: 0.8365 - val_mse: 0.0034 - val_rmse: 0.0514 - val_r_square: 0.9767\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 241us/step - loss: 0.0089 - acc: 0.9296 - mse: 0.0089 - rmse: 0.0585 - r_square: 0.8791 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0367 - val_r_square: 0.9855\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0075 - acc: 0.9327 - mse: 0.0075 - rmse: 0.0551 - r_square: 0.8997 - val_loss: 0.0025 - val_acc: 0.8365 - val_mse: 0.0025 - val_rmse: 0.0404 - val_r_square: 0.9840\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0065 - acc: 0.9433 - mse: 0.0065 - rmse: 0.0519 - r_square: 0.9129 - val_loss: 0.0027 - val_acc: 0.8365 - val_mse: 0.0027 - val_rmse: 0.0417 - val_r_square: 0.9828\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0070 - acc: 0.9158 - mse: 0.0070 - rmse: 0.0507 - r_square: 0.9059 - val_loss: 0.0063 - val_acc: 0.9942 - val_mse: 0.0063 - val_rmse: 0.0738 - val_r_square: 0.9540\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0065 - acc: 0.9073 - mse: 0.0065 - rmse: 0.0509 - r_square: 0.9091 - val_loss: 0.0031 - val_acc: 0.9942 - val_mse: 0.0031 - val_rmse: 0.0474 - val_r_square: 0.9786\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 244us/step - loss: 0.0066 - acc: 0.9411 - mse: 0.0066 - rmse: 0.0543 - r_square: 0.9122 - val_loss: 0.0043 - val_acc: 0.9942 - val_mse: 0.0043 - val_rmse: 0.0589 - val_r_square: 0.9695\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 244us/step - loss: 0.0068 - acc: 0.9573 - mse: 0.0068 - rmse: 0.0522 - r_square: 0.9107 - val_loss: 0.0051 - val_acc: 0.9171 - val_mse: 0.0051 - val_rmse: 0.0649 - val_r_square: 0.9637\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 245us/step - loss: 0.0057 - acc: 0.9365 - mse: 0.0057 - rmse: 0.0445 - r_square: 0.9268 - val_loss: 0.0018 - val_acc: 0.8371 - val_mse: 0.0018 - val_rmse: 0.0297 - val_r_square: 0.9891\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 245us/step - loss: 0.0068 - acc: 0.9296 - mse: 0.0068 - rmse: 0.0541 - r_square: 0.9167 - val_loss: 0.0038 - val_acc: 0.8918 - val_mse: 0.0038 - val_rmse: 0.0557 - val_r_square: 0.9737\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0069 - acc: 0.9453 - mse: 0.0069 - rmse: 0.0563 - r_square: 0.9079 - val_loss: 0.0043 - val_acc: 0.8646 - val_mse: 0.0043 - val_rmse: 0.0591 - val_r_square: 0.9692\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 246us/step - loss: 0.0073 - acc: 0.9003 - mse: 0.0073 - rmse: 0.0600 - r_square: 0.8958 - val_loss: 0.0029 - val_acc: 0.9942 - val_mse: 0.0029 - val_rmse: 0.0439 - val_r_square: 0.9813\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 245us/step - loss: 0.0080 - acc: 0.9293 - mse: 0.0080 - rmse: 0.0662 - r_square: 0.8859 - val_loss: 0.0033 - val_acc: 0.9942 - val_mse: 0.0033 - val_rmse: 0.0486 - val_r_square: 0.9786\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 245us/step - loss: 0.0064 - acc: 0.9355 - mse: 0.0064 - rmse: 0.0530 - r_square: 0.9033 - val_loss: 0.0022 - val_acc: 0.9940 - val_mse: 0.0022 - val_rmse: 0.0343 - val_r_square: 0.9858\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 246us/step - loss: 0.0057 - acc: 0.9478 - mse: 0.0057 - rmse: 0.0447 - r_square: 0.9255 - val_loss: 0.0022 - val_acc: 0.8371 - val_mse: 0.0022 - val_rmse: 0.0363 - val_r_square: 0.9857\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0071 - acc: 0.9369 - mse: 0.0071 - rmse: 0.0553 - r_square: 0.9148 - val_loss: 0.0038 - val_acc: 0.9911 - val_mse: 0.0038 - val_rmse: 0.0541 - val_r_square: 0.9745\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 228us/step - loss: 0.0059 - acc: 0.9538 - mse: 0.0059 - rmse: 0.0463 - r_square: 0.9255 - val_loss: 0.0028 - val_acc: 0.9678 - val_mse: 0.0028 - val_rmse: 0.0438 - val_r_square: 0.9816\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 228us/step - loss: 0.0069 - acc: 0.9107 - mse: 0.0069 - rmse: 0.0569 - r_square: 0.9108 - val_loss: 0.0025 - val_acc: 0.9942 - val_mse: 0.0025 - val_rmse: 0.0356 - val_r_square: 0.9852\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 228us/step - loss: 0.0074 - acc: 0.9313 - mse: 0.0074 - rmse: 0.0618 - r_square: 0.9034 - val_loss: 0.0039 - val_acc: 0.9942 - val_mse: 0.0039 - val_rmse: 0.0542 - val_r_square: 0.9743\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0065 - acc: 0.9503 - mse: 0.0065 - rmse: 0.0544 - r_square: 0.9072 - val_loss: 0.0025 - val_acc: 0.9942 - val_mse: 0.0025 - val_rmse: 0.0395 - val_r_square: 0.9838\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 233us/step - loss: 0.0065 - acc: 0.9543 - mse: 0.0065 - rmse: 0.0536 - r_square: 0.9062 - val_loss: 0.0023 - val_acc: 0.8502 - val_mse: 0.0023 - val_rmse: 0.0372 - val_r_square: 0.9851\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 227us/step - loss: 0.0071 - acc: 0.9317 - mse: 0.0071 - rmse: 0.0596 - r_square: 0.8994 - val_loss: 0.0024 - val_acc: 0.8391 - val_mse: 0.0024 - val_rmse: 0.0383 - val_r_square: 0.9850\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0065 - acc: 0.9393 - mse: 0.0065 - rmse: 0.0532 - r_square: 0.9060 - val_loss: 0.0019 - val_acc: 0.9537 - val_mse: 0.0019 - val_rmse: 0.0312 - val_r_square: 0.9884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0067 - acc: 0.9408 - mse: 0.0067 - rmse: 0.0553 - r_square: 0.8994 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0281 - val_r_square: 0.9890\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 201us/step - loss: 0.0060 - acc: 0.9611 - mse: 0.0060 - rmse: 0.0499 - r_square: 0.9178 - val_loss: 0.0023 - val_acc: 0.9020 - val_mse: 0.0023 - val_rmse: 0.0359 - val_r_square: 0.9857\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0062 - acc: 0.9541 - mse: 0.0062 - rmse: 0.0514 - r_square: 0.9067 - val_loss: 0.0026 - val_acc: 0.9941 - val_mse: 0.0026 - val_rmse: 0.0415 - val_r_square: 0.9823\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0070 - acc: 0.9392 - mse: 0.0070 - rmse: 0.0579 - r_square: 0.9000 - val_loss: 0.0018 - val_acc: 0.9918 - val_mse: 0.0018 - val_rmse: 0.0284 - val_r_square: 0.9890\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0059 - acc: 0.9455 - mse: 0.0059 - rmse: 0.0489 - r_square: 0.9190 - val_loss: 0.0018 - val_acc: 0.9403 - val_mse: 0.0018 - val_rmse: 0.0293 - val_r_square: 0.9888\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0063 - acc: 0.9297 - mse: 0.0063 - rmse: 0.0507 - r_square: 0.9207 - val_loss: 0.0035 - val_acc: 0.9885 - val_mse: 0.0035 - val_rmse: 0.0511 - val_r_square: 0.9761\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0062 - acc: 0.9295 - mse: 0.0062 - rmse: 0.0492 - r_square: 0.9143 - val_loss: 0.0016 - val_acc: 0.9929 - val_mse: 0.0016 - val_rmse: 0.0250 - val_r_square: 0.9903\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0059 - acc: 0.9329 - mse: 0.0059 - rmse: 0.0485 - r_square: 0.9187 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0226 - val_r_square: 0.9908\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 203us/step - loss: 0.0063 - acc: 0.9509 - mse: 0.0063 - rmse: 0.0535 - r_square: 0.9091 - val_loss: 0.0023 - val_acc: 0.9876 - val_mse: 0.0023 - val_rmse: 0.0354 - val_r_square: 0.9853\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 1s 203us/step - loss: 0.0069 - acc: 0.9352 - mse: 0.0069 - rmse: 0.0591 - r_square: 0.9034 - val_loss: 0.0018 - val_acc: 0.9430 - val_mse: 0.0018 - val_rmse: 0.0289 - val_r_square: 0.9886\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 203us/step - loss: 0.0074 - acc: 0.9517 - mse: 0.0074 - rmse: 0.0603 - r_square: 0.8957 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0254 - val_r_square: 0.9903\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0069 - acc: 0.9063 - mse: 0.0069 - rmse: 0.0570 - r_square: 0.8953 - val_loss: 0.0032 - val_acc: 0.9436 - val_mse: 0.0032 - val_rmse: 0.0485 - val_r_square: 0.9779\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0060 - acc: 0.9432 - mse: 0.0060 - rmse: 0.0479 - r_square: 0.9159 - val_loss: 0.0023 - val_acc: 0.9915 - val_mse: 0.0023 - val_rmse: 0.0364 - val_r_square: 0.9846\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0057 - acc: 0.9528 - mse: 0.0057 - rmse: 0.0443 - r_square: 0.9237 - val_loss: 0.0026 - val_acc: 0.9306 - val_mse: 0.0026 - val_rmse: 0.0417 - val_r_square: 0.9821\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0055 - acc: 0.9599 - mse: 0.0055 - rmse: 0.0433 - r_square: 0.9272 - val_loss: 0.0027 - val_acc: 0.9306 - val_mse: 0.0027 - val_rmse: 0.0438 - val_r_square: 0.9821\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0055 - acc: 0.9487 - mse: 0.0055 - rmse: 0.0444 - r_square: 0.9240 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0322 - val_r_square: 0.9875\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0056 - acc: 0.9617 - mse: 0.0056 - rmse: 0.0430 - r_square: 0.9262 - val_loss: 0.0027 - val_acc: 0.8529 - val_mse: 0.0027 - val_rmse: 0.0434 - val_r_square: 0.9815\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 1s 202us/step - loss: 0.0052 - acc: 0.9617 - mse: 0.0052 - rmse: 0.0396 - r_square: 0.9324 - val_loss: 0.0014 - val_acc: 0.9086 - val_mse: 0.0014 - val_rmse: 0.0196 - val_r_square: 0.9921\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0060 - acc: 0.9239 - mse: 0.0060 - rmse: 0.0476 - r_square: 0.9206 - val_loss: 0.0030 - val_acc: 0.9942 - val_mse: 0.0030 - val_rmse: 0.0456 - val_r_square: 0.9807\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0057 - acc: 0.9367 - mse: 0.0057 - rmse: 0.0465 - r_square: 0.9223 - val_loss: 0.0027 - val_acc: 0.9538 - val_mse: 0.0027 - val_rmse: 0.0414 - val_r_square: 0.9818\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0063 - acc: 0.9402 - mse: 0.0063 - rmse: 0.0490 - r_square: 0.9126 - val_loss: 0.0028 - val_acc: 0.8374 - val_mse: 0.0028 - val_rmse: 0.0447 - val_r_square: 0.9806\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0062 - acc: 0.9351 - mse: 0.0062 - rmse: 0.0522 - r_square: 0.9057 - val_loss: 0.0016 - val_acc: 0.9430 - val_mse: 0.0016 - val_rmse: 0.0231 - val_r_square: 0.9909\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0064 - acc: 0.9460 - mse: 0.0064 - rmse: 0.0509 - r_square: 0.9011 - val_loss: 0.0029 - val_acc: 0.8372 - val_mse: 0.0029 - val_rmse: 0.0450 - val_r_square: 0.9799\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0059 - acc: 0.9379 - mse: 0.0059 - rmse: 0.0501 - r_square: 0.9165 - val_loss: 0.0019 - val_acc: 0.8372 - val_mse: 0.0019 - val_rmse: 0.0316 - val_r_square: 0.9880\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0067 - acc: 0.9355 - mse: 0.0067 - rmse: 0.0539 - r_square: 0.9152 - val_loss: 0.0035 - val_acc: 0.9942 - val_mse: 0.0035 - val_rmse: 0.0520 - val_r_square: 0.9757\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0053 - acc: 0.9539 - mse: 0.0053 - rmse: 0.0410 - r_square: 0.9258 - val_loss: 0.0021 - val_acc: 0.9175 - val_mse: 0.0021 - val_rmse: 0.0342 - val_r_square: 0.9863\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0053 - acc: 0.9437 - mse: 0.0053 - rmse: 0.0434 - r_square: 0.9251 - val_loss: 0.0016 - val_acc: 0.8408 - val_mse: 0.0016 - val_rmse: 0.0257 - val_r_square: 0.9903\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.9592 - mse: 0.0057 - rmse: 0.0437 - r_square: 0.9232 - val_loss: 0.0028 - val_acc: 0.9942 - val_mse: 0.0028 - val_rmse: 0.0443 - val_r_square: 0.9809\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0060 - acc: 0.9512 - mse: 0.0060 - rmse: 0.0482 - r_square: 0.9154 - val_loss: 0.0020 - val_acc: 0.9928 - val_mse: 0.0020 - val_rmse: 0.0326 - val_r_square: 0.9868\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0062 - acc: 0.9530 - mse: 0.0062 - rmse: 0.0494 - r_square: 0.9101 - val_loss: 0.0021 - val_acc: 0.8371 - val_mse: 0.0021 - val_rmse: 0.0350 - val_r_square: 0.9864\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0056 - acc: 0.9543 - mse: 0.0056 - rmse: 0.0437 - r_square: 0.9248 - val_loss: 0.0024 - val_acc: 0.9430 - val_mse: 0.0024 - val_rmse: 0.0398 - val_r_square: 0.9836\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0055 - acc: 0.9424 - mse: 0.0055 - rmse: 0.0427 - r_square: 0.9252 - val_loss: 0.0017 - val_acc: 0.8912 - val_mse: 0.0017 - val_rmse: 0.0289 - val_r_square: 0.9892\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0053 - acc: 0.9466 - mse: 0.0053 - rmse: 0.0419 - r_square: 0.9294 - val_loss: 0.0021 - val_acc: 0.8388 - val_mse: 0.0021 - val_rmse: 0.0349 - val_r_square: 0.9863\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0056 - acc: 0.9610 - mse: 0.0056 - rmse: 0.0448 - r_square: 0.9243 - val_loss: 0.0034 - val_acc: 0.9430 - val_mse: 0.0034 - val_rmse: 0.0506 - val_r_square: 0.9763\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0057 - acc: 0.9484 - mse: 0.0057 - rmse: 0.0444 - r_square: 0.9253 - val_loss: 0.0036 - val_acc: 0.9430 - val_mse: 0.0036 - val_rmse: 0.0526 - val_r_square: 0.9752\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 203us/step - loss: 0.0055 - acc: 0.9440 - mse: 0.0055 - rmse: 0.0438 - r_square: 0.9250 - val_loss: 0.0024 - val_acc: 0.8446 - val_mse: 0.0024 - val_rmse: 0.0393 - val_r_square: 0.9839\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0050 - acc: 0.9527 - mse: 0.0050 - rmse: 0.0382 - r_square: 0.9347 - val_loss: 0.0019 - val_acc: 0.8575 - val_mse: 0.0019 - val_rmse: 0.0315 - val_r_square: 0.9881\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0053 - acc: 0.9421 - mse: 0.0053 - rmse: 0.0416 - r_square: 0.9312 - val_loss: 0.0025 - val_acc: 0.9433 - val_mse: 0.0025 - val_rmse: 0.0400 - val_r_square: 0.9831\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0051 - acc: 0.9621 - mse: 0.0051 - rmse: 0.0392 - r_square: 0.9316 - val_loss: 0.0019 - val_acc: 0.9430 - val_mse: 0.0019 - val_rmse: 0.0320 - val_r_square: 0.9875\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0056 - acc: 0.9440 - mse: 0.0056 - rmse: 0.0449 - r_square: 0.9255 - val_loss: 0.0019 - val_acc: 0.8377 - val_mse: 0.0019 - val_rmse: 0.0297 - val_r_square: 0.9885\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 202us/step - loss: 0.0054 - acc: 0.9548 - mse: 0.0054 - rmse: 0.0410 - r_square: 0.9294 - val_loss: 0.0028 - val_acc: 0.8377 - val_mse: 0.0028 - val_rmse: 0.0440 - val_r_square: 0.9816\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0054 - acc: 0.9563 - mse: 0.0054 - rmse: 0.0434 - r_square: 0.9304 - val_loss: 0.0025 - val_acc: 0.9911 - val_mse: 0.0025 - val_rmse: 0.0390 - val_r_square: 0.9832\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0056 - acc: 0.9368 - mse: 0.0056 - rmse: 0.0456 - r_square: 0.9227 - val_loss: 0.0025 - val_acc: 0.9873 - val_mse: 0.0025 - val_rmse: 0.0381 - val_r_square: 0.9835\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0051 - acc: 0.9628 - mse: 0.0051 - rmse: 0.0393 - r_square: 0.9327 - val_loss: 0.0019 - val_acc: 0.9925 - val_mse: 0.0019 - val_rmse: 0.0322 - val_r_square: 0.9879\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0054 - acc: 0.9633 - mse: 0.0054 - rmse: 0.0437 - r_square: 0.9268 - val_loss: 0.0025 - val_acc: 0.9430 - val_mse: 0.0025 - val_rmse: 0.0390 - val_r_square: 0.9836\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0062 - acc: 0.9598 - mse: 0.0062 - rmse: 0.0498 - r_square: 0.9185 - val_loss: 0.0032 - val_acc: 0.8371 - val_mse: 0.0032 - val_rmse: 0.0478 - val_r_square: 0.9784\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0056 - acc: 0.9651 - mse: 0.0056 - rmse: 0.0424 - r_square: 0.9318 - val_loss: 0.0041 - val_acc: 0.8446 - val_mse: 0.0041 - val_rmse: 0.0573 - val_r_square: 0.9710\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0058 - acc: 0.9631 - mse: 0.0058 - rmse: 0.0459 - r_square: 0.9247 - val_loss: 0.0017 - val_acc: 0.9430 - val_mse: 0.0017 - val_rmse: 0.0279 - val_r_square: 0.9896\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0056 - acc: 0.9475 - mse: 0.0056 - rmse: 0.0432 - r_square: 0.9289 - val_loss: 0.0027 - val_acc: 0.9938 - val_mse: 0.0027 - val_rmse: 0.0428 - val_r_square: 0.9815\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0060 - acc: 0.9378 - mse: 0.0060 - rmse: 0.0470 - r_square: 0.9144 - val_loss: 0.0019 - val_acc: 0.9413 - val_mse: 0.0019 - val_rmse: 0.0322 - val_r_square: 0.9877\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0055 - acc: 0.9442 - mse: 0.0055 - rmse: 0.0441 - r_square: 0.9263 - val_loss: 0.0026 - val_acc: 0.8378 - val_mse: 0.0026 - val_rmse: 0.0414 - val_r_square: 0.9829\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0067 - acc: 0.9184 - mse: 0.0067 - rmse: 0.0542 - r_square: 0.9002 - val_loss: 0.0025 - val_acc: 0.9942 - val_mse: 0.0025 - val_rmse: 0.0397 - val_r_square: 0.9840\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0068 - acc: 0.9449 - mse: 0.0068 - rmse: 0.0552 - r_square: 0.9000 - val_loss: 0.0031 - val_acc: 0.8412 - val_mse: 0.0031 - val_rmse: 0.0482 - val_r_square: 0.9785\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0077 - acc: 0.9376 - mse: 0.0077 - rmse: 0.0621 - r_square: 0.8801 - val_loss: 0.0024 - val_acc: 0.8366 - val_mse: 0.0024 - val_rmse: 0.0397 - val_r_square: 0.9847\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0060 - acc: 0.9451 - mse: 0.0060 - rmse: 0.0515 - r_square: 0.9153 - val_loss: 0.0020 - val_acc: 0.8374 - val_mse: 0.0020 - val_rmse: 0.0305 - val_r_square: 0.9882\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0078 - acc: 0.8715 - mse: 0.0078 - rmse: 0.0632 - r_square: 0.8882 - val_loss: 0.0035 - val_acc: 0.9942 - val_mse: 0.0035 - val_rmse: 0.0514 - val_r_square: 0.9766\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0062 - acc: 0.9366 - mse: 0.0062 - rmse: 0.0510 - r_square: 0.9106 - val_loss: 0.0019 - val_acc: 0.9429 - val_mse: 0.0019 - val_rmse: 0.0308 - val_r_square: 0.9882\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0079 - acc: 0.9236 - mse: 0.0079 - rmse: 0.0629 - r_square: 0.8912 - val_loss: 0.0023 - val_acc: 0.9917 - val_mse: 0.0023 - val_rmse: 0.0374 - val_r_square: 0.9850\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0065 - acc: 0.9421 - mse: 0.0065 - rmse: 0.0548 - r_square: 0.9064 - val_loss: 0.0020 - val_acc: 0.9427 - val_mse: 0.0020 - val_rmse: 0.0315 - val_r_square: 0.9872\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0057 - acc: 0.9385 - mse: 0.0057 - rmse: 0.0483 - r_square: 0.9215 - val_loss: 0.0022 - val_acc: 0.8420 - val_mse: 0.0022 - val_rmse: 0.0352 - val_r_square: 0.9862\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0066 - acc: 0.9185 - mse: 0.0066 - rmse: 0.0535 - r_square: 0.9065 - val_loss: 0.0037 - val_acc: 0.9898 - val_mse: 0.0037 - val_rmse: 0.0524 - val_r_square: 0.9737\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0061 - acc: 0.9337 - mse: 0.0061 - rmse: 0.0498 - r_square: 0.9192 - val_loss: 0.0020 - val_acc: 0.9430 - val_mse: 0.0020 - val_rmse: 0.0319 - val_r_square: 0.9876\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0054 - acc: 0.9549 - mse: 0.0054 - rmse: 0.0425 - r_square: 0.9312 - val_loss: 0.0026 - val_acc: 0.8371 - val_mse: 0.0026 - val_rmse: 0.0390 - val_r_square: 0.9841\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0054 - acc: 0.9520 - mse: 0.0054 - rmse: 0.0427 - r_square: 0.9284 - val_loss: 0.0032 - val_acc: 0.8436 - val_mse: 0.0032 - val_rmse: 0.0486 - val_r_square: 0.9785\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0055 - acc: 0.9306 - mse: 0.0055 - rmse: 0.0434 - r_square: 0.9303 - val_loss: 0.0029 - val_acc: 0.9407 - val_mse: 0.0029 - val_rmse: 0.0441 - val_r_square: 0.9806\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0054 - acc: 0.9619 - mse: 0.0054 - rmse: 0.0424 - r_square: 0.9289 - val_loss: 0.0017 - val_acc: 0.9430 - val_mse: 0.0017 - val_rmse: 0.0285 - val_r_square: 0.9896\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0059 - acc: 0.9471 - mse: 0.0059 - rmse: 0.0479 - r_square: 0.9164 - val_loss: 0.0017 - val_acc: 0.9436 - val_mse: 0.0017 - val_rmse: 0.0272 - val_r_square: 0.9898\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0063 - acc: 0.9425 - mse: 0.0063 - rmse: 0.0494 - r_square: 0.9133 - val_loss: 0.0022 - val_acc: 0.8935 - val_mse: 0.0022 - val_rmse: 0.0365 - val_r_square: 0.9856\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0059 - acc: 0.9303 - mse: 0.0059 - rmse: 0.0473 - r_square: 0.9167 - val_loss: 0.0016 - val_acc: 0.9185 - val_mse: 0.0016 - val_rmse: 0.0253 - val_r_square: 0.9905\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0055 - acc: 0.9533 - mse: 0.0055 - rmse: 0.0442 - r_square: 0.9222 - val_loss: 0.0021 - val_acc: 0.9442 - val_mse: 0.0021 - val_rmse: 0.0342 - val_r_square: 0.9866\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],'k-*',label='train')\n",
    "plt.plot(history.history['val_loss'],'r-*', label='test')\n",
    "plt.legend()\n",
    "plt.title(\"GRU loss during training Covid19 and Sars\")\n",
    "#plt.savefig(\"LSTMLOSS_Covid19_Sars.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 10s 1ms/step - loss: 0.0357 - acc: 0.6459 - rmse: 0.1640 - mse: 0.0357 - r_square: 0.4811 - val_loss: 0.0167 - val_acc: 0.9357 - val_rmse: 0.1245 - val_mse: 0.0167 - val_r_square: 0.8782\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0179 - acc: 0.8035 - rmse: 0.1038 - mse: 0.0179 - r_square: 0.7637 - val_loss: 0.0088 - val_acc: 0.8365 - val_rmse: 0.0888 - val_mse: 0.0088 - val_r_square: 0.9395\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 349us/step - loss: 0.0135 - acc: 0.8675 - rmse: 0.0857 - mse: 0.0135 - r_square: 0.8217 - val_loss: 0.0037 - val_acc: 0.8365 - val_rmse: 0.0494 - val_mse: 0.0037 - val_r_square: 0.9766\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0089 - acc: 0.9097 - rmse: 0.0618 - mse: 0.0089 - r_square: 0.8798 - val_loss: 0.0029 - val_acc: 0.8365 - val_rmse: 0.0409 - val_mse: 0.0029 - val_r_square: 0.9815\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0073 - acc: 0.9359 - rmse: 0.0495 - mse: 0.0073 - r_square: 0.8996 - val_loss: 0.0023 - val_acc: 0.9383 - val_rmse: 0.0323 - val_mse: 0.0023 - val_r_square: 0.9859\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0066 - acc: 0.9391 - rmse: 0.0415 - mse: 0.0066 - r_square: 0.9117 - val_loss: 0.0021 - val_acc: 0.8535 - val_rmse: 0.0297 - val_mse: 0.0021 - val_r_square: 0.9874\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0063 - acc: 0.9419 - rmse: 0.0397 - mse: 0.0063 - r_square: 0.9162 - val_loss: 0.0020 - val_acc: 0.9411 - val_rmse: 0.0292 - val_mse: 0.0020 - val_r_square: 0.9877\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0061 - acc: 0.9449 - rmse: 0.0383 - mse: 0.0061 - r_square: 0.9194 - val_loss: 0.0020 - val_acc: 0.8823 - val_rmse: 0.0295 - val_mse: 0.0020 - val_r_square: 0.9878\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0060 - acc: 0.9466 - rmse: 0.0371 - mse: 0.0060 - r_square: 0.9217 - val_loss: 0.0020 - val_acc: 0.8827 - val_rmse: 0.0299 - val_mse: 0.0020 - val_r_square: 0.9878\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0058 - acc: 0.9486 - rmse: 0.0360 - mse: 0.0058 - r_square: 0.9235 - val_loss: 0.0019 - val_acc: 0.8824 - val_rmse: 0.0296 - val_mse: 0.0019 - val_r_square: 0.9881\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0057 - acc: 0.9503 - rmse: 0.0350 - mse: 0.0057 - r_square: 0.9250 - val_loss: 0.0019 - val_acc: 0.8944 - val_rmse: 0.0290 - val_mse: 0.0019 - val_r_square: 0.9883\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 344us/step - loss: 0.0056 - acc: 0.9512 - rmse: 0.0342 - mse: 0.0056 - r_square: 0.9263 - val_loss: 0.0018 - val_acc: 0.8828 - val_rmse: 0.0277 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0055 - acc: 0.9522 - rmse: 0.0336 - mse: 0.0055 - r_square: 0.9275 - val_loss: 0.0017 - val_acc: 0.8686 - val_rmse: 0.0267 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 3s 365us/step - loss: 0.0054 - acc: 0.9530 - rmse: 0.0332 - mse: 0.0054 - r_square: 0.9284 - val_loss: 0.0017 - val_acc: 0.8428 - val_rmse: 0.0263 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 3s 419us/step - loss: 0.0054 - acc: 0.9533 - rmse: 0.0332 - mse: 0.0054 - r_square: 0.9291 - val_loss: 0.0017 - val_acc: 0.8412 - val_rmse: 0.0268 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 3s 374us/step - loss: 0.0053 - acc: 0.9541 - rmse: 0.0331 - mse: 0.0053 - r_square: 0.9297 - val_loss: 0.0017 - val_acc: 0.8539 - val_rmse: 0.0272 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 3s 394us/step - loss: 0.0053 - acc: 0.9547 - rmse: 0.0329 - mse: 0.0053 - r_square: 0.9302 - val_loss: 0.0017 - val_acc: 0.8800 - val_rmse: 0.0274 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 4s 545us/step - loss: 0.0053 - acc: 0.9557 - rmse: 0.0328 - mse: 0.0053 - r_square: 0.9303 - val_loss: 0.0017 - val_acc: 0.8923 - val_rmse: 0.0262 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 4s 623us/step - loss: 0.0055 - acc: 0.9542 - rmse: 0.0334 - mse: 0.0055 - r_square: 0.9266 - val_loss: 0.0016 - val_acc: 0.8918 - val_rmse: 0.0248 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 341us/step - loss: 0.0052 - acc: 0.9564 - rmse: 0.0320 - mse: 0.0052 - r_square: 0.9303 - val_loss: 0.0015 - val_acc: 0.8400 - val_rmse: 0.0229 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0053 - acc: 0.9555 - rmse: 0.0321 - mse: 0.0053 - r_square: 0.9295 - val_loss: 0.0016 - val_acc: 0.8398 - val_rmse: 0.0240 - val_mse: 0.0016 - val_r_square: 0.9908\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 352us/step - loss: 0.0051 - acc: 0.9568 - rmse: 0.0318 - mse: 0.0051 - r_square: 0.9330 - val_loss: 0.0016 - val_acc: 0.8388 - val_rmse: 0.0248 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 4s 567us/step - loss: 0.0051 - acc: 0.9579 - rmse: 0.0324 - mse: 0.0051 - r_square: 0.9328 - val_loss: 0.0017 - val_acc: 0.8387 - val_rmse: 0.0263 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0051 - acc: 0.9523 - rmse: 0.0335 - mse: 0.0051 - r_square: 0.9324 - val_loss: 0.0017 - val_acc: 0.8388 - val_rmse: 0.0281 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 4s 615us/step - loss: 0.0052 - acc: 0.9477 - rmse: 0.0342 - mse: 0.0052 - r_square: 0.9320 - val_loss: 0.0018 - val_acc: 0.8902 - val_rmse: 0.0290 - val_mse: 0.0018 - val_r_square: 0.9887\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 4s 597us/step - loss: 0.0051 - acc: 0.9452 - rmse: 0.0337 - mse: 0.0051 - r_square: 0.9324 - val_loss: 0.0017 - val_acc: 0.9542 - val_rmse: 0.0272 - val_mse: 0.0017 - val_r_square: 0.9891\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 4s 558us/step - loss: 0.0050 - acc: 0.9545 - rmse: 0.0342 - mse: 0.0050 - r_square: 0.9329 - val_loss: 0.0015 - val_acc: 0.9154 - val_rmse: 0.0217 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 4s 607us/step - loss: 0.0050 - acc: 0.9563 - rmse: 0.0331 - mse: 0.0050 - r_square: 0.9346 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0244 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 4s 599us/step - loss: 0.0051 - acc: 0.9590 - rmse: 0.0342 - mse: 0.0051 - r_square: 0.9344 - val_loss: 0.0017 - val_acc: 0.8371 - val_rmse: 0.0231 - val_mse: 0.0017 - val_r_square: 0.9904\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 354us/step - loss: 0.0052 - acc: 0.9591 - rmse: 0.0367 - mse: 0.0052 - r_square: 0.9320 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0237 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0051 - acc: 0.9561 - rmse: 0.0351 - mse: 0.0051 - r_square: 0.9330 - val_loss: 0.0017 - val_acc: 0.8381 - val_rmse: 0.0274 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0053 - acc: 0.9504 - rmse: 0.0356 - mse: 0.0053 - r_square: 0.9294 - val_loss: 0.0016 - val_acc: 0.9414 - val_rmse: 0.0250 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 3s 377us/step - loss: 0.0052 - acc: 0.9508 - rmse: 0.0377 - mse: 0.0052 - r_square: 0.9321 - val_loss: 0.0018 - val_acc: 0.8377 - val_rmse: 0.0304 - val_mse: 0.0018 - val_r_square: 0.9885\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 343us/step - loss: 0.0052 - acc: 0.9482 - rmse: 0.0366 - mse: 0.0052 - r_square: 0.9337 - val_loss: 0.0015 - val_acc: 0.8369 - val_rmse: 0.0221 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 353us/step - loss: 0.0053 - acc: 0.9550 - rmse: 0.0383 - mse: 0.0053 - r_square: 0.9330 - val_loss: 0.0017 - val_acc: 0.8368 - val_rmse: 0.0243 - val_mse: 0.0017 - val_r_square: 0.9903\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 3s 400us/step - loss: 0.0051 - acc: 0.9561 - rmse: 0.0373 - mse: 0.0051 - r_square: 0.9341 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 3s 417us/step - loss: 0.0051 - acc: 0.9514 - rmse: 0.0360 - mse: 0.0051 - r_square: 0.9342 - val_loss: 0.0016 - val_acc: 0.8497 - val_rmse: 0.0249 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 3s 419us/step - loss: 0.0052 - acc: 0.9495 - rmse: 0.0382 - mse: 0.0052 - r_square: 0.9335 - val_loss: 0.0017 - val_acc: 0.8497 - val_rmse: 0.0275 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 3s 375us/step - loss: 0.0055 - acc: 0.9374 - rmse: 0.0426 - mse: 0.0055 - r_square: 0.9300 - val_loss: 0.0018 - val_acc: 0.8372 - val_rmse: 0.0292 - val_mse: 0.0018 - val_r_square: 0.9891\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 3s 373us/step - loss: 0.0056 - acc: 0.9445 - rmse: 0.0424 - mse: 0.0056 - r_square: 0.9304 - val_loss: 0.0021 - val_acc: 0.8495 - val_rmse: 0.0328 - val_mse: 0.0021 - val_r_square: 0.9875\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 356us/step - loss: 0.0056 - acc: 0.9338 - rmse: 0.0441 - mse: 0.0056 - r_square: 0.9284 - val_loss: 0.0022 - val_acc: 0.9675 - val_rmse: 0.0352 - val_mse: 0.0022 - val_r_square: 0.9862\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 3s 368us/step - loss: 0.0056 - acc: 0.9349 - rmse: 0.0439 - mse: 0.0056 - r_square: 0.9283 - val_loss: 0.0021 - val_acc: 0.9934 - val_rmse: 0.0344 - val_mse: 0.0021 - val_r_square: 0.9865\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0061 - acc: 0.9220 - rmse: 0.0488 - mse: 0.0061 - r_square: 0.9201 - val_loss: 0.0023 - val_acc: 0.9937 - val_rmse: 0.0365 - val_mse: 0.0023 - val_r_square: 0.9857\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 349us/step - loss: 0.0059 - acc: 0.9351 - rmse: 0.0484 - mse: 0.0059 - r_square: 0.9206 - val_loss: 0.0014 - val_acc: 0.9551 - val_rmse: 0.0185 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 3s 370us/step - loss: 0.0058 - acc: 0.9535 - rmse: 0.0450 - mse: 0.0058 - r_square: 0.9194 - val_loss: 0.0020 - val_acc: 0.8631 - val_rmse: 0.0318 - val_mse: 0.0020 - val_r_square: 0.9874\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0056 - acc: 0.9373 - rmse: 0.0450 - mse: 0.0056 - r_square: 0.9191 - val_loss: 0.0017 - val_acc: 0.8489 - val_rmse: 0.0279 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0054 - acc: 0.9550 - rmse: 0.0427 - mse: 0.0054 - r_square: 0.9227 - val_loss: 0.0015 - val_acc: 0.8368 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0050 - acc: 0.9629 - rmse: 0.0354 - mse: 0.0050 - r_square: 0.9315 - val_loss: 0.0014 - val_acc: 0.8633 - val_rmse: 0.0213 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0049 - acc: 0.9612 - rmse: 0.0322 - mse: 0.0049 - r_square: 0.9349 - val_loss: 0.0015 - val_acc: 0.8767 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 3s 361us/step - loss: 0.0048 - acc: 0.9583 - rmse: 0.0310 - mse: 0.0048 - r_square: 0.9368 - val_loss: 0.0015 - val_acc: 0.9142 - val_rmse: 0.0226 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 3s 474us/step - loss: 0.0047 - acc: 0.9593 - rmse: 0.0303 - mse: 0.0047 - r_square: 0.9373 - val_loss: 0.0015 - val_acc: 0.9267 - val_rmse: 0.0220 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 3s 489us/step - loss: 0.0048 - acc: 0.9579 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9374 - val_loss: 0.0014 - val_acc: 0.9407 - val_rmse: 0.0211 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 3s 387us/step - loss: 0.0047 - acc: 0.9583 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9379 - val_loss: 0.0015 - val_acc: 0.9404 - val_rmse: 0.0227 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 355us/step - loss: 0.0048 - acc: 0.9577 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9373 - val_loss: 0.0015 - val_acc: 0.9417 - val_rmse: 0.0227 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 337us/step - loss: 0.0047 - acc: 0.9581 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9385 - val_loss: 0.0015 - val_acc: 0.9413 - val_rmse: 0.0225 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 346us/step - loss: 0.0047 - acc: 0.9574 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9388 - val_loss: 0.0014 - val_acc: 0.9414 - val_rmse: 0.0214 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 357us/step - loss: 0.0047 - acc: 0.9570 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0015 - val_acc: 0.9413 - val_rmse: 0.0218 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0047 - acc: 0.9560 - rmse: 0.0290 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0015 - val_acc: 0.9414 - val_rmse: 0.0221 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0047 - acc: 0.9570 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0015 - val_acc: 0.9414 - val_rmse: 0.0227 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0047 - acc: 0.9557 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9390 - val_loss: 0.0015 - val_acc: 0.9416 - val_rmse: 0.0220 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 347us/step - loss: 0.0047 - acc: 0.9570 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9390 - val_loss: 0.0015 - val_acc: 0.9416 - val_rmse: 0.0218 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 349us/step - loss: 0.0047 - acc: 0.9552 - rmse: 0.0291 - mse: 0.0047 - r_square: 0.9387 - val_loss: 0.0014 - val_acc: 0.9417 - val_rmse: 0.0215 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0047 - acc: 0.9562 - rmse: 0.0287 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0015 - val_acc: 0.9414 - val_rmse: 0.0225 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0047 - acc: 0.9551 - rmse: 0.0291 - mse: 0.0047 - r_square: 0.9388 - val_loss: 0.0015 - val_acc: 0.9420 - val_rmse: 0.0225 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0046 - acc: 0.9558 - rmse: 0.0288 - mse: 0.0046 - r_square: 0.9392 - val_loss: 0.0015 - val_acc: 0.9417 - val_rmse: 0.0226 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0047 - acc: 0.9549 - rmse: 0.0291 - mse: 0.0047 - r_square: 0.9393 - val_loss: 0.0014 - val_acc: 0.9541 - val_rmse: 0.0214 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0046 - acc: 0.9556 - rmse: 0.0286 - mse: 0.0046 - r_square: 0.9396 - val_loss: 0.0015 - val_acc: 0.9414 - val_rmse: 0.0217 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0047 - acc: 0.9545 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9394 - val_loss: 0.0014 - val_acc: 0.9518 - val_rmse: 0.0216 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0046 - acc: 0.9557 - rmse: 0.0287 - mse: 0.0046 - r_square: 0.9394 - val_loss: 0.0015 - val_acc: 0.9416 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0047 - acc: 0.9545 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9390 - val_loss: 0.0015 - val_acc: 0.9548 - val_rmse: 0.0226 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0047 - acc: 0.9554 - rmse: 0.0291 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0015 - val_acc: 0.9548 - val_rmse: 0.0223 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0047 - acc: 0.9544 - rmse: 0.0296 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0014 - val_acc: 0.9547 - val_rmse: 0.0205 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0047 - acc: 0.9550 - rmse: 0.0288 - mse: 0.0047 - r_square: 0.9395 - val_loss: 0.0014 - val_acc: 0.9521 - val_rmse: 0.0216 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0047 - acc: 0.9538 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9393 - val_loss: 0.0015 - val_acc: 0.9532 - val_rmse: 0.0223 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0047 - acc: 0.9545 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0016 - val_acc: 0.9666 - val_rmse: 0.0251 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0047 - acc: 0.9538 - rmse: 0.0305 - mse: 0.0047 - r_square: 0.9386 - val_loss: 0.0015 - val_acc: 0.9676 - val_rmse: 0.0230 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0047 - acc: 0.9550 - rmse: 0.0299 - mse: 0.0047 - r_square: 0.9388 - val_loss: 0.0015 - val_acc: 0.9675 - val_rmse: 0.0213 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0047 - acc: 0.9539 - rmse: 0.0306 - mse: 0.0047 - r_square: 0.9388 - val_loss: 0.0014 - val_acc: 0.9541 - val_rmse: 0.0200 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 359us/step - loss: 0.0047 - acc: 0.9544 - rmse: 0.0298 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0014 - val_acc: 0.9404 - val_rmse: 0.0219 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 3s 387us/step - loss: 0.0047 - acc: 0.9535 - rmse: 0.0305 - mse: 0.0047 - r_square: 0.9388 - val_loss: 0.0016 - val_acc: 0.9532 - val_rmse: 0.0252 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0047 - acc: 0.9545 - rmse: 0.0306 - mse: 0.0047 - r_square: 0.9380 - val_loss: 0.0018 - val_acc: 0.9799 - val_rmse: 0.0277 - val_mse: 0.0018 - val_r_square: 0.9888\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 3s 374us/step - loss: 0.0048 - acc: 0.9538 - rmse: 0.0333 - mse: 0.0048 - r_square: 0.9370 - val_loss: 0.0015 - val_acc: 0.9794 - val_rmse: 0.0228 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 352us/step - loss: 0.0047 - acc: 0.9549 - rmse: 0.0314 - mse: 0.0047 - r_square: 0.9381 - val_loss: 0.0014 - val_acc: 0.9672 - val_rmse: 0.0198 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 3s 392us/step - loss: 0.0049 - acc: 0.9532 - rmse: 0.0332 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0014 - val_acc: 0.9280 - val_rmse: 0.0196 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9547 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9377 - val_loss: 0.0017 - val_acc: 0.9014 - val_rmse: 0.0288 - val_mse: 0.0017 - val_r_square: 0.9889\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 3s 364us/step - loss: 0.0048 - acc: 0.9536 - rmse: 0.0337 - mse: 0.0048 - r_square: 0.9360 - val_loss: 0.0019 - val_acc: 0.9796 - val_rmse: 0.0299 - val_mse: 0.0019 - val_r_square: 0.9879\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 3s 407us/step - loss: 0.0049 - acc: 0.9549 - rmse: 0.0354 - mse: 0.0049 - r_square: 0.9347 - val_loss: 0.0015 - val_acc: 0.9679 - val_rmse: 0.0229 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 340us/step - loss: 0.0049 - acc: 0.9511 - rmse: 0.0344 - mse: 0.0049 - r_square: 0.9362 - val_loss: 0.0014 - val_acc: 0.9672 - val_rmse: 0.0199 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 3s 399us/step - loss: 0.0050 - acc: 0.9556 - rmse: 0.0341 - mse: 0.0050 - r_square: 0.9366 - val_loss: 0.0015 - val_acc: 0.8889 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 351us/step - loss: 0.0048 - acc: 0.9532 - rmse: 0.0317 - mse: 0.0048 - r_square: 0.9383 - val_loss: 0.0018 - val_acc: 0.9535 - val_rmse: 0.0291 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 3s 361us/step - loss: 0.0047 - acc: 0.9555 - rmse: 0.0333 - mse: 0.0047 - r_square: 0.9371 - val_loss: 0.0016 - val_acc: 0.9793 - val_rmse: 0.0252 - val_mse: 0.0016 - val_r_square: 0.9898\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 359us/step - loss: 0.0047 - acc: 0.9541 - rmse: 0.0327 - mse: 0.0047 - r_square: 0.9378 - val_loss: 0.0014 - val_acc: 0.9670 - val_rmse: 0.0195 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 358us/step - loss: 0.0048 - acc: 0.9558 - rmse: 0.0324 - mse: 0.0048 - r_square: 0.9381 - val_loss: 0.0014 - val_acc: 0.9165 - val_rmse: 0.0216 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0048 - acc: 0.9540 - rmse: 0.0311 - mse: 0.0048 - r_square: 0.9385 - val_loss: 0.0015 - val_acc: 0.9528 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 3s 363us/step - loss: 0.0048 - acc: 0.9537 - rmse: 0.0317 - mse: 0.0048 - r_square: 0.9377 - val_loss: 0.0016 - val_acc: 0.9675 - val_rmse: 0.0256 - val_mse: 0.0016 - val_r_square: 0.9898\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 3s 388us/step - loss: 0.0048 - acc: 0.9553 - rmse: 0.0323 - mse: 0.0048 - r_square: 0.9372 - val_loss: 0.0014 - val_acc: 0.9672 - val_rmse: 0.0213 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 342us/step - loss: 0.0047 - acc: 0.9553 - rmse: 0.0318 - mse: 0.0047 - r_square: 0.9385 - val_loss: 0.0014 - val_acc: 0.9535 - val_rmse: 0.0209 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 358us/step - loss: 0.0047 - acc: 0.9538 - rmse: 0.0312 - mse: 0.0047 - r_square: 0.9391 - val_loss: 0.0015 - val_acc: 0.9531 - val_rmse: 0.0233 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0048 - acc: 0.9539 - rmse: 0.0319 - mse: 0.0048 - r_square: 0.9384 - val_loss: 0.0016 - val_acc: 0.9660 - val_rmse: 0.0249 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 356us/step - loss: 0.0048 - acc: 0.9534 - rmse: 0.0321 - mse: 0.0048 - r_square: 0.9376 - val_loss: 0.0015 - val_acc: 0.9670 - val_rmse: 0.0231 - val_mse: 0.0015 - val_r_square: 0.9908\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],'k-*',label='train')\n",
    "plt.plot(history.history['val_loss'],'r-*', label='test')\n",
    "plt.legend()\n",
    "plt.title(\"GRU loss during training Covid19 and Sars\")\n",
    "#plt.savefig(\"LSTMLOSS_Covid19_Sars.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deathrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed_x',\n",
       "       'Deaths', 'Recovered', 'Confirmed_y', 'Country', 'Region', 'Population',\n",
       "       'Area (sq. mi.)', 'Pop. Density (per sq. mi.)',\n",
       "       'Coastline (coast/area ratio)', 'Net migration',\n",
       "       'Infant mortality (per 1000 births)', 'GDP ($ per capita)',\n",
       "       'Literacy (%)', 'Phones (per 1000)', 'Arable (%)', 'Crops (%)',\n",
       "       'Climate', 'Birthrate', 'Deathrate', 'Agriculture', 'Industry',\n",
       "       'Service', 'Month', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['Outbreak','Country/Region', 'Deathrate','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 8s 1ms/step - loss: 0.0465 - acc: 0.7278 - rmse: 0.1816 - mse: 0.0465 - r_square: 0.3195 - val_loss: 0.0233 - val_acc: 0.8365 - val_rmse: 0.1342 - val_mse: 0.0233 - val_r_square: 0.8382\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0309 - acc: 0.7264 - rmse: 0.1436 - mse: 0.0309 - r_square: 0.5718 - val_loss: 0.0205 - val_acc: 0.8365 - val_rmse: 0.1353 - val_mse: 0.0205 - val_r_square: 0.8567\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0242 - acc: 0.7404 - rmse: 0.1257 - mse: 0.0242 - r_square: 0.6706 - val_loss: 0.0167 - val_acc: 0.8365 - val_rmse: 0.1222 - val_mse: 0.0167 - val_r_square: 0.8835\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0178 - acc: 0.8760 - rmse: 0.1040 - mse: 0.0178 - r_square: 0.7562 - val_loss: 0.0109 - val_acc: 0.8365 - val_rmse: 0.0974 - val_mse: 0.0109 - val_r_square: 0.9244\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 359us/step - loss: 0.0128 - acc: 0.8878 - rmse: 0.0813 - mse: 0.0128 - r_square: 0.8240 - val_loss: 0.0067 - val_acc: 0.8365 - val_rmse: 0.0744 - val_mse: 0.0067 - val_r_square: 0.9547\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0102 - acc: 0.9139 - rmse: 0.0694 - mse: 0.0102 - r_square: 0.8534 - val_loss: 0.0049 - val_acc: 0.8365 - val_rmse: 0.0580 - val_mse: 0.0049 - val_r_square: 0.9672\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0087 - acc: 0.9261 - rmse: 0.0601 - mse: 0.0087 - r_square: 0.8765 - val_loss: 0.0038 - val_acc: 0.8365 - val_rmse: 0.0488 - val_mse: 0.0038 - val_r_square: 0.9755\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0083 - acc: 0.9270 - rmse: 0.0582 - mse: 0.0083 - r_square: 0.8835 - val_loss: 0.0037 - val_acc: 0.8371 - val_rmse: 0.0484 - val_mse: 0.0037 - val_r_square: 0.9764\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0087 - acc: 0.9214 - rmse: 0.0629 - mse: 0.0087 - r_square: 0.8743 - val_loss: 0.0047 - val_acc: 0.9442 - val_rmse: 0.0605 - val_mse: 0.0047 - val_r_square: 0.9677\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0073 - acc: 0.9357 - rmse: 0.0499 - mse: 0.0073 - r_square: 0.8984 - val_loss: 0.0023 - val_acc: 0.8408 - val_rmse: 0.0346 - val_mse: 0.0023 - val_r_square: 0.9858\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0070 - acc: 0.9402 - rmse: 0.0487 - mse: 0.0070 - r_square: 0.9034 - val_loss: 0.0022 - val_acc: 0.8381 - val_rmse: 0.0314 - val_mse: 0.0022 - val_r_square: 0.9870\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 343us/step - loss: 0.0068 - acc: 0.9356 - rmse: 0.0473 - mse: 0.0068 - r_square: 0.9055 - val_loss: 0.0025 - val_acc: 0.8374 - val_rmse: 0.0365 - val_mse: 0.0025 - val_r_square: 0.9850\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0067 - acc: 0.9368 - rmse: 0.0478 - mse: 0.0067 - r_square: 0.9076 - val_loss: 0.0025 - val_acc: 0.8391 - val_rmse: 0.0392 - val_mse: 0.0025 - val_r_square: 0.9841\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 3s 373us/step - loss: 0.0065 - acc: 0.9363 - rmse: 0.0454 - mse: 0.0065 - r_square: 0.9124 - val_loss: 0.0021 - val_acc: 0.8375 - val_rmse: 0.0329 - val_mse: 0.0021 - val_r_square: 0.9872\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 3s 362us/step - loss: 0.0065 - acc: 0.9455 - rmse: 0.0453 - mse: 0.0065 - r_square: 0.9147 - val_loss: 0.0027 - val_acc: 0.8368 - val_rmse: 0.0392 - val_mse: 0.0027 - val_r_square: 0.9837\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 358us/step - loss: 0.0066 - acc: 0.9420 - rmse: 0.0469 - mse: 0.0066 - r_square: 0.9148 - val_loss: 0.0038 - val_acc: 0.8365 - val_rmse: 0.0507 - val_mse: 0.0038 - val_r_square: 0.9767\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 3s 374us/step - loss: 0.0067 - acc: 0.9381 - rmse: 0.0491 - mse: 0.0067 - r_square: 0.9130 - val_loss: 0.0040 - val_acc: 0.8371 - val_rmse: 0.0548 - val_mse: 0.0040 - val_r_square: 0.9743\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0070 - acc: 0.9290 - rmse: 0.0534 - mse: 0.0070 - r_square: 0.9083 - val_loss: 0.0053 - val_acc: 0.8402 - val_rmse: 0.0668 - val_mse: 0.0053 - val_r_square: 0.9637\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0078 - acc: 0.8981 - rmse: 0.0602 - mse: 0.0078 - r_square: 0.8988 - val_loss: 0.0054 - val_acc: 0.8788 - val_rmse: 0.0667 - val_mse: 0.0054 - val_r_square: 0.9622\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0083 - acc: 0.8681 - rmse: 0.0638 - mse: 0.0083 - r_square: 0.8938 - val_loss: 0.0035 - val_acc: 0.9521 - val_rmse: 0.0511 - val_mse: 0.0035 - val_r_square: 0.9764\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 348us/step - loss: 0.0084 - acc: 0.9106 - rmse: 0.0667 - mse: 0.0084 - r_square: 0.8810 - val_loss: 0.0025 - val_acc: 0.8492 - val_rmse: 0.0384 - val_mse: 0.0025 - val_r_square: 0.9841\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 3s 414us/step - loss: 0.0077 - acc: 0.9268 - rmse: 0.0610 - mse: 0.0077 - r_square: 0.8933 - val_loss: 0.0029 - val_acc: 0.9265 - val_rmse: 0.0444 - val_mse: 0.0029 - val_r_square: 0.9811\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0068 - acc: 0.9048 - rmse: 0.0525 - mse: 0.0068 - r_square: 0.9106 - val_loss: 0.0021 - val_acc: 0.9423 - val_rmse: 0.0335 - val_mse: 0.0021 - val_r_square: 0.9869\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0066 - acc: 0.9115 - rmse: 0.0508 - mse: 0.0066 - r_square: 0.9140 - val_loss: 0.0017 - val_acc: 0.8507 - val_rmse: 0.0258 - val_mse: 0.0017 - val_r_square: 0.9901\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0063 - acc: 0.9170 - rmse: 0.0476 - mse: 0.0063 - r_square: 0.9169 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0275 - val_mse: 0.0018 - val_r_square: 0.9895\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0061 - acc: 0.9176 - rmse: 0.0457 - mse: 0.0061 - r_square: 0.9189 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0274 - val_mse: 0.0018 - val_r_square: 0.9895\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 337us/step - loss: 0.0058 - acc: 0.9178 - rmse: 0.0420 - mse: 0.0058 - r_square: 0.9218 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0235 - val_mse: 0.0016 - val_r_square: 0.9908\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0057 - acc: 0.9311 - rmse: 0.0398 - mse: 0.0057 - r_square: 0.9224 - val_loss: 0.0014 - val_acc: 0.8374 - val_rmse: 0.0202 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 349us/step - loss: 0.0057 - acc: 0.9342 - rmse: 0.0381 - mse: 0.0057 - r_square: 0.9222 - val_loss: 0.0014 - val_acc: 0.8379 - val_rmse: 0.0219 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0054 - acc: 0.9535 - rmse: 0.0362 - mse: 0.0054 - r_square: 0.9289 - val_loss: 0.0015 - val_acc: 0.8394 - val_rmse: 0.0228 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0052 - acc: 0.9460 - rmse: 0.0346 - mse: 0.0052 - r_square: 0.9320 - val_loss: 0.0015 - val_acc: 0.8644 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0052 - acc: 0.9517 - rmse: 0.0343 - mse: 0.0052 - r_square: 0.9322 - val_loss: 0.0015 - val_acc: 0.8772 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 3s 374us/step - loss: 0.0051 - acc: 0.9479 - rmse: 0.0335 - mse: 0.0051 - r_square: 0.9335 - val_loss: 0.0015 - val_acc: 0.8898 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 3s 366us/step - loss: 0.0051 - acc: 0.9524 - rmse: 0.0331 - mse: 0.0051 - r_square: 0.9342 - val_loss: 0.0015 - val_acc: 0.9027 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 3s 379us/step - loss: 0.0050 - acc: 0.9481 - rmse: 0.0327 - mse: 0.0050 - r_square: 0.9348 - val_loss: 0.0015 - val_acc: 0.9276 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0050 - acc: 0.9508 - rmse: 0.0324 - mse: 0.0050 - r_square: 0.9354 - val_loss: 0.0016 - val_acc: 0.9406 - val_rmse: 0.0245 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0050 - acc: 0.9508 - rmse: 0.0322 - mse: 0.0050 - r_square: 0.9358 - val_loss: 0.0016 - val_acc: 0.9413 - val_rmse: 0.0246 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 353us/step - loss: 0.0050 - acc: 0.9505 - rmse: 0.0324 - mse: 0.0050 - r_square: 0.9353 - val_loss: 0.0016 - val_acc: 0.9417 - val_rmse: 0.0252 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0051 - acc: 0.9536 - rmse: 0.0325 - mse: 0.0051 - r_square: 0.9335 - val_loss: 0.0016 - val_acc: 0.9410 - val_rmse: 0.0249 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0053 - acc: 0.9469 - rmse: 0.0336 - mse: 0.0053 - r_square: 0.9273 - val_loss: 0.0016 - val_acc: 0.9539 - val_rmse: 0.0254 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0051 - acc: 0.9564 - rmse: 0.0337 - mse: 0.0051 - r_square: 0.9347 - val_loss: 0.0016 - val_acc: 0.9420 - val_rmse: 0.0260 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0050 - acc: 0.9500 - rmse: 0.0326 - mse: 0.0050 - r_square: 0.9356 - val_loss: 0.0016 - val_acc: 0.9544 - val_rmse: 0.0258 - val_mse: 0.0016 - val_r_square: 0.9898\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0050 - acc: 0.9528 - rmse: 0.0323 - mse: 0.0050 - r_square: 0.9365 - val_loss: 0.0017 - val_acc: 0.9657 - val_rmse: 0.0266 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0050 - acc: 0.9530 - rmse: 0.0327 - mse: 0.0050 - r_square: 0.9362 - val_loss: 0.0017 - val_acc: 0.9657 - val_rmse: 0.0271 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 351us/step - loss: 0.0049 - acc: 0.9527 - rmse: 0.0323 - mse: 0.0049 - r_square: 0.9371 - val_loss: 0.0017 - val_acc: 0.9659 - val_rmse: 0.0268 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0049 - acc: 0.9530 - rmse: 0.0325 - mse: 0.0049 - r_square: 0.9373 - val_loss: 0.0017 - val_acc: 0.9659 - val_rmse: 0.0267 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0049 - acc: 0.9507 - rmse: 0.0322 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0017 - val_acc: 0.9780 - val_rmse: 0.0275 - val_mse: 0.0017 - val_r_square: 0.9890\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9529 - rmse: 0.0325 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0017 - val_acc: 0.9893 - val_rmse: 0.0273 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0049 - acc: 0.9531 - rmse: 0.0331 - mse: 0.0049 - r_square: 0.9372 - val_loss: 0.0018 - val_acc: 0.9899 - val_rmse: 0.0280 - val_mse: 0.0018 - val_r_square: 0.9888\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0050 - acc: 0.9503 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9362 - val_loss: 0.0017 - val_acc: 0.9896 - val_rmse: 0.0275 - val_mse: 0.0017 - val_r_square: 0.9890\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 348us/step - loss: 0.0052 - acc: 0.9533 - rmse: 0.0344 - mse: 0.0052 - r_square: 0.9327 - val_loss: 0.0018 - val_acc: 0.9551 - val_rmse: 0.0281 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0054 - acc: 0.9433 - rmse: 0.0371 - mse: 0.0054 - r_square: 0.9242 - val_loss: 0.0017 - val_acc: 0.9781 - val_rmse: 0.0264 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0050 - acc: 0.9521 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9362 - val_loss: 0.0017 - val_acc: 0.9904 - val_rmse: 0.0265 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 3s 412us/step - loss: 0.0049 - acc: 0.9498 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9364 - val_loss: 0.0017 - val_acc: 0.9908 - val_rmse: 0.0268 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 358us/step - loss: 0.0049 - acc: 0.9520 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9370 - val_loss: 0.0017 - val_acc: 0.9901 - val_rmse: 0.0264 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0049 - acc: 0.9544 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0017 - val_acc: 0.9893 - val_rmse: 0.0260 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0049 - acc: 0.9499 - rmse: 0.0324 - mse: 0.0049 - r_square: 0.9379 - val_loss: 0.0017 - val_acc: 0.9898 - val_rmse: 0.0257 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0049 - acc: 0.9524 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9376 - val_loss: 0.0017 - val_acc: 0.9906 - val_rmse: 0.0260 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0049 - acc: 0.9521 - rmse: 0.0325 - mse: 0.0049 - r_square: 0.9380 - val_loss: 0.0016 - val_acc: 0.9902 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9898\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0049 - acc: 0.9550 - rmse: 0.0327 - mse: 0.0049 - r_square: 0.9376 - val_loss: 0.0016 - val_acc: 0.9899 - val_rmse: 0.0253 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0049 - acc: 0.9519 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9370 - val_loss: 0.0016 - val_acc: 0.9896 - val_rmse: 0.0248 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0049 - acc: 0.9529 - rmse: 0.0331 - mse: 0.0049 - r_square: 0.9365 - val_loss: 0.0016 - val_acc: 0.9786 - val_rmse: 0.0246 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0049 - acc: 0.9498 - rmse: 0.0329 - mse: 0.0049 - r_square: 0.9364 - val_loss: 0.0016 - val_acc: 0.9896 - val_rmse: 0.0244 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0049 - acc: 0.9532 - rmse: 0.0326 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0016 - val_acc: 0.9787 - val_rmse: 0.0244 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9528 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9379 - val_loss: 0.0015 - val_acc: 0.9670 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 3s 411us/step - loss: 0.0048 - acc: 0.9554 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9380 - val_loss: 0.0016 - val_acc: 0.9670 - val_rmse: 0.0241 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0048 - acc: 0.9529 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9380 - val_loss: 0.0015 - val_acc: 0.9666 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0048 - acc: 0.9534 - rmse: 0.0327 - mse: 0.0048 - r_square: 0.9379 - val_loss: 0.0015 - val_acc: 0.9647 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0049 - acc: 0.9506 - rmse: 0.0331 - mse: 0.0049 - r_square: 0.9370 - val_loss: 0.0015 - val_acc: 0.9665 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 3s 388us/step - loss: 0.0049 - acc: 0.9538 - rmse: 0.0330 - mse: 0.0049 - r_square: 0.9364 - val_loss: 0.0015 - val_acc: 0.9551 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0050 - acc: 0.9507 - rmse: 0.0339 - mse: 0.0050 - r_square: 0.9349 - val_loss: 0.0015 - val_acc: 0.9551 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0049 - acc: 0.9517 - rmse: 0.0334 - mse: 0.0049 - r_square: 0.9371 - val_loss: 0.0015 - val_acc: 0.9550 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0049 - acc: 0.9516 - rmse: 0.0335 - mse: 0.0049 - r_square: 0.9371 - val_loss: 0.0015 - val_acc: 0.9547 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9513 - rmse: 0.0335 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0015 - val_acc: 0.9547 - val_rmse: 0.0244 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0049 - acc: 0.9540 - rmse: 0.0341 - mse: 0.0049 - r_square: 0.9368 - val_loss: 0.0015 - val_acc: 0.9512 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 348us/step - loss: 0.0049 - acc: 0.9511 - rmse: 0.0339 - mse: 0.0049 - r_square: 0.9370 - val_loss: 0.0015 - val_acc: 0.9421 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0049 - acc: 0.9513 - rmse: 0.0351 - mse: 0.0049 - r_square: 0.9351 - val_loss: 0.0015 - val_acc: 0.9397 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0050 - acc: 0.9510 - rmse: 0.0350 - mse: 0.0050 - r_square: 0.9345 - val_loss: 0.0016 - val_acc: 0.8906 - val_rmse: 0.0250 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0051 - acc: 0.9494 - rmse: 0.0362 - mse: 0.0051 - r_square: 0.9326 - val_loss: 0.0016 - val_acc: 0.8923 - val_rmse: 0.0249 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0050 - acc: 0.9513 - rmse: 0.0355 - mse: 0.0050 - r_square: 0.9354 - val_loss: 0.0016 - val_acc: 0.8903 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0050 - acc: 0.9495 - rmse: 0.0358 - mse: 0.0050 - r_square: 0.9355 - val_loss: 0.0016 - val_acc: 0.8856 - val_rmse: 0.0256 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9503 - rmse: 0.0363 - mse: 0.0050 - r_square: 0.9354 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0260 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0050 - acc: 0.9478 - rmse: 0.0367 - mse: 0.0050 - r_square: 0.9349 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0265 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0051 - acc: 0.9475 - rmse: 0.0377 - mse: 0.0051 - r_square: 0.9326 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0260 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0052 - acc: 0.9432 - rmse: 0.0380 - mse: 0.0052 - r_square: 0.9321 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0263 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0052 - acc: 0.9388 - rmse: 0.0386 - mse: 0.0052 - r_square: 0.9313 - val_loss: 0.0016 - val_acc: 0.8372 - val_rmse: 0.0260 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 277us/step - loss: 0.0052 - acc: 0.9278 - rmse: 0.0386 - mse: 0.0052 - r_square: 0.9330 - val_loss: 0.0016 - val_acc: 0.8369 - val_rmse: 0.0260 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0051 - acc: 0.9309 - rmse: 0.0382 - mse: 0.0051 - r_square: 0.9342 - val_loss: 0.0016 - val_acc: 0.8368 - val_rmse: 0.0256 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 251us/step - loss: 0.0051 - acc: 0.9286 - rmse: 0.0387 - mse: 0.0051 - r_square: 0.9333 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0252 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 248us/step - loss: 0.0051 - acc: 0.9286 - rmse: 0.0382 - mse: 0.0051 - r_square: 0.9336 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 248us/step - loss: 0.0053 - acc: 0.9311 - rmse: 0.0393 - mse: 0.0053 - r_square: 0.9304 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0226 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 252us/step - loss: 0.0053 - acc: 0.9346 - rmse: 0.0389 - mse: 0.0053 - r_square: 0.9312 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0227 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 250us/step - loss: 0.0053 - acc: 0.9340 - rmse: 0.0396 - mse: 0.0053 - r_square: 0.9310 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0054 - acc: 0.9397 - rmse: 0.0405 - mse: 0.0054 - r_square: 0.9306 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0260 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0056 - acc: 0.9491 - rmse: 0.0430 - mse: 0.0056 - r_square: 0.9274 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0292 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 253us/step - loss: 0.0059 - acc: 0.9567 - rmse: 0.0459 - mse: 0.0059 - r_square: 0.9238 - val_loss: 0.0022 - val_acc: 0.8365 - val_rmse: 0.0359 - val_mse: 0.0022 - val_r_square: 0.9862\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0062 - acc: 0.9623 - rmse: 0.0485 - mse: 0.0062 - r_square: 0.9190 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0293 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0058 - acc: 0.9594 - rmse: 0.0455 - mse: 0.0058 - r_square: 0.9248 - val_loss: 0.0020 - val_acc: 0.8365 - val_rmse: 0.0339 - val_mse: 0.0020 - val_r_square: 0.9872\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 249us/step - loss: 0.0056 - acc: 0.9615 - rmse: 0.0436 - mse: 0.0056 - r_square: 0.9282 - val_loss: 0.0022 - val_acc: 0.8365 - val_rmse: 0.0369 - val_mse: 0.0022 - val_r_square: 0.9857\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 250us/step - loss: 0.0068 - acc: 0.9619 - rmse: 0.0529 - mse: 0.0068 - r_square: 0.9152 - val_loss: 0.0027 - val_acc: 0.8365 - val_rmse: 0.0423 - val_mse: 0.0027 - val_r_square: 0.9828\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, Activation, TimeDistributed, Dropout, Lambda, RepeatVector, Input, Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD,Adam\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],'k-*',label='train')\n",
    "plt.plot(history.history['val_loss'],'r-*', label='test')\n",
    "plt.legend()\n",
    "plt.title(\"GRU loss during training Covid19 and Sars\")\n",
    "#plt.savefig(\"LSTMLOSS_Covid19_Sars.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 9s 1ms/step - loss: 0.0269 - acc: 0.7440 - rmse: 0.1394 - mse: 0.0269 - r_square: 0.5291 - val_loss: 0.0058 - val_acc: 0.8365 - val_rmse: 0.0666 - val_mse: 0.0058 - val_r_square: 0.9621\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0159 - acc: 0.7590 - rmse: 0.0979 - mse: 0.0159 - r_square: 0.7610 - val_loss: 0.0065 - val_acc: 0.8365 - val_rmse: 0.0746 - val_mse: 0.0065 - val_r_square: 0.9556\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0102 - acc: 0.8666 - rmse: 0.0667 - mse: 0.0102 - r_square: 0.8621 - val_loss: 0.0031 - val_acc: 0.8365 - val_rmse: 0.0441 - val_mse: 0.0031 - val_r_square: 0.9804\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0077 - acc: 0.9139 - rmse: 0.0553 - mse: 0.0077 - r_square: 0.8963 - val_loss: 0.0024 - val_acc: 0.8365 - val_rmse: 0.0353 - val_mse: 0.0024 - val_r_square: 0.9854\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0070 - acc: 0.9255 - rmse: 0.0460 - mse: 0.0070 - r_square: 0.9080 - val_loss: 0.0021 - val_acc: 0.8365 - val_rmse: 0.0313 - val_mse: 0.0021 - val_r_square: 0.9871\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 3s 416us/step - loss: 0.0063 - acc: 0.9385 - rmse: 0.0403 - mse: 0.0063 - r_square: 0.9179 - val_loss: 0.0018 - val_acc: 0.8381 - val_rmse: 0.0262 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 352us/step - loss: 0.0062 - acc: 0.9328 - rmse: 0.0387 - mse: 0.0062 - r_square: 0.9200 - val_loss: 0.0018 - val_acc: 0.8414 - val_rmse: 0.0263 - val_mse: 0.0018 - val_r_square: 0.9894\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 3s 386us/step - loss: 0.0059 - acc: 0.9437 - rmse: 0.0368 - mse: 0.0059 - r_square: 0.9225 - val_loss: 0.0017 - val_acc: 0.8448 - val_rmse: 0.0266 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 346us/step - loss: 0.0058 - acc: 0.9445 - rmse: 0.0358 - mse: 0.0058 - r_square: 0.9251 - val_loss: 0.0016 - val_acc: 0.8437 - val_rmse: 0.0243 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 352us/step - loss: 0.0057 - acc: 0.9464 - rmse: 0.0354 - mse: 0.0057 - r_square: 0.9252 - val_loss: 0.0016 - val_acc: 0.8438 - val_rmse: 0.0243 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 347us/step - loss: 0.0056 - acc: 0.9473 - rmse: 0.0348 - mse: 0.0056 - r_square: 0.9269 - val_loss: 0.0016 - val_acc: 0.8577 - val_rmse: 0.0251 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 354us/step - loss: 0.0055 - acc: 0.9488 - rmse: 0.0340 - mse: 0.0055 - r_square: 0.9283 - val_loss: 0.0016 - val_acc: 0.8705 - val_rmse: 0.0242 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 359us/step - loss: 0.0054 - acc: 0.9457 - rmse: 0.0332 - mse: 0.0054 - r_square: 0.9298 - val_loss: 0.0015 - val_acc: 0.8687 - val_rmse: 0.0223 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 340us/step - loss: 0.0053 - acc: 0.9504 - rmse: 0.0330 - mse: 0.0053 - r_square: 0.9302 - val_loss: 0.0014 - val_acc: 0.8641 - val_rmse: 0.0213 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 341us/step - loss: 0.0054 - acc: 0.9513 - rmse: 0.0333 - mse: 0.0054 - r_square: 0.9282 - val_loss: 0.0014 - val_acc: 0.8412 - val_rmse: 0.0206 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0054 - acc: 0.9512 - rmse: 0.0338 - mse: 0.0054 - r_square: 0.9279 - val_loss: 0.0014 - val_acc: 0.8408 - val_rmse: 0.0207 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0055 - acc: 0.9471 - rmse: 0.0338 - mse: 0.0055 - r_square: 0.9248 - val_loss: 0.0014 - val_acc: 0.8400 - val_rmse: 0.0218 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0053 - acc: 0.9489 - rmse: 0.0348 - mse: 0.0053 - r_square: 0.9303 - val_loss: 0.0015 - val_acc: 0.8397 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0052 - acc: 0.9488 - rmse: 0.0337 - mse: 0.0052 - r_square: 0.9322 - val_loss: 0.0015 - val_acc: 0.8398 - val_rmse: 0.0229 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0052 - acc: 0.9485 - rmse: 0.0336 - mse: 0.0052 - r_square: 0.9322 - val_loss: 0.0015 - val_acc: 0.8666 - val_rmse: 0.0228 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0051 - acc: 0.9499 - rmse: 0.0326 - mse: 0.0051 - r_square: 0.9339 - val_loss: 0.0014 - val_acc: 0.8795 - val_rmse: 0.0211 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0050 - acc: 0.9540 - rmse: 0.0323 - mse: 0.0050 - r_square: 0.9350 - val_loss: 0.0013 - val_acc: 0.8654 - val_rmse: 0.0180 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0050 - acc: 0.9553 - rmse: 0.0326 - mse: 0.0050 - r_square: 0.9354 - val_loss: 0.0013 - val_acc: 0.8391 - val_rmse: 0.0176 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0050 - acc: 0.9540 - rmse: 0.0321 - mse: 0.0050 - r_square: 0.9355 - val_loss: 0.0014 - val_acc: 0.8378 - val_rmse: 0.0165 - val_mse: 0.0014 - val_r_square: 0.9923\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0051 - acc: 0.9550 - rmse: 0.0326 - mse: 0.0051 - r_square: 0.9341 - val_loss: 0.0015 - val_acc: 0.8369 - val_rmse: 0.0185 - val_mse: 0.0015 - val_r_square: 0.9917\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0052 - acc: 0.9523 - rmse: 0.0338 - mse: 0.0052 - r_square: 0.9304 - val_loss: 0.0015 - val_acc: 0.8368 - val_rmse: 0.0210 - val_mse: 0.0015 - val_r_square: 0.9915\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0051 - acc: 0.9496 - rmse: 0.0337 - mse: 0.0051 - r_square: 0.9332 - val_loss: 0.0015 - val_acc: 0.8371 - val_rmse: 0.0226 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0051 - acc: 0.9479 - rmse: 0.0346 - mse: 0.0051 - r_square: 0.9331 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0230 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0050 - acc: 0.9488 - rmse: 0.0344 - mse: 0.0050 - r_square: 0.9343 - val_loss: 0.0013 - val_acc: 0.8509 - val_rmse: 0.0186 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0049 - acc: 0.9503 - rmse: 0.0325 - mse: 0.0049 - r_square: 0.9361 - val_loss: 0.0012 - val_acc: 0.8638 - val_rmse: 0.0160 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0050 - acc: 0.9580 - rmse: 0.0329 - mse: 0.0050 - r_square: 0.9369 - val_loss: 0.0014 - val_acc: 0.8374 - val_rmse: 0.0178 - val_mse: 0.0014 - val_r_square: 0.9923\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0051 - acc: 0.9582 - rmse: 0.0342 - mse: 0.0051 - r_square: 0.9364 - val_loss: 0.0015 - val_acc: 0.8366 - val_rmse: 0.0219 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0050 - acc: 0.9582 - rmse: 0.0346 - mse: 0.0050 - r_square: 0.9361 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0258 - val_mse: 0.0017 - val_r_square: 0.9902\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0051 - acc: 0.9516 - rmse: 0.0366 - mse: 0.0051 - r_square: 0.9332 - val_loss: 0.0016 - val_acc: 0.8366 - val_rmse: 0.0248 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0052 - acc: 0.9572 - rmse: 0.0378 - mse: 0.0052 - r_square: 0.9314 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0220 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0052 - acc: 0.9525 - rmse: 0.0387 - mse: 0.0052 - r_square: 0.9289 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0210 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0053 - acc: 0.9527 - rmse: 0.0402 - mse: 0.0053 - r_square: 0.9288 - val_loss: 0.0015 - val_acc: 0.8366 - val_rmse: 0.0221 - val_mse: 0.0015 - val_r_square: 0.9915\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0053 - acc: 0.9513 - rmse: 0.0392 - mse: 0.0053 - r_square: 0.9319 - val_loss: 0.0016 - val_acc: 0.8500 - val_rmse: 0.0257 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0052 - acc: 0.9534 - rmse: 0.0389 - mse: 0.0052 - r_square: 0.9337 - val_loss: 0.0017 - val_acc: 0.8627 - val_rmse: 0.0288 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0054 - acc: 0.9568 - rmse: 0.0413 - mse: 0.0054 - r_square: 0.9301 - val_loss: 0.0021 - val_acc: 0.8623 - val_rmse: 0.0350 - val_mse: 0.0021 - val_r_square: 0.9867\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0058 - acc: 0.9535 - rmse: 0.0460 - mse: 0.0058 - r_square: 0.9241 - val_loss: 0.0030 - val_acc: 0.8631 - val_rmse: 0.0469 - val_mse: 0.0030 - val_r_square: 0.9802\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0061 - acc: 0.9426 - rmse: 0.0505 - mse: 0.0061 - r_square: 0.9152 - val_loss: 0.0030 - val_acc: 0.9666 - val_rmse: 0.0461 - val_mse: 0.0030 - val_r_square: 0.9805\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0060 - acc: 0.9110 - rmse: 0.0499 - mse: 0.0060 - r_square: 0.9169 - val_loss: 0.0026 - val_acc: 0.9931 - val_rmse: 0.0412 - val_mse: 0.0026 - val_r_square: 0.9828\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0063 - acc: 0.8835 - rmse: 0.0521 - mse: 0.0063 - r_square: 0.9187 - val_loss: 0.0019 - val_acc: 0.8630 - val_rmse: 0.0318 - val_mse: 0.0019 - val_r_square: 0.9881\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0060 - acc: 0.9146 - rmse: 0.0475 - mse: 0.0060 - r_square: 0.9227 - val_loss: 0.0019 - val_acc: 0.8375 - val_rmse: 0.0306 - val_mse: 0.0019 - val_r_square: 0.9885\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0057 - acc: 0.9092 - rmse: 0.0458 - mse: 0.0057 - r_square: 0.9220 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0056 - acc: 0.9017 - rmse: 0.0446 - mse: 0.0056 - r_square: 0.9239 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0230 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0054 - acc: 0.9184 - rmse: 0.0418 - mse: 0.0054 - r_square: 0.9283 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0053 - acc: 0.9347 - rmse: 0.0405 - mse: 0.0053 - r_square: 0.9297 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0244 - val_mse: 0.0016 - val_r_square: 0.9908\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0053 - acc: 0.9408 - rmse: 0.0408 - mse: 0.0053 - r_square: 0.9297 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0271 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0054 - acc: 0.9471 - rmse: 0.0412 - mse: 0.0054 - r_square: 0.9296 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0303 - val_mse: 0.0018 - val_r_square: 0.9887\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0056 - acc: 0.9447 - rmse: 0.0431 - mse: 0.0056 - r_square: 0.9276 - val_loss: 0.0020 - val_acc: 0.8368 - val_rmse: 0.0322 - val_mse: 0.0020 - val_r_square: 0.9879\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0057 - acc: 0.9408 - rmse: 0.0447 - mse: 0.0057 - r_square: 0.9260 - val_loss: 0.0021 - val_acc: 0.8368 - val_rmse: 0.0349 - val_mse: 0.0021 - val_r_square: 0.9867\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0060 - acc: 0.9292 - rmse: 0.0471 - mse: 0.0060 - r_square: 0.9229 - val_loss: 0.0022 - val_acc: 0.8366 - val_rmse: 0.0361 - val_mse: 0.0022 - val_r_square: 0.9861\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0061 - acc: 0.9281 - rmse: 0.0480 - mse: 0.0061 - r_square: 0.9218 - val_loss: 0.0022 - val_acc: 0.8365 - val_rmse: 0.0364 - val_mse: 0.0022 - val_r_square: 0.9860\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0060 - acc: 0.9309 - rmse: 0.0471 - mse: 0.0060 - r_square: 0.9230 - val_loss: 0.0020 - val_acc: 0.8366 - val_rmse: 0.0327 - val_mse: 0.0020 - val_r_square: 0.9877\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0056 - acc: 0.9450 - rmse: 0.0434 - mse: 0.0056 - r_square: 0.9285 - val_loss: 0.0019 - val_acc: 0.8368 - val_rmse: 0.0310 - val_mse: 0.0019 - val_r_square: 0.9885\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0057 - acc: 0.9433 - rmse: 0.0438 - mse: 0.0057 - r_square: 0.9282 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0289 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0055 - acc: 0.9470 - rmse: 0.0421 - mse: 0.0055 - r_square: 0.9303 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0297 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0054 - acc: 0.9441 - rmse: 0.0401 - mse: 0.0054 - r_square: 0.9322 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0298 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0053 - acc: 0.9462 - rmse: 0.0388 - mse: 0.0053 - r_square: 0.9336 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0281 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0052 - acc: 0.9523 - rmse: 0.0374 - mse: 0.0052 - r_square: 0.9346 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0257 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0051 - acc: 0.9565 - rmse: 0.0360 - mse: 0.0051 - r_square: 0.9355 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0050 - acc: 0.9603 - rmse: 0.0347 - mse: 0.0050 - r_square: 0.9360 - val_loss: 0.0015 - val_acc: 0.8366 - val_rmse: 0.0250 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0049 - acc: 0.9609 - rmse: 0.0334 - mse: 0.0049 - r_square: 0.9370 - val_loss: 0.0015 - val_acc: 0.8371 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0049 - acc: 0.9608 - rmse: 0.0322 - mse: 0.0049 - r_square: 0.9376 - val_loss: 0.0014 - val_acc: 0.8372 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9608 - rmse: 0.0309 - mse: 0.0048 - r_square: 0.9391 - val_loss: 0.0014 - val_acc: 0.8513 - val_rmse: 0.0214 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0048 - acc: 0.9607 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9398 - val_loss: 0.0013 - val_acc: 0.8650 - val_rmse: 0.0204 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0047 - acc: 0.9598 - rmse: 0.0291 - mse: 0.0047 - r_square: 0.9403 - val_loss: 0.0013 - val_acc: 0.8659 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0047 - acc: 0.9600 - rmse: 0.0286 - mse: 0.0047 - r_square: 0.9402 - val_loss: 0.0013 - val_acc: 0.8784 - val_rmse: 0.0192 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0047 - acc: 0.9594 - rmse: 0.0282 - mse: 0.0047 - r_square: 0.9402 - val_loss: 0.0013 - val_acc: 0.8908 - val_rmse: 0.0190 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0047 - acc: 0.9600 - rmse: 0.0280 - mse: 0.0047 - r_square: 0.9399 - val_loss: 0.0013 - val_acc: 0.8915 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9597 - rmse: 0.0274 - mse: 0.0046 - r_square: 0.9410 - val_loss: 0.0013 - val_acc: 0.8919 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0046 - acc: 0.9583 - rmse: 0.0272 - mse: 0.0046 - r_square: 0.9415 - val_loss: 0.0013 - val_acc: 0.8921 - val_rmse: 0.0193 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0046 - acc: 0.9598 - rmse: 0.0269 - mse: 0.0046 - r_square: 0.9416 - val_loss: 0.0013 - val_acc: 0.8928 - val_rmse: 0.0195 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0046 - acc: 0.9583 - rmse: 0.0269 - mse: 0.0046 - r_square: 0.9412 - val_loss: 0.0013 - val_acc: 0.9050 - val_rmse: 0.0197 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9586 - rmse: 0.0268 - mse: 0.0046 - r_square: 0.9407 - val_loss: 0.0013 - val_acc: 0.9193 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0047 - acc: 0.9599 - rmse: 0.0271 - mse: 0.0047 - r_square: 0.9404 - val_loss: 0.0013 - val_acc: 0.9207 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9581 - rmse: 0.0266 - mse: 0.0046 - r_square: 0.9418 - val_loss: 0.0013 - val_acc: 0.9437 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9595 - rmse: 0.0267 - mse: 0.0046 - r_square: 0.9420 - val_loss: 0.0013 - val_acc: 0.9436 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9575 - rmse: 0.0266 - mse: 0.0046 - r_square: 0.9420 - val_loss: 0.0014 - val_acc: 0.9557 - val_rmse: 0.0203 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0046 - acc: 0.9598 - rmse: 0.0269 - mse: 0.0046 - r_square: 0.9412 - val_loss: 0.0014 - val_acc: 0.9558 - val_rmse: 0.0202 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9576 - rmse: 0.0266 - mse: 0.0046 - r_square: 0.9411 - val_loss: 0.0014 - val_acc: 0.9565 - val_rmse: 0.0204 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9583 - rmse: 0.0271 - mse: 0.0046 - r_square: 0.9409 - val_loss: 0.0014 - val_acc: 0.9565 - val_rmse: 0.0205 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9590 - rmse: 0.0269 - mse: 0.0046 - r_square: 0.9419 - val_loss: 0.0014 - val_acc: 0.9565 - val_rmse: 0.0205 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9564 - rmse: 0.0269 - mse: 0.0046 - r_square: 0.9415 - val_loss: 0.0014 - val_acc: 0.9691 - val_rmse: 0.0206 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9589 - rmse: 0.0270 - mse: 0.0046 - r_square: 0.9408 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0208 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0046 - acc: 0.9535 - rmse: 0.0271 - mse: 0.0046 - r_square: 0.9416 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0208 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9593 - rmse: 0.0270 - mse: 0.0046 - r_square: 0.9422 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0209 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9551 - rmse: 0.0271 - mse: 0.0046 - r_square: 0.9419 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0209 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0047 - acc: 0.9574 - rmse: 0.0272 - mse: 0.0047 - r_square: 0.9405 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0211 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0047 - acc: 0.9531 - rmse: 0.0278 - mse: 0.0047 - r_square: 0.9395 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0213 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9592 - rmse: 0.0275 - mse: 0.0046 - r_square: 0.9419 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0214 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9541 - rmse: 0.0274 - mse: 0.0046 - r_square: 0.9423 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0214 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0046 - acc: 0.9551 - rmse: 0.0276 - mse: 0.0046 - r_square: 0.9419 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0215 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9540 - rmse: 0.0278 - mse: 0.0046 - r_square: 0.9414 - val_loss: 0.0014 - val_acc: 0.9693 - val_rmse: 0.0218 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0047 - acc: 0.9552 - rmse: 0.0280 - mse: 0.0047 - r_square: 0.9401 - val_loss: 0.0015 - val_acc: 0.9813 - val_rmse: 0.0220 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0047 - acc: 0.9512 - rmse: 0.0283 - mse: 0.0047 - r_square: 0.9407 - val_loss: 0.0015 - val_acc: 0.9924 - val_rmse: 0.0222 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9574 - rmse: 0.0284 - mse: 0.0046 - r_square: 0.9415 - val_loss: 0.0015 - val_acc: 0.9927 - val_rmse: 0.0223 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0046 - acc: 0.9537 - rmse: 0.0285 - mse: 0.0046 - r_square: 0.9416 - val_loss: 0.0015 - val_acc: 0.9816 - val_rmse: 0.0224 - val_mse: 0.0015 - val_r_square: 0.9910\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_8 (RepeatVecto (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 7s 1ms/step - loss: 0.0169 - acc: 0.7232 - mse: 0.0169 - rmse: 0.1061 - r_square: 0.7136 - val_loss: 0.0055 - val_acc: 0.8368 - val_mse: 0.0055 - val_rmse: 0.0680 - val_r_square: 0.9617\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0143 - acc: 0.8598 - mse: 0.0143 - rmse: 0.0997 - r_square: 0.7152 - val_loss: 0.0071 - val_acc: 0.8500 - val_mse: 0.0071 - val_rmse: 0.0789 - val_r_square: 0.9520\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 237us/step - loss: 0.0139 - acc: 0.7472 - mse: 0.0139 - rmse: 0.0966 - r_square: 0.7631 - val_loss: 0.0053 - val_acc: 0.8772 - val_mse: 0.0053 - val_rmse: 0.0686 - val_r_square: 0.9630\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 240us/step - loss: 0.0092 - acc: 0.9534 - mse: 0.0092 - rmse: 0.0701 - r_square: 0.8474 - val_loss: 0.0020 - val_acc: 0.8916 - val_mse: 0.0020 - val_rmse: 0.0307 - val_r_square: 0.9880\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 239us/step - loss: 0.0082 - acc: 0.9381 - mse: 0.0082 - rmse: 0.0596 - r_square: 0.8811 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0518 - val_r_square: 0.9767\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 239us/step - loss: 0.0089 - acc: 0.8461 - mse: 0.0089 - rmse: 0.0656 - r_square: 0.8681 - val_loss: 0.0029 - val_acc: 0.9941 - val_mse: 0.0029 - val_rmse: 0.0400 - val_r_square: 0.9826\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 240us/step - loss: 0.0095 - acc: 0.8991 - mse: 0.0095 - rmse: 0.0712 - r_square: 0.8494 - val_loss: 0.0043 - val_acc: 0.8365 - val_mse: 0.0043 - val_rmse: 0.0581 - val_r_square: 0.9720\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0112 - acc: 0.8902 - mse: 0.0112 - rmse: 0.0795 - r_square: 0.8123 - val_loss: 0.0029 - val_acc: 0.9503 - val_mse: 0.0029 - val_rmse: 0.0442 - val_r_square: 0.9816\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 241us/step - loss: 0.0080 - acc: 0.9558 - mse: 0.0080 - rmse: 0.0571 - r_square: 0.8869 - val_loss: 0.0026 - val_acc: 0.8365 - val_mse: 0.0026 - val_rmse: 0.0413 - val_r_square: 0.9833\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0087 - acc: 0.9189 - mse: 0.0087 - rmse: 0.0667 - r_square: 0.8672 - val_loss: 0.0021 - val_acc: 0.8365 - val_mse: 0.0021 - val_rmse: 0.0310 - val_r_square: 0.9875\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0093 - acc: 0.9449 - mse: 0.0093 - rmse: 0.0691 - r_square: 0.8582 - val_loss: 0.0031 - val_acc: 0.8365 - val_mse: 0.0031 - val_rmse: 0.0434 - val_r_square: 0.9809\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0094 - acc: 0.9271 - mse: 0.0094 - rmse: 0.0693 - r_square: 0.8539 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0345 - val_r_square: 0.9798\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0078 - acc: 0.9398 - mse: 0.0078 - rmse: 0.0599 - r_square: 0.8964 - val_loss: 0.0032 - val_acc: 0.8365 - val_mse: 0.0032 - val_rmse: 0.0370 - val_r_square: 0.9815\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 245us/step - loss: 0.0072 - acc: 0.9417 - mse: 0.0072 - rmse: 0.0579 - r_square: 0.8960 - val_loss: 0.0027 - val_acc: 0.8365 - val_mse: 0.0027 - val_rmse: 0.0408 - val_r_square: 0.9833\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 241us/step - loss: 0.0090 - acc: 0.9374 - mse: 0.0090 - rmse: 0.0659 - r_square: 0.8739 - val_loss: 0.0075 - val_acc: 0.9940 - val_mse: 0.0075 - val_rmse: 0.0816 - val_r_square: 0.9459\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 246us/step - loss: 0.0069 - acc: 0.9547 - mse: 0.0069 - rmse: 0.0521 - r_square: 0.9055 - val_loss: 0.0027 - val_acc: 0.8765 - val_mse: 0.0027 - val_rmse: 0.0439 - val_r_square: 0.9815\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0061 - acc: 0.9117 - mse: 0.0061 - rmse: 0.0492 - r_square: 0.9154 - val_loss: 0.0015 - val_acc: 0.8634 - val_mse: 0.0015 - val_rmse: 0.0217 - val_r_square: 0.9915\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 248us/step - loss: 0.0064 - acc: 0.9581 - mse: 0.0064 - rmse: 0.0495 - r_square: 0.9047 - val_loss: 0.0022 - val_acc: 0.9917 - val_mse: 0.0022 - val_rmse: 0.0373 - val_r_square: 0.9861\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 244us/step - loss: 0.0057 - acc: 0.9412 - mse: 0.0057 - rmse: 0.0443 - r_square: 0.9259 - val_loss: 0.0022 - val_acc: 0.9942 - val_mse: 0.0022 - val_rmse: 0.0367 - val_r_square: 0.9859\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0059 - acc: 0.9390 - mse: 0.0059 - rmse: 0.0479 - r_square: 0.9140 - val_loss: 0.0018 - val_acc: 0.9680 - val_mse: 0.0018 - val_rmse: 0.0281 - val_r_square: 0.9888\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0069 - acc: 0.9488 - mse: 0.0069 - rmse: 0.0585 - r_square: 0.9016 - val_loss: 0.0023 - val_acc: 0.9030 - val_mse: 0.0023 - val_rmse: 0.0363 - val_r_square: 0.9855\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0072 - acc: 0.9484 - mse: 0.0072 - rmse: 0.0550 - r_square: 0.9090 - val_loss: 0.0038 - val_acc: 0.8365 - val_mse: 0.0038 - val_rmse: 0.0535 - val_r_square: 0.9753\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 237us/step - loss: 0.0066 - acc: 0.9412 - mse: 0.0066 - rmse: 0.0511 - r_square: 0.9154 - val_loss: 0.0032 - val_acc: 0.8365 - val_mse: 0.0032 - val_rmse: 0.0452 - val_r_square: 0.9800\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0071 - acc: 0.9451 - mse: 0.0071 - rmse: 0.0563 - r_square: 0.9087 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0304 - val_r_square: 0.9892\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 237us/step - loss: 0.0070 - acc: 0.9381 - mse: 0.0070 - rmse: 0.0567 - r_square: 0.8978 - val_loss: 0.0041 - val_acc: 0.9873 - val_mse: 0.0041 - val_rmse: 0.0563 - val_r_square: 0.9717\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0071 - acc: 0.9435 - mse: 0.0071 - rmse: 0.0568 - r_square: 0.8988 - val_loss: 0.0017 - val_acc: 0.9396 - val_mse: 0.0017 - val_rmse: 0.0267 - val_r_square: 0.9899\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 233us/step - loss: 0.0061 - acc: 0.9452 - mse: 0.0061 - rmse: 0.0523 - r_square: 0.9114 - val_loss: 0.0013 - val_acc: 0.8994 - val_mse: 0.0013 - val_rmse: 0.0189 - val_r_square: 0.9923\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0075 - acc: 0.9280 - mse: 0.0075 - rmse: 0.0583 - r_square: 0.8970 - val_loss: 0.0038 - val_acc: 0.9942 - val_mse: 0.0038 - val_rmse: 0.0556 - val_r_square: 0.9739\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 235us/step - loss: 0.0062 - acc: 0.9282 - mse: 0.0062 - rmse: 0.0532 - r_square: 0.9086 - val_loss: 0.0027 - val_acc: 0.9885 - val_mse: 0.0027 - val_rmse: 0.0412 - val_r_square: 0.9818\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0069 - acc: 0.9401 - mse: 0.0069 - rmse: 0.0519 - r_square: 0.9016 - val_loss: 0.0014 - val_acc: 0.9843 - val_mse: 0.0014 - val_rmse: 0.0202 - val_r_square: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0063 - acc: 0.9455 - mse: 0.0063 - rmse: 0.0495 - r_square: 0.9098 - val_loss: 0.0018 - val_acc: 0.9925 - val_mse: 0.0018 - val_rmse: 0.0300 - val_r_square: 0.9889\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0062 - acc: 0.9529 - mse: 0.0062 - rmse: 0.0494 - r_square: 0.9154 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0459 - val_r_square: 0.9804\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0065 - acc: 0.9386 - mse: 0.0065 - rmse: 0.0535 - r_square: 0.9008 - val_loss: 0.0014 - val_acc: 0.8366 - val_mse: 0.0014 - val_rmse: 0.0192 - val_r_square: 0.9920\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0065 - acc: 0.9502 - mse: 0.0065 - rmse: 0.0482 - r_square: 0.9134 - val_loss: 0.0035 - val_acc: 0.9937 - val_mse: 0.0035 - val_rmse: 0.0504 - val_r_square: 0.9760\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0062 - acc: 0.9359 - mse: 0.0062 - rmse: 0.0499 - r_square: 0.9165 - val_loss: 0.0029 - val_acc: 0.9911 - val_mse: 0.0029 - val_rmse: 0.0446 - val_r_square: 0.9810\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0060 - acc: 0.9497 - mse: 0.0060 - rmse: 0.0489 - r_square: 0.9083 - val_loss: 0.0016 - val_acc: 0.8758 - val_mse: 0.0016 - val_rmse: 0.0250 - val_r_square: 0.9905\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0056 - acc: 0.9280 - mse: 0.0056 - rmse: 0.0423 - r_square: 0.9276 - val_loss: 0.0019 - val_acc: 0.9941 - val_mse: 0.0019 - val_rmse: 0.0305 - val_r_square: 0.9884\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0064 - acc: 0.9524 - mse: 0.0064 - rmse: 0.0523 - r_square: 0.9118 - val_loss: 0.0017 - val_acc: 0.9899 - val_mse: 0.0017 - val_rmse: 0.0270 - val_r_square: 0.9894\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0060 - acc: 0.9471 - mse: 0.0060 - rmse: 0.0497 - r_square: 0.9162 - val_loss: 0.0016 - val_acc: 0.9552 - val_mse: 0.0016 - val_rmse: 0.0263 - val_r_square: 0.9901\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0058 - acc: 0.9440 - mse: 0.0058 - rmse: 0.0449 - r_square: 0.9228 - val_loss: 0.0021 - val_acc: 0.9931 - val_mse: 0.0021 - val_rmse: 0.0340 - val_r_square: 0.9864\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0063 - acc: 0.9506 - mse: 0.0063 - rmse: 0.0537 - r_square: 0.9050 - val_loss: 0.0017 - val_acc: 0.9539 - val_mse: 0.0017 - val_rmse: 0.0262 - val_r_square: 0.9900\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0050 - acc: 0.9377 - mse: 0.0050 - rmse: 0.0364 - r_square: 0.9336 - val_loss: 0.0013 - val_acc: 0.9809 - val_mse: 0.0013 - val_rmse: 0.0168 - val_r_square: 0.9927\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0053 - acc: 0.9395 - mse: 0.0053 - rmse: 0.0415 - r_square: 0.9220 - val_loss: 0.0016 - val_acc: 0.9932 - val_mse: 0.0016 - val_rmse: 0.0264 - val_r_square: 0.9898\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0053 - acc: 0.9545 - mse: 0.0053 - rmse: 0.0419 - r_square: 0.9232 - val_loss: 0.0016 - val_acc: 0.9932 - val_mse: 0.0016 - val_rmse: 0.0240 - val_r_square: 0.9907\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0055 - acc: 0.9450 - mse: 0.0055 - rmse: 0.0443 - r_square: 0.9193 - val_loss: 0.0016 - val_acc: 0.9629 - val_mse: 0.0016 - val_rmse: 0.0246 - val_r_square: 0.9905\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0055 - acc: 0.9337 - mse: 0.0055 - rmse: 0.0411 - r_square: 0.9225 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0212 - val_r_square: 0.9919\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.9454 - mse: 0.0057 - rmse: 0.0459 - r_square: 0.9101 - val_loss: 0.0020 - val_acc: 0.8650 - val_mse: 0.0020 - val_rmse: 0.0332 - val_r_square: 0.9873\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0059 - acc: 0.9293 - mse: 0.0059 - rmse: 0.0443 - r_square: 0.9216 - val_loss: 0.0032 - val_acc: 0.9935 - val_mse: 0.0032 - val_rmse: 0.0493 - val_r_square: 0.9781\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0059 - acc: 0.9209 - mse: 0.0059 - rmse: 0.0479 - r_square: 0.9200 - val_loss: 0.0021 - val_acc: 0.9931 - val_mse: 0.0021 - val_rmse: 0.0344 - val_r_square: 0.9864\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0058 - acc: 0.9558 - mse: 0.0058 - rmse: 0.0444 - r_square: 0.9152 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0224 - val_r_square: 0.9915\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0057 - acc: 0.9413 - mse: 0.0057 - rmse: 0.0463 - r_square: 0.9205 - val_loss: 0.0025 - val_acc: 0.9934 - val_mse: 0.0025 - val_rmse: 0.0399 - val_r_square: 0.9837\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0058 - acc: 0.9191 - mse: 0.0058 - rmse: 0.0452 - r_square: 0.9216 - val_loss: 0.0017 - val_acc: 0.9931 - val_mse: 0.0017 - val_rmse: 0.0272 - val_r_square: 0.9898\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0059 - acc: 0.9487 - mse: 0.0059 - rmse: 0.0490 - r_square: 0.9155 - val_loss: 0.0020 - val_acc: 0.9931 - val_mse: 0.0020 - val_rmse: 0.0330 - val_r_square: 0.9871\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0056 - acc: 0.9581 - mse: 0.0056 - rmse: 0.0430 - r_square: 0.9185 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0206 - val_r_square: 0.9918\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0056 - acc: 0.9557 - mse: 0.0056 - rmse: 0.0449 - r_square: 0.9224 - val_loss: 0.0022 - val_acc: 0.9937 - val_mse: 0.0022 - val_rmse: 0.0361 - val_r_square: 0.9854\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0054 - acc: 0.9385 - mse: 0.0054 - rmse: 0.0427 - r_square: 0.9221 - val_loss: 0.0013 - val_acc: 0.9905 - val_mse: 0.0013 - val_rmse: 0.0182 - val_r_square: 0.9922\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0052 - acc: 0.9445 - mse: 0.0052 - rmse: 0.0401 - r_square: 0.9284 - val_loss: 0.0015 - val_acc: 0.9013 - val_mse: 0.0015 - val_rmse: 0.0229 - val_r_square: 0.9910\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0056 - acc: 0.9561 - mse: 0.0056 - rmse: 0.0422 - r_square: 0.9163 - val_loss: 0.0017 - val_acc: 0.8371 - val_mse: 0.0017 - val_rmse: 0.0279 - val_r_square: 0.9896\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0053 - acc: 0.9408 - mse: 0.0053 - rmse: 0.0414 - r_square: 0.9274 - val_loss: 0.0019 - val_acc: 0.9935 - val_mse: 0.0019 - val_rmse: 0.0302 - val_r_square: 0.9881\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0054 - acc: 0.9576 - mse: 0.0054 - rmse: 0.0408 - r_square: 0.9259 - val_loss: 0.0015 - val_acc: 0.8647 - val_mse: 0.0015 - val_rmse: 0.0244 - val_r_square: 0.9908\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0055 - acc: 0.9471 - mse: 0.0055 - rmse: 0.0436 - r_square: 0.9247 - val_loss: 0.0018 - val_acc: 0.9932 - val_mse: 0.0018 - val_rmse: 0.0293 - val_r_square: 0.9891\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0052 - acc: 0.9568 - mse: 0.0052 - rmse: 0.0385 - r_square: 0.9295 - val_loss: 0.0015 - val_acc: 0.8654 - val_mse: 0.0015 - val_rmse: 0.0224 - val_r_square: 0.9912\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0053 - acc: 0.9510 - mse: 0.0053 - rmse: 0.0409 - r_square: 0.9257 - val_loss: 0.0016 - val_acc: 0.9935 - val_mse: 0.0016 - val_rmse: 0.0252 - val_r_square: 0.9906\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0052 - acc: 0.9427 - mse: 0.0052 - rmse: 0.0395 - r_square: 0.9278 - val_loss: 0.0016 - val_acc: 0.9518 - val_mse: 0.0016 - val_rmse: 0.0246 - val_r_square: 0.9905\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0051 - acc: 0.9482 - mse: 0.0051 - rmse: 0.0366 - r_square: 0.9283 - val_loss: 0.0014 - val_acc: 0.9791 - val_mse: 0.0014 - val_rmse: 0.0200 - val_r_square: 0.9918\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0051 - acc: 0.9495 - mse: 0.0051 - rmse: 0.0380 - r_square: 0.9294 - val_loss: 0.0013 - val_acc: 0.9301 - val_mse: 0.0013 - val_rmse: 0.0187 - val_r_square: 0.9924\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0052 - acc: 0.9587 - mse: 0.0052 - rmse: 0.0381 - r_square: 0.9268 - val_loss: 0.0014 - val_acc: 0.8790 - val_mse: 0.0014 - val_rmse: 0.0209 - val_r_square: 0.9918\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0052 - acc: 0.9435 - mse: 0.0052 - rmse: 0.0364 - r_square: 0.9276 - val_loss: 0.0012 - val_acc: 0.9041 - val_mse: 0.0012 - val_rmse: 0.0147 - val_r_square: 0.9930\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0050 - acc: 0.9514 - mse: 0.0050 - rmse: 0.0347 - r_square: 0.9333 - val_loss: 0.0013 - val_acc: 0.9551 - val_mse: 0.0013 - val_rmse: 0.0173 - val_r_square: 0.9926\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0053 - acc: 0.9539 - mse: 0.0053 - rmse: 0.0389 - r_square: 0.9263 - val_loss: 0.0016 - val_acc: 0.8634 - val_mse: 0.0016 - val_rmse: 0.0251 - val_r_square: 0.9905\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0050 - acc: 0.9488 - mse: 0.0050 - rmse: 0.0360 - r_square: 0.9322 - val_loss: 0.0013 - val_acc: 0.9158 - val_mse: 0.0013 - val_rmse: 0.0183 - val_r_square: 0.9923\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0051 - acc: 0.9583 - mse: 0.0051 - rmse: 0.0352 - r_square: 0.9333 - val_loss: 0.0013 - val_acc: 0.9301 - val_mse: 0.0013 - val_rmse: 0.0164 - val_r_square: 0.9927\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0050 - acc: 0.9559 - mse: 0.0050 - rmse: 0.0359 - r_square: 0.9314 - val_loss: 0.0013 - val_acc: 0.9701 - val_mse: 0.0013 - val_rmse: 0.0155 - val_r_square: 0.9928\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0053 - acc: 0.9579 - mse: 0.0053 - rmse: 0.0408 - r_square: 0.9241 - val_loss: 0.0016 - val_acc: 0.9647 - val_mse: 0.0016 - val_rmse: 0.0253 - val_r_square: 0.9903\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0049 - acc: 0.9542 - mse: 0.0049 - rmse: 0.0357 - r_square: 0.9343 - val_loss: 0.0013 - val_acc: 0.9912 - val_mse: 0.0013 - val_rmse: 0.0171 - val_r_square: 0.9924\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 240us/step - loss: 0.0049 - acc: 0.9377 - mse: 0.0049 - rmse: 0.0367 - r_square: 0.9347 - val_loss: 0.0014 - val_acc: 0.9550 - val_mse: 0.0014 - val_rmse: 0.0213 - val_r_square: 0.9916\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0051 - acc: 0.9417 - mse: 0.0051 - rmse: 0.0396 - r_square: 0.9299 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0241 - val_r_square: 0.9907\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0050 - acc: 0.9435 - mse: 0.0050 - rmse: 0.0381 - r_square: 0.9293 - val_loss: 0.0012 - val_acc: 0.8759 - val_mse: 0.0012 - val_rmse: 0.0151 - val_r_square: 0.9929\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0056 - acc: 0.9555 - mse: 0.0056 - rmse: 0.0423 - r_square: 0.9249 - val_loss: 0.0019 - val_acc: 0.9901 - val_mse: 0.0019 - val_rmse: 0.0315 - val_r_square: 0.9875\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.9446 - mse: 0.0057 - rmse: 0.0444 - r_square: 0.9180 - val_loss: 0.0013 - val_acc: 0.9775 - val_mse: 0.0013 - val_rmse: 0.0178 - val_r_square: 0.9923\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0054 - acc: 0.9448 - mse: 0.0054 - rmse: 0.0408 - r_square: 0.9192 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0229 - val_r_square: 0.9913\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0057 - acc: 0.9479 - mse: 0.0057 - rmse: 0.0445 - r_square: 0.9170 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0248 - val_r_square: 0.9905\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0062 - acc: 0.9510 - mse: 0.0062 - rmse: 0.0467 - r_square: 0.9160 - val_loss: 0.0037 - val_acc: 0.9932 - val_mse: 0.0037 - val_rmse: 0.0534 - val_r_square: 0.9746\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0062 - acc: 0.9350 - mse: 0.0062 - rmse: 0.0478 - r_square: 0.9031 - val_loss: 0.0015 - val_acc: 0.9931 - val_mse: 0.0015 - val_rmse: 0.0237 - val_r_square: 0.9908\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0051 - acc: 0.9512 - mse: 0.0051 - rmse: 0.0381 - r_square: 0.9304 - val_loss: 0.0014 - val_acc: 0.9411 - val_mse: 0.0014 - val_rmse: 0.0207 - val_r_square: 0.9916\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0055 - acc: 0.9484 - mse: 0.0055 - rmse: 0.0445 - r_square: 0.9246 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0234 - val_r_square: 0.9910\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0059 - acc: 0.9611 - mse: 0.0059 - rmse: 0.0464 - r_square: 0.9168 - val_loss: 0.0027 - val_acc: 0.9942 - val_mse: 0.0027 - val_rmse: 0.0428 - val_r_square: 0.9817\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0053 - acc: 0.9383 - mse: 0.0053 - rmse: 0.0408 - r_square: 0.9288 - val_loss: 0.0014 - val_acc: 0.8752 - val_mse: 0.0014 - val_rmse: 0.0207 - val_r_square: 0.9915\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0049 - acc: 0.9577 - mse: 0.0049 - rmse: 0.0375 - r_square: 0.9317 - val_loss: 0.0013 - val_acc: 0.8921 - val_mse: 0.0013 - val_rmse: 0.0143 - val_r_square: 0.9929\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0054 - acc: 0.9514 - mse: 0.0054 - rmse: 0.0427 - r_square: 0.9244 - val_loss: 0.0024 - val_acc: 0.9942 - val_mse: 0.0024 - val_rmse: 0.0396 - val_r_square: 0.9841\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0053 - acc: 0.9457 - mse: 0.0053 - rmse: 0.0436 - r_square: 0.9229 - val_loss: 0.0013 - val_acc: 0.9904 - val_mse: 0.0013 - val_rmse: 0.0178 - val_r_square: 0.9921\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0052 - acc: 0.9500 - mse: 0.0052 - rmse: 0.0395 - r_square: 0.9295 - val_loss: 0.0013 - val_acc: 0.8634 - val_mse: 0.0013 - val_rmse: 0.0172 - val_r_square: 0.9925\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0053 - acc: 0.9508 - mse: 0.0053 - rmse: 0.0432 - r_square: 0.9258 - val_loss: 0.0012 - val_acc: 0.8368 - val_mse: 0.0012 - val_rmse: 0.0139 - val_r_square: 0.9931\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0051 - acc: 0.9602 - mse: 0.0051 - rmse: 0.0380 - r_square: 0.9307 - val_loss: 0.0015 - val_acc: 0.9164 - val_mse: 0.0015 - val_rmse: 0.0247 - val_r_square: 0.9907\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0052 - acc: 0.9561 - mse: 0.0052 - rmse: 0.0416 - r_square: 0.9304 - val_loss: 0.0013 - val_acc: 0.9548 - val_mse: 0.0013 - val_rmse: 0.0190 - val_r_square: 0.9923\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0050 - acc: 0.9482 - mse: 0.0050 - rmse: 0.0362 - r_square: 0.9337 - val_loss: 0.0019 - val_acc: 0.9568 - val_mse: 0.0019 - val_rmse: 0.0307 - val_r_square: 0.9879\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0053 - acc: 0.9440 - mse: 0.0053 - rmse: 0.0420 - r_square: 0.9289 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0292 - val_r_square: 0.9890\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0054 - acc: 0.9536 - mse: 0.0054 - rmse: 0.0433 - r_square: 0.9271 - val_loss: 0.0022 - val_acc: 0.8641 - val_mse: 0.0022 - val_rmse: 0.0358 - val_r_square: 0.9861\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0053 - acc: 0.9216 - mse: 0.0053 - rmse: 0.0413 - r_square: 0.9268 - val_loss: 0.0012 - val_acc: 0.8502 - val_mse: 0.0012 - val_rmse: 0.0131 - val_r_square: 0.9931\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0052 - acc: 0.9511 - mse: 0.0052 - rmse: 0.0413 - r_square: 0.9290 - val_loss: 0.0021 - val_acc: 0.9942 - val_mse: 0.0021 - val_rmse: 0.0337 - val_r_square: 0.9867\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    model.add(RepeatVector(after_day))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],'k-*',label='train')\n",
    "plt.plot(history.history['val_loss'],'r-*', label='test')\n",
    "plt.legend()\n",
    "plt.title(\"GRU loss during training Covid19 and Sars\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Agriculture','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 11s 2ms/step - loss: 0.0348 - acc: 0.7535 - rmse: 0.1535 - mse: 0.0348 - r_square: 0.3632 - val_loss: 0.0266 - val_acc: 0.8994 - val_rmse: 0.1475 - val_mse: 0.0266 - val_r_square: 0.8151\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0240 - acc: 0.8875 - rmse: 0.1242 - mse: 0.0240 - r_square: 0.5582 - val_loss: 0.0199 - val_acc: 0.8365 - val_rmse: 0.1338 - val_mse: 0.0199 - val_r_square: 0.8615\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0188 - acc: 0.8950 - rmse: 0.1051 - mse: 0.0188 - r_square: 0.6655 - val_loss: 0.0165 - val_acc: 0.8365 - val_rmse: 0.1232 - val_mse: 0.0165 - val_r_square: 0.8851\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0153 - acc: 0.8007 - rmse: 0.0932 - mse: 0.0153 - r_square: 0.7346 - val_loss: 0.0142 - val_acc: 0.8365 - val_rmse: 0.1151 - val_mse: 0.0142 - val_r_square: 0.8993\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0111 - acc: 0.8284 - rmse: 0.0731 - mse: 0.0111 - r_square: 0.7943 - val_loss: 0.0080 - val_acc: 0.8365 - val_rmse: 0.0838 - val_mse: 0.0080 - val_r_square: 0.9443\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0090 - acc: 0.8920 - rmse: 0.0606 - mse: 0.0090 - r_square: 0.8239 - val_loss: 0.0056 - val_acc: 0.8378 - val_rmse: 0.0631 - val_mse: 0.0056 - val_r_square: 0.9615\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0078 - acc: 0.8866 - rmse: 0.0529 - mse: 0.0078 - r_square: 0.8452 - val_loss: 0.0035 - val_acc: 0.8382 - val_rmse: 0.0470 - val_mse: 0.0035 - val_r_square: 0.9772\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0072 - acc: 0.8834 - rmse: 0.0500 - mse: 0.0072 - r_square: 0.8507 - val_loss: 0.0028 - val_acc: 0.8394 - val_rmse: 0.0420 - val_mse: 0.0028 - val_r_square: 0.9825\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0068 - acc: 0.8759 - rmse: 0.0477 - mse: 0.0068 - r_square: 0.8575 - val_loss: 0.0025 - val_acc: 0.8407 - val_rmse: 0.0381 - val_mse: 0.0025 - val_r_square: 0.9851\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0066 - acc: 0.8818 - rmse: 0.0462 - mse: 0.0066 - r_square: 0.8626 - val_loss: 0.0024 - val_acc: 0.8407 - val_rmse: 0.0380 - val_mse: 0.0024 - val_r_square: 0.9853\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0066 - acc: 0.8813 - rmse: 0.0471 - mse: 0.0066 - r_square: 0.8670 - val_loss: 0.0022 - val_acc: 0.8384 - val_rmse: 0.0336 - val_mse: 0.0022 - val_r_square: 0.9871\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0068 - acc: 0.9025 - rmse: 0.0496 - mse: 0.0068 - r_square: 0.8674 - val_loss: 0.0039 - val_acc: 0.8365 - val_rmse: 0.0496 - val_mse: 0.0039 - val_r_square: 0.9764\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0070 - acc: 0.8523 - rmse: 0.0534 - mse: 0.0070 - r_square: 0.8525 - val_loss: 0.0035 - val_acc: 0.8377 - val_rmse: 0.0520 - val_mse: 0.0035 - val_r_square: 0.9769\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0068 - acc: 0.8542 - rmse: 0.0502 - mse: 0.0068 - r_square: 0.8640 - val_loss: 0.0044 - val_acc: 0.8803 - val_rmse: 0.0598 - val_mse: 0.0044 - val_r_square: 0.9698\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0067 - acc: 0.9065 - rmse: 0.0498 - mse: 0.0067 - r_square: 0.8684 - val_loss: 0.0027 - val_acc: 0.8375 - val_rmse: 0.0427 - val_mse: 0.0027 - val_r_square: 0.9831\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0067 - acc: 0.9223 - rmse: 0.0507 - mse: 0.0067 - r_square: 0.8670 - val_loss: 0.0027 - val_acc: 0.8387 - val_rmse: 0.0442 - val_mse: 0.0027 - val_r_square: 0.9822\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0064 - acc: 0.9022 - rmse: 0.0488 - mse: 0.0064 - r_square: 0.8731 - val_loss: 0.0027 - val_acc: 0.8398 - val_rmse: 0.0434 - val_mse: 0.0027 - val_r_square: 0.9826\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 276us/step - loss: 0.0061 - acc: 0.9256 - rmse: 0.0452 - mse: 0.0061 - r_square: 0.8804 - val_loss: 0.0024 - val_acc: 0.8385 - val_rmse: 0.0389 - val_mse: 0.0024 - val_r_square: 0.9852\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0064 - acc: 0.9223 - rmse: 0.0473 - mse: 0.0064 - r_square: 0.8767 - val_loss: 0.0027 - val_acc: 0.8395 - val_rmse: 0.0440 - val_mse: 0.0027 - val_r_square: 0.9823\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0065 - acc: 0.9189 - rmse: 0.0483 - mse: 0.0065 - r_square: 0.8770 - val_loss: 0.0033 - val_acc: 0.8389 - val_rmse: 0.0501 - val_mse: 0.0033 - val_r_square: 0.9783\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0070 - acc: 0.8880 - rmse: 0.0526 - mse: 0.0070 - r_square: 0.8696 - val_loss: 0.0044 - val_acc: 0.9184 - val_rmse: 0.0596 - val_mse: 0.0044 - val_r_square: 0.9697\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0065 - acc: 0.9225 - rmse: 0.0498 - mse: 0.0065 - r_square: 0.8776 - val_loss: 0.0026 - val_acc: 0.9158 - val_rmse: 0.0422 - val_mse: 0.0026 - val_r_square: 0.9827\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0060 - acc: 0.9576 - rmse: 0.0450 - mse: 0.0060 - r_square: 0.8841 - val_loss: 0.0017 - val_acc: 0.9293 - val_rmse: 0.0267 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0057 - acc: 0.9559 - rmse: 0.0422 - mse: 0.0057 - r_square: 0.8866 - val_loss: 0.0019 - val_acc: 0.9760 - val_rmse: 0.0285 - val_mse: 0.0019 - val_r_square: 0.9891\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0055 - acc: 0.9399 - rmse: 0.0393 - mse: 0.0055 - r_square: 0.8923 - val_loss: 0.0021 - val_acc: 0.9888 - val_rmse: 0.0345 - val_mse: 0.0021 - val_r_square: 0.9869\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0055 - acc: 0.9144 - rmse: 0.0397 - mse: 0.0055 - r_square: 0.8896 - val_loss: 0.0023 - val_acc: 0.9885 - val_rmse: 0.0383 - val_mse: 0.0023 - val_r_square: 0.9850\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0058 - acc: 0.9126 - rmse: 0.0396 - mse: 0.0058 - r_square: 0.8836 - val_loss: 0.0022 - val_acc: 0.9895 - val_rmse: 0.0354 - val_mse: 0.0022 - val_r_square: 0.9862\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0053 - acc: 0.9260 - rmse: 0.0375 - mse: 0.0053 - r_square: 0.8935 - val_loss: 0.0019 - val_acc: 0.9901 - val_rmse: 0.0313 - val_mse: 0.0019 - val_r_square: 0.9882\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0053 - acc: 0.9277 - rmse: 0.0378 - mse: 0.0053 - r_square: 0.8926 - val_loss: 0.0017 - val_acc: 0.9883 - val_rmse: 0.0278 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0052 - acc: 0.9492 - rmse: 0.0369 - mse: 0.0052 - r_square: 0.8948 - val_loss: 0.0016 - val_acc: 0.9748 - val_rmse: 0.0263 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0051 - acc: 0.9395 - rmse: 0.0365 - mse: 0.0051 - r_square: 0.8949 - val_loss: 0.0015 - val_acc: 0.9159 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0051 - acc: 0.9405 - rmse: 0.0357 - mse: 0.0051 - r_square: 0.8966 - val_loss: 0.0015 - val_acc: 0.9031 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0050 - acc: 0.9320 - rmse: 0.0345 - mse: 0.0050 - r_square: 0.8981 - val_loss: 0.0015 - val_acc: 0.9036 - val_rmse: 0.0244 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0050 - acc: 0.9359 - rmse: 0.0342 - mse: 0.0050 - r_square: 0.8983 - val_loss: 0.0015 - val_acc: 0.8903 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9297 - rmse: 0.0340 - mse: 0.0050 - r_square: 0.8977 - val_loss: 0.0016 - val_acc: 0.9028 - val_rmse: 0.0266 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9305 - rmse: 0.0344 - mse: 0.0052 - r_square: 0.8940 - val_loss: 0.0016 - val_acc: 0.8893 - val_rmse: 0.0271 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0049 - acc: 0.9269 - rmse: 0.0337 - mse: 0.0049 - r_square: 0.9013 - val_loss: 0.0016 - val_acc: 0.9014 - val_rmse: 0.0276 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0049 - acc: 0.9309 - rmse: 0.0329 - mse: 0.0049 - r_square: 0.9032 - val_loss: 0.0016 - val_acc: 0.8895 - val_rmse: 0.0279 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0049 - acc: 0.9312 - rmse: 0.0331 - mse: 0.0049 - r_square: 0.9036 - val_loss: 0.0017 - val_acc: 0.8767 - val_rmse: 0.0291 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0049 - acc: 0.9316 - rmse: 0.0330 - mse: 0.0049 - r_square: 0.9042 - val_loss: 0.0017 - val_acc: 0.8765 - val_rmse: 0.0292 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0049 - acc: 0.9318 - rmse: 0.0334 - mse: 0.0049 - r_square: 0.9045 - val_loss: 0.0018 - val_acc: 0.8756 - val_rmse: 0.0306 - val_mse: 0.0018 - val_r_square: 0.9888\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0049 - acc: 0.9412 - rmse: 0.0334 - mse: 0.0049 - r_square: 0.9047 - val_loss: 0.0018 - val_acc: 0.8637 - val_rmse: 0.0306 - val_mse: 0.0018 - val_r_square: 0.9888\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0049 - acc: 0.9411 - rmse: 0.0338 - mse: 0.0049 - r_square: 0.9049 - val_loss: 0.0018 - val_acc: 0.8630 - val_rmse: 0.0317 - val_mse: 0.0018 - val_r_square: 0.9884\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0049 - acc: 0.9557 - rmse: 0.0342 - mse: 0.0049 - r_square: 0.9044 - val_loss: 0.0018 - val_acc: 0.8620 - val_rmse: 0.0314 - val_mse: 0.0018 - val_r_square: 0.9885\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0050 - acc: 0.9588 - rmse: 0.0349 - mse: 0.0050 - r_square: 0.9032 - val_loss: 0.0019 - val_acc: 0.8751 - val_rmse: 0.0324 - val_mse: 0.0019 - val_r_square: 0.9880\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 273us/step - loss: 0.0051 - acc: 0.9605 - rmse: 0.0357 - mse: 0.0051 - r_square: 0.9011 - val_loss: 0.0019 - val_acc: 0.9335 - val_rmse: 0.0318 - val_mse: 0.0019 - val_r_square: 0.9882\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0052 - acc: 0.9589 - rmse: 0.0365 - mse: 0.0052 - r_square: 0.8995 - val_loss: 0.0019 - val_acc: 0.9478 - val_rmse: 0.0319 - val_mse: 0.0019 - val_r_square: 0.9882\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0051 - acc: 0.9605 - rmse: 0.0366 - mse: 0.0051 - r_square: 0.9028 - val_loss: 0.0018 - val_acc: 0.9853 - val_rmse: 0.0312 - val_mse: 0.0018 - val_r_square: 0.9884\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0051 - acc: 0.9612 - rmse: 0.0366 - mse: 0.0051 - r_square: 0.9042 - val_loss: 0.0017 - val_acc: 0.9882 - val_rmse: 0.0293 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0052 - acc: 0.9608 - rmse: 0.0374 - mse: 0.0052 - r_square: 0.9037 - val_loss: 0.0017 - val_acc: 0.9909 - val_rmse: 0.0295 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9614 - rmse: 0.0382 - mse: 0.0052 - r_square: 0.9030 - val_loss: 0.0018 - val_acc: 0.9922 - val_rmse: 0.0306 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0052 - acc: 0.9602 - rmse: 0.0381 - mse: 0.0052 - r_square: 0.9030 - val_loss: 0.0021 - val_acc: 0.9929 - val_rmse: 0.0347 - val_mse: 0.0021 - val_r_square: 0.9871\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0050 - acc: 0.9621 - rmse: 0.0373 - mse: 0.0050 - r_square: 0.9020 - val_loss: 0.0021 - val_acc: 0.9927 - val_rmse: 0.0347 - val_mse: 0.0021 - val_r_square: 0.9873\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0049 - acc: 0.9627 - rmse: 0.0356 - mse: 0.0049 - r_square: 0.9009 - val_loss: 0.0017 - val_acc: 0.9416 - val_rmse: 0.0287 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0054 - acc: 0.9341 - rmse: 0.0406 - mse: 0.0054 - r_square: 0.8892 - val_loss: 0.0017 - val_acc: 0.8369 - val_rmse: 0.0286 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0055 - acc: 0.9365 - rmse: 0.0418 - mse: 0.0055 - r_square: 0.8829 - val_loss: 0.0021 - val_acc: 0.8365 - val_rmse: 0.0354 - val_mse: 0.0021 - val_r_square: 0.9872\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0052 - acc: 0.9392 - rmse: 0.0384 - mse: 0.0052 - r_square: 0.8876 - val_loss: 0.0017 - val_acc: 0.8369 - val_rmse: 0.0296 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0047 - acc: 0.9599 - rmse: 0.0332 - mse: 0.0047 - r_square: 0.9014 - val_loss: 0.0016 - val_acc: 0.8495 - val_rmse: 0.0281 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0046 - acc: 0.9653 - rmse: 0.0304 - mse: 0.0046 - r_square: 0.9045 - val_loss: 0.0015 - val_acc: 0.8905 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0045 - acc: 0.9653 - rmse: 0.0291 - mse: 0.0045 - r_square: 0.9076 - val_loss: 0.0015 - val_acc: 0.9306 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0046 - acc: 0.9656 - rmse: 0.0287 - mse: 0.0046 - r_square: 0.9083 - val_loss: 0.0014 - val_acc: 0.9177 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0046 - acc: 0.9653 - rmse: 0.0283 - mse: 0.0046 - r_square: 0.9081 - val_loss: 0.0014 - val_acc: 0.9324 - val_rmse: 0.0236 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0046 - acc: 0.9659 - rmse: 0.0288 - mse: 0.0046 - r_square: 0.9073 - val_loss: 0.0014 - val_acc: 0.9181 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0045 - acc: 0.9649 - rmse: 0.0276 - mse: 0.0045 - r_square: 0.9100 - val_loss: 0.0015 - val_acc: 0.9439 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0045 - acc: 0.9663 - rmse: 0.0275 - mse: 0.0045 - r_square: 0.9115 - val_loss: 0.0014 - val_acc: 0.9312 - val_rmse: 0.0231 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0044 - acc: 0.9644 - rmse: 0.0269 - mse: 0.0044 - r_square: 0.9119 - val_loss: 0.0015 - val_acc: 0.9442 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9666 - rmse: 0.0269 - mse: 0.0044 - r_square: 0.9126 - val_loss: 0.0014 - val_acc: 0.9442 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9641 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9126 - val_loss: 0.0015 - val_acc: 0.9442 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0045 - acc: 0.9657 - rmse: 0.0271 - mse: 0.0045 - r_square: 0.9109 - val_loss: 0.0015 - val_acc: 0.9444 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0045 - acc: 0.9655 - rmse: 0.0268 - mse: 0.0045 - r_square: 0.9097 - val_loss: 0.0015 - val_acc: 0.9446 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0046 - acc: 0.9637 - rmse: 0.0275 - mse: 0.0046 - r_square: 0.9088 - val_loss: 0.0015 - val_acc: 0.9444 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0045 - acc: 0.9654 - rmse: 0.0268 - mse: 0.0045 - r_square: 0.9120 - val_loss: 0.0015 - val_acc: 0.9444 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9661 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9130 - val_loss: 0.0015 - val_acc: 0.9447 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0044 - acc: 0.9640 - rmse: 0.0264 - mse: 0.0044 - r_square: 0.9133 - val_loss: 0.0015 - val_acc: 0.9446 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9669 - rmse: 0.0262 - mse: 0.0044 - r_square: 0.9137 - val_loss: 0.0015 - val_acc: 0.9453 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9631 - rmse: 0.0264 - mse: 0.0044 - r_square: 0.9136 - val_loss: 0.0015 - val_acc: 0.9444 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9666 - rmse: 0.0263 - mse: 0.0044 - r_square: 0.9126 - val_loss: 0.0015 - val_acc: 0.9460 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0045 - acc: 0.9644 - rmse: 0.0269 - mse: 0.0045 - r_square: 0.9112 - val_loss: 0.0015 - val_acc: 0.9444 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0045 - acc: 0.9666 - rmse: 0.0266 - mse: 0.0045 - r_square: 0.9118 - val_loss: 0.0015 - val_acc: 0.9459 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0045 - acc: 0.9653 - rmse: 0.0268 - mse: 0.0045 - r_square: 0.9123 - val_loss: 0.0015 - val_acc: 0.9452 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9645 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9136 - val_loss: 0.0015 - val_acc: 0.9444 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0044 - acc: 0.9676 - rmse: 0.0266 - mse: 0.0044 - r_square: 0.9133 - val_loss: 0.0015 - val_acc: 0.9577 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0044 - acc: 0.9587 - rmse: 0.0266 - mse: 0.0044 - r_square: 0.9134 - val_loss: 0.0015 - val_acc: 0.9447 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0045 - acc: 0.9663 - rmse: 0.0273 - mse: 0.0045 - r_square: 0.9110 - val_loss: 0.0015 - val_acc: 0.9578 - val_rmse: 0.0233 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0045 - acc: 0.9608 - rmse: 0.0269 - mse: 0.0045 - r_square: 0.9121 - val_loss: 0.0015 - val_acc: 0.9459 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9654 - rmse: 0.0268 - mse: 0.0044 - r_square: 0.9132 - val_loss: 0.0015 - val_acc: 0.9583 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9660 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9142 - val_loss: 0.0015 - val_acc: 0.9583 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9658 - rmse: 0.0263 - mse: 0.0044 - r_square: 0.9149 - val_loss: 0.0015 - val_acc: 0.9583 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9670 - rmse: 0.0264 - mse: 0.0044 - r_square: 0.9148 - val_loss: 0.0015 - val_acc: 0.9585 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9645 - rmse: 0.0266 - mse: 0.0044 - r_square: 0.9142 - val_loss: 0.0015 - val_acc: 0.9467 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0046 - acc: 0.9673 - rmse: 0.0274 - mse: 0.0046 - r_square: 0.9109 - val_loss: 0.0015 - val_acc: 0.9587 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0045 - acc: 0.9638 - rmse: 0.0276 - mse: 0.0045 - r_square: 0.9115 - val_loss: 0.0015 - val_acc: 0.9585 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0045 - acc: 0.9674 - rmse: 0.0276 - mse: 0.0045 - r_square: 0.9123 - val_loss: 0.0015 - val_acc: 0.9587 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0044 - acc: 0.9679 - rmse: 0.0269 - mse: 0.0044 - r_square: 0.9139 - val_loss: 0.0015 - val_acc: 0.9584 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0044 - acc: 0.9670 - rmse: 0.0273 - mse: 0.0044 - r_square: 0.9136 - val_loss: 0.0015 - val_acc: 0.9587 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9670 - rmse: 0.0268 - mse: 0.0044 - r_square: 0.9143 - val_loss: 0.0015 - val_acc: 0.9585 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0045 - acc: 0.9664 - rmse: 0.0273 - mse: 0.0045 - r_square: 0.9136 - val_loss: 0.0015 - val_acc: 0.9585 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0045 - acc: 0.9669 - rmse: 0.0271 - mse: 0.0045 - r_square: 0.9138 - val_loss: 0.0015 - val_acc: 0.9587 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0045 - acc: 0.9666 - rmse: 0.0275 - mse: 0.0045 - r_square: 0.9137 - val_loss: 0.0015 - val_acc: 0.9587 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9670 - rmse: 0.0272 - mse: 0.0044 - r_square: 0.9145 - val_loss: 0.0015 - val_acc: 0.9587 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9907\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 13s 2ms/step - loss: 0.0282 - acc: 0.7359 - rmse: 0.1338 - mse: 0.0282 - r_square: 0.4631 - val_loss: 0.0070 - val_acc: 0.9368 - val_rmse: 0.0764 - val_mse: 0.0070 - val_r_square: 0.9530\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0141 - acc: 0.8742 - rmse: 0.0964 - mse: 0.0141 - r_square: 0.6487 - val_loss: 0.0067 - val_acc: 0.8365 - val_rmse: 0.0755 - val_mse: 0.0067 - val_r_square: 0.9554\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0102 - acc: 0.8811 - rmse: 0.0669 - mse: 0.0102 - r_square: 0.8043 - val_loss: 0.0034 - val_acc: 0.8365 - val_rmse: 0.0481 - val_mse: 0.0034 - val_r_square: 0.9785\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0079 - acc: 0.8770 - rmse: 0.0564 - mse: 0.0079 - r_square: 0.8407 - val_loss: 0.0031 - val_acc: 0.8365 - val_rmse: 0.0456 - val_mse: 0.0031 - val_r_square: 0.9805\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0072 - acc: 0.9017 - rmse: 0.0501 - mse: 0.0072 - r_square: 0.8539 - val_loss: 0.0028 - val_acc: 0.8365 - val_rmse: 0.0429 - val_mse: 0.0028 - val_r_square: 0.9820\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0062 - acc: 0.9045 - rmse: 0.0413 - mse: 0.0062 - r_square: 0.8770 - val_loss: 0.0019 - val_acc: 0.8392 - val_rmse: 0.0299 - val_mse: 0.0019 - val_r_square: 0.9885\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0058 - acc: 0.9099 - rmse: 0.0370 - mse: 0.0058 - r_square: 0.8848 - val_loss: 0.0018 - val_acc: 0.8397 - val_rmse: 0.0280 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0057 - acc: 0.9090 - rmse: 0.0358 - mse: 0.0057 - r_square: 0.8871 - val_loss: 0.0018 - val_acc: 0.8407 - val_rmse: 0.0288 - val_mse: 0.0018 - val_r_square: 0.9892\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0055 - acc: 0.9103 - rmse: 0.0353 - mse: 0.0055 - r_square: 0.8888 - val_loss: 0.0018 - val_acc: 0.8423 - val_rmse: 0.0293 - val_mse: 0.0018 - val_r_square: 0.9891\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0054 - acc: 0.9115 - rmse: 0.0343 - mse: 0.0054 - r_square: 0.8906 - val_loss: 0.0018 - val_acc: 0.8425 - val_rmse: 0.0293 - val_mse: 0.0018 - val_r_square: 0.9892\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0053 - acc: 0.9125 - rmse: 0.0339 - mse: 0.0053 - r_square: 0.8920 - val_loss: 0.0018 - val_acc: 0.8552 - val_rmse: 0.0293 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0053 - acc: 0.9129 - rmse: 0.0334 - mse: 0.0053 - r_square: 0.8921 - val_loss: 0.0017 - val_acc: 0.8551 - val_rmse: 0.0292 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0054 - acc: 0.9126 - rmse: 0.0335 - mse: 0.0054 - r_square: 0.8896 - val_loss: 0.0017 - val_acc: 0.8551 - val_rmse: 0.0283 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0051 - acc: 0.9154 - rmse: 0.0329 - mse: 0.0051 - r_square: 0.8942 - val_loss: 0.0018 - val_acc: 0.8543 - val_rmse: 0.0305 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0051 - acc: 0.9159 - rmse: 0.0328 - mse: 0.0051 - r_square: 0.8961 - val_loss: 0.0017 - val_acc: 0.8680 - val_rmse: 0.0297 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0050 - acc: 0.9174 - rmse: 0.0326 - mse: 0.0050 - r_square: 0.8959 - val_loss: 0.0017 - val_acc: 0.8531 - val_rmse: 0.0298 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0051 - acc: 0.9166 - rmse: 0.0324 - mse: 0.0051 - r_square: 0.8956 - val_loss: 0.0017 - val_acc: 0.8790 - val_rmse: 0.0290 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0050 - acc: 0.9188 - rmse: 0.0328 - mse: 0.0050 - r_square: 0.8967 - val_loss: 0.0019 - val_acc: 0.8405 - val_rmse: 0.0320 - val_mse: 0.0019 - val_r_square: 0.9885\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0050 - acc: 0.9179 - rmse: 0.0324 - mse: 0.0050 - r_square: 0.8974 - val_loss: 0.0017 - val_acc: 0.8667 - val_rmse: 0.0292 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9197 - rmse: 0.0322 - mse: 0.0049 - r_square: 0.8986 - val_loss: 0.0018 - val_acc: 0.8402 - val_rmse: 0.0304 - val_mse: 0.0018 - val_r_square: 0.9892\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0049 - acc: 0.9189 - rmse: 0.0321 - mse: 0.0049 - r_square: 0.8990 - val_loss: 0.0017 - val_acc: 0.8659 - val_rmse: 0.0291 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0048 - acc: 0.9206 - rmse: 0.0317 - mse: 0.0048 - r_square: 0.8999 - val_loss: 0.0017 - val_acc: 0.8395 - val_rmse: 0.0285 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9192 - rmse: 0.0317 - mse: 0.0049 - r_square: 0.9000 - val_loss: 0.0016 - val_acc: 0.8656 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0048 - acc: 0.9207 - rmse: 0.0313 - mse: 0.0048 - r_square: 0.9009 - val_loss: 0.0016 - val_acc: 0.8398 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0048 - acc: 0.9196 - rmse: 0.0312 - mse: 0.0048 - r_square: 0.9010 - val_loss: 0.0015 - val_acc: 0.8653 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0048 - acc: 0.9209 - rmse: 0.0307 - mse: 0.0048 - r_square: 0.9025 - val_loss: 0.0015 - val_acc: 0.8394 - val_rmse: 0.0257 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9196 - rmse: 0.0308 - mse: 0.0048 - r_square: 0.9025 - val_loss: 0.0014 - val_acc: 0.8516 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0047 - acc: 0.9221 - rmse: 0.0305 - mse: 0.0047 - r_square: 0.9036 - val_loss: 0.0015 - val_acc: 0.8389 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9915\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0048 - acc: 0.9197 - rmse: 0.0308 - mse: 0.0048 - r_square: 0.9032 - val_loss: 0.0014 - val_acc: 0.8389 - val_rmse: 0.0223 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0047 - acc: 0.9227 - rmse: 0.0308 - mse: 0.0047 - r_square: 0.9039 - val_loss: 0.0015 - val_acc: 0.8384 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9916\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0048 - acc: 0.9210 - rmse: 0.0313 - mse: 0.0048 - r_square: 0.9033 - val_loss: 0.0014 - val_acc: 0.8385 - val_rmse: 0.0215 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0047 - acc: 0.9242 - rmse: 0.0315 - mse: 0.0047 - r_square: 0.9039 - val_loss: 0.0015 - val_acc: 0.8379 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0048 - acc: 0.9216 - rmse: 0.0320 - mse: 0.0048 - r_square: 0.9032 - val_loss: 0.0014 - val_acc: 0.8379 - val_rmse: 0.0208 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9252 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9039 - val_loss: 0.0015 - val_acc: 0.8375 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9221 - rmse: 0.0332 - mse: 0.0048 - r_square: 0.9030 - val_loss: 0.0015 - val_acc: 0.8374 - val_rmse: 0.0213 - val_mse: 0.0015 - val_r_square: 0.9918\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0048 - acc: 0.9539 - rmse: 0.0337 - mse: 0.0048 - r_square: 0.9027 - val_loss: 0.0017 - val_acc: 0.8368 - val_rmse: 0.0269 - val_mse: 0.0017 - val_r_square: 0.9904\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0050 - acc: 0.9228 - rmse: 0.0360 - mse: 0.0050 - r_square: 0.9004 - val_loss: 0.0017 - val_acc: 0.8368 - val_rmse: 0.0249 - val_mse: 0.0017 - val_r_square: 0.9906\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0050 - acc: 0.9671 - rmse: 0.0369 - mse: 0.0050 - r_square: 0.8973 - val_loss: 0.0019 - val_acc: 0.8365 - val_rmse: 0.0315 - val_mse: 0.0019 - val_r_square: 0.9886\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0054 - acc: 0.9181 - rmse: 0.0413 - mse: 0.0054 - r_square: 0.8926 - val_loss: 0.0018 - val_acc: 0.8368 - val_rmse: 0.0292 - val_mse: 0.0018 - val_r_square: 0.9895\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0053 - acc: 0.9661 - rmse: 0.0414 - mse: 0.0053 - r_square: 0.8867 - val_loss: 0.0020 - val_acc: 0.8365 - val_rmse: 0.0335 - val_mse: 0.0020 - val_r_square: 0.9879\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0061 - acc: 0.8646 - rmse: 0.0490 - mse: 0.0061 - r_square: 0.8835 - val_loss: 0.0027 - val_acc: 0.8644 - val_rmse: 0.0444 - val_mse: 0.0027 - val_r_square: 0.9821\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0055 - acc: 0.9632 - rmse: 0.0443 - mse: 0.0055 - r_square: 0.8778 - val_loss: 0.0017 - val_acc: 0.9008 - val_rmse: 0.0286 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0062 - acc: 0.9617 - rmse: 0.0489 - mse: 0.0062 - r_square: 0.8873 - val_loss: 0.0018 - val_acc: 0.9046 - val_rmse: 0.0310 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0052 - acc: 0.9424 - rmse: 0.0386 - mse: 0.0052 - r_square: 0.8983 - val_loss: 0.0015 - val_acc: 0.9138 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0053 - acc: 0.9522 - rmse: 0.0410 - mse: 0.0053 - r_square: 0.8940 - val_loss: 0.0021 - val_acc: 0.9691 - val_rmse: 0.0353 - val_mse: 0.0021 - val_r_square: 0.9866\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0050 - acc: 0.8642 - rmse: 0.0363 - mse: 0.0050 - r_square: 0.9043 - val_loss: 0.0019 - val_acc: 0.9931 - val_rmse: 0.0310 - val_mse: 0.0019 - val_r_square: 0.9886\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0053 - acc: 0.9364 - rmse: 0.0385 - mse: 0.0053 - r_square: 0.9040 - val_loss: 0.0026 - val_acc: 0.9934 - val_rmse: 0.0410 - val_mse: 0.0026 - val_r_square: 0.9837\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0054 - acc: 0.9260 - rmse: 0.0405 - mse: 0.0054 - r_square: 0.9037 - val_loss: 0.0026 - val_acc: 0.9934 - val_rmse: 0.0423 - val_mse: 0.0026 - val_r_square: 0.9829\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0054 - acc: 0.9468 - rmse: 0.0418 - mse: 0.0054 - r_square: 0.9024 - val_loss: 0.0020 - val_acc: 0.9685 - val_rmse: 0.0339 - val_mse: 0.0020 - val_r_square: 0.9873\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0054 - acc: 0.9269 - rmse: 0.0416 - mse: 0.0054 - r_square: 0.8997 - val_loss: 0.0014 - val_acc: 0.8366 - val_rmse: 0.0206 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0053 - acc: 0.9085 - rmse: 0.0412 - mse: 0.0053 - r_square: 0.8938 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0205 - val_mse: 0.0015 - val_r_square: 0.9919\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0052 - acc: 0.8293 - rmse: 0.0404 - mse: 0.0052 - r_square: 0.8974 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0219 - val_mse: 0.0015 - val_r_square: 0.9916\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0050 - acc: 0.9193 - rmse: 0.0379 - mse: 0.0050 - r_square: 0.9027 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0050 - acc: 0.8649 - rmse: 0.0371 - mse: 0.0050 - r_square: 0.9048 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0266 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0050 - acc: 0.9330 - rmse: 0.0362 - mse: 0.0050 - r_square: 0.9066 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0289 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0051 - acc: 0.9162 - rmse: 0.0375 - mse: 0.0051 - r_square: 0.9049 - val_loss: 0.0018 - val_acc: 0.8368 - val_rmse: 0.0304 - val_mse: 0.0018 - val_r_square: 0.9892\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0050 - acc: 0.9463 - rmse: 0.0366 - mse: 0.0050 - r_square: 0.9065 - val_loss: 0.0017 - val_acc: 0.8368 - val_rmse: 0.0294 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0050 - acc: 0.9260 - rmse: 0.0376 - mse: 0.0050 - r_square: 0.9054 - val_loss: 0.0017 - val_acc: 0.8371 - val_rmse: 0.0284 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0049 - acc: 0.9457 - rmse: 0.0355 - mse: 0.0049 - r_square: 0.9082 - val_loss: 0.0016 - val_acc: 0.8371 - val_rmse: 0.0261 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0049 - acc: 0.9332 - rmse: 0.0359 - mse: 0.0049 - r_square: 0.9065 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0267 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0048 - acc: 0.9409 - rmse: 0.0339 - mse: 0.0048 - r_square: 0.9088 - val_loss: 0.0016 - val_acc: 0.8375 - val_rmse: 0.0265 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9113 - rmse: 0.0346 - mse: 0.0048 - r_square: 0.9070 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0292 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0047 - acc: 0.9266 - rmse: 0.0327 - mse: 0.0047 - r_square: 0.9102 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0284 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0047 - acc: 0.9224 - rmse: 0.0328 - mse: 0.0047 - r_square: 0.9104 - val_loss: 0.0017 - val_acc: 0.8379 - val_rmse: 0.0289 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0047 - acc: 0.9257 - rmse: 0.0318 - mse: 0.0047 - r_square: 0.9114 - val_loss: 0.0016 - val_acc: 0.8381 - val_rmse: 0.0278 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0047 - acc: 0.9255 - rmse: 0.0320 - mse: 0.0047 - r_square: 0.9095 - val_loss: 0.0016 - val_acc: 0.8379 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9254 - rmse: 0.0307 - mse: 0.0047 - r_square: 0.9106 - val_loss: 0.0016 - val_acc: 0.8382 - val_rmse: 0.0265 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9264 - rmse: 0.0301 - mse: 0.0046 - r_square: 0.9119 - val_loss: 0.0015 - val_acc: 0.8502 - val_rmse: 0.0257 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0045 - acc: 0.9263 - rmse: 0.0295 - mse: 0.0045 - r_square: 0.9129 - val_loss: 0.0015 - val_acc: 0.8507 - val_rmse: 0.0257 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0045 - acc: 0.9268 - rmse: 0.0289 - mse: 0.0045 - r_square: 0.9131 - val_loss: 0.0015 - val_acc: 0.8649 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0045 - acc: 0.9254 - rmse: 0.0283 - mse: 0.0045 - r_square: 0.9131 - val_loss: 0.0015 - val_acc: 0.8651 - val_rmse: 0.0253 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0046 - acc: 0.9275 - rmse: 0.0283 - mse: 0.0046 - r_square: 0.9114 - val_loss: 0.0015 - val_acc: 0.8787 - val_rmse: 0.0248 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0045 - acc: 0.9254 - rmse: 0.0274 - mse: 0.0045 - r_square: 0.9125 - val_loss: 0.0015 - val_acc: 0.8787 - val_rmse: 0.0253 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0044 - acc: 0.9281 - rmse: 0.0267 - mse: 0.0044 - r_square: 0.9152 - val_loss: 0.0015 - val_acc: 0.8916 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0044 - acc: 0.9259 - rmse: 0.0266 - mse: 0.0044 - r_square: 0.9155 - val_loss: 0.0015 - val_acc: 0.8916 - val_rmse: 0.0250 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0044 - acc: 0.9278 - rmse: 0.0262 - mse: 0.0044 - r_square: 0.9160 - val_loss: 0.0015 - val_acc: 0.8916 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0043 - acc: 0.9272 - rmse: 0.0261 - mse: 0.0043 - r_square: 0.9162 - val_loss: 0.0015 - val_acc: 0.9034 - val_rmse: 0.0248 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0043 - acc: 0.9276 - rmse: 0.0260 - mse: 0.0043 - r_square: 0.9162 - val_loss: 0.0015 - val_acc: 0.9040 - val_rmse: 0.0248 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0044 - acc: 0.9274 - rmse: 0.0260 - mse: 0.0044 - r_square: 0.9137 - val_loss: 0.0015 - val_acc: 0.9041 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0045 - acc: 0.9290 - rmse: 0.0265 - mse: 0.0045 - r_square: 0.9119 - val_loss: 0.0015 - val_acc: 0.9295 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0044 - acc: 0.9279 - rmse: 0.0261 - mse: 0.0044 - r_square: 0.9148 - val_loss: 0.0015 - val_acc: 0.9164 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0043 - acc: 0.9295 - rmse: 0.0254 - mse: 0.0043 - r_square: 0.9164 - val_loss: 0.0015 - val_acc: 0.9295 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0044 - acc: 0.9281 - rmse: 0.0253 - mse: 0.0044 - r_square: 0.9155 - val_loss: 0.0015 - val_acc: 0.9298 - val_rmse: 0.0243 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0044 - acc: 0.9280 - rmse: 0.0256 - mse: 0.0044 - r_square: 0.9152 - val_loss: 0.0015 - val_acc: 0.9308 - val_rmse: 0.0244 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0044 - acc: 0.9290 - rmse: 0.0252 - mse: 0.0044 - r_square: 0.9146 - val_loss: 0.0015 - val_acc: 0.9303 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0044 - acc: 0.9280 - rmse: 0.0254 - mse: 0.0044 - r_square: 0.9156 - val_loss: 0.0015 - val_acc: 0.9436 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0043 - acc: 0.9283 - rmse: 0.0253 - mse: 0.0043 - r_square: 0.9164 - val_loss: 0.0015 - val_acc: 0.9311 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0043 - acc: 0.9289 - rmse: 0.0251 - mse: 0.0043 - r_square: 0.9167 - val_loss: 0.0015 - val_acc: 0.9558 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0043 - acc: 0.9264 - rmse: 0.0252 - mse: 0.0043 - r_square: 0.9168 - val_loss: 0.0015 - val_acc: 0.9552 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0043 - acc: 0.9383 - rmse: 0.0252 - mse: 0.0043 - r_square: 0.9163 - val_loss: 0.0015 - val_acc: 0.9561 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0044 - acc: 0.9255 - rmse: 0.0255 - mse: 0.0044 - r_square: 0.9139 - val_loss: 0.0015 - val_acc: 0.9552 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0045 - acc: 0.9625 - rmse: 0.0259 - mse: 0.0045 - r_square: 0.9122 - val_loss: 0.0015 - val_acc: 0.9692 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0043 - acc: 0.9268 - rmse: 0.0256 - mse: 0.0043 - r_square: 0.9158 - val_loss: 0.0015 - val_acc: 0.9557 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0043 - acc: 0.9483 - rmse: 0.0247 - mse: 0.0043 - r_square: 0.9172 - val_loss: 0.0014 - val_acc: 0.9682 - val_rmse: 0.0231 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0043 - acc: 0.9269 - rmse: 0.0248 - mse: 0.0043 - r_square: 0.9163 - val_loss: 0.0015 - val_acc: 0.9682 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0044 - acc: 0.9288 - rmse: 0.0252 - mse: 0.0044 - r_square: 0.9157 - val_loss: 0.0015 - val_acc: 0.9683 - val_rmse: 0.0233 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0044 - acc: 0.9347 - rmse: 0.0249 - mse: 0.0044 - r_square: 0.9147 - val_loss: 0.0014 - val_acc: 0.9685 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0044 - acc: 0.9270 - rmse: 0.0253 - mse: 0.0044 - r_square: 0.9151 - val_loss: 0.0015 - val_acc: 0.9686 - val_rmse: 0.0231 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0044 - acc: 0.9350 - rmse: 0.0251 - mse: 0.0044 - r_square: 0.9163 - val_loss: 0.0015 - val_acc: 0.9686 - val_rmse: 0.0231 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0043 - acc: 0.9335 - rmse: 0.0253 - mse: 0.0043 - r_square: 0.9165 - val_loss: 0.0014 - val_acc: 0.9688 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9913\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_14 (RepeatVect (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 11s 2ms/step - loss: 0.0147 - acc: 0.7676 - mse: 0.0147 - rmse: 0.0974 - r_square: 0.5798 - val_loss: 0.0094 - val_acc: 0.9934 - val_mse: 0.0094 - val_rmse: 0.0911 - val_r_square: 0.9351\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0138 - acc: 0.8622 - mse: 0.0138 - rmse: 0.0988 - r_square: 0.5462 - val_loss: 0.0077 - val_acc: 0.9942 - val_mse: 0.0077 - val_rmse: 0.0822 - val_r_square: 0.9466\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0093 - acc: 0.9008 - mse: 0.0093 - rmse: 0.0708 - r_square: 0.7733 - val_loss: 0.0025 - val_acc: 0.9942 - val_mse: 0.0025 - val_rmse: 0.0401 - val_r_square: 0.9845\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 235us/step - loss: 0.0096 - acc: 0.9083 - mse: 0.0096 - rmse: 0.0720 - r_square: 0.7461 - val_loss: 0.0033 - val_acc: 0.9293 - val_mse: 0.0033 - val_rmse: 0.0461 - val_r_square: 0.9800\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 235us/step - loss: 0.0084 - acc: 0.9067 - mse: 0.0084 - rmse: 0.0631 - r_square: 0.8258 - val_loss: 0.0038 - val_acc: 0.8366 - val_mse: 0.0038 - val_rmse: 0.0555 - val_r_square: 0.9749\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 241us/step - loss: 0.0123 - acc: 0.8127 - mse: 0.0123 - rmse: 0.0896 - r_square: 0.6901 - val_loss: 0.0023 - val_acc: 0.8851 - val_mse: 0.0023 - val_rmse: 0.0341 - val_r_square: 0.9865\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 239us/step - loss: 0.0096 - acc: 0.9322 - mse: 0.0096 - rmse: 0.0738 - r_square: 0.6543 - val_loss: 0.0035 - val_acc: 0.9942 - val_mse: 0.0035 - val_rmse: 0.0494 - val_r_square: 0.9771\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 246us/step - loss: 0.0090 - acc: 0.8780 - mse: 0.0090 - rmse: 0.0620 - r_square: 0.8121 - val_loss: 0.0041 - val_acc: 0.8615 - val_mse: 0.0041 - val_rmse: 0.0569 - val_r_square: 0.9724\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0081 - acc: 0.7659 - mse: 0.0081 - rmse: 0.0590 - r_square: 0.8155 - val_loss: 0.0022 - val_acc: 0.8365 - val_mse: 0.0022 - val_rmse: 0.0343 - val_r_square: 0.9871\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 245us/step - loss: 0.0093 - acc: 0.9541 - mse: 0.0093 - rmse: 0.0719 - r_square: 0.7678 - val_loss: 0.0040 - val_acc: 0.8365 - val_mse: 0.0040 - val_rmse: 0.0559 - val_r_square: 0.9739\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 247us/step - loss: 0.0083 - acc: 0.9182 - mse: 0.0083 - rmse: 0.0605 - r_square: 0.7782 - val_loss: 0.0020 - val_acc: 0.8528 - val_mse: 0.0020 - val_rmse: 0.0295 - val_r_square: 0.9884\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 250us/step - loss: 0.0080 - acc: 0.9242 - mse: 0.0080 - rmse: 0.0610 - r_square: 0.8437 - val_loss: 0.0047 - val_acc: 0.8365 - val_mse: 0.0047 - val_rmse: 0.0567 - val_r_square: 0.9717\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 252us/step - loss: 0.0083 - acc: 0.9144 - mse: 0.0083 - rmse: 0.0638 - r_square: 0.8086 - val_loss: 0.0063 - val_acc: 0.8365 - val_mse: 0.0063 - val_rmse: 0.0745 - val_r_square: 0.9568\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0073 - acc: 0.9182 - mse: 0.0073 - rmse: 0.0518 - r_square: 0.8476 - val_loss: 0.0047 - val_acc: 0.8365 - val_mse: 0.0047 - val_rmse: 0.0634 - val_r_square: 0.9682\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 254us/step - loss: 0.0061 - acc: 0.9171 - mse: 0.0061 - rmse: 0.0497 - r_square: 0.8673 - val_loss: 0.0020 - val_acc: 0.8369 - val_mse: 0.0020 - val_rmse: 0.0306 - val_r_square: 0.9885\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0060 - acc: 0.9626 - mse: 0.0060 - rmse: 0.0463 - r_square: 0.8851 - val_loss: 0.0014 - val_acc: 0.8369 - val_mse: 0.0014 - val_rmse: 0.0207 - val_r_square: 0.9920\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0062 - acc: 0.9265 - mse: 0.0062 - rmse: 0.0470 - r_square: 0.8747 - val_loss: 0.0031 - val_acc: 0.8366 - val_mse: 0.0031 - val_rmse: 0.0486 - val_r_square: 0.9798\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0066 - acc: 0.8687 - mse: 0.0066 - rmse: 0.0483 - r_square: 0.8812 - val_loss: 0.0079 - val_acc: 0.9790 - val_mse: 0.0079 - val_rmse: 0.0843 - val_r_square: 0.9430\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0055 - acc: 0.9680 - mse: 0.0055 - rmse: 0.0465 - r_square: 0.8784 - val_loss: 0.0021 - val_acc: 0.9537 - val_mse: 0.0021 - val_rmse: 0.0314 - val_r_square: 0.9871\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0057 - acc: 0.8956 - mse: 0.0057 - rmse: 0.0436 - r_square: 0.8856 - val_loss: 0.0027 - val_acc: 0.9426 - val_mse: 0.0027 - val_rmse: 0.0433 - val_r_square: 0.9820\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0056 - acc: 0.9222 - mse: 0.0056 - rmse: 0.0426 - r_square: 0.8948 - val_loss: 0.0037 - val_acc: 0.9426 - val_mse: 0.0037 - val_rmse: 0.0535 - val_r_square: 0.9748\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0051 - acc: 0.9097 - mse: 0.0051 - rmse: 0.0424 - r_square: 0.8815 - val_loss: 0.0022 - val_acc: 0.8880 - val_mse: 0.0022 - val_rmse: 0.0364 - val_r_square: 0.9858\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0050 - acc: 0.9654 - mse: 0.0050 - rmse: 0.0374 - r_square: 0.8945 - val_loss: 0.0019 - val_acc: 0.9660 - val_mse: 0.0019 - val_rmse: 0.0313 - val_r_square: 0.9883\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 228us/step - loss: 0.0050 - acc: 0.9519 - mse: 0.0050 - rmse: 0.0377 - r_square: 0.8939 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0297 - val_r_square: 0.9891\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0050 - acc: 0.9395 - mse: 0.0050 - rmse: 0.0371 - r_square: 0.9014 - val_loss: 0.0021 - val_acc: 0.9942 - val_mse: 0.0021 - val_rmse: 0.0352 - val_r_square: 0.9867\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0049 - acc: 0.9698 - mse: 0.0049 - rmse: 0.0377 - r_square: 0.8962 - val_loss: 0.0024 - val_acc: 0.9768 - val_mse: 0.0024 - val_rmse: 0.0386 - val_r_square: 0.9839\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0055 - acc: 0.8754 - mse: 0.0055 - rmse: 0.0427 - r_square: 0.8862 - val_loss: 0.0020 - val_acc: 0.8490 - val_mse: 0.0020 - val_rmse: 0.0327 - val_r_square: 0.9877\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0055 - acc: 0.7568 - mse: 0.0055 - rmse: 0.0429 - r_square: 0.8846 - val_loss: 0.0016 - val_acc: 0.8377 - val_mse: 0.0016 - val_rmse: 0.0263 - val_r_square: 0.9904\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0066 - acc: 0.9468 - mse: 0.0066 - rmse: 0.0489 - r_square: 0.8907 - val_loss: 0.0051 - val_acc: 0.9942 - val_mse: 0.0051 - val_rmse: 0.0651 - val_r_square: 0.9650\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0055 - acc: 0.9662 - mse: 0.0055 - rmse: 0.0439 - r_square: 0.8667 - val_loss: 0.0025 - val_acc: 0.9915 - val_mse: 0.0025 - val_rmse: 0.0399 - val_r_square: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0049 - acc: 0.9261 - mse: 0.0049 - rmse: 0.0365 - r_square: 0.8918 - val_loss: 0.0014 - val_acc: 0.9915 - val_mse: 0.0014 - val_rmse: 0.0203 - val_r_square: 0.9920\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0052 - acc: 0.9481 - mse: 0.0052 - rmse: 0.0391 - r_square: 0.8996 - val_loss: 0.0021 - val_acc: 0.9942 - val_mse: 0.0021 - val_rmse: 0.0342 - val_r_square: 0.9871\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0051 - acc: 0.9479 - mse: 0.0051 - rmse: 0.0392 - r_square: 0.8941 - val_loss: 0.0023 - val_acc: 0.9927 - val_mse: 0.0023 - val_rmse: 0.0377 - val_r_square: 0.9848\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0050 - acc: 0.9267 - mse: 0.0050 - rmse: 0.0389 - r_square: 0.8948 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0237 - val_r_square: 0.9911\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0052 - acc: 0.9675 - mse: 0.0052 - rmse: 0.0417 - r_square: 0.8911 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0270 - val_r_square: 0.9895\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0051 - acc: 0.9689 - mse: 0.0051 - rmse: 0.0376 - r_square: 0.9028 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0341 - val_r_square: 0.9872\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0050 - acc: 0.9256 - mse: 0.0050 - rmse: 0.0366 - r_square: 0.9021 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0382 - val_r_square: 0.9849\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0052 - acc: 0.9213 - mse: 0.0052 - rmse: 0.0419 - r_square: 0.8736 - val_loss: 0.0015 - val_acc: 0.9787 - val_mse: 0.0015 - val_rmse: 0.0216 - val_r_square: 0.9916\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0049 - acc: 0.9696 - mse: 0.0049 - rmse: 0.0378 - r_square: 0.9027 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0299 - val_r_square: 0.9888\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0050 - acc: 0.8049 - mse: 0.0050 - rmse: 0.0362 - r_square: 0.9034 - val_loss: 0.0017 - val_acc: 0.9820 - val_mse: 0.0017 - val_rmse: 0.0276 - val_r_square: 0.9897\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0051 - acc: 0.9094 - mse: 0.0051 - rmse: 0.0386 - r_square: 0.9050 - val_loss: 0.0035 - val_acc: 0.9942 - val_mse: 0.0035 - val_rmse: 0.0519 - val_r_square: 0.9762\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0052 - acc: 0.9639 - mse: 0.0052 - rmse: 0.0420 - r_square: 0.8831 - val_loss: 0.0024 - val_acc: 0.9786 - val_mse: 0.0024 - val_rmse: 0.0386 - val_r_square: 0.9845\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0051 - acc: 0.8755 - mse: 0.0051 - rmse: 0.0390 - r_square: 0.8970 - val_loss: 0.0015 - val_acc: 0.8638 - val_mse: 0.0015 - val_rmse: 0.0233 - val_r_square: 0.9912\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0053 - acc: 0.7160 - mse: 0.0053 - rmse: 0.0415 - r_square: 0.8925 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0387 - val_r_square: 0.9848\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0050 - acc: 0.9663 - mse: 0.0050 - rmse: 0.0372 - r_square: 0.8973 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0307 - val_r_square: 0.9883\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0052 - acc: 0.9252 - mse: 0.0052 - rmse: 0.0407 - r_square: 0.8876 - val_loss: 0.0017 - val_acc: 0.8815 - val_mse: 0.0017 - val_rmse: 0.0276 - val_r_square: 0.9900\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0049 - acc: 0.9436 - mse: 0.0049 - rmse: 0.0363 - r_square: 0.9025 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0238 - val_r_square: 0.9911\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0052 - acc: 0.9691 - mse: 0.0052 - rmse: 0.0379 - r_square: 0.8944 - val_loss: 0.0022 - val_acc: 0.9942 - val_mse: 0.0022 - val_rmse: 0.0359 - val_r_square: 0.9856\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0050 - acc: 0.9245 - mse: 0.0050 - rmse: 0.0396 - r_square: 0.8924 - val_loss: 0.0024 - val_acc: 0.8918 - val_mse: 0.0024 - val_rmse: 0.0391 - val_r_square: 0.9847\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0052 - acc: 0.9251 - mse: 0.0052 - rmse: 0.0410 - r_square: 0.8856 - val_loss: 0.0015 - val_acc: 0.8692 - val_mse: 0.0015 - val_rmse: 0.0247 - val_r_square: 0.9910\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0049 - acc: 0.9670 - mse: 0.0049 - rmse: 0.0373 - r_square: 0.9011 - val_loss: 0.0018 - val_acc: 0.9931 - val_mse: 0.0018 - val_rmse: 0.0305 - val_r_square: 0.9886\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0047 - acc: 0.9589 - mse: 0.0047 - rmse: 0.0344 - r_square: 0.9078 - val_loss: 0.0019 - val_acc: 0.9564 - val_mse: 0.0019 - val_rmse: 0.0311 - val_r_square: 0.9882\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0050 - acc: 0.9207 - mse: 0.0050 - rmse: 0.0401 - r_square: 0.8905 - val_loss: 0.0016 - val_acc: 0.9823 - val_mse: 0.0016 - val_rmse: 0.0251 - val_r_square: 0.9909\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0055 - acc: 0.9375 - mse: 0.0055 - rmse: 0.0443 - r_square: 0.8841 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0310 - val_r_square: 0.9887\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0056 - acc: 0.9646 - mse: 0.0056 - rmse: 0.0459 - r_square: 0.8700 - val_loss: 0.0027 - val_acc: 0.8365 - val_mse: 0.0027 - val_rmse: 0.0427 - val_r_square: 0.9823\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0054 - acc: 0.8880 - mse: 0.0054 - rmse: 0.0420 - r_square: 0.8839 - val_loss: 0.0029 - val_acc: 0.8542 - val_mse: 0.0029 - val_rmse: 0.0461 - val_r_square: 0.9806\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0051 - acc: 0.9218 - mse: 0.0051 - rmse: 0.0419 - r_square: 0.8707 - val_loss: 0.0013 - val_acc: 0.9456 - val_mse: 0.0013 - val_rmse: 0.0194 - val_r_square: 0.9924\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0054 - acc: 0.9210 - mse: 0.0054 - rmse: 0.0396 - r_square: 0.8972 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0256 - val_r_square: 0.9907\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0052 - acc: 0.9504 - mse: 0.0052 - rmse: 0.0397 - r_square: 0.8884 - val_loss: 0.0027 - val_acc: 0.8366 - val_mse: 0.0027 - val_rmse: 0.0442 - val_r_square: 0.9821\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0050 - acc: 0.9228 - mse: 0.0050 - rmse: 0.0369 - r_square: 0.8964 - val_loss: 0.0016 - val_acc: 0.8728 - val_mse: 0.0016 - val_rmse: 0.0275 - val_r_square: 0.9903\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0054 - acc: 0.9043 - mse: 0.0054 - rmse: 0.0423 - r_square: 0.8997 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0380 - val_r_square: 0.9857\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0053 - acc: 0.9487 - mse: 0.0053 - rmse: 0.0407 - r_square: 0.8821 - val_loss: 0.0026 - val_acc: 0.8506 - val_mse: 0.0026 - val_rmse: 0.0424 - val_r_square: 0.9824\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0051 - acc: 0.9213 - mse: 0.0051 - rmse: 0.0400 - r_square: 0.8898 - val_loss: 0.0018 - val_acc: 0.9557 - val_mse: 0.0018 - val_rmse: 0.0307 - val_r_square: 0.9887\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0049 - acc: 0.9386 - mse: 0.0049 - rmse: 0.0381 - r_square: 0.9028 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0301 - val_r_square: 0.9887\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0054 - acc: 0.9620 - mse: 0.0054 - rmse: 0.0411 - r_square: 0.8829 - val_loss: 0.0024 - val_acc: 0.8368 - val_mse: 0.0024 - val_rmse: 0.0395 - val_r_square: 0.9845\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0047 - acc: 0.9250 - mse: 0.0047 - rmse: 0.0326 - r_square: 0.9032 - val_loss: 0.0016 - val_acc: 0.8395 - val_mse: 0.0016 - val_rmse: 0.0272 - val_r_square: 0.9903\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0047 - acc: 0.9578 - mse: 0.0047 - rmse: 0.0339 - r_square: 0.9055 - val_loss: 0.0018 - val_acc: 0.9585 - val_mse: 0.0018 - val_rmse: 0.0304 - val_r_square: 0.9885\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0048 - acc: 0.9681 - mse: 0.0048 - rmse: 0.0365 - r_square: 0.8979 - val_loss: 0.0014 - val_acc: 0.8828 - val_mse: 0.0014 - val_rmse: 0.0214 - val_r_square: 0.9917\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0057 - acc: 0.9131 - mse: 0.0057 - rmse: 0.0440 - r_square: 0.8942 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0262 - val_r_square: 0.9900\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0048 - acc: 0.9700 - mse: 0.0048 - rmse: 0.0336 - r_square: 0.9001 - val_loss: 0.0019 - val_acc: 0.8807 - val_mse: 0.0019 - val_rmse: 0.0322 - val_r_square: 0.9879\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0051 - acc: 0.9684 - mse: 0.0051 - rmse: 0.0406 - r_square: 0.8909 - val_loss: 0.0017 - val_acc: 0.8893 - val_mse: 0.0017 - val_rmse: 0.0275 - val_r_square: 0.9900\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0050 - acc: 0.9298 - mse: 0.0050 - rmse: 0.0387 - r_square: 0.8971 - val_loss: 0.0013 - val_acc: 0.8441 - val_mse: 0.0013 - val_rmse: 0.0186 - val_r_square: 0.9926\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0058 - acc: 0.9654 - mse: 0.0058 - rmse: 0.0468 - r_square: 0.8672 - val_loss: 0.0022 - val_acc: 0.9942 - val_mse: 0.0022 - val_rmse: 0.0360 - val_r_square: 0.9857\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0048 - acc: 0.9368 - mse: 0.0048 - rmse: 0.0340 - r_square: 0.8987 - val_loss: 0.0020 - val_acc: 0.9043 - val_mse: 0.0020 - val_rmse: 0.0338 - val_r_square: 0.9872\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0052 - acc: 0.9680 - mse: 0.0052 - rmse: 0.0407 - r_square: 0.8935 - val_loss: 0.0025 - val_acc: 0.8708 - val_mse: 0.0025 - val_rmse: 0.0402 - val_r_square: 0.9842\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0050 - acc: 0.9233 - mse: 0.0050 - rmse: 0.0389 - r_square: 0.8986 - val_loss: 0.0014 - val_acc: 0.9424 - val_mse: 0.0014 - val_rmse: 0.0228 - val_r_square: 0.9915\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0051 - acc: 0.9633 - mse: 0.0051 - rmse: 0.0383 - r_square: 0.8987 - val_loss: 0.0028 - val_acc: 0.9820 - val_mse: 0.0028 - val_rmse: 0.0447 - val_r_square: 0.9809\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0051 - acc: 0.9653 - mse: 0.0051 - rmse: 0.0393 - r_square: 0.8908 - val_loss: 0.0022 - val_acc: 0.9136 - val_mse: 0.0022 - val_rmse: 0.0362 - val_r_square: 0.9857\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0047 - acc: 0.8781 - mse: 0.0047 - rmse: 0.0343 - r_square: 0.9053 - val_loss: 0.0015 - val_acc: 0.8569 - val_mse: 0.0015 - val_rmse: 0.0244 - val_r_square: 0.9913\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0049 - acc: 0.7898 - mse: 0.0049 - rmse: 0.0366 - r_square: 0.9058 - val_loss: 0.0024 - val_acc: 0.9942 - val_mse: 0.0024 - val_rmse: 0.0391 - val_r_square: 0.9842\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0050 - acc: 0.9642 - mse: 0.0050 - rmse: 0.0388 - r_square: 0.8922 - val_loss: 0.0022 - val_acc: 0.9023 - val_mse: 0.0022 - val_rmse: 0.0366 - val_r_square: 0.9858\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0048 - acc: 0.9250 - mse: 0.0048 - rmse: 0.0366 - r_square: 0.9003 - val_loss: 0.0013 - val_acc: 0.9937 - val_mse: 0.0013 - val_rmse: 0.0188 - val_r_square: 0.9925\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0049 - acc: 0.9550 - mse: 0.0049 - rmse: 0.0358 - r_square: 0.9005 - val_loss: 0.0017 - val_acc: 0.9800 - val_mse: 0.0017 - val_rmse: 0.0274 - val_r_square: 0.9898\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 226us/step - loss: 0.0049 - acc: 0.9197 - mse: 0.0049 - rmse: 0.0358 - r_square: 0.8990 - val_loss: 0.0018 - val_acc: 0.9567 - val_mse: 0.0018 - val_rmse: 0.0305 - val_r_square: 0.9886\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0049 - acc: 0.8758 - mse: 0.0049 - rmse: 0.0363 - r_square: 0.8948 - val_loss: 0.0016 - val_acc: 0.9581 - val_mse: 0.0016 - val_rmse: 0.0268 - val_r_square: 0.9903\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0051 - acc: 0.9563 - mse: 0.0051 - rmse: 0.0402 - r_square: 0.8874 - val_loss: 0.0017 - val_acc: 0.8945 - val_mse: 0.0017 - val_rmse: 0.0289 - val_r_square: 0.9895\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0049 - acc: 0.9650 - mse: 0.0049 - rmse: 0.0353 - r_square: 0.9020 - val_loss: 0.0017 - val_acc: 0.8649 - val_mse: 0.0017 - val_rmse: 0.0284 - val_r_square: 0.9896\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0050 - acc: 0.8464 - mse: 0.0050 - rmse: 0.0367 - r_square: 0.8910 - val_loss: 0.0020 - val_acc: 0.8375 - val_mse: 0.0020 - val_rmse: 0.0343 - val_r_square: 0.9875\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0048 - acc: 0.9233 - mse: 0.0048 - rmse: 0.0350 - r_square: 0.9014 - val_loss: 0.0019 - val_acc: 0.9062 - val_mse: 0.0019 - val_rmse: 0.0325 - val_r_square: 0.9881\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0049 - acc: 0.9262 - mse: 0.0049 - rmse: 0.0390 - r_square: 0.8961 - val_loss: 0.0013 - val_acc: 0.8993 - val_mse: 0.0013 - val_rmse: 0.0204 - val_r_square: 0.9923\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0049 - acc: 0.9680 - mse: 0.0049 - rmse: 0.0376 - r_square: 0.8890 - val_loss: 0.0015 - val_acc: 0.8397 - val_mse: 0.0015 - val_rmse: 0.0256 - val_r_square: 0.9909\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0048 - acc: 0.8859 - mse: 0.0048 - rmse: 0.0348 - r_square: 0.8913 - val_loss: 0.0018 - val_acc: 0.8562 - val_mse: 0.0018 - val_rmse: 0.0308 - val_r_square: 0.9891\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0048 - acc: 0.9039 - mse: 0.0048 - rmse: 0.0366 - r_square: 0.9019 - val_loss: 0.0020 - val_acc: 0.8702 - val_mse: 0.0020 - val_rmse: 0.0344 - val_r_square: 0.9871\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0050 - acc: 0.9351 - mse: 0.0050 - rmse: 0.0395 - r_square: 0.8945 - val_loss: 0.0024 - val_acc: 0.8436 - val_mse: 0.0024 - val_rmse: 0.0386 - val_r_square: 0.9851\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0049 - acc: 0.8461 - mse: 0.0049 - rmse: 0.0368 - r_square: 0.9007 - val_loss: 0.0017 - val_acc: 0.8765 - val_mse: 0.0017 - val_rmse: 0.0283 - val_r_square: 0.9898\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0056 - acc: 0.9681 - mse: 0.0056 - rmse: 0.0448 - r_square: 0.8750 - val_loss: 0.0030 - val_acc: 0.8821 - val_mse: 0.0030 - val_rmse: 0.0465 - val_r_square: 0.9805\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0048 - acc: 0.9247 - mse: 0.0048 - rmse: 0.0356 - r_square: 0.9054 - val_loss: 0.0018 - val_acc: 0.8371 - val_mse: 0.0018 - val_rmse: 0.0300 - val_r_square: 0.9893\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0051 - acc: 0.8259 - mse: 0.0051 - rmse: 0.0399 - r_square: 0.8841 - val_loss: 0.0025 - val_acc: 0.8374 - val_mse: 0.0025 - val_rmse: 0.0404 - val_r_square: 0.9844\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0049 - acc: 0.9333 - mse: 0.0049 - rmse: 0.0378 - r_square: 0.8967 - val_loss: 0.0016 - val_acc: 0.8392 - val_mse: 0.0016 - val_rmse: 0.0249 - val_r_square: 0.9908\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0055 - acc: 0.9525 - mse: 0.0055 - rmse: 0.0451 - r_square: 0.8812 - val_loss: 0.0026 - val_acc: 0.9551 - val_mse: 0.0026 - val_rmse: 0.0411 - val_r_square: 0.9827\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed_x',\n",
       "       'Deaths', 'Recovered', 'Confirmed_y', 'Country', 'Region', 'Population',\n",
       "       'Area (sq. mi.)', 'Pop. Density (per sq. mi.)',\n",
       "       'Coastline (coast/area ratio)', 'Net migration',\n",
       "       'Infant mortality (per 1000 births)', 'GDP ($ per capita)',\n",
       "       'Literacy (%)', 'Phones (per 1000)', 'Arable (%)', 'Crops (%)',\n",
       "       'Climate', 'Birthrate', 'Deathrate', 'Agriculture', 'Industry',\n",
       "       'Service', 'Month', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region', 'Population','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 11s 2ms/step - loss: 0.0742 - acc: 0.6680 - rmse: 0.2424 - mse: 0.0742 - r_square: 0.2644 - val_loss: 0.0534 - val_acc: 0.8365 - val_rmse: 0.2218 - val_mse: 0.0534 - val_r_square: 0.6055\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0335 - acc: 0.9257 - rmse: 0.1563 - mse: 0.0335 - r_square: 0.5974 - val_loss: 0.0293 - val_acc: 0.8365 - val_rmse: 0.1633 - val_mse: 0.0293 - val_r_square: 0.7856\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0275 - acc: 0.8997 - rmse: 0.1411 - mse: 0.0275 - r_square: 0.5631 - val_loss: 0.0149 - val_acc: 0.9096 - val_rmse: 0.1042 - val_mse: 0.0149 - val_r_square: 0.8955\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0241 - acc: 0.9200 - rmse: 0.1295 - mse: 0.0241 - r_square: 0.6954 - val_loss: 0.0168 - val_acc: 0.8365 - val_rmse: 0.1221 - val_mse: 0.0168 - val_r_square: 0.8787\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0181 - acc: 0.9075 - rmse: 0.1044 - mse: 0.0181 - r_square: 0.7651 - val_loss: 0.0093 - val_acc: 0.8365 - val_rmse: 0.0807 - val_mse: 0.0093 - val_r_square: 0.9342\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0150 - acc: 0.9205 - rmse: 0.0921 - mse: 0.0150 - r_square: 0.8030 - val_loss: 0.0078 - val_acc: 0.8365 - val_rmse: 0.0758 - val_mse: 0.0078 - val_r_square: 0.9450\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0137 - acc: 0.9318 - rmse: 0.0851 - mse: 0.0137 - r_square: 0.8158 - val_loss: 0.0064 - val_acc: 0.9113 - val_rmse: 0.0621 - val_mse: 0.0064 - val_r_square: 0.9544\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0139 - acc: 0.9375 - rmse: 0.0882 - mse: 0.0139 - r_square: 0.8150 - val_loss: 0.0055 - val_acc: 0.8490 - val_rmse: 0.0619 - val_mse: 0.0055 - val_r_square: 0.9617\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0147 - acc: 0.9491 - rmse: 0.0929 - mse: 0.0147 - r_square: 0.8101 - val_loss: 0.0055 - val_acc: 0.8499 - val_rmse: 0.0615 - val_mse: 0.0055 - val_r_square: 0.9615\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0147 - acc: 0.9392 - rmse: 0.0974 - mse: 0.0147 - r_square: 0.7943 - val_loss: 0.0051 - val_acc: 0.8525 - val_rmse: 0.0608 - val_mse: 0.0051 - val_r_square: 0.9651\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0099 - acc: 0.9516 - rmse: 0.0718 - mse: 0.0099 - r_square: 0.8533 - val_loss: 0.0062 - val_acc: 0.9079 - val_rmse: 0.0697 - val_mse: 0.0062 - val_r_square: 0.9554\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0089 - acc: 0.9544 - rmse: 0.0682 - mse: 0.0089 - r_square: 0.8495 - val_loss: 0.0034 - val_acc: 0.8538 - val_rmse: 0.0465 - val_mse: 0.0034 - val_r_square: 0.9778\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0076 - acc: 0.9430 - rmse: 0.0538 - mse: 0.0076 - r_square: 0.8763 - val_loss: 0.0040 - val_acc: 0.8436 - val_rmse: 0.0553 - val_mse: 0.0040 - val_r_square: 0.9721\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0070 - acc: 0.9555 - rmse: 0.0515 - mse: 0.0070 - r_square: 0.8785 - val_loss: 0.0031 - val_acc: 0.8745 - val_rmse: 0.0459 - val_mse: 0.0031 - val_r_square: 0.9797\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0068 - acc: 0.9573 - rmse: 0.0475 - mse: 0.0068 - r_square: 0.8852 - val_loss: 0.0033 - val_acc: 0.8443 - val_rmse: 0.0495 - val_mse: 0.0033 - val_r_square: 0.9774\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0066 - acc: 0.9582 - rmse: 0.0465 - mse: 0.0066 - r_square: 0.8889 - val_loss: 0.0030 - val_acc: 0.8433 - val_rmse: 0.0460 - val_mse: 0.0030 - val_r_square: 0.9802\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0072 - acc: 0.9585 - rmse: 0.0533 - mse: 0.0072 - r_square: 0.8852 - val_loss: 0.0031 - val_acc: 0.8410 - val_rmse: 0.0466 - val_mse: 0.0031 - val_r_square: 0.9798\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0083 - acc: 0.9580 - rmse: 0.0629 - mse: 0.0083 - r_square: 0.8740 - val_loss: 0.0023 - val_acc: 0.8405 - val_rmse: 0.0374 - val_mse: 0.0023 - val_r_square: 0.9853\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0073 - acc: 0.9583 - rmse: 0.0558 - mse: 0.0073 - r_square: 0.8764 - val_loss: 0.0035 - val_acc: 0.8395 - val_rmse: 0.0519 - val_mse: 0.0035 - val_r_square: 0.9762\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0068 - acc: 0.9582 - rmse: 0.0488 - mse: 0.0068 - r_square: 0.8791 - val_loss: 0.0057 - val_acc: 0.9431 - val_rmse: 0.0692 - val_mse: 0.0057 - val_r_square: 0.9592\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0067 - acc: 0.9243 - rmse: 0.0482 - mse: 0.0067 - r_square: 0.8863 - val_loss: 0.0050 - val_acc: 0.9911 - val_rmse: 0.0643 - val_mse: 0.0050 - val_r_square: 0.9641\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0074 - acc: 0.8981 - rmse: 0.0566 - mse: 0.0074 - r_square: 0.8776 - val_loss: 0.0046 - val_acc: 0.9917 - val_rmse: 0.0610 - val_mse: 0.0046 - val_r_square: 0.9681\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0078 - acc: 0.9229 - rmse: 0.0610 - mse: 0.0078 - r_square: 0.8773 - val_loss: 0.0025 - val_acc: 0.9915 - val_rmse: 0.0406 - val_mse: 0.0025 - val_r_square: 0.9833\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0075 - acc: 0.9466 - rmse: 0.0518 - mse: 0.0075 - r_square: 0.8812 - val_loss: 0.0024 - val_acc: 0.9436 - val_rmse: 0.0384 - val_mse: 0.0024 - val_r_square: 0.9848\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0063 - acc: 0.9175 - rmse: 0.0472 - mse: 0.0063 - r_square: 0.8885 - val_loss: 0.0016 - val_acc: 0.8387 - val_rmse: 0.0269 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0063 - acc: 0.9203 - rmse: 0.0466 - mse: 0.0063 - r_square: 0.8908 - val_loss: 0.0020 - val_acc: 0.8385 - val_rmse: 0.0342 - val_mse: 0.0020 - val_r_square: 0.9871\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0059 - acc: 0.9320 - rmse: 0.0430 - mse: 0.0059 - r_square: 0.8954 - val_loss: 0.0019 - val_acc: 0.8407 - val_rmse: 0.0330 - val_mse: 0.0019 - val_r_square: 0.9877\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0061 - acc: 0.9201 - rmse: 0.0445 - mse: 0.0061 - r_square: 0.8973 - val_loss: 0.0027 - val_acc: 0.8387 - val_rmse: 0.0437 - val_mse: 0.0027 - val_r_square: 0.9815\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0062 - acc: 0.9572 - rmse: 0.0462 - mse: 0.0062 - r_square: 0.8948 - val_loss: 0.0022 - val_acc: 0.9325 - val_rmse: 0.0375 - val_mse: 0.0022 - val_r_square: 0.9855\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0064 - acc: 0.9221 - rmse: 0.0480 - mse: 0.0064 - r_square: 0.8956 - val_loss: 0.0033 - val_acc: 0.8389 - val_rmse: 0.0493 - val_mse: 0.0033 - val_r_square: 0.9774\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0070 - acc: 0.9605 - rmse: 0.0547 - mse: 0.0070 - r_square: 0.8863 - val_loss: 0.0025 - val_acc: 0.9557 - val_rmse: 0.0416 - val_mse: 0.0025 - val_r_square: 0.9832\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0069 - acc: 0.9434 - rmse: 0.0520 - mse: 0.0069 - r_square: 0.8921 - val_loss: 0.0039 - val_acc: 0.8392 - val_rmse: 0.0555 - val_mse: 0.0039 - val_r_square: 0.9723\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0074 - acc: 0.9665 - rmse: 0.0608 - mse: 0.0074 - r_square: 0.8789 - val_loss: 0.0028 - val_acc: 0.9552 - val_rmse: 0.0453 - val_mse: 0.0028 - val_r_square: 0.9809\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0064 - acc: 0.9523 - rmse: 0.0495 - mse: 0.0064 - r_square: 0.8950 - val_loss: 0.0043 - val_acc: 0.8404 - val_rmse: 0.0587 - val_mse: 0.0043 - val_r_square: 0.9693\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0070 - acc: 0.9664 - rmse: 0.0571 - mse: 0.0070 - r_square: 0.8817 - val_loss: 0.0030 - val_acc: 0.9181 - val_rmse: 0.0470 - val_mse: 0.0030 - val_r_square: 0.9798\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0059 - acc: 0.9513 - rmse: 0.0440 - mse: 0.0059 - r_square: 0.8994 - val_loss: 0.0041 - val_acc: 0.8659 - val_rmse: 0.0572 - val_mse: 0.0041 - val_r_square: 0.9706\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0064 - acc: 0.9666 - rmse: 0.0496 - mse: 0.0064 - r_square: 0.8914 - val_loss: 0.0031 - val_acc: 0.8935 - val_rmse: 0.0482 - val_mse: 0.0031 - val_r_square: 0.9789\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0057 - acc: 0.9497 - rmse: 0.0416 - mse: 0.0057 - r_square: 0.9007 - val_loss: 0.0035 - val_acc: 0.8656 - val_rmse: 0.0518 - val_mse: 0.0035 - val_r_square: 0.9754\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0058 - acc: 0.9562 - rmse: 0.0431 - mse: 0.0058 - r_square: 0.8998 - val_loss: 0.0027 - val_acc: 0.8908 - val_rmse: 0.0440 - val_mse: 0.0027 - val_r_square: 0.9814\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0055 - acc: 0.9501 - rmse: 0.0381 - mse: 0.0055 - r_square: 0.9033 - val_loss: 0.0026 - val_acc: 0.8800 - val_rmse: 0.0420 - val_mse: 0.0026 - val_r_square: 0.9824\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0054 - acc: 0.9527 - rmse: 0.0365 - mse: 0.0054 - r_square: 0.9048 - val_loss: 0.0023 - val_acc: 0.9800 - val_rmse: 0.0388 - val_mse: 0.0023 - val_r_square: 0.9842\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0052 - acc: 0.9511 - rmse: 0.0345 - mse: 0.0052 - r_square: 0.9064 - val_loss: 0.0024 - val_acc: 0.9918 - val_rmse: 0.0398 - val_mse: 0.0024 - val_r_square: 0.9839\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 273us/step - loss: 0.0051 - acc: 0.9562 - rmse: 0.0343 - mse: 0.0051 - r_square: 0.9083 - val_loss: 0.0025 - val_acc: 0.9928 - val_rmse: 0.0408 - val_mse: 0.0025 - val_r_square: 0.9832\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0051 - acc: 0.9580 - rmse: 0.0344 - mse: 0.0051 - r_square: 0.9079 - val_loss: 0.0025 - val_acc: 0.9929 - val_rmse: 0.0409 - val_mse: 0.0025 - val_r_square: 0.9834\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0050 - acc: 0.9581 - rmse: 0.0335 - mse: 0.0050 - r_square: 0.9096 - val_loss: 0.0025 - val_acc: 0.9922 - val_rmse: 0.0405 - val_mse: 0.0025 - val_r_square: 0.9834\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0051 - acc: 0.9603 - rmse: 0.0355 - mse: 0.0051 - r_square: 0.9078 - val_loss: 0.0025 - val_acc: 0.9929 - val_rmse: 0.0407 - val_mse: 0.0025 - val_r_square: 0.9836\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0050 - acc: 0.9604 - rmse: 0.0343 - mse: 0.0050 - r_square: 0.9094 - val_loss: 0.0025 - val_acc: 0.9919 - val_rmse: 0.0404 - val_mse: 0.0025 - val_r_square: 0.9834\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0052 - acc: 0.9645 - rmse: 0.0369 - mse: 0.0052 - r_square: 0.9071 - val_loss: 0.0024 - val_acc: 0.9931 - val_rmse: 0.0405 - val_mse: 0.0024 - val_r_square: 0.9837\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0051 - acc: 0.9597 - rmse: 0.0347 - mse: 0.0051 - r_square: 0.9091 - val_loss: 0.0025 - val_acc: 0.9918 - val_rmse: 0.0403 - val_mse: 0.0025 - val_r_square: 0.9834\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0052 - acc: 0.9635 - rmse: 0.0375 - mse: 0.0052 - r_square: 0.9070 - val_loss: 0.0024 - val_acc: 0.9931 - val_rmse: 0.0396 - val_mse: 0.0024 - val_r_square: 0.9843\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0050 - acc: 0.9567 - rmse: 0.0335 - mse: 0.0050 - r_square: 0.9101 - val_loss: 0.0024 - val_acc: 0.9800 - val_rmse: 0.0397 - val_mse: 0.0024 - val_r_square: 0.9836\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0051 - acc: 0.9657 - rmse: 0.0365 - mse: 0.0051 - r_square: 0.9081 - val_loss: 0.0022 - val_acc: 0.9931 - val_rmse: 0.0376 - val_mse: 0.0022 - val_r_square: 0.9854\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0049 - acc: 0.9558 - rmse: 0.0318 - mse: 0.0049 - r_square: 0.9114 - val_loss: 0.0024 - val_acc: 0.9800 - val_rmse: 0.0386 - val_mse: 0.0024 - val_r_square: 0.9841\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0050 - acc: 0.9662 - rmse: 0.0356 - mse: 0.0050 - r_square: 0.9091 - val_loss: 0.0021 - val_acc: 0.9932 - val_rmse: 0.0357 - val_mse: 0.0021 - val_r_square: 0.9864\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0048 - acc: 0.9544 - rmse: 0.0313 - mse: 0.0048 - r_square: 0.9117 - val_loss: 0.0023 - val_acc: 0.9797 - val_rmse: 0.0377 - val_mse: 0.0023 - val_r_square: 0.9846\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0050 - acc: 0.9662 - rmse: 0.0360 - mse: 0.0050 - r_square: 0.9091 - val_loss: 0.0020 - val_acc: 0.9934 - val_rmse: 0.0339 - val_mse: 0.0020 - val_r_square: 0.9873\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0049 - acc: 0.9542 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9109 - val_loss: 0.0023 - val_acc: 0.9299 - val_rmse: 0.0375 - val_mse: 0.0023 - val_r_square: 0.9847\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0051 - acc: 0.9656 - rmse: 0.0375 - mse: 0.0051 - r_square: 0.9079 - val_loss: 0.0019 - val_acc: 0.9935 - val_rmse: 0.0333 - val_mse: 0.0019 - val_r_square: 0.9876\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0051 - acc: 0.9533 - rmse: 0.0352 - mse: 0.0051 - r_square: 0.9094 - val_loss: 0.0023 - val_acc: 0.9289 - val_rmse: 0.0382 - val_mse: 0.0023 - val_r_square: 0.9844\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0053 - acc: 0.9658 - rmse: 0.0393 - mse: 0.0053 - r_square: 0.9062 - val_loss: 0.0020 - val_acc: 0.9937 - val_rmse: 0.0340 - val_mse: 0.0020 - val_r_square: 0.9873\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0052 - acc: 0.9534 - rmse: 0.0362 - mse: 0.0052 - r_square: 0.9090 - val_loss: 0.0024 - val_acc: 0.8939 - val_rmse: 0.0395 - val_mse: 0.0024 - val_r_square: 0.9836\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0052 - acc: 0.9688 - rmse: 0.0396 - mse: 0.0052 - r_square: 0.9060 - val_loss: 0.0021 - val_acc: 0.9938 - val_rmse: 0.0353 - val_mse: 0.0021 - val_r_square: 0.9866\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0051 - acc: 0.9512 - rmse: 0.0350 - mse: 0.0051 - r_square: 0.9105 - val_loss: 0.0025 - val_acc: 0.9290 - val_rmse: 0.0405 - val_mse: 0.0025 - val_r_square: 0.9829\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0052 - acc: 0.9695 - rmse: 0.0385 - mse: 0.0052 - r_square: 0.9069 - val_loss: 0.0022 - val_acc: 0.9940 - val_rmse: 0.0369 - val_mse: 0.0022 - val_r_square: 0.9857\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0049 - acc: 0.9512 - rmse: 0.0330 - mse: 0.0049 - r_square: 0.9119 - val_loss: 0.0025 - val_acc: 0.9305 - val_rmse: 0.0410 - val_mse: 0.0025 - val_r_square: 0.9825\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0050 - acc: 0.9703 - rmse: 0.0363 - mse: 0.0050 - r_square: 0.9089 - val_loss: 0.0023 - val_acc: 0.9940 - val_rmse: 0.0388 - val_mse: 0.0023 - val_r_square: 0.9846\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9535 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9139 - val_loss: 0.0025 - val_acc: 0.9692 - val_rmse: 0.0405 - val_mse: 0.0025 - val_r_square: 0.9827\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9703 - rmse: 0.0341 - mse: 0.0048 - r_square: 0.9112 - val_loss: 0.0024 - val_acc: 0.9940 - val_rmse: 0.0398 - val_mse: 0.0024 - val_r_square: 0.9840\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0047 - acc: 0.9557 - rmse: 0.0293 - mse: 0.0047 - r_square: 0.9150 - val_loss: 0.0025 - val_acc: 0.9804 - val_rmse: 0.0399 - val_mse: 0.0025 - val_r_square: 0.9831\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9699 - rmse: 0.0328 - mse: 0.0048 - r_square: 0.9126 - val_loss: 0.0024 - val_acc: 0.9940 - val_rmse: 0.0400 - val_mse: 0.0024 - val_r_square: 0.9839\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0047 - acc: 0.9548 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9149 - val_loss: 0.0024 - val_acc: 0.9804 - val_rmse: 0.0394 - val_mse: 0.0024 - val_r_square: 0.9835\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9689 - rmse: 0.0329 - mse: 0.0050 - r_square: 0.9122 - val_loss: 0.0024 - val_acc: 0.9938 - val_rmse: 0.0396 - val_mse: 0.0024 - val_r_square: 0.9841\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0047 - acc: 0.9576 - rmse: 0.0295 - mse: 0.0047 - r_square: 0.9153 - val_loss: 0.0023 - val_acc: 0.9804 - val_rmse: 0.0385 - val_mse: 0.0023 - val_r_square: 0.9840\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0048 - acc: 0.9636 - rmse: 0.0320 - mse: 0.0048 - r_square: 0.9139 - val_loss: 0.0023 - val_acc: 0.9938 - val_rmse: 0.0389 - val_mse: 0.0023 - val_r_square: 0.9845\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0047 - acc: 0.9570 - rmse: 0.0299 - mse: 0.0047 - r_square: 0.9154 - val_loss: 0.0023 - val_acc: 0.9804 - val_rmse: 0.0383 - val_mse: 0.0023 - val_r_square: 0.9842\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0048 - acc: 0.9664 - rmse: 0.0325 - mse: 0.0048 - r_square: 0.9140 - val_loss: 0.0023 - val_acc: 0.9937 - val_rmse: 0.0388 - val_mse: 0.0023 - val_r_square: 0.9846\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0047 - acc: 0.9585 - rmse: 0.0309 - mse: 0.0047 - r_square: 0.9153 - val_loss: 0.0024 - val_acc: 0.9683 - val_rmse: 0.0390 - val_mse: 0.0024 - val_r_square: 0.9839\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9668 - rmse: 0.0336 - mse: 0.0048 - r_square: 0.9137 - val_loss: 0.0023 - val_acc: 0.9937 - val_rmse: 0.0389 - val_mse: 0.0023 - val_r_square: 0.9846\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9585 - rmse: 0.0320 - mse: 0.0048 - r_square: 0.9149 - val_loss: 0.0024 - val_acc: 0.9437 - val_rmse: 0.0398 - val_mse: 0.0024 - val_r_square: 0.9835\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0049 - acc: 0.9669 - rmse: 0.0348 - mse: 0.0049 - r_square: 0.9133 - val_loss: 0.0023 - val_acc: 0.9937 - val_rmse: 0.0392 - val_mse: 0.0023 - val_r_square: 0.9845\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9576 - rmse: 0.0333 - mse: 0.0048 - r_square: 0.9142 - val_loss: 0.0025 - val_acc: 0.9296 - val_rmse: 0.0407 - val_mse: 0.0025 - val_r_square: 0.9830\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0050 - acc: 0.9670 - rmse: 0.0359 - mse: 0.0050 - r_square: 0.9129 - val_loss: 0.0023 - val_acc: 0.9935 - val_rmse: 0.0394 - val_mse: 0.0023 - val_r_square: 0.9844\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0049 - acc: 0.9556 - rmse: 0.0347 - mse: 0.0049 - r_square: 0.9132 - val_loss: 0.0025 - val_acc: 0.9167 - val_rmse: 0.0415 - val_mse: 0.0025 - val_r_square: 0.9826\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0050 - acc: 0.9675 - rmse: 0.0369 - mse: 0.0050 - r_square: 0.9123 - val_loss: 0.0023 - val_acc: 0.9934 - val_rmse: 0.0392 - val_mse: 0.0023 - val_r_square: 0.9845\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0050 - acc: 0.9516 - rmse: 0.0359 - mse: 0.0050 - r_square: 0.9118 - val_loss: 0.0026 - val_acc: 0.8756 - val_rmse: 0.0420 - val_mse: 0.0026 - val_r_square: 0.9824\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9695 - rmse: 0.0379 - mse: 0.0052 - r_square: 0.9111 - val_loss: 0.0023 - val_acc: 0.9803 - val_rmse: 0.0386 - val_mse: 0.0023 - val_r_square: 0.9848\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0050 - acc: 0.9368 - rmse: 0.0365 - mse: 0.0050 - r_square: 0.9107 - val_loss: 0.0026 - val_acc: 0.8512 - val_rmse: 0.0419 - val_mse: 0.0026 - val_r_square: 0.9826\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0051 - acc: 0.9680 - rmse: 0.0374 - mse: 0.0051 - r_square: 0.9117 - val_loss: 0.0023 - val_acc: 0.9682 - val_rmse: 0.0385 - val_mse: 0.0023 - val_r_square: 0.9849\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0049 - acc: 0.9315 - rmse: 0.0359 - mse: 0.0049 - r_square: 0.9112 - val_loss: 0.0025 - val_acc: 0.8372 - val_rmse: 0.0418 - val_mse: 0.0025 - val_r_square: 0.9827\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0050 - acc: 0.9665 - rmse: 0.0367 - mse: 0.0050 - r_square: 0.9117 - val_loss: 0.0022 - val_acc: 0.9675 - val_rmse: 0.0377 - val_mse: 0.0022 - val_r_square: 0.9854\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0049 - acc: 0.9393 - rmse: 0.0353 - mse: 0.0049 - r_square: 0.9120 - val_loss: 0.0025 - val_acc: 0.8375 - val_rmse: 0.0410 - val_mse: 0.0025 - val_r_square: 0.9831\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0049 - acc: 0.9657 - rmse: 0.0356 - mse: 0.0049 - r_square: 0.9121 - val_loss: 0.0021 - val_acc: 0.9797 - val_rmse: 0.0360 - val_mse: 0.0021 - val_r_square: 0.9862\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0048 - acc: 0.9553 - rmse: 0.0340 - mse: 0.0048 - r_square: 0.9131 - val_loss: 0.0024 - val_acc: 0.8626 - val_rmse: 0.0398 - val_mse: 0.0024 - val_r_square: 0.9837\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0049 - acc: 0.9663 - rmse: 0.0345 - mse: 0.0049 - r_square: 0.9125 - val_loss: 0.0020 - val_acc: 0.9929 - val_rmse: 0.0345 - val_mse: 0.0020 - val_r_square: 0.9870\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0048 - acc: 0.9564 - rmse: 0.0328 - mse: 0.0048 - r_square: 0.9140 - val_loss: 0.0024 - val_acc: 0.8892 - val_rmse: 0.0392 - val_mse: 0.0024 - val_r_square: 0.9839\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0050 - acc: 0.9665 - rmse: 0.0348 - mse: 0.0050 - r_square: 0.9121 - val_loss: 0.0020 - val_acc: 0.9935 - val_rmse: 0.0348 - val_mse: 0.0020 - val_r_square: 0.9869\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0048 - acc: 0.9555 - rmse: 0.0325 - mse: 0.0048 - r_square: 0.9138 - val_loss: 0.0024 - val_acc: 0.9159 - val_rmse: 0.0389 - val_mse: 0.0024 - val_r_square: 0.9839\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0050 - acc: 0.9682 - rmse: 0.0353 - mse: 0.0050 - r_square: 0.9115 - val_loss: 0.0021 - val_acc: 0.9938 - val_rmse: 0.0359 - val_mse: 0.0021 - val_r_square: 0.9863\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0047 - acc: 0.9542 - rmse: 0.0327 - mse: 0.0047 - r_square: 0.9132 - val_loss: 0.0023 - val_acc: 0.9421 - val_rmse: 0.0385 - val_mse: 0.0023 - val_r_square: 0.9842\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0050 - acc: 0.9704 - rmse: 0.0357 - mse: 0.0050 - r_square: 0.9103 - val_loss: 0.0021 - val_acc: 0.9938 - val_rmse: 0.0366 - val_mse: 0.0021 - val_r_square: 0.9859\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 16s 2ms/step - loss: 0.0566 - acc: 0.7458 - rmse: 0.1993 - mse: 0.0566 - r_square: 0.4145 - val_loss: 0.0134 - val_acc: 0.8365 - val_rmse: 0.1085 - val_mse: 0.0134 - val_r_square: 0.9106\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0144 - acc: 0.9041 - rmse: 0.0902 - mse: 0.0144 - r_square: 0.7683 - val_loss: 0.0070 - val_acc: 0.8365 - val_rmse: 0.0784 - val_mse: 0.0070 - val_r_square: 0.9504\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0137 - acc: 0.9437 - rmse: 0.0924 - mse: 0.0137 - r_square: 0.7554 - val_loss: 0.0028 - val_acc: 0.8365 - val_rmse: 0.0378 - val_mse: 0.0028 - val_r_square: 0.9835\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0113 - acc: 0.8532 - rmse: 0.0768 - mse: 0.0113 - r_square: 0.7834 - val_loss: 0.0038 - val_acc: 0.8365 - val_rmse: 0.0533 - val_mse: 0.0038 - val_r_square: 0.9745\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0104 - acc: 0.9461 - rmse: 0.0745 - mse: 0.0104 - r_square: 0.8414 - val_loss: 0.0023 - val_acc: 0.9865 - val_rmse: 0.0330 - val_mse: 0.0023 - val_r_square: 0.9863\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0089 - acc: 0.8949 - rmse: 0.0615 - mse: 0.0089 - r_square: 0.8585 - val_loss: 0.0048 - val_acc: 0.8365 - val_rmse: 0.0615 - val_mse: 0.0048 - val_r_square: 0.9660\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0105 - acc: 0.9494 - rmse: 0.0735 - mse: 0.0105 - r_square: 0.8532 - val_loss: 0.0021 - val_acc: 0.9885 - val_rmse: 0.0303 - val_mse: 0.0021 - val_r_square: 0.9876\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0087 - acc: 0.9400 - rmse: 0.0616 - mse: 0.0087 - r_square: 0.8645 - val_loss: 0.0055 - val_acc: 0.8365 - val_rmse: 0.0678 - val_mse: 0.0055 - val_r_square: 0.9599\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0100 - acc: 0.9411 - rmse: 0.0712 - mse: 0.0100 - r_square: 0.8570 - val_loss: 0.0020 - val_acc: 0.9891 - val_rmse: 0.0298 - val_mse: 0.0020 - val_r_square: 0.9884\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0077 - acc: 0.9470 - rmse: 0.0572 - mse: 0.0077 - r_square: 0.8738 - val_loss: 0.0043 - val_acc: 0.8384 - val_rmse: 0.0583 - val_mse: 0.0043 - val_r_square: 0.9695\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0076 - acc: 0.9469 - rmse: 0.0573 - mse: 0.0076 - r_square: 0.8757 - val_loss: 0.0019 - val_acc: 0.9450 - val_rmse: 0.0303 - val_mse: 0.0019 - val_r_square: 0.9886\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0062 - acc: 0.9519 - rmse: 0.0440 - mse: 0.0062 - r_square: 0.8901 - val_loss: 0.0024 - val_acc: 0.8425 - val_rmse: 0.0387 - val_mse: 0.0024 - val_r_square: 0.9843\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0060 - acc: 0.9493 - rmse: 0.0423 - mse: 0.0060 - r_square: 0.8930 - val_loss: 0.0017 - val_acc: 0.9456 - val_rmse: 0.0276 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0055 - acc: 0.9500 - rmse: 0.0359 - mse: 0.0055 - r_square: 0.8984 - val_loss: 0.0019 - val_acc: 0.8440 - val_rmse: 0.0320 - val_mse: 0.0019 - val_r_square: 0.9879\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0055 - acc: 0.9481 - rmse: 0.0355 - mse: 0.0055 - r_square: 0.9001 - val_loss: 0.0016 - val_acc: 0.9459 - val_rmse: 0.0259 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0053 - acc: 0.9471 - rmse: 0.0343 - mse: 0.0053 - r_square: 0.9007 - val_loss: 0.0019 - val_acc: 0.8568 - val_rmse: 0.0316 - val_mse: 0.0019 - val_r_square: 0.9882\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0054 - acc: 0.9495 - rmse: 0.0345 - mse: 0.0054 - r_square: 0.9022 - val_loss: 0.0015 - val_acc: 0.9578 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0053 - acc: 0.9474 - rmse: 0.0347 - mse: 0.0053 - r_square: 0.9019 - val_loss: 0.0019 - val_acc: 0.8569 - val_rmse: 0.0325 - val_mse: 0.0019 - val_r_square: 0.9879\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0054 - acc: 0.9593 - rmse: 0.0359 - mse: 0.0054 - r_square: 0.9024 - val_loss: 0.0015 - val_acc: 0.9575 - val_rmse: 0.0244 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0054 - acc: 0.9484 - rmse: 0.0362 - mse: 0.0054 - r_square: 0.9023 - val_loss: 0.0020 - val_acc: 0.8558 - val_rmse: 0.0341 - val_mse: 0.0020 - val_r_square: 0.9872\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0056 - acc: 0.9596 - rmse: 0.0388 - mse: 0.0056 - r_square: 0.9011 - val_loss: 0.0015 - val_acc: 0.9574 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0055 - acc: 0.9504 - rmse: 0.0389 - mse: 0.0055 - r_square: 0.9016 - val_loss: 0.0022 - val_acc: 0.8545 - val_rmse: 0.0369 - val_mse: 0.0022 - val_r_square: 0.9858\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0058 - acc: 0.9615 - rmse: 0.0424 - mse: 0.0058 - r_square: 0.8994 - val_loss: 0.0015 - val_acc: 0.9421 - val_rmse: 0.0251 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0057 - acc: 0.9528 - rmse: 0.0417 - mse: 0.0057 - r_square: 0.9005 - val_loss: 0.0024 - val_acc: 0.8546 - val_rmse: 0.0403 - val_mse: 0.0024 - val_r_square: 0.9838\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0059 - acc: 0.9651 - rmse: 0.0449 - mse: 0.0059 - r_square: 0.8981 - val_loss: 0.0015 - val_acc: 0.9328 - val_rmse: 0.0251 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0057 - acc: 0.9541 - rmse: 0.0419 - mse: 0.0057 - r_square: 0.9011 - val_loss: 0.0024 - val_acc: 0.8546 - val_rmse: 0.0396 - val_mse: 0.0024 - val_r_square: 0.9842\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0057 - acc: 0.9630 - rmse: 0.0428 - mse: 0.0057 - r_square: 0.9003 - val_loss: 0.0014 - val_acc: 0.9321 - val_rmse: 0.0242 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0054 - acc: 0.9557 - rmse: 0.0385 - mse: 0.0054 - r_square: 0.9041 - val_loss: 0.0020 - val_acc: 0.8672 - val_rmse: 0.0349 - val_mse: 0.0020 - val_r_square: 0.9867\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0055 - acc: 0.9683 - rmse: 0.0388 - mse: 0.0055 - r_square: 0.9039 - val_loss: 0.0014 - val_acc: 0.9073 - val_rmse: 0.0238 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0054 - acc: 0.9555 - rmse: 0.0358 - mse: 0.0054 - r_square: 0.9056 - val_loss: 0.0018 - val_acc: 0.8682 - val_rmse: 0.0313 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0056 - acc: 0.9665 - rmse: 0.0368 - mse: 0.0056 - r_square: 0.9043 - val_loss: 0.0014 - val_acc: 0.8942 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0050 - acc: 0.9570 - rmse: 0.0339 - mse: 0.0050 - r_square: 0.9085 - val_loss: 0.0016 - val_acc: 0.8801 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0050 - acc: 0.9518 - rmse: 0.0337 - mse: 0.0050 - r_square: 0.9087 - val_loss: 0.0013 - val_acc: 0.9313 - val_rmse: 0.0215 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9576 - rmse: 0.0331 - mse: 0.0049 - r_square: 0.9091 - val_loss: 0.0015 - val_acc: 0.8941 - val_rmse: 0.0271 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9624 - rmse: 0.0327 - mse: 0.0049 - r_square: 0.9097 - val_loss: 0.0013 - val_acc: 0.9431 - val_rmse: 0.0217 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9665 - rmse: 0.0323 - mse: 0.0049 - r_square: 0.9107 - val_loss: 0.0015 - val_acc: 0.8938 - val_rmse: 0.0253 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9661 - rmse: 0.0321 - mse: 0.0048 - r_square: 0.9110 - val_loss: 0.0013 - val_acc: 0.9193 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9665 - rmse: 0.0323 - mse: 0.0048 - r_square: 0.9112 - val_loss: 0.0014 - val_acc: 0.8932 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9661 - rmse: 0.0320 - mse: 0.0048 - r_square: 0.9115 - val_loss: 0.0013 - val_acc: 0.9292 - val_rmse: 0.0210 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9671 - rmse: 0.0325 - mse: 0.0049 - r_square: 0.9115 - val_loss: 0.0013 - val_acc: 0.8932 - val_rmse: 0.0226 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9662 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9116 - val_loss: 0.0013 - val_acc: 0.9417 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9690 - rmse: 0.0330 - mse: 0.0049 - r_square: 0.9114 - val_loss: 0.0013 - val_acc: 0.8932 - val_rmse: 0.0215 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9667 - rmse: 0.0325 - mse: 0.0048 - r_square: 0.9120 - val_loss: 0.0013 - val_acc: 0.9180 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0049 - acc: 0.9703 - rmse: 0.0333 - mse: 0.0049 - r_square: 0.9118 - val_loss: 0.0013 - val_acc: 0.9053 - val_rmse: 0.0207 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9671 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9125 - val_loss: 0.0013 - val_acc: 0.8939 - val_rmse: 0.0214 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9710 - rmse: 0.0334 - mse: 0.0049 - r_square: 0.9122 - val_loss: 0.0013 - val_acc: 0.9054 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0048 - acc: 0.9683 - rmse: 0.0328 - mse: 0.0048 - r_square: 0.9130 - val_loss: 0.0013 - val_acc: 0.8922 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9699 - rmse: 0.0340 - mse: 0.0049 - r_square: 0.9123 - val_loss: 0.0012 - val_acc: 0.9043 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0048 - acc: 0.9667 - rmse: 0.0333 - mse: 0.0048 - r_square: 0.9130 - val_loss: 0.0014 - val_acc: 0.8780 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9685 - rmse: 0.0352 - mse: 0.0049 - r_square: 0.9116 - val_loss: 0.0012 - val_acc: 0.8918 - val_rmse: 0.0195 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0049 - acc: 0.9620 - rmse: 0.0348 - mse: 0.0049 - r_square: 0.9122 - val_loss: 0.0014 - val_acc: 0.8650 - val_rmse: 0.0247 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0052 - acc: 0.9657 - rmse: 0.0382 - mse: 0.0052 - r_square: 0.9091 - val_loss: 0.0013 - val_acc: 0.8794 - val_rmse: 0.0205 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0054 - acc: 0.9581 - rmse: 0.0384 - mse: 0.0054 - r_square: 0.9083 - val_loss: 0.0016 - val_acc: 0.8647 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0055 - acc: 0.9696 - rmse: 0.0428 - mse: 0.0055 - r_square: 0.9062 - val_loss: 0.0015 - val_acc: 0.9168 - val_rmse: 0.0260 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0054 - acc: 0.9660 - rmse: 0.0410 - mse: 0.0054 - r_square: 0.9070 - val_loss: 0.0021 - val_acc: 0.8646 - val_rmse: 0.0357 - val_mse: 0.0021 - val_r_square: 0.9866\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0056 - acc: 0.9678 - rmse: 0.0448 - mse: 0.0056 - r_square: 0.9048 - val_loss: 0.0018 - val_acc: 0.9164 - val_rmse: 0.0306 - val_mse: 0.0018 - val_r_square: 0.9891\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0056 - acc: 0.9657 - rmse: 0.0428 - mse: 0.0056 - r_square: 0.9062 - val_loss: 0.0022 - val_acc: 0.8785 - val_rmse: 0.0373 - val_mse: 0.0022 - val_r_square: 0.9858\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0059 - acc: 0.9659 - rmse: 0.0465 - mse: 0.0059 - r_square: 0.9034 - val_loss: 0.0022 - val_acc: 0.9185 - val_rmse: 0.0369 - val_mse: 0.0022 - val_r_square: 0.9860\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0060 - acc: 0.9697 - rmse: 0.0453 - mse: 0.0060 - r_square: 0.9034 - val_loss: 0.0024 - val_acc: 0.8790 - val_rmse: 0.0405 - val_mse: 0.0024 - val_r_square: 0.9841\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0058 - acc: 0.9694 - rmse: 0.0446 - mse: 0.0058 - r_square: 0.9048 - val_loss: 0.0025 - val_acc: 0.9682 - val_rmse: 0.0412 - val_mse: 0.0025 - val_r_square: 0.9837\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0056 - acc: 0.9635 - rmse: 0.0429 - mse: 0.0056 - r_square: 0.9057 - val_loss: 0.0029 - val_acc: 0.9675 - val_rmse: 0.0455 - val_mse: 0.0029 - val_r_square: 0.9809\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0054 - acc: 0.9469 - rmse: 0.0414 - mse: 0.0054 - r_square: 0.9064 - val_loss: 0.0025 - val_acc: 0.9806 - val_rmse: 0.0412 - val_mse: 0.0025 - val_r_square: 0.9836\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0055 - acc: 0.9185 - rmse: 0.0424 - mse: 0.0055 - r_square: 0.9038 - val_loss: 0.0024 - val_acc: 0.9683 - val_rmse: 0.0403 - val_mse: 0.0024 - val_r_square: 0.9840\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0054 - acc: 0.9079 - rmse: 0.0419 - mse: 0.0054 - r_square: 0.9027 - val_loss: 0.0017 - val_acc: 0.9544 - val_rmse: 0.0285 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0052 - acc: 0.9006 - rmse: 0.0393 - mse: 0.0052 - r_square: 0.9004 - val_loss: 0.0013 - val_acc: 0.8900 - val_rmse: 0.0215 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0051 - acc: 0.9063 - rmse: 0.0376 - mse: 0.0051 - r_square: 0.9042 - val_loss: 0.0011 - val_acc: 0.8761 - val_rmse: 0.0141 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9463 - rmse: 0.0352 - mse: 0.0050 - r_square: 0.9093 - val_loss: 0.0012 - val_acc: 0.8507 - val_rmse: 0.0199 - val_mse: 0.0012 - val_r_square: 0.9927\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9222 - rmse: 0.0352 - mse: 0.0049 - r_square: 0.9098 - val_loss: 0.0011 - val_acc: 0.8636 - val_rmse: 0.0153 - val_mse: 0.0011 - val_r_square: 0.9937\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9387 - rmse: 0.0350 - mse: 0.0049 - r_square: 0.9127 - val_loss: 0.0014 - val_acc: 0.8506 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9499 - rmse: 0.0353 - mse: 0.0049 - r_square: 0.9119 - val_loss: 0.0012 - val_acc: 0.8528 - val_rmse: 0.0191 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0050 - acc: 0.9138 - rmse: 0.0369 - mse: 0.0050 - r_square: 0.9119 - val_loss: 0.0015 - val_acc: 0.8378 - val_rmse: 0.0260 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0050 - acc: 0.9469 - rmse: 0.0368 - mse: 0.0050 - r_square: 0.9126 - val_loss: 0.0013 - val_acc: 0.8391 - val_rmse: 0.0214 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0051 - acc: 0.9122 - rmse: 0.0385 - mse: 0.0051 - r_square: 0.9097 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0051 - acc: 0.9507 - rmse: 0.0379 - mse: 0.0051 - r_square: 0.9123 - val_loss: 0.0014 - val_acc: 0.8381 - val_rmse: 0.0224 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0051 - acc: 0.9096 - rmse: 0.0385 - mse: 0.0051 - r_square: 0.9092 - val_loss: 0.0016 - val_acc: 0.8366 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0051 - acc: 0.9505 - rmse: 0.0376 - mse: 0.0051 - r_square: 0.9124 - val_loss: 0.0014 - val_acc: 0.8377 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0051 - acc: 0.9116 - rmse: 0.0378 - mse: 0.0051 - r_square: 0.9096 - val_loss: 0.0016 - val_acc: 0.8368 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0051 - acc: 0.9522 - rmse: 0.0372 - mse: 0.0051 - r_square: 0.9120 - val_loss: 0.0014 - val_acc: 0.8371 - val_rmse: 0.0238 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0052 - acc: 0.9135 - rmse: 0.0383 - mse: 0.0052 - r_square: 0.9082 - val_loss: 0.0016 - val_acc: 0.8369 - val_rmse: 0.0276 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0052 - acc: 0.9511 - rmse: 0.0378 - mse: 0.0052 - r_square: 0.9108 - val_loss: 0.0015 - val_acc: 0.8372 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0053 - acc: 0.9108 - rmse: 0.0399 - mse: 0.0053 - r_square: 0.9051 - val_loss: 0.0017 - val_acc: 0.8369 - val_rmse: 0.0282 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0053 - acc: 0.9527 - rmse: 0.0386 - mse: 0.0053 - r_square: 0.9100 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0264 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0053 - acc: 0.9082 - rmse: 0.0408 - mse: 0.0053 - r_square: 0.9025 - val_loss: 0.0016 - val_acc: 0.8372 - val_rmse: 0.0279 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0052 - acc: 0.9540 - rmse: 0.0382 - mse: 0.0052 - r_square: 0.9102 - val_loss: 0.0015 - val_acc: 0.8382 - val_rmse: 0.0258 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0053 - acc: 0.9057 - rmse: 0.0406 - mse: 0.0053 - r_square: 0.9015 - val_loss: 0.0015 - val_acc: 0.8631 - val_rmse: 0.0250 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0051 - acc: 0.9534 - rmse: 0.0363 - mse: 0.0051 - r_square: 0.9113 - val_loss: 0.0013 - val_acc: 0.8650 - val_rmse: 0.0224 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0051 - acc: 0.9048 - rmse: 0.0387 - mse: 0.0051 - r_square: 0.9037 - val_loss: 0.0013 - val_acc: 0.8896 - val_rmse: 0.0213 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0049 - acc: 0.9524 - rmse: 0.0342 - mse: 0.0049 - r_square: 0.9123 - val_loss: 0.0012 - val_acc: 0.9080 - val_rmse: 0.0179 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0048 - acc: 0.9096 - rmse: 0.0337 - mse: 0.0048 - r_square: 0.9115 - val_loss: 0.0013 - val_acc: 0.9161 - val_rmse: 0.0205 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0047 - acc: 0.9526 - rmse: 0.0324 - mse: 0.0047 - r_square: 0.9143 - val_loss: 0.0012 - val_acc: 0.9672 - val_rmse: 0.0173 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0046 - acc: 0.9577 - rmse: 0.0303 - mse: 0.0046 - r_square: 0.9171 - val_loss: 0.0013 - val_acc: 0.9554 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0047 - acc: 0.9527 - rmse: 0.0310 - mse: 0.0047 - r_square: 0.9160 - val_loss: 0.0012 - val_acc: 0.9797 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0047 - acc: 0.9637 - rmse: 0.0307 - mse: 0.0047 - r_square: 0.9165 - val_loss: 0.0014 - val_acc: 0.9689 - val_rmse: 0.0231 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0047 - acc: 0.9547 - rmse: 0.0309 - mse: 0.0047 - r_square: 0.9163 - val_loss: 0.0012 - val_acc: 0.9928 - val_rmse: 0.0186 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0046 - acc: 0.9621 - rmse: 0.0310 - mse: 0.0046 - r_square: 0.9162 - val_loss: 0.0014 - val_acc: 0.9932 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0046 - acc: 0.9635 - rmse: 0.0308 - mse: 0.0046 - r_square: 0.9168 - val_loss: 0.0012 - val_acc: 0.9935 - val_rmse: 0.0187 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0046 - acc: 0.9619 - rmse: 0.0311 - mse: 0.0046 - r_square: 0.9158 - val_loss: 0.0014 - val_acc: 0.9937 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0046 - acc: 0.9640 - rmse: 0.0309 - mse: 0.0046 - r_square: 0.9163 - val_loss: 0.0012 - val_acc: 0.9937 - val_rmse: 0.0178 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0047 - acc: 0.9583 - rmse: 0.0319 - mse: 0.0047 - r_square: 0.9143 - val_loss: 0.0013 - val_acc: 0.9935 - val_rmse: 0.0219 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0047 - acc: 0.9583 - rmse: 0.0316 - mse: 0.0047 - r_square: 0.9147 - val_loss: 0.0011 - val_acc: 0.9935 - val_rmse: 0.0163 - val_mse: 0.0011 - val_r_square: 0.9935\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_16 (RepeatVect (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 13s 2ms/step - loss: 0.0207 - acc: 0.9153 - mse: 0.0207 - rmse: 0.1171 - r_square: 0.7042 - val_loss: 0.0111 - val_acc: 0.9741 - val_mse: 0.0111 - val_rmse: 0.0994 - val_r_square: 0.9181\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 226us/step - loss: 0.0192 - acc: 0.9574 - mse: 0.0192 - rmse: 0.1132 - r_square: 0.5650 - val_loss: 0.0049 - val_acc: 0.9028 - val_mse: 0.0049 - val_rmse: 0.0634 - val_r_square: 0.9642\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0136 - acc: 0.9432 - mse: 0.0136 - rmse: 0.0896 - r_square: 0.7549 - val_loss: 0.0055 - val_acc: 0.8638 - val_mse: 0.0055 - val_rmse: 0.0678 - val_r_square: 0.9598\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0099 - acc: 0.9085 - mse: 0.0099 - rmse: 0.0658 - r_square: 0.8343 - val_loss: 0.0038 - val_acc: 0.9942 - val_mse: 0.0038 - val_rmse: 0.0527 - val_r_square: 0.9732\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0143 - acc: 0.8737 - mse: 0.0143 - rmse: 0.0936 - r_square: 0.6634 - val_loss: 0.0036 - val_acc: 0.9942 - val_mse: 0.0036 - val_rmse: 0.0523 - val_r_square: 0.9763\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0107 - acc: 0.9521 - mse: 0.0107 - rmse: 0.0747 - r_square: 0.8260 - val_loss: 0.0038 - val_acc: 0.9820 - val_mse: 0.0038 - val_rmse: 0.0542 - val_r_square: 0.9728\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0129 - acc: 0.9181 - mse: 0.0129 - rmse: 0.0917 - r_square: 0.7913 - val_loss: 0.0027 - val_acc: 0.8365 - val_mse: 0.0027 - val_rmse: 0.0373 - val_r_square: 0.9842\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0119 - acc: 0.9716 - mse: 0.0119 - rmse: 0.0800 - r_square: 0.8571 - val_loss: 0.0018 - val_acc: 0.8872 - val_mse: 0.0018 - val_rmse: 0.0278 - val_r_square: 0.9896\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0093 - acc: 0.8877 - mse: 0.0093 - rmse: 0.0735 - r_square: 0.8487 - val_loss: 0.0049 - val_acc: 0.8372 - val_mse: 0.0049 - val_rmse: 0.0639 - val_r_square: 0.9664\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0080 - acc: 0.9131 - mse: 0.0080 - rmse: 0.0614 - r_square: 0.8218 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0408 - val_r_square: 0.9842\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0064 - acc: 0.9599 - mse: 0.0064 - rmse: 0.0484 - r_square: 0.8891 - val_loss: 0.0019 - val_acc: 0.8366 - val_mse: 0.0019 - val_rmse: 0.0327 - val_r_square: 0.9884\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0064 - acc: 0.8392 - mse: 0.0064 - rmse: 0.0514 - r_square: 0.8432 - val_loss: 0.0046 - val_acc: 0.8365 - val_mse: 0.0046 - val_rmse: 0.0623 - val_r_square: 0.9670\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0064 - acc: 0.8945 - mse: 0.0064 - rmse: 0.0515 - r_square: 0.8436 - val_loss: 0.0024 - val_acc: 0.9170 - val_mse: 0.0024 - val_rmse: 0.0391 - val_r_square: 0.9840\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0058 - acc: 0.9570 - mse: 0.0058 - rmse: 0.0434 - r_square: 0.8855 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0409 - val_r_square: 0.9839\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0057 - acc: 0.8854 - mse: 0.0057 - rmse: 0.0431 - r_square: 0.8370 - val_loss: 0.0025 - val_acc: 0.8365 - val_mse: 0.0025 - val_rmse: 0.0422 - val_r_square: 0.9828\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0070 - acc: 0.9071 - mse: 0.0070 - rmse: 0.0570 - r_square: 0.8177 - val_loss: 0.0020 - val_acc: 0.9152 - val_mse: 0.0020 - val_rmse: 0.0342 - val_r_square: 0.9863\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0081 - acc: 0.9482 - mse: 0.0081 - rmse: 0.0614 - r_square: 0.8807 - val_loss: 0.0038 - val_acc: 0.9938 - val_mse: 0.0038 - val_rmse: 0.0546 - val_r_square: 0.9735\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0079 - acc: 0.9509 - mse: 0.0079 - rmse: 0.0611 - r_square: 0.8696 - val_loss: 0.0032 - val_acc: 0.9396 - val_mse: 0.0032 - val_rmse: 0.0481 - val_r_square: 0.9782\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0085 - acc: 0.9568 - mse: 0.0085 - rmse: 0.0633 - r_square: 0.8747 - val_loss: 0.0055 - val_acc: 0.8869 - val_mse: 0.0055 - val_rmse: 0.0686 - val_r_square: 0.9614\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0079 - acc: 0.8614 - mse: 0.0079 - rmse: 0.0630 - r_square: 0.8510 - val_loss: 0.0020 - val_acc: 0.8365 - val_mse: 0.0020 - val_rmse: 0.0327 - val_r_square: 0.9879\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0110 - acc: 0.9472 - mse: 0.0110 - rmse: 0.0820 - r_square: 0.7502 - val_loss: 0.0037 - val_acc: 0.8365 - val_mse: 0.0037 - val_rmse: 0.0518 - val_r_square: 0.9766\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0090 - acc: 0.9112 - mse: 0.0090 - rmse: 0.0718 - r_square: 0.8198 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0465 - val_r_square: 0.9805\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0079 - acc: 0.8645 - mse: 0.0079 - rmse: 0.0649 - r_square: 0.8459 - val_loss: 0.0044 - val_acc: 0.9942 - val_mse: 0.0044 - val_rmse: 0.0604 - val_r_square: 0.9696\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0086 - acc: 0.8974 - mse: 0.0086 - rmse: 0.0691 - r_square: 0.8218 - val_loss: 0.0026 - val_acc: 0.8506 - val_mse: 0.0026 - val_rmse: 0.0419 - val_r_square: 0.9830\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0106 - acc: 0.9459 - mse: 0.0106 - rmse: 0.0823 - r_square: 0.7604 - val_loss: 0.0026 - val_acc: 0.9128 - val_mse: 0.0026 - val_rmse: 0.0423 - val_r_square: 0.9833\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0105 - acc: 0.8670 - mse: 0.0105 - rmse: 0.0781 - r_square: 0.7227 - val_loss: 0.0041 - val_acc: 0.8756 - val_mse: 0.0041 - val_rmse: 0.0569 - val_r_square: 0.9713\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 228us/step - loss: 0.0102 - acc: 0.8933 - mse: 0.0102 - rmse: 0.0784 - r_square: 0.7507 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0365 - val_r_square: 0.9857\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 227us/step - loss: 0.0084 - acc: 0.9171 - mse: 0.0084 - rmse: 0.0656 - r_square: 0.8060 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0316 - val_r_square: 0.9883\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0079 - acc: 0.8977 - mse: 0.0079 - rmse: 0.0644 - r_square: 0.8027 - val_loss: 0.0025 - val_acc: 0.8764 - val_mse: 0.0025 - val_rmse: 0.0429 - val_r_square: 0.9833\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 227us/step - loss: 0.0078 - acc: 0.9045 - mse: 0.0078 - rmse: 0.0635 - r_square: 0.7928 - val_loss: 0.0028 - val_acc: 0.8497 - val_mse: 0.0028 - val_rmse: 0.0440 - val_r_square: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0076 - acc: 0.9054 - mse: 0.0076 - rmse: 0.0638 - r_square: 0.7952 - val_loss: 0.0023 - val_acc: 0.9820 - val_mse: 0.0023 - val_rmse: 0.0364 - val_r_square: 0.9851\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0076 - acc: 0.9144 - mse: 0.0076 - rmse: 0.0624 - r_square: 0.8441 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0373 - val_r_square: 0.9852\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0072 - acc: 0.9442 - mse: 0.0072 - rmse: 0.0593 - r_square: 0.8255 - val_loss: 0.0027 - val_acc: 0.8365 - val_mse: 0.0027 - val_rmse: 0.0441 - val_r_square: 0.9826\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0082 - acc: 0.8526 - mse: 0.0082 - rmse: 0.0679 - r_square: 0.7965 - val_loss: 0.0027 - val_acc: 0.9806 - val_mse: 0.0027 - val_rmse: 0.0436 - val_r_square: 0.9818\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0079 - acc: 0.9666 - mse: 0.0079 - rmse: 0.0651 - r_square: 0.8036 - val_loss: 0.0027 - val_acc: 0.9929 - val_mse: 0.0027 - val_rmse: 0.0416 - val_r_square: 0.9816\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0076 - acc: 0.9554 - mse: 0.0076 - rmse: 0.0624 - r_square: 0.8652 - val_loss: 0.0031 - val_acc: 0.8365 - val_mse: 0.0031 - val_rmse: 0.0470 - val_r_square: 0.9800\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0083 - acc: 0.9520 - mse: 0.0083 - rmse: 0.0658 - r_square: 0.7939 - val_loss: 0.0027 - val_acc: 0.8500 - val_mse: 0.0027 - val_rmse: 0.0440 - val_r_square: 0.9821\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0083 - acc: 0.8893 - mse: 0.0083 - rmse: 0.0678 - r_square: 0.8118 - val_loss: 0.0040 - val_acc: 0.8641 - val_mse: 0.0040 - val_rmse: 0.0561 - val_r_square: 0.9737\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0076 - acc: 0.9580 - mse: 0.0076 - rmse: 0.0641 - r_square: 0.8346 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0462 - val_r_square: 0.9800\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0075 - acc: 0.9374 - mse: 0.0075 - rmse: 0.0620 - r_square: 0.8637 - val_loss: 0.0019 - val_acc: 0.8389 - val_mse: 0.0019 - val_rmse: 0.0332 - val_r_square: 0.9877\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0083 - acc: 0.9103 - mse: 0.0083 - rmse: 0.0668 - r_square: 0.7393 - val_loss: 0.0028 - val_acc: 0.9014 - val_mse: 0.0028 - val_rmse: 0.0445 - val_r_square: 0.9814\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0077 - acc: 0.9191 - mse: 0.0077 - rmse: 0.0643 - r_square: 0.8756 - val_loss: 0.0029 - val_acc: 0.8365 - val_mse: 0.0029 - val_rmse: 0.0461 - val_r_square: 0.9800\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 293us/step - loss: 0.0070 - acc: 0.9543 - mse: 0.0070 - rmse: 0.0574 - r_square: 0.8495 - val_loss: 0.0028 - val_acc: 0.8499 - val_mse: 0.0028 - val_rmse: 0.0450 - val_r_square: 0.9808\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0077 - acc: 0.8949 - mse: 0.0077 - rmse: 0.0643 - r_square: 0.7684 - val_loss: 0.0025 - val_acc: 0.8516 - val_mse: 0.0025 - val_rmse: 0.0399 - val_r_square: 0.9840\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0080 - acc: 0.9659 - mse: 0.0080 - rmse: 0.0643 - r_square: 0.6878 - val_loss: 0.0030 - val_acc: 0.8882 - val_mse: 0.0030 - val_rmse: 0.0462 - val_r_square: 0.9794\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0087 - acc: 0.8830 - mse: 0.0087 - rmse: 0.0712 - r_square: 0.7952 - val_loss: 0.0058 - val_acc: 0.8365 - val_mse: 0.0058 - val_rmse: 0.0702 - val_r_square: 0.9579\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0078 - acc: 0.8855 - mse: 0.0078 - rmse: 0.0647 - r_square: 0.8019 - val_loss: 0.0027 - val_acc: 0.8902 - val_mse: 0.0027 - val_rmse: 0.0436 - val_r_square: 0.9823\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0086 - acc: 0.9572 - mse: 0.0086 - rmse: 0.0702 - r_square: 0.7312 - val_loss: 0.0024 - val_acc: 0.8497 - val_mse: 0.0024 - val_rmse: 0.0392 - val_r_square: 0.9846\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0091 - acc: 0.9007 - mse: 0.0091 - rmse: 0.0722 - r_square: 0.7266 - val_loss: 0.0085 - val_acc: 0.8896 - val_mse: 0.0085 - val_rmse: 0.0865 - val_r_square: 0.9374\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0078 - acc: 0.8949 - mse: 0.0078 - rmse: 0.0631 - r_square: 0.7994 - val_loss: 0.0082 - val_acc: 0.9090 - val_mse: 0.0082 - val_rmse: 0.0858 - val_r_square: 0.9391\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0073 - acc: 0.9505 - mse: 0.0073 - rmse: 0.0607 - r_square: 0.7910 - val_loss: 0.0038 - val_acc: 0.8608 - val_mse: 0.0038 - val_rmse: 0.0531 - val_r_square: 0.9740\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0081 - acc: 0.8970 - mse: 0.0081 - rmse: 0.0676 - r_square: 0.8071 - val_loss: 0.0047 - val_acc: 0.8496 - val_mse: 0.0047 - val_rmse: 0.0606 - val_r_square: 0.9669\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0101 - acc: 0.8938 - mse: 0.0101 - rmse: 0.0783 - r_square: 0.8203 - val_loss: 0.0055 - val_acc: 0.9940 - val_mse: 0.0055 - val_rmse: 0.0689 - val_r_square: 0.9611\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0082 - acc: 0.8853 - mse: 0.0082 - rmse: 0.0656 - r_square: 0.8492 - val_loss: 0.0042 - val_acc: 0.9942 - val_mse: 0.0042 - val_rmse: 0.0586 - val_r_square: 0.9706\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0069 - acc: 0.9557 - mse: 0.0069 - rmse: 0.0551 - r_square: 0.8847 - val_loss: 0.0034 - val_acc: 0.9942 - val_mse: 0.0034 - val_rmse: 0.0495 - val_r_square: 0.9766\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0063 - acc: 0.9689 - mse: 0.0063 - rmse: 0.0528 - r_square: 0.8795 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0367 - val_r_square: 0.9848\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0059 - acc: 0.9383 - mse: 0.0059 - rmse: 0.0480 - r_square: 0.8838 - val_loss: 0.0025 - val_acc: 0.9942 - val_mse: 0.0025 - val_rmse: 0.0407 - val_r_square: 0.9831\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0067 - acc: 0.8998 - mse: 0.0067 - rmse: 0.0549 - r_square: 0.8294 - val_loss: 0.0022 - val_acc: 0.9942 - val_mse: 0.0022 - val_rmse: 0.0358 - val_r_square: 0.9858\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0064 - acc: 0.9545 - mse: 0.0064 - rmse: 0.0526 - r_square: 0.8641 - val_loss: 0.0037 - val_acc: 0.9942 - val_mse: 0.0037 - val_rmse: 0.0527 - val_r_square: 0.9737\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0063 - acc: 0.9526 - mse: 0.0063 - rmse: 0.0523 - r_square: 0.8926 - val_loss: 0.0028 - val_acc: 0.9942 - val_mse: 0.0028 - val_rmse: 0.0437 - val_r_square: 0.9808\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0064 - acc: 0.9544 - mse: 0.0064 - rmse: 0.0540 - r_square: 0.8791 - val_loss: 0.0035 - val_acc: 0.9803 - val_mse: 0.0035 - val_rmse: 0.0505 - val_r_square: 0.9758\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0071 - acc: 0.9649 - mse: 0.0071 - rmse: 0.0577 - r_square: 0.8669 - val_loss: 0.0031 - val_acc: 0.8497 - val_mse: 0.0031 - val_rmse: 0.0459 - val_r_square: 0.9787\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0064 - acc: 0.9365 - mse: 0.0064 - rmse: 0.0526 - r_square: 0.8903 - val_loss: 0.0031 - val_acc: 0.9436 - val_mse: 0.0031 - val_rmse: 0.0463 - val_r_square: 0.9790\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0061 - acc: 0.9457 - mse: 0.0061 - rmse: 0.0478 - r_square: 0.8955 - val_loss: 0.0027 - val_acc: 0.8885 - val_mse: 0.0027 - val_rmse: 0.0432 - val_r_square: 0.9818\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0064 - acc: 0.9544 - mse: 0.0064 - rmse: 0.0528 - r_square: 0.8855 - val_loss: 0.0034 - val_acc: 0.8365 - val_mse: 0.0034 - val_rmse: 0.0501 - val_r_square: 0.9758\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0065 - acc: 0.9070 - mse: 0.0065 - rmse: 0.0522 - r_square: 0.8808 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0526 - val_r_square: 0.9746\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0061 - acc: 0.9019 - mse: 0.0061 - rmse: 0.0506 - r_square: 0.8789 - val_loss: 0.0032 - val_acc: 0.8630 - val_mse: 0.0032 - val_rmse: 0.0471 - val_r_square: 0.9782\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0070 - acc: 0.9641 - mse: 0.0070 - rmse: 0.0587 - r_square: 0.8419 - val_loss: 0.0031 - val_acc: 0.8615 - val_mse: 0.0031 - val_rmse: 0.0482 - val_r_square: 0.9785\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0073 - acc: 0.9077 - mse: 0.0073 - rmse: 0.0617 - r_square: 0.8351 - val_loss: 0.0029 - val_acc: 0.8365 - val_mse: 0.0029 - val_rmse: 0.0441 - val_r_square: 0.9811\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0064 - acc: 0.9126 - mse: 0.0064 - rmse: 0.0553 - r_square: 0.8543 - val_loss: 0.0025 - val_acc: 0.8374 - val_mse: 0.0025 - val_rmse: 0.0394 - val_r_square: 0.9830\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0062 - acc: 0.9045 - mse: 0.0062 - rmse: 0.0515 - r_square: 0.8715 - val_loss: 0.0022 - val_acc: 0.8627 - val_mse: 0.0022 - val_rmse: 0.0370 - val_r_square: 0.9863\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0068 - acc: 0.9557 - mse: 0.0068 - rmse: 0.0574 - r_square: 0.8419 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0319 - val_r_square: 0.9879\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0070 - acc: 0.9679 - mse: 0.0070 - rmse: 0.0586 - r_square: 0.8079 - val_loss: 0.0026 - val_acc: 0.8365 - val_mse: 0.0026 - val_rmse: 0.0404 - val_r_square: 0.9832\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0058 - acc: 0.8958 - mse: 0.0058 - rmse: 0.0480 - r_square: 0.8840 - val_loss: 0.0025 - val_acc: 0.9614 - val_mse: 0.0025 - val_rmse: 0.0397 - val_r_square: 0.9834\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0059 - acc: 0.9642 - mse: 0.0059 - rmse: 0.0501 - r_square: 0.8644 - val_loss: 0.0032 - val_acc: 0.9552 - val_mse: 0.0032 - val_rmse: 0.0487 - val_r_square: 0.9777\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0061 - acc: 0.9676 - mse: 0.0061 - rmse: 0.0513 - r_square: 0.8582 - val_loss: 0.0023 - val_acc: 0.9431 - val_mse: 0.0023 - val_rmse: 0.0376 - val_r_square: 0.9847\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0053 - acc: 0.9533 - mse: 0.0053 - rmse: 0.0423 - r_square: 0.8977 - val_loss: 0.0027 - val_acc: 0.9545 - val_mse: 0.0027 - val_rmse: 0.0428 - val_r_square: 0.9821\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 228us/step - loss: 0.0052 - acc: 0.9431 - mse: 0.0052 - rmse: 0.0405 - r_square: 0.9077 - val_loss: 0.0022 - val_acc: 0.9433 - val_mse: 0.0022 - val_rmse: 0.0362 - val_r_square: 0.9858\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0060 - acc: 0.9574 - mse: 0.0060 - rmse: 0.0490 - r_square: 0.8361 - val_loss: 0.0022 - val_acc: 0.9394 - val_mse: 0.0022 - val_rmse: 0.0374 - val_r_square: 0.9854\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0060 - acc: 0.9143 - mse: 0.0060 - rmse: 0.0479 - r_square: 0.8880 - val_loss: 0.0015 - val_acc: 0.9269 - val_mse: 0.0015 - val_rmse: 0.0234 - val_r_square: 0.9912\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0064 - acc: 0.9465 - mse: 0.0064 - rmse: 0.0538 - r_square: 0.8432 - val_loss: 0.0025 - val_acc: 0.8748 - val_mse: 0.0025 - val_rmse: 0.0392 - val_r_square: 0.9833\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0064 - acc: 0.9694 - mse: 0.0064 - rmse: 0.0532 - r_square: 0.8652 - val_loss: 0.0034 - val_acc: 0.9705 - val_mse: 0.0034 - val_rmse: 0.0491 - val_r_square: 0.9759\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0076 - acc: 0.9084 - mse: 0.0076 - rmse: 0.0647 - r_square: 0.8446 - val_loss: 0.0032 - val_acc: 0.8366 - val_mse: 0.0032 - val_rmse: 0.0476 - val_r_square: 0.9772\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0084 - acc: 0.9508 - mse: 0.0084 - rmse: 0.0673 - r_square: 0.7790 - val_loss: 0.0028 - val_acc: 0.8624 - val_mse: 0.0028 - val_rmse: 0.0444 - val_r_square: 0.9807\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0075 - acc: 0.9641 - mse: 0.0075 - rmse: 0.0619 - r_square: 0.8278 - val_loss: 0.0028 - val_acc: 0.8915 - val_mse: 0.0028 - val_rmse: 0.0428 - val_r_square: 0.9808\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0122 - acc: 0.8850 - mse: 0.0122 - rmse: 0.0714 - r_square: 0.7802 - val_loss: 0.0034 - val_acc: 0.8365 - val_mse: 0.0034 - val_rmse: 0.0507 - val_r_square: 0.9770\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0102 - acc: 0.9421 - mse: 0.0102 - rmse: 0.0641 - r_square: 0.8075 - val_loss: 0.0030 - val_acc: 0.8372 - val_mse: 0.0030 - val_rmse: 0.0455 - val_r_square: 0.9799\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0721 - acc: 0.7147 - mse: 0.0721 - rmse: 0.2057 - r_square: 0.3417 - val_loss: 0.0431 - val_acc: 0.8988 - val_mse: 0.0431 - val_rmse: 0.2029 - val_r_square: 0.6823\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0770 - acc: 0.5401 - mse: 0.0770 - rmse: 0.2489 - r_square: -0.7796 - val_loss: 0.0360 - val_acc: 0.9010 - val_mse: 0.0360 - val_rmse: 0.1847 - val_r_square: 0.7326\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0877 - acc: 0.5233 - mse: 0.0877 - rmse: 0.2715 - r_square: -0.5484 - val_loss: 0.0519 - val_acc: 0.8365 - val_mse: 0.0519 - val_rmse: 0.2263 - val_r_square: 0.6292\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.1373 - acc: 0.4456 - mse: 0.1373 - rmse: 0.3436 - r_square: -1.3818 - val_loss: 0.1173 - val_acc: 0.8365 - val_mse: 0.1173 - val_rmse: 0.3382 - val_r_square: 0.1085\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.1517 - acc: 0.4653 - mse: 0.1517 - rmse: 0.3604 - r_square: -4.5217 - val_loss: 0.1108 - val_acc: 0.8365 - val_mse: 0.1108 - val_rmse: 0.3240 - val_r_square: 0.1503\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.1726 - acc: 0.4089 - mse: 0.1726 - rmse: 0.3900 - r_square: -3.9312 - val_loss: 0.0664 - val_acc: 0.8365 - val_mse: 0.0664 - val_rmse: 0.2556 - val_r_square: 0.5017\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.1779 - acc: 0.3262 - mse: 0.1779 - rmse: 0.4078 - r_square: -3.5825 - val_loss: 0.0692 - val_acc: 0.8365 - val_mse: 0.0692 - val_rmse: 0.2618 - val_r_square: 0.5048\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.1584 - acc: 0.2767 - mse: 0.1584 - rmse: 0.3839 - r_square: -2.9449 - val_loss: 0.0586 - val_acc: 0.8365 - val_mse: 0.0586 - val_rmse: 0.2403 - val_r_square: 0.5844\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.1486 - acc: 0.2812 - mse: 0.1486 - rmse: 0.3725 - r_square: -2.3894 - val_loss: 0.0596 - val_acc: 0.8365 - val_mse: 0.0596 - val_rmse: 0.2412 - val_r_square: 0.5819\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.1394 - acc: 0.2812 - mse: 0.1394 - rmse: 0.3605 - r_square: -1.8202 - val_loss: 0.0626 - val_acc: 0.8365 - val_mse: 0.0626 - val_rmse: 0.2462 - val_r_square: 0.5642\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.1324 - acc: 0.2964 - mse: 0.1324 - rmse: 0.3507 - r_square: -1.5094 - val_loss: 0.0636 - val_acc: 0.8365 - val_mse: 0.0636 - val_rmse: 0.2475 - val_r_square: 0.5593\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.1277 - acc: 0.2596 - mse: 0.1277 - rmse: 0.3444 - r_square: -1.3478 - val_loss: 0.0644 - val_acc: 0.8365 - val_mse: 0.0644 - val_rmse: 0.2488 - val_r_square: 0.5545\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.1245 - acc: 0.2596 - mse: 0.1245 - rmse: 0.3400 - r_square: -1.2492 - val_loss: 0.0652 - val_acc: 0.8365 - val_mse: 0.0652 - val_rmse: 0.2504 - val_r_square: 0.5487\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop. Density (per sq. mi.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed_x',\n",
       "       'Deaths', 'Recovered', 'Confirmed_y', 'Country', 'Region', 'Population',\n",
       "       'Area (sq. mi.)', 'Pop. Density (per sq. mi.)',\n",
       "       'Coastline (coast/area ratio)', 'Net migration',\n",
       "       'Infant mortality (per 1000 births)', 'GDP ($ per capita)',\n",
       "       'Literacy (%)', 'Phones (per 1000)', 'Arable (%)', 'Crops (%)',\n",
       "       'Climate', 'Birthrate', 'Deathrate', 'Agriculture', 'Industry',\n",
       "       'Service', 'Month', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Pop. Density (per sq. mi.)' ,'Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 13s 2ms/step - loss: 0.0401 - acc: 0.6292 - rmse: 0.1624 - mse: 0.0401 - r_square: 0.2522 - val_loss: 0.0295 - val_acc: 0.8365 - val_rmse: 0.1542 - val_mse: 0.0295 - val_r_square: 0.7948\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0271 - acc: 0.9359 - rmse: 0.1291 - mse: 0.0271 - r_square: 0.5011 - val_loss: 0.0195 - val_acc: 0.8365 - val_rmse: 0.1300 - val_mse: 0.0195 - val_r_square: 0.8673\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0209 - acc: 0.9378 - rmse: 0.1076 - mse: 0.0209 - r_square: 0.6410 - val_loss: 0.0164 - val_acc: 0.8365 - val_rmse: 0.1218 - val_mse: 0.0164 - val_r_square: 0.8874\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0162 - acc: 0.9003 - rmse: 0.0899 - mse: 0.0162 - r_square: 0.7402 - val_loss: 0.0131 - val_acc: 0.8365 - val_rmse: 0.1098 - val_mse: 0.0131 - val_r_square: 0.9092\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 280us/step - loss: 0.0115 - acc: 0.9399 - rmse: 0.0678 - mse: 0.0115 - r_square: 0.8032 - val_loss: 0.0066 - val_acc: 0.8365 - val_rmse: 0.0738 - val_mse: 0.0066 - val_r_square: 0.9558\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0095 - acc: 0.9397 - rmse: 0.0595 - mse: 0.0095 - r_square: 0.8195 - val_loss: 0.0047 - val_acc: 0.8381 - val_rmse: 0.0575 - val_mse: 0.0047 - val_r_square: 0.9687\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0083 - acc: 0.9420 - rmse: 0.0530 - mse: 0.0083 - r_square: 0.8344 - val_loss: 0.0037 - val_acc: 0.8374 - val_rmse: 0.0491 - val_mse: 0.0037 - val_r_square: 0.9761\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0080 - acc: 0.9511 - rmse: 0.0519 - mse: 0.0080 - r_square: 0.8393 - val_loss: 0.0032 - val_acc: 0.8369 - val_rmse: 0.0462 - val_mse: 0.0032 - val_r_square: 0.9799\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0080 - acc: 0.9327 - rmse: 0.0530 - mse: 0.0080 - r_square: 0.8403 - val_loss: 0.0050 - val_acc: 0.9683 - val_rmse: 0.0625 - val_mse: 0.0050 - val_r_square: 0.9656\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0070 - acc: 0.9575 - rmse: 0.0438 - mse: 0.0070 - r_square: 0.8618 - val_loss: 0.0022 - val_acc: 0.8369 - val_rmse: 0.0345 - val_mse: 0.0022 - val_r_square: 0.9871\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0068 - acc: 0.9584 - rmse: 0.0437 - mse: 0.0068 - r_square: 0.8619 - val_loss: 0.0021 - val_acc: 0.8427 - val_rmse: 0.0357 - val_mse: 0.0021 - val_r_square: 0.9870\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0066 - acc: 0.9591 - rmse: 0.0418 - mse: 0.0066 - r_square: 0.8670 - val_loss: 0.0022 - val_acc: 0.8369 - val_rmse: 0.0336 - val_mse: 0.0022 - val_r_square: 0.9873\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0065 - acc: 0.9611 - rmse: 0.0424 - mse: 0.0065 - r_square: 0.8685 - val_loss: 0.0021 - val_acc: 0.8411 - val_rmse: 0.0355 - val_mse: 0.0021 - val_r_square: 0.9873\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0065 - acc: 0.9596 - rmse: 0.0432 - mse: 0.0065 - r_square: 0.8711 - val_loss: 0.0025 - val_acc: 0.8365 - val_rmse: 0.0381 - val_mse: 0.0025 - val_r_square: 0.9854\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0066 - acc: 0.9615 - rmse: 0.0455 - mse: 0.0066 - r_square: 0.8685 - val_loss: 0.0031 - val_acc: 0.8410 - val_rmse: 0.0476 - val_mse: 0.0031 - val_r_square: 0.9800\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0068 - acc: 0.9566 - rmse: 0.0475 - mse: 0.0068 - r_square: 0.8697 - val_loss: 0.0025 - val_acc: 0.8512 - val_rmse: 0.0405 - val_mse: 0.0025 - val_r_square: 0.9843\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0067 - acc: 0.9614 - rmse: 0.0464 - mse: 0.0067 - r_square: 0.8726 - val_loss: 0.0037 - val_acc: 0.8401 - val_rmse: 0.0539 - val_mse: 0.0037 - val_r_square: 0.9757\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0067 - acc: 0.9421 - rmse: 0.0475 - mse: 0.0067 - r_square: 0.8707 - val_loss: 0.0038 - val_acc: 0.9682 - val_rmse: 0.0537 - val_mse: 0.0038 - val_r_square: 0.9749\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0068 - acc: 0.9434 - rmse: 0.0480 - mse: 0.0068 - r_square: 0.8737 - val_loss: 0.0022 - val_acc: 0.9545 - val_rmse: 0.0353 - val_mse: 0.0022 - val_r_square: 0.9861\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0067 - acc: 0.9658 - rmse: 0.0481 - mse: 0.0067 - r_square: 0.8723 - val_loss: 0.0023 - val_acc: 0.8395 - val_rmse: 0.0380 - val_mse: 0.0023 - val_r_square: 0.9857\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0071 - acc: 0.9662 - rmse: 0.0513 - mse: 0.0071 - r_square: 0.8653 - val_loss: 0.0027 - val_acc: 0.8407 - val_rmse: 0.0418 - val_mse: 0.0027 - val_r_square: 0.9834\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0070 - acc: 0.9628 - rmse: 0.0492 - mse: 0.0070 - r_square: 0.8684 - val_loss: 0.0026 - val_acc: 0.9439 - val_rmse: 0.0405 - val_mse: 0.0026 - val_r_square: 0.9835\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0065 - acc: 0.9611 - rmse: 0.0452 - mse: 0.0065 - r_square: 0.8760 - val_loss: 0.0024 - val_acc: 0.9906 - val_rmse: 0.0388 - val_mse: 0.0024 - val_r_square: 0.9843\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0060 - acc: 0.9573 - rmse: 0.0402 - mse: 0.0060 - r_square: 0.8809 - val_loss: 0.0014 - val_acc: 0.9561 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0057 - acc: 0.9668 - rmse: 0.0384 - mse: 0.0057 - r_square: 0.8845 - val_loss: 0.0013 - val_acc: 0.8667 - val_rmse: 0.0188 - val_mse: 0.0013 - val_r_square: 0.9930\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0054 - acc: 0.9678 - rmse: 0.0362 - mse: 0.0054 - r_square: 0.8854 - val_loss: 0.0012 - val_acc: 0.8533 - val_rmse: 0.0167 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0053 - acc: 0.9679 - rmse: 0.0344 - mse: 0.0053 - r_square: 0.8923 - val_loss: 0.0012 - val_acc: 0.8405 - val_rmse: 0.0164 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 280us/step - loss: 0.0051 - acc: 0.9686 - rmse: 0.0315 - mse: 0.0051 - r_square: 0.8958 - val_loss: 0.0013 - val_acc: 0.8410 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9930\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0051 - acc: 0.9661 - rmse: 0.0328 - mse: 0.0051 - r_square: 0.8955 - val_loss: 0.0012 - val_acc: 0.8400 - val_rmse: 0.0193 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0052 - acc: 0.9687 - rmse: 0.0318 - mse: 0.0052 - r_square: 0.8941 - val_loss: 0.0014 - val_acc: 0.8405 - val_rmse: 0.0240 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0051 - acc: 0.9650 - rmse: 0.0334 - mse: 0.0051 - r_square: 0.8942 - val_loss: 0.0013 - val_acc: 0.8401 - val_rmse: 0.0226 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0051 - acc: 0.9693 - rmse: 0.0329 - mse: 0.0051 - r_square: 0.8941 - val_loss: 0.0015 - val_acc: 0.8402 - val_rmse: 0.0260 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0051 - acc: 0.9661 - rmse: 0.0344 - mse: 0.0051 - r_square: 0.8948 - val_loss: 0.0015 - val_acc: 0.8400 - val_rmse: 0.0254 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0050 - acc: 0.9695 - rmse: 0.0320 - mse: 0.0050 - r_square: 0.8982 - val_loss: 0.0015 - val_acc: 0.8395 - val_rmse: 0.0257 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9678 - rmse: 0.0341 - mse: 0.0050 - r_square: 0.8975 - val_loss: 0.0016 - val_acc: 0.8389 - val_rmse: 0.0281 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9695 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9010 - val_loss: 0.0014 - val_acc: 0.8392 - val_rmse: 0.0245 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0051 - acc: 0.9675 - rmse: 0.0344 - mse: 0.0051 - r_square: 0.8985 - val_loss: 0.0018 - val_acc: 0.8388 - val_rmse: 0.0328 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9692 - rmse: 0.0295 - mse: 0.0048 - r_square: 0.9017 - val_loss: 0.0014 - val_acc: 0.8391 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0053 - acc: 0.9680 - rmse: 0.0367 - mse: 0.0053 - r_square: 0.8963 - val_loss: 0.0019 - val_acc: 0.9016 - val_rmse: 0.0339 - val_mse: 0.0019 - val_r_square: 0.9877\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0048 - acc: 0.9688 - rmse: 0.0302 - mse: 0.0048 - r_square: 0.8993 - val_loss: 0.0014 - val_acc: 0.8523 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0055 - acc: 0.9664 - rmse: 0.0381 - mse: 0.0055 - r_square: 0.8937 - val_loss: 0.0015 - val_acc: 0.9642 - val_rmse: 0.0269 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9685 - rmse: 0.0327 - mse: 0.0053 - r_square: 0.8904 - val_loss: 0.0014 - val_acc: 0.8519 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0053 - acc: 0.9646 - rmse: 0.0371 - mse: 0.0053 - r_square: 0.8973 - val_loss: 0.0013 - val_acc: 0.9411 - val_rmse: 0.0228 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0049 - acc: 0.9706 - rmse: 0.0323 - mse: 0.0049 - r_square: 0.9014 - val_loss: 0.0013 - val_acc: 0.8741 - val_rmse: 0.0224 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9682 - rmse: 0.0353 - mse: 0.0051 - r_square: 0.9007 - val_loss: 0.0013 - val_acc: 0.9416 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9704 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9019 - val_loss: 0.0013 - val_acc: 0.9416 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0051 - acc: 0.9703 - rmse: 0.0351 - mse: 0.0051 - r_square: 0.9012 - val_loss: 0.0014 - val_acc: 0.9893 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0051 - acc: 0.9699 - rmse: 0.0348 - mse: 0.0051 - r_square: 0.9008 - val_loss: 0.0015 - val_acc: 0.9909 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9666 - rmse: 0.0348 - mse: 0.0050 - r_square: 0.9011 - val_loss: 0.0016 - val_acc: 0.9917 - val_rmse: 0.0280 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0049 - acc: 0.9652 - rmse: 0.0338 - mse: 0.0049 - r_square: 0.9013 - val_loss: 0.0016 - val_acc: 0.9911 - val_rmse: 0.0280 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0048 - acc: 0.9660 - rmse: 0.0323 - mse: 0.0048 - r_square: 0.9011 - val_loss: 0.0013 - val_acc: 0.9773 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9621 - rmse: 0.0321 - mse: 0.0048 - r_square: 0.8994 - val_loss: 0.0012 - val_acc: 0.8896 - val_rmse: 0.0173 - val_mse: 0.0012 - val_r_square: 0.9937\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9461 - rmse: 0.0350 - mse: 0.0050 - r_square: 0.8932 - val_loss: 0.0015 - val_acc: 0.8374 - val_rmse: 0.0263 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0052 - acc: 0.9556 - rmse: 0.0356 - mse: 0.0052 - r_square: 0.8873 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0293 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0052 - acc: 0.9642 - rmse: 0.0338 - mse: 0.0052 - r_square: 0.8889 - val_loss: 0.0015 - val_acc: 0.8379 - val_rmse: 0.0273 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0046 - acc: 0.9712 - rmse: 0.0291 - mse: 0.0046 - r_square: 0.9016 - val_loss: 0.0013 - val_acc: 0.8522 - val_rmse: 0.0225 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0045 - acc: 0.9717 - rmse: 0.0266 - mse: 0.0045 - r_square: 0.9056 - val_loss: 0.0012 - val_acc: 0.9053 - val_rmse: 0.0200 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0045 - acc: 0.9724 - rmse: 0.0253 - mse: 0.0045 - r_square: 0.9078 - val_loss: 0.0012 - val_acc: 0.9424 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0044 - acc: 0.9724 - rmse: 0.0248 - mse: 0.0044 - r_square: 0.9090 - val_loss: 0.0012 - val_acc: 0.9426 - val_rmse: 0.0186 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9723 - rmse: 0.0245 - mse: 0.0044 - r_square: 0.9095 - val_loss: 0.0012 - val_acc: 0.9426 - val_rmse: 0.0184 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9723 - rmse: 0.0241 - mse: 0.0044 - r_square: 0.9101 - val_loss: 0.0012 - val_acc: 0.9426 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9723 - rmse: 0.0239 - mse: 0.0044 - r_square: 0.9104 - val_loss: 0.0012 - val_acc: 0.9424 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0044 - acc: 0.9726 - rmse: 0.0236 - mse: 0.0044 - r_square: 0.9108 - val_loss: 0.0012 - val_acc: 0.9427 - val_rmse: 0.0186 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0044 - acc: 0.9720 - rmse: 0.0236 - mse: 0.0044 - r_square: 0.9108 - val_loss: 0.0012 - val_acc: 0.9427 - val_rmse: 0.0188 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0044 - acc: 0.9723 - rmse: 0.0234 - mse: 0.0044 - r_square: 0.9107 - val_loss: 0.0012 - val_acc: 0.9433 - val_rmse: 0.0187 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0045 - acc: 0.9712 - rmse: 0.0240 - mse: 0.0045 - r_square: 0.9088 - val_loss: 0.0012 - val_acc: 0.9426 - val_rmse: 0.0190 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0045 - acc: 0.9711 - rmse: 0.0242 - mse: 0.0045 - r_square: 0.9083 - val_loss: 0.0012 - val_acc: 0.9439 - val_rmse: 0.0188 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0045 - acc: 0.9720 - rmse: 0.0247 - mse: 0.0045 - r_square: 0.9077 - val_loss: 0.0012 - val_acc: 0.9426 - val_rmse: 0.0192 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0044 - acc: 0.9684 - rmse: 0.0244 - mse: 0.0044 - r_square: 0.9096 - val_loss: 0.0012 - val_acc: 0.9551 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9738 - rmse: 0.0241 - mse: 0.0044 - r_square: 0.9105 - val_loss: 0.0012 - val_acc: 0.9426 - val_rmse: 0.0194 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9701 - rmse: 0.0238 - mse: 0.0044 - r_square: 0.9109 - val_loss: 0.0012 - val_acc: 0.9551 - val_rmse: 0.0190 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0043 - acc: 0.9720 - rmse: 0.0236 - mse: 0.0043 - r_square: 0.9116 - val_loss: 0.0012 - val_acc: 0.9426 - val_rmse: 0.0194 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0043 - acc: 0.9712 - rmse: 0.0234 - mse: 0.0043 - r_square: 0.9114 - val_loss: 0.0012 - val_acc: 0.9551 - val_rmse: 0.0192 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9714 - rmse: 0.0232 - mse: 0.0044 - r_square: 0.9114 - val_loss: 0.0012 - val_acc: 0.9424 - val_rmse: 0.0195 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0045 - acc: 0.9718 - rmse: 0.0236 - mse: 0.0045 - r_square: 0.9091 - val_loss: 0.0012 - val_acc: 0.9551 - val_rmse: 0.0193 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9712 - rmse: 0.0234 - mse: 0.0044 - r_square: 0.9106 - val_loss: 0.0012 - val_acc: 0.9431 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9714 - rmse: 0.0237 - mse: 0.0044 - r_square: 0.9104 - val_loss: 0.0012 - val_acc: 0.9433 - val_rmse: 0.0195 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0043 - acc: 0.9710 - rmse: 0.0236 - mse: 0.0043 - r_square: 0.9115 - val_loss: 0.0012 - val_acc: 0.9554 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9722 - rmse: 0.0236 - mse: 0.0044 - r_square: 0.9117 - val_loss: 0.0012 - val_acc: 0.9436 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0043 - acc: 0.9712 - rmse: 0.0235 - mse: 0.0043 - r_square: 0.9118 - val_loss: 0.0012 - val_acc: 0.9554 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0044 - acc: 0.9717 - rmse: 0.0238 - mse: 0.0044 - r_square: 0.9113 - val_loss: 0.0013 - val_acc: 0.9442 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9712 - rmse: 0.0241 - mse: 0.0044 - r_square: 0.9102 - val_loss: 0.0012 - val_acc: 0.9555 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9712 - rmse: 0.0242 - mse: 0.0044 - r_square: 0.9101 - val_loss: 0.0013 - val_acc: 0.9555 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9692 - rmse: 0.0242 - mse: 0.0044 - r_square: 0.9109 - val_loss: 0.0012 - val_acc: 0.9555 - val_rmse: 0.0198 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0043 - acc: 0.9734 - rmse: 0.0239 - mse: 0.0043 - r_square: 0.9122 - val_loss: 0.0013 - val_acc: 0.9558 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0043 - acc: 0.9693 - rmse: 0.0236 - mse: 0.0043 - r_square: 0.9123 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0043 - acc: 0.9730 - rmse: 0.0237 - mse: 0.0043 - r_square: 0.9128 - val_loss: 0.0013 - val_acc: 0.9558 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9697 - rmse: 0.0237 - mse: 0.0044 - r_square: 0.9112 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9729 - rmse: 0.0242 - mse: 0.0044 - r_square: 0.9104 - val_loss: 0.0013 - val_acc: 0.9560 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9690 - rmse: 0.0242 - mse: 0.0044 - r_square: 0.9106 - val_loss: 0.0013 - val_acc: 0.9560 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0044 - acc: 0.9727 - rmse: 0.0240 - mse: 0.0044 - r_square: 0.9122 - val_loss: 0.0013 - val_acc: 0.9560 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0043 - acc: 0.9688 - rmse: 0.0236 - mse: 0.0043 - r_square: 0.9126 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0043 - acc: 0.9734 - rmse: 0.0238 - mse: 0.0043 - r_square: 0.9133 - val_loss: 0.0013 - val_acc: 0.9560 - val_rmse: 0.0197 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0043 - acc: 0.9690 - rmse: 0.0235 - mse: 0.0043 - r_square: 0.9132 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9734 - rmse: 0.0239 - mse: 0.0044 - r_square: 0.9125 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0194 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9686 - rmse: 0.0240 - mse: 0.0044 - r_square: 0.9104 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0045 - acc: 0.9739 - rmse: 0.0249 - mse: 0.0045 - r_square: 0.9084 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0194 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0043 - acc: 0.9676 - rmse: 0.0242 - mse: 0.0043 - r_square: 0.9122 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0043 - acc: 0.9734 - rmse: 0.0239 - mse: 0.0043 - r_square: 0.9134 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0193 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0043 - acc: 0.9701 - rmse: 0.0235 - mse: 0.0043 - r_square: 0.9140 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0192 - val_mse: 0.0012 - val_r_square: 0.9929\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 16s 2ms/step - loss: 0.0261 - acc: 0.7786 - rmse: 0.1276 - mse: 0.0261 - r_square: 0.4417 - val_loss: 0.0085 - val_acc: 0.9852 - val_rmse: 0.0857 - val_mse: 0.0085 - val_r_square: 0.9418\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0144 - acc: 0.8912 - rmse: 0.0898 - mse: 0.0144 - r_square: 0.6761 - val_loss: 0.0088 - val_acc: 0.8365 - val_rmse: 0.0894 - val_mse: 0.0088 - val_r_square: 0.9385\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0098 - acc: 0.9139 - rmse: 0.0617 - mse: 0.0098 - r_square: 0.8120 - val_loss: 0.0036 - val_acc: 0.8365 - val_rmse: 0.0509 - val_mse: 0.0036 - val_r_square: 0.9772\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0075 - acc: 0.9459 - rmse: 0.0470 - mse: 0.0075 - r_square: 0.8568 - val_loss: 0.0024 - val_acc: 0.8378 - val_rmse: 0.0377 - val_mse: 0.0024 - val_r_square: 0.9848\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0064 - acc: 0.9545 - rmse: 0.0348 - mse: 0.0064 - r_square: 0.8766 - val_loss: 0.0016 - val_acc: 0.8905 - val_rmse: 0.0238 - val_mse: 0.0016 - val_r_square: 0.9909\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0060 - acc: 0.9562 - rmse: 0.0338 - mse: 0.0060 - r_square: 0.8823 - val_loss: 0.0015 - val_acc: 0.8428 - val_rmse: 0.0221 - val_mse: 0.0015 - val_r_square: 0.9916\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0058 - acc: 0.9604 - rmse: 0.0320 - mse: 0.0058 - r_square: 0.8848 - val_loss: 0.0016 - val_acc: 0.8569 - val_rmse: 0.0249 - val_mse: 0.0016 - val_r_square: 0.9910\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0056 - acc: 0.9568 - rmse: 0.0320 - mse: 0.0056 - r_square: 0.8867 - val_loss: 0.0014 - val_acc: 0.8421 - val_rmse: 0.0218 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 346us/step - loss: 0.0055 - acc: 0.9596 - rmse: 0.0317 - mse: 0.0055 - r_square: 0.8858 - val_loss: 0.0016 - val_acc: 0.8441 - val_rmse: 0.0266 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 339us/step - loss: 0.0053 - acc: 0.9583 - rmse: 0.0304 - mse: 0.0053 - r_square: 0.8891 - val_loss: 0.0014 - val_acc: 0.8430 - val_rmse: 0.0236 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0053 - acc: 0.9634 - rmse: 0.0297 - mse: 0.0053 - r_square: 0.8898 - val_loss: 0.0015 - val_acc: 0.8434 - val_rmse: 0.0251 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0052 - acc: 0.9655 - rmse: 0.0293 - mse: 0.0052 - r_square: 0.8920 - val_loss: 0.0014 - val_acc: 0.8430 - val_rmse: 0.0224 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 343us/step - loss: 0.0052 - acc: 0.9666 - rmse: 0.0294 - mse: 0.0052 - r_square: 0.8923 - val_loss: 0.0015 - val_acc: 0.8417 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9916\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 342us/step - loss: 0.0051 - acc: 0.9673 - rmse: 0.0301 - mse: 0.0051 - r_square: 0.8932 - val_loss: 0.0013 - val_acc: 0.8411 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 342us/step - loss: 0.0052 - acc: 0.9680 - rmse: 0.0322 - mse: 0.0052 - r_square: 0.8913 - val_loss: 0.0016 - val_acc: 0.8398 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9909\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 340us/step - loss: 0.0051 - acc: 0.9688 - rmse: 0.0337 - mse: 0.0051 - r_square: 0.8899 - val_loss: 0.0013 - val_acc: 0.8404 - val_rmse: 0.0216 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 342us/step - loss: 0.0054 - acc: 0.9690 - rmse: 0.0358 - mse: 0.0054 - r_square: 0.8884 - val_loss: 0.0014 - val_acc: 0.8400 - val_rmse: 0.0246 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 343us/step - loss: 0.0053 - acc: 0.9693 - rmse: 0.0373 - mse: 0.0053 - r_square: 0.8862 - val_loss: 0.0015 - val_acc: 0.9062 - val_rmse: 0.0263 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0053 - acc: 0.9691 - rmse: 0.0343 - mse: 0.0053 - r_square: 0.8923 - val_loss: 0.0013 - val_acc: 0.8926 - val_rmse: 0.0210 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0051 - acc: 0.9698 - rmse: 0.0332 - mse: 0.0051 - r_square: 0.8898 - val_loss: 0.0013 - val_acc: 0.9182 - val_rmse: 0.0227 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 352us/step - loss: 0.0052 - acc: 0.9670 - rmse: 0.0305 - mse: 0.0052 - r_square: 0.8915 - val_loss: 0.0011 - val_acc: 0.8520 - val_rmse: 0.0159 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0052 - acc: 0.9688 - rmse: 0.0295 - mse: 0.0052 - r_square: 0.8896 - val_loss: 0.0012 - val_acc: 0.8400 - val_rmse: 0.0180 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 343us/step - loss: 0.0049 - acc: 0.9699 - rmse: 0.0280 - mse: 0.0049 - r_square: 0.8985 - val_loss: 0.0012 - val_acc: 0.8388 - val_rmse: 0.0166 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0047 - acc: 0.9707 - rmse: 0.0271 - mse: 0.0047 - r_square: 0.9020 - val_loss: 0.0012 - val_acc: 0.8392 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0047 - acc: 0.9703 - rmse: 0.0267 - mse: 0.0047 - r_square: 0.9022 - val_loss: 0.0012 - val_acc: 0.8385 - val_rmse: 0.0177 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 344us/step - loss: 0.0046 - acc: 0.9709 - rmse: 0.0264 - mse: 0.0046 - r_square: 0.9029 - val_loss: 0.0012 - val_acc: 0.8391 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 339us/step - loss: 0.0046 - acc: 0.9711 - rmse: 0.0266 - mse: 0.0046 - r_square: 0.9021 - val_loss: 0.0012 - val_acc: 0.8388 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0046 - acc: 0.9712 - rmse: 0.0266 - mse: 0.0046 - r_square: 0.9029 - val_loss: 0.0012 - val_acc: 0.8509 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0046 - acc: 0.9715 - rmse: 0.0270 - mse: 0.0046 - r_square: 0.9024 - val_loss: 0.0012 - val_acc: 0.8382 - val_rmse: 0.0174 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0046 - acc: 0.9716 - rmse: 0.0269 - mse: 0.0046 - r_square: 0.9036 - val_loss: 0.0012 - val_acc: 0.8650 - val_rmse: 0.0186 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0046 - acc: 0.9719 - rmse: 0.0275 - mse: 0.0046 - r_square: 0.9033 - val_loss: 0.0011 - val_acc: 0.8503 - val_rmse: 0.0162 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0046 - acc: 0.9719 - rmse: 0.0272 - mse: 0.0046 - r_square: 0.9046 - val_loss: 0.0011 - val_acc: 0.8774 - val_rmse: 0.0173 - val_mse: 0.0011 - val_r_square: 0.9937\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0047 - acc: 0.9723 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9028 - val_loss: 0.0011 - val_acc: 0.8378 - val_rmse: 0.0149 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0046 - acc: 0.9721 - rmse: 0.0282 - mse: 0.0046 - r_square: 0.9042 - val_loss: 0.0011 - val_acc: 0.8641 - val_rmse: 0.0159 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0048 - acc: 0.9722 - rmse: 0.0304 - mse: 0.0048 - r_square: 0.9012 - val_loss: 0.0011 - val_acc: 0.8372 - val_rmse: 0.0145 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0046 - acc: 0.9705 - rmse: 0.0288 - mse: 0.0046 - r_square: 0.9036 - val_loss: 0.0011 - val_acc: 0.8379 - val_rmse: 0.0164 - val_mse: 0.0011 - val_r_square: 0.9938\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0047 - acc: 0.9722 - rmse: 0.0298 - mse: 0.0047 - r_square: 0.9020 - val_loss: 0.0012 - val_acc: 0.8372 - val_rmse: 0.0161 - val_mse: 0.0012 - val_r_square: 0.9937\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0046 - acc: 0.9703 - rmse: 0.0275 - mse: 0.0046 - r_square: 0.9051 - val_loss: 0.0011 - val_acc: 0.8374 - val_rmse: 0.0160 - val_mse: 0.0011 - val_r_square: 0.9938\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0046 - acc: 0.9722 - rmse: 0.0278 - mse: 0.0046 - r_square: 0.9043 - val_loss: 0.0012 - val_acc: 0.8372 - val_rmse: 0.0172 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0045 - acc: 0.9714 - rmse: 0.0266 - mse: 0.0045 - r_square: 0.9062 - val_loss: 0.0011 - val_acc: 0.8372 - val_rmse: 0.0153 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0045 - acc: 0.9721 - rmse: 0.0268 - mse: 0.0045 - r_square: 0.9052 - val_loss: 0.0012 - val_acc: 0.8371 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0045 - acc: 0.9718 - rmse: 0.0266 - mse: 0.0045 - r_square: 0.9067 - val_loss: 0.0011 - val_acc: 0.8371 - val_rmse: 0.0143 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0045 - acc: 0.9722 - rmse: 0.0265 - mse: 0.0045 - r_square: 0.9051 - val_loss: 0.0012 - val_acc: 0.8369 - val_rmse: 0.0162 - val_mse: 0.0012 - val_r_square: 0.9938\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0045 - acc: 0.9732 - rmse: 0.0273 - mse: 0.0045 - r_square: 0.9066 - val_loss: 0.0012 - val_acc: 0.8368 - val_rmse: 0.0158 - val_mse: 0.0012 - val_r_square: 0.9937\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0045 - acc: 0.9724 - rmse: 0.0267 - mse: 0.0045 - r_square: 0.9055 - val_loss: 0.0012 - val_acc: 0.8366 - val_rmse: 0.0166 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0046 - acc: 0.9736 - rmse: 0.0280 - mse: 0.0046 - r_square: 0.9071 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0186 - val_mse: 0.0013 - val_r_square: 0.9931\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0046 - acc: 0.9725 - rmse: 0.0282 - mse: 0.0046 - r_square: 0.9053 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0190 - val_mse: 0.0013 - val_r_square: 0.9930\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0046 - acc: 0.9736 - rmse: 0.0295 - mse: 0.0046 - r_square: 0.9067 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0184 - val_mse: 0.0013 - val_r_square: 0.9930\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0047 - acc: 0.9725 - rmse: 0.0305 - mse: 0.0047 - r_square: 0.9043 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9919\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0048 - acc: 0.9727 - rmse: 0.0320 - mse: 0.0048 - r_square: 0.9033 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0049 - acc: 0.9725 - rmse: 0.0336 - mse: 0.0049 - r_square: 0.9011 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0285 - val_mse: 0.0017 - val_r_square: 0.9902\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0050 - acc: 0.9691 - rmse: 0.0364 - mse: 0.0050 - r_square: 0.8942 - val_loss: 0.0016 - val_acc: 0.8495 - val_rmse: 0.0271 - val_mse: 0.0016 - val_r_square: 0.9910\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0050 - acc: 0.9701 - rmse: 0.0368 - mse: 0.0050 - r_square: 0.8947 - val_loss: 0.0016 - val_acc: 0.8503 - val_rmse: 0.0288 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0053 - acc: 0.9559 - rmse: 0.0394 - mse: 0.0053 - r_square: 0.8913 - val_loss: 0.0022 - val_acc: 0.9918 - val_rmse: 0.0376 - val_mse: 0.0022 - val_r_square: 0.9859\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0049 - acc: 0.9710 - rmse: 0.0347 - mse: 0.0049 - r_square: 0.8995 - val_loss: 0.0010 - val_acc: 0.9646 - val_rmse: 0.0123 - val_mse: 0.0010 - val_r_square: 0.9944\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0053 - acc: 0.9682 - rmse: 0.0393 - mse: 0.0053 - r_square: 0.8979 - val_loss: 0.0014 - val_acc: 0.9919 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0049 - acc: 0.9728 - rmse: 0.0348 - mse: 0.0049 - r_square: 0.9023 - val_loss: 0.0015 - val_acc: 0.9653 - val_rmse: 0.0254 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0050 - acc: 0.9739 - rmse: 0.0363 - mse: 0.0050 - r_square: 0.8961 - val_loss: 0.0020 - val_acc: 0.9919 - val_rmse: 0.0343 - val_mse: 0.0020 - val_r_square: 0.9877\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0048 - acc: 0.9702 - rmse: 0.0323 - mse: 0.0048 - r_square: 0.9070 - val_loss: 0.0016 - val_acc: 0.9931 - val_rmse: 0.0280 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0048 - acc: 0.9722 - rmse: 0.0325 - mse: 0.0048 - r_square: 0.9057 - val_loss: 0.0016 - val_acc: 0.9932 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0048 - acc: 0.9693 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9077 - val_loss: 0.0014 - val_acc: 0.9927 - val_rmse: 0.0243 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0049 - acc: 0.9723 - rmse: 0.0335 - mse: 0.0049 - r_square: 0.9057 - val_loss: 0.0012 - val_acc: 0.9544 - val_rmse: 0.0195 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0048 - acc: 0.9482 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9054 - val_loss: 0.0011 - val_acc: 0.8503 - val_rmse: 0.0158 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0048 - acc: 0.9420 - rmse: 0.0328 - mse: 0.0048 - r_square: 0.9028 - val_loss: 0.0011 - val_acc: 0.8365 - val_rmse: 0.0155 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0047 - acc: 0.9450 - rmse: 0.0312 - mse: 0.0047 - r_square: 0.9060 - val_loss: 0.0011 - val_acc: 0.8365 - val_rmse: 0.0160 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0046 - acc: 0.9572 - rmse: 0.0308 - mse: 0.0046 - r_square: 0.9062 - val_loss: 0.0011 - val_acc: 0.8365 - val_rmse: 0.0160 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0046 - acc: 0.9633 - rmse: 0.0294 - mse: 0.0046 - r_square: 0.9082 - val_loss: 0.0011 - val_acc: 0.8368 - val_rmse: 0.0170 - val_mse: 0.0011 - val_r_square: 0.9937\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0046 - acc: 0.9675 - rmse: 0.0296 - mse: 0.0046 - r_square: 0.9089 - val_loss: 0.0012 - val_acc: 0.8368 - val_rmse: 0.0179 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0045 - acc: 0.9702 - rmse: 0.0292 - mse: 0.0045 - r_square: 0.9094 - val_loss: 0.0012 - val_acc: 0.8374 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0046 - acc: 0.9739 - rmse: 0.0301 - mse: 0.0046 - r_square: 0.9092 - val_loss: 0.0012 - val_acc: 0.8374 - val_rmse: 0.0199 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0046 - acc: 0.9737 - rmse: 0.0306 - mse: 0.0046 - r_square: 0.9079 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0208 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0047 - acc: 0.9739 - rmse: 0.0316 - mse: 0.0047 - r_square: 0.9068 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0048 - acc: 0.9703 - rmse: 0.0329 - mse: 0.0048 - r_square: 0.9050 - val_loss: 0.0014 - val_acc: 0.8375 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0048 - acc: 0.9742 - rmse: 0.0336 - mse: 0.0048 - r_square: 0.9064 - val_loss: 0.0014 - val_acc: 0.8374 - val_rmse: 0.0246 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0049 - acc: 0.9674 - rmse: 0.0355 - mse: 0.0049 - r_square: 0.9026 - val_loss: 0.0015 - val_acc: 0.8375 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0050 - acc: 0.9739 - rmse: 0.0361 - mse: 0.0050 - r_square: 0.9014 - val_loss: 0.0016 - val_acc: 0.8375 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9908\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0052 - acc: 0.9733 - rmse: 0.0380 - mse: 0.0052 - r_square: 0.8986 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9908\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0050 - acc: 0.9739 - rmse: 0.0354 - mse: 0.0050 - r_square: 0.9030 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0288 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0051 - acc: 0.9734 - rmse: 0.0380 - mse: 0.0051 - r_square: 0.9004 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0277 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0052 - acc: 0.9646 - rmse: 0.0385 - mse: 0.0052 - r_square: 0.9014 - val_loss: 0.0014 - val_acc: 0.8375 - val_rmse: 0.0242 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0051 - acc: 0.9640 - rmse: 0.0374 - mse: 0.0051 - r_square: 0.9001 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0207 - val_mse: 0.0013 - val_r_square: 0.9929\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0049 - acc: 0.9696 - rmse: 0.0351 - mse: 0.0049 - r_square: 0.9053 - val_loss: 0.0014 - val_acc: 0.8375 - val_rmse: 0.0236 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0050 - acc: 0.9714 - rmse: 0.0364 - mse: 0.0050 - r_square: 0.9014 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0269 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0048 - acc: 0.9651 - rmse: 0.0329 - mse: 0.0048 - r_square: 0.9054 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0274 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0048 - acc: 0.9707 - rmse: 0.0332 - mse: 0.0048 - r_square: 0.9054 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0280 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0046 - acc: 0.9656 - rmse: 0.0309 - mse: 0.0046 - r_square: 0.9097 - val_loss: 0.0015 - val_acc: 0.8377 - val_rmse: 0.0256 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0046 - acc: 0.9663 - rmse: 0.0309 - mse: 0.0046 - r_square: 0.9089 - val_loss: 0.0014 - val_acc: 0.8377 - val_rmse: 0.0247 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0047 - acc: 0.9661 - rmse: 0.0296 - mse: 0.0047 - r_square: 0.9082 - val_loss: 0.0013 - val_acc: 0.8377 - val_rmse: 0.0233 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0047 - acc: 0.9690 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9078 - val_loss: 0.0013 - val_acc: 0.8377 - val_rmse: 0.0221 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0045 - acc: 0.9631 - rmse: 0.0275 - mse: 0.0045 - r_square: 0.9114 - val_loss: 0.0012 - val_acc: 0.8377 - val_rmse: 0.0205 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0044 - acc: 0.9706 - rmse: 0.0259 - mse: 0.0044 - r_square: 0.9129 - val_loss: 0.0012 - val_acc: 0.8512 - val_rmse: 0.0194 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0044 - acc: 0.9657 - rmse: 0.0248 - mse: 0.0044 - r_square: 0.9129 - val_loss: 0.0012 - val_acc: 0.8777 - val_rmse: 0.0184 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0044 - acc: 0.9713 - rmse: 0.0239 - mse: 0.0044 - r_square: 0.9121 - val_loss: 0.0012 - val_acc: 0.8909 - val_rmse: 0.0184 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0044 - acc: 0.9654 - rmse: 0.0237 - mse: 0.0044 - r_square: 0.9101 - val_loss: 0.0012 - val_acc: 0.9039 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0044 - acc: 0.9720 - rmse: 0.0229 - mse: 0.0044 - r_square: 0.9114 - val_loss: 0.0012 - val_acc: 0.9303 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0043 - acc: 0.9683 - rmse: 0.0230 - mse: 0.0043 - r_square: 0.9122 - val_loss: 0.0012 - val_acc: 0.9316 - val_rmse: 0.0186 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0043 - acc: 0.9727 - rmse: 0.0220 - mse: 0.0043 - r_square: 0.9134 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0191 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0043 - acc: 0.9697 - rmse: 0.0226 - mse: 0.0043 - r_square: 0.9132 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0043 - acc: 0.9729 - rmse: 0.0218 - mse: 0.0043 - r_square: 0.9144 - val_loss: 0.0012 - val_acc: 0.9564 - val_rmse: 0.0192 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 341us/step - loss: 0.0043 - acc: 0.9723 - rmse: 0.0223 - mse: 0.0043 - r_square: 0.9138 - val_loss: 0.0012 - val_acc: 0.9561 - val_rmse: 0.0191 - val_mse: 0.0012 - val_r_square: 0.9932\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 3s 475us/step - loss: 0.0139 - acc: 0.9051 - mse: 0.0139 - rmse: 0.0895 - r_square: 0.6758 - val_loss: 0.0052 - val_acc: 0.8765 - val_mse: 0.0052 - val_rmse: 0.0674 - val_r_square: 0.9648\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 250us/step - loss: 0.0133 - acc: 0.8974 - mse: 0.0133 - rmse: 0.0946 - r_square: 0.5123 - val_loss: 0.0066 - val_acc: 0.9937 - val_mse: 0.0066 - val_rmse: 0.0763 - val_r_square: 0.9527\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0104 - acc: 0.9045 - mse: 0.0104 - rmse: 0.0701 - r_square: 0.7564 - val_loss: 0.0021 - val_acc: 0.8365 - val_mse: 0.0021 - val_rmse: 0.0293 - val_r_square: 0.9886\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0121 - acc: 0.9511 - mse: 0.0121 - rmse: 0.0861 - r_square: 0.5739 - val_loss: 0.0033 - val_acc: 0.9922 - val_mse: 0.0033 - val_rmse: 0.0492 - val_r_square: 0.9786\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0097 - acc: 0.8832 - mse: 0.0097 - rmse: 0.0742 - r_square: 0.6238 - val_loss: 0.0043 - val_acc: 0.8365 - val_mse: 0.0043 - val_rmse: 0.0598 - val_r_square: 0.9716\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0104 - acc: 0.9525 - mse: 0.0104 - rmse: 0.0745 - r_square: 0.7731 - val_loss: 0.0034 - val_acc: 0.8372 - val_mse: 0.0034 - val_rmse: 0.0504 - val_r_square: 0.9789\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0091 - acc: 0.9388 - mse: 0.0091 - rmse: 0.0627 - r_square: 0.7267 - val_loss: 0.0019 - val_acc: 0.8371 - val_mse: 0.0019 - val_rmse: 0.0339 - val_r_square: 0.9878\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0076 - acc: 0.9742 - mse: 0.0076 - rmse: 0.0591 - r_square: 0.8071 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0545 - val_r_square: 0.9755\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 239us/step - loss: 0.0084 - acc: 0.9176 - mse: 0.0084 - rmse: 0.0649 - r_square: 0.7478 - val_loss: 0.0064 - val_acc: 0.8368 - val_mse: 0.0064 - val_rmse: 0.0769 - val_r_square: 0.9561\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 239us/step - loss: 0.0087 - acc: 0.9406 - mse: 0.0087 - rmse: 0.0630 - r_square: 0.8112 - val_loss: 0.0035 - val_acc: 0.8371 - val_mse: 0.0035 - val_rmse: 0.0529 - val_r_square: 0.9778\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 241us/step - loss: 0.0089 - acc: 0.9106 - mse: 0.0089 - rmse: 0.0623 - r_square: 0.7946 - val_loss: 0.0041 - val_acc: 0.8365 - val_mse: 0.0041 - val_rmse: 0.0591 - val_r_square: 0.9728\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 251us/step - loss: 0.0081 - acc: 0.9688 - mse: 0.0081 - rmse: 0.0617 - r_square: 0.8042 - val_loss: 0.0038 - val_acc: 0.9537 - val_mse: 0.0038 - val_rmse: 0.0558 - val_r_square: 0.9744\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 253us/step - loss: 0.0094 - acc: 0.9651 - mse: 0.0094 - rmse: 0.0626 - r_square: 0.7673 - val_loss: 0.0019 - val_acc: 0.8893 - val_mse: 0.0019 - val_rmse: 0.0311 - val_r_square: 0.9879\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 246us/step - loss: 0.0070 - acc: 0.9738 - mse: 0.0070 - rmse: 0.0581 - r_square: 0.7318 - val_loss: 0.0021 - val_acc: 0.9784 - val_mse: 0.0021 - val_rmse: 0.0355 - val_r_square: 0.9864\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 243us/step - loss: 0.0054 - acc: 0.9570 - mse: 0.0054 - rmse: 0.0403 - r_square: 0.8741 - val_loss: 0.0017 - val_acc: 0.8643 - val_mse: 0.0017 - val_rmse: 0.0306 - val_r_square: 0.9892\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0054 - acc: 0.9634 - mse: 0.0054 - rmse: 0.0393 - r_square: 0.8685 - val_loss: 0.0012 - val_acc: 0.9942 - val_mse: 0.0012 - val_rmse: 0.0165 - val_r_square: 0.9936\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 239us/step - loss: 0.0049 - acc: 0.9713 - mse: 0.0049 - rmse: 0.0327 - r_square: 0.8851 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0254 - val_r_square: 0.9914\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0051 - acc: 0.9741 - mse: 0.0051 - rmse: 0.0377 - r_square: 0.8884 - val_loss: 0.0024 - val_acc: 0.9657 - val_mse: 0.0024 - val_rmse: 0.0383 - val_r_square: 0.9845\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 235us/step - loss: 0.0061 - acc: 0.9672 - mse: 0.0061 - rmse: 0.0451 - r_square: 0.8729 - val_loss: 0.0036 - val_acc: 0.9157 - val_mse: 0.0036 - val_rmse: 0.0514 - val_r_square: 0.9756\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 242us/step - loss: 0.0063 - acc: 0.9744 - mse: 0.0063 - rmse: 0.0480 - r_square: 0.8643 - val_loss: 0.0020 - val_acc: 0.8366 - val_mse: 0.0020 - val_rmse: 0.0299 - val_r_square: 0.9887\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0066 - acc: 0.9729 - mse: 0.0066 - rmse: 0.0520 - r_square: 0.8500 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0421 - val_r_square: 0.9821\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0062 - acc: 0.9733 - mse: 0.0062 - rmse: 0.0487 - r_square: 0.8688 - val_loss: 0.0028 - val_acc: 0.8365 - val_mse: 0.0028 - val_rmse: 0.0346 - val_r_square: 0.9841\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 246us/step - loss: 0.0062 - acc: 0.9505 - mse: 0.0062 - rmse: 0.0435 - r_square: 0.8825 - val_loss: 0.0042 - val_acc: 0.9942 - val_mse: 0.0042 - val_rmse: 0.0591 - val_r_square: 0.9726\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0059 - acc: 0.9664 - mse: 0.0059 - rmse: 0.0478 - r_square: 0.8430 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0277 - val_r_square: 0.9902\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0064 - acc: 0.9687 - mse: 0.0064 - rmse: 0.0493 - r_square: 0.8185 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0295 - val_r_square: 0.9903\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0060 - acc: 0.9691 - mse: 0.0060 - rmse: 0.0481 - r_square: 0.8450 - val_loss: 0.0023 - val_acc: 0.8371 - val_mse: 0.0023 - val_rmse: 0.0407 - val_r_square: 0.9848\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 235us/step - loss: 0.0052 - acc: 0.9659 - mse: 0.0052 - rmse: 0.0395 - r_square: 0.8785 - val_loss: 0.0016 - val_acc: 0.9544 - val_mse: 0.0016 - val_rmse: 0.0290 - val_r_square: 0.9903\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 239us/step - loss: 0.0056 - acc: 0.9743 - mse: 0.0056 - rmse: 0.0448 - r_square: 0.8752 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0273 - val_r_square: 0.9906\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 252us/step - loss: 0.0063 - acc: 0.9750 - mse: 0.0063 - rmse: 0.0510 - r_square: 0.8459 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0286 - val_r_square: 0.9903\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 249us/step - loss: 0.0063 - acc: 0.9450 - mse: 0.0063 - rmse: 0.0515 - r_square: 0.8403 - val_loss: 0.0026 - val_acc: 0.8365 - val_mse: 0.0026 - val_rmse: 0.0425 - val_r_square: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0054 - acc: 0.9745 - mse: 0.0054 - rmse: 0.0428 - r_square: 0.8696 - val_loss: 0.0015 - val_acc: 0.8371 - val_mse: 0.0015 - val_rmse: 0.0248 - val_r_square: 0.9914\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0067 - acc: 0.9322 - mse: 0.0067 - rmse: 0.0535 - r_square: 0.8641 - val_loss: 0.0040 - val_acc: 0.8365 - val_mse: 0.0040 - val_rmse: 0.0564 - val_r_square: 0.9743\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0064 - acc: 0.9569 - mse: 0.0064 - rmse: 0.0510 - r_square: 0.8673 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0279 - val_r_square: 0.9902\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0059 - acc: 0.9697 - mse: 0.0059 - rmse: 0.0437 - r_square: 0.8579 - val_loss: 0.0025 - val_acc: 0.8365 - val_mse: 0.0025 - val_rmse: 0.0425 - val_r_square: 0.9835\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0061 - acc: 0.9235 - mse: 0.0061 - rmse: 0.0499 - r_square: 0.8604 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0300 - val_r_square: 0.9894\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0057 - acc: 0.9671 - mse: 0.0057 - rmse: 0.0456 - r_square: 0.8766 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0342 - val_r_square: 0.9873\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0056 - acc: 0.9667 - mse: 0.0056 - rmse: 0.0448 - r_square: 0.8721 - val_loss: 0.0019 - val_acc: 0.9234 - val_mse: 0.0019 - val_rmse: 0.0322 - val_r_square: 0.9883\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 238us/step - loss: 0.0054 - acc: 0.9704 - mse: 0.0054 - rmse: 0.0429 - r_square: 0.8831 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0268 - val_r_square: 0.9910\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 245us/step - loss: 0.0058 - acc: 0.9749 - mse: 0.0058 - rmse: 0.0468 - r_square: 0.8608 - val_loss: 0.0015 - val_acc: 0.8372 - val_mse: 0.0015 - val_rmse: 0.0236 - val_r_square: 0.9917\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0055 - acc: 0.9719 - mse: 0.0055 - rmse: 0.0413 - r_square: 0.8745 - val_loss: 0.0023 - val_acc: 0.8366 - val_mse: 0.0023 - val_rmse: 0.0404 - val_r_square: 0.9853\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 233us/step - loss: 0.0053 - acc: 0.9747 - mse: 0.0053 - rmse: 0.0410 - r_square: 0.8861 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0304 - val_r_square: 0.9898\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0053 - acc: 0.9729 - mse: 0.0053 - rmse: 0.0415 - r_square: 0.8614 - val_loss: 0.0013 - val_acc: 0.8366 - val_mse: 0.0013 - val_rmse: 0.0200 - val_r_square: 0.9926\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0065 - acc: 0.9749 - mse: 0.0065 - rmse: 0.0529 - r_square: 0.8264 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0386 - val_r_square: 0.9861\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0054 - acc: 0.9678 - mse: 0.0054 - rmse: 0.0449 - r_square: 0.8661 - val_loss: 0.0022 - val_acc: 0.8365 - val_mse: 0.0022 - val_rmse: 0.0367 - val_r_square: 0.9869\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 238us/step - loss: 0.0051 - acc: 0.9746 - mse: 0.0051 - rmse: 0.0385 - r_square: 0.8884 - val_loss: 0.0014 - val_acc: 0.9424 - val_mse: 0.0014 - val_rmse: 0.0235 - val_r_square: 0.9919\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 244us/step - loss: 0.0055 - acc: 0.9687 - mse: 0.0055 - rmse: 0.0459 - r_square: 0.8671 - val_loss: 0.0015 - val_acc: 0.9417 - val_mse: 0.0015 - val_rmse: 0.0268 - val_r_square: 0.9908\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0057 - acc: 0.9747 - mse: 0.0057 - rmse: 0.0458 - r_square: 0.8481 - val_loss: 0.0012 - val_acc: 0.8604 - val_mse: 0.0012 - val_rmse: 0.0189 - val_r_square: 0.9932\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0059 - acc: 0.9495 - mse: 0.0059 - rmse: 0.0504 - r_square: 0.8448 - val_loss: 0.0019 - val_acc: 0.9289 - val_mse: 0.0019 - val_rmse: 0.0334 - val_r_square: 0.9881\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0055 - acc: 0.8787 - mse: 0.0055 - rmse: 0.0430 - r_square: 0.8471 - val_loss: 0.0025 - val_acc: 0.8900 - val_mse: 0.0025 - val_rmse: 0.0421 - val_r_square: 0.9835\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0053 - acc: 0.9222 - mse: 0.0053 - rmse: 0.0429 - r_square: 0.8625 - val_loss: 0.0013 - val_acc: 0.9424 - val_mse: 0.0013 - val_rmse: 0.0208 - val_r_square: 0.9927\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0053 - acc: 0.9457 - mse: 0.0053 - rmse: 0.0416 - r_square: 0.8538 - val_loss: 0.0014 - val_acc: 0.8974 - val_mse: 0.0014 - val_rmse: 0.0253 - val_r_square: 0.9913\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0055 - acc: 0.9704 - mse: 0.0055 - rmse: 0.0428 - r_square: 0.8477 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0253 - val_r_square: 0.9916\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0057 - acc: 0.9326 - mse: 0.0057 - rmse: 0.0452 - r_square: 0.8095 - val_loss: 0.0013 - val_acc: 0.8759 - val_mse: 0.0013 - val_rmse: 0.0198 - val_r_square: 0.9929\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0059 - acc: 0.9706 - mse: 0.0059 - rmse: 0.0454 - r_square: 0.8521 - val_loss: 0.0012 - val_acc: 0.9430 - val_mse: 0.0012 - val_rmse: 0.0177 - val_r_square: 0.9934\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0056 - acc: 0.9522 - mse: 0.0056 - rmse: 0.0461 - r_square: 0.8543 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0248 - val_r_square: 0.9911\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0053 - acc: 0.9665 - mse: 0.0053 - rmse: 0.0401 - r_square: 0.8666 - val_loss: 0.0015 - val_acc: 0.9908 - val_mse: 0.0015 - val_rmse: 0.0258 - val_r_square: 0.9910\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0055 - acc: 0.9701 - mse: 0.0055 - rmse: 0.0414 - r_square: 0.8772 - val_loss: 0.0013 - val_acc: 0.8615 - val_mse: 0.0013 - val_rmse: 0.0213 - val_r_square: 0.9927\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0052 - acc: 0.9584 - mse: 0.0052 - rmse: 0.0404 - r_square: 0.8723 - val_loss: 0.0012 - val_acc: 0.8365 - val_mse: 0.0012 - val_rmse: 0.0162 - val_r_square: 0.9936\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0056 - acc: 0.9445 - mse: 0.0056 - rmse: 0.0446 - r_square: 0.8280 - val_loss: 0.0013 - val_acc: 0.8772 - val_mse: 0.0013 - val_rmse: 0.0189 - val_r_square: 0.9930\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0067 - acc: 0.9325 - mse: 0.0067 - rmse: 0.0553 - r_square: 0.7588 - val_loss: 0.0015 - val_acc: 0.9064 - val_mse: 0.0015 - val_rmse: 0.0262 - val_r_square: 0.9912\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0058 - acc: 0.9514 - mse: 0.0058 - rmse: 0.0463 - r_square: 0.8516 - val_loss: 0.0027 - val_acc: 0.8365 - val_mse: 0.0027 - val_rmse: 0.0446 - val_r_square: 0.9826\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0059 - acc: 0.9520 - mse: 0.0059 - rmse: 0.0461 - r_square: 0.8586 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0408 - val_r_square: 0.9847\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0053 - acc: 0.9672 - mse: 0.0053 - rmse: 0.0432 - r_square: 0.8879 - val_loss: 0.0012 - val_acc: 0.8499 - val_mse: 0.0012 - val_rmse: 0.0146 - val_r_square: 0.9938\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0059 - acc: 0.9566 - mse: 0.0059 - rmse: 0.0478 - r_square: 0.8278 - val_loss: 0.0025 - val_acc: 0.9430 - val_mse: 0.0025 - val_rmse: 0.0408 - val_r_square: 0.9844\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0055 - acc: 0.9735 - mse: 0.0055 - rmse: 0.0437 - r_square: 0.8760 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0468 - val_r_square: 0.9811\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0051 - acc: 0.9689 - mse: 0.0051 - rmse: 0.0405 - r_square: 0.8853 - val_loss: 0.0023 - val_acc: 0.8371 - val_mse: 0.0023 - val_rmse: 0.0391 - val_r_square: 0.9855\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0053 - acc: 0.9718 - mse: 0.0053 - rmse: 0.0394 - r_square: 0.8879 - val_loss: 0.0026 - val_acc: 0.8365 - val_mse: 0.0026 - val_rmse: 0.0417 - val_r_square: 0.9841\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0057 - acc: 0.9743 - mse: 0.0057 - rmse: 0.0428 - r_square: 0.8865 - val_loss: 0.0026 - val_acc: 0.9003 - val_mse: 0.0026 - val_rmse: 0.0415 - val_r_square: 0.9841\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0054 - acc: 0.9619 - mse: 0.0054 - rmse: 0.0408 - r_square: 0.8846 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0324 - val_r_square: 0.9887\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0056 - acc: 0.9739 - mse: 0.0056 - rmse: 0.0473 - r_square: 0.8527 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0256 - val_r_square: 0.9914\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0062 - acc: 0.9554 - mse: 0.0062 - rmse: 0.0499 - r_square: 0.8217 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0355 - val_r_square: 0.9870\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0067 - acc: 0.9635 - mse: 0.0067 - rmse: 0.0536 - r_square: 0.8015 - val_loss: 0.0021 - val_acc: 0.9940 - val_mse: 0.0021 - val_rmse: 0.0361 - val_r_square: 0.9866\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0060 - acc: 0.8440 - mse: 0.0060 - rmse: 0.0501 - r_square: 0.8214 - val_loss: 0.0014 - val_acc: 0.9349 - val_mse: 0.0014 - val_rmse: 0.0224 - val_r_square: 0.9921\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0058 - acc: 0.9596 - mse: 0.0058 - rmse: 0.0492 - r_square: 0.8532 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0241 - val_r_square: 0.9918\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0059 - acc: 0.9183 - mse: 0.0059 - rmse: 0.0468 - r_square: 0.7921 - val_loss: 0.0014 - val_acc: 0.9008 - val_mse: 0.0014 - val_rmse: 0.0242 - val_r_square: 0.9916\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0055 - acc: 0.9541 - mse: 0.0055 - rmse: 0.0430 - r_square: 0.8481 - val_loss: 0.0021 - val_acc: 0.9942 - val_mse: 0.0021 - val_rmse: 0.0364 - val_r_square: 0.9869\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0055 - acc: 0.9537 - mse: 0.0055 - rmse: 0.0436 - r_square: 0.8500 - val_loss: 0.0013 - val_acc: 0.8365 - val_mse: 0.0013 - val_rmse: 0.0216 - val_r_square: 0.9927\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0052 - acc: 0.9337 - mse: 0.0052 - rmse: 0.0387 - r_square: 0.8726 - val_loss: 0.0012 - val_acc: 0.9869 - val_mse: 0.0012 - val_rmse: 0.0183 - val_r_square: 0.9934\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0051 - acc: 0.9748 - mse: 0.0051 - rmse: 0.0378 - r_square: 0.8587 - val_loss: 0.0014 - val_acc: 0.9931 - val_mse: 0.0014 - val_rmse: 0.0240 - val_r_square: 0.9915\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0054 - acc: 0.9698 - mse: 0.0054 - rmse: 0.0400 - r_square: 0.8657 - val_loss: 0.0011 - val_acc: 0.9937 - val_mse: 0.0011 - val_rmse: 0.0159 - val_r_square: 0.9936\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0052 - acc: 0.9697 - mse: 0.0052 - rmse: 0.0373 - r_square: 0.8652 - val_loss: 0.0013 - val_acc: 0.9931 - val_mse: 0.0013 - val_rmse: 0.0194 - val_r_square: 0.9925\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.9533 - mse: 0.0057 - rmse: 0.0436 - r_square: 0.8501 - val_loss: 0.0015 - val_acc: 0.9293 - val_mse: 0.0015 - val_rmse: 0.0258 - val_r_square: 0.9912\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0100 - acc: 0.9111 - mse: 0.0100 - rmse: 0.0612 - r_square: 0.7765 - val_loss: 0.0030 - val_acc: 0.9557 - val_mse: 0.0030 - val_rmse: 0.0459 - val_r_square: 0.9803\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0323 - acc: 0.7410 - mse: 0.0323 - rmse: 0.1418 - r_square: 0.2326 - val_loss: 0.0388 - val_acc: 0.8388 - val_mse: 0.0388 - val_rmse: 0.1933 - val_r_square: 0.7204\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0438 - acc: 0.7392 - mse: 0.0438 - rmse: 0.1729 - r_square: -2.0968 - val_loss: 0.0071 - val_acc: 0.9856 - val_mse: 0.0071 - val_rmse: 0.0643 - val_r_square: 0.9595\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0454 - acc: 0.6983 - mse: 0.0454 - rmse: 0.1867 - r_square: -1.8367 - val_loss: 0.0095 - val_acc: 0.8365 - val_mse: 0.0095 - val_rmse: 0.0928 - val_r_square: 0.9374\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0442 - acc: 0.7726 - mse: 0.0442 - rmse: 0.1771 - r_square: -0.4761 - val_loss: 0.0099 - val_acc: 0.9067 - val_mse: 0.0099 - val_rmse: 0.0929 - val_r_square: 0.9302\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0442 - acc: 0.8728 - mse: 0.0442 - rmse: 0.1814 - r_square: -0.6502 - val_loss: 0.0419 - val_acc: 0.9931 - val_mse: 0.0419 - val_rmse: 0.2001 - val_r_square: 0.6944\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0303 - acc: 0.9020 - mse: 0.0303 - rmse: 0.1499 - r_square: 0.0582 - val_loss: 0.0470 - val_acc: 0.9942 - val_mse: 0.0470 - val_rmse: 0.2139 - val_r_square: 0.6597\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0274 - acc: 0.9472 - mse: 0.0274 - rmse: 0.1429 - r_square: 0.1054 - val_loss: 0.0486 - val_acc: 0.9931 - val_mse: 0.0486 - val_rmse: 0.2171 - val_r_square: 0.6468\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0255 - acc: 0.9582 - mse: 0.0255 - rmse: 0.1351 - r_square: 0.2079 - val_loss: 0.0486 - val_acc: 0.9942 - val_mse: 0.0486 - val_rmse: 0.2169 - val_r_square: 0.6473\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0245 - acc: 0.9550 - mse: 0.0245 - rmse: 0.1337 - r_square: 0.2159 - val_loss: 0.0447 - val_acc: 0.9924 - val_mse: 0.0447 - val_rmse: 0.2086 - val_r_square: 0.6760\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0248 - acc: 0.9610 - mse: 0.0248 - rmse: 0.1334 - r_square: 0.2335 - val_loss: 0.0497 - val_acc: 0.9942 - val_mse: 0.0497 - val_rmse: 0.2195 - val_r_square: 0.6397\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0237 - acc: 0.9588 - mse: 0.0237 - rmse: 0.1303 - r_square: 0.2516 - val_loss: 0.0493 - val_acc: 0.9932 - val_mse: 0.0493 - val_rmse: 0.2190 - val_r_square: 0.6427\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0234 - acc: 0.9606 - mse: 0.0234 - rmse: 0.1294 - r_square: 0.2556 - val_loss: 0.0486 - val_acc: 0.9942 - val_mse: 0.0486 - val_rmse: 0.2175 - val_r_square: 0.6482\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0234 - acc: 0.9609 - mse: 0.0234 - rmse: 0.1298 - r_square: 0.2302 - val_loss: 0.0495 - val_acc: 0.9941 - val_mse: 0.0495 - val_rmse: 0.2196 - val_r_square: 0.6421\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0229 - acc: 0.9606 - mse: 0.0229 - rmse: 0.1286 - r_square: 0.2440 - val_loss: 0.0494 - val_acc: 0.9942 - val_mse: 0.0494 - val_rmse: 0.2195 - val_r_square: 0.6423\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0229 - acc: 0.9612 - mse: 0.0229 - rmse: 0.1282 - r_square: 0.2439 - val_loss: 0.0498 - val_acc: 0.9940 - val_mse: 0.0498 - val_rmse: 0.2203 - val_r_square: 0.6400\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0226 - acc: 0.9611 - mse: 0.0226 - rmse: 0.1275 - r_square: 0.2510 - val_loss: 0.0499 - val_acc: 0.9937 - val_mse: 0.0499 - val_rmse: 0.2206 - val_r_square: 0.6392\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0225 - acc: 0.9612 - mse: 0.0225 - rmse: 0.1271 - r_square: 0.2538 - val_loss: 0.0500 - val_acc: 0.9935 - val_mse: 0.0500 - val_rmse: 0.2209 - val_r_square: 0.6382\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Area (sq. mi.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Area (sq. mi.)','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 4s 539us/step - loss: 0.0510 - acc: 0.7075 - rmse: 0.1987 - mse: 0.0510 - r_square: 0.3586 - val_loss: 0.0406 - val_acc: 0.8365 - val_rmse: 0.1840 - val_mse: 0.0406 - val_r_square: 0.7376\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0338 - acc: 0.8439 - rmse: 0.1537 - mse: 0.0338 - r_square: 0.5890 - val_loss: 0.0260 - val_acc: 0.8365 - val_rmse: 0.1432 - val_mse: 0.0260 - val_r_square: 0.8330\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0251 - acc: 0.9262 - rmse: 0.1322 - mse: 0.0251 - r_square: 0.6845 - val_loss: 0.0261 - val_acc: 0.9822 - val_rmse: 0.1457 - val_mse: 0.0261 - val_r_square: 0.8309\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 277us/step - loss: 0.0177 - acc: 0.9324 - rmse: 0.1028 - mse: 0.0177 - r_square: 0.7783 - val_loss: 0.0182 - val_acc: 0.9105 - val_rmse: 0.1165 - val_mse: 0.0182 - val_r_square: 0.8824\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 273us/step - loss: 0.0135 - acc: 0.9334 - rmse: 0.0865 - mse: 0.0135 - r_square: 0.8282 - val_loss: 0.0118 - val_acc: 0.9229 - val_rmse: 0.0937 - val_mse: 0.0118 - val_r_square: 0.9240\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0114 - acc: 0.9376 - rmse: 0.0758 - mse: 0.0114 - r_square: 0.8526 - val_loss: 0.0082 - val_acc: 0.8818 - val_rmse: 0.0747 - val_mse: 0.0082 - val_r_square: 0.9480\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0100 - acc: 0.9389 - rmse: 0.0690 - mse: 0.0100 - r_square: 0.8691 - val_loss: 0.0068 - val_acc: 0.8828 - val_rmse: 0.0706 - val_mse: 0.0068 - val_r_square: 0.9567\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0086 - acc: 0.9425 - rmse: 0.0607 - mse: 0.0086 - r_square: 0.8851 - val_loss: 0.0062 - val_acc: 0.8821 - val_rmse: 0.0691 - val_mse: 0.0062 - val_r_square: 0.9609\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0079 - acc: 0.9438 - rmse: 0.0567 - mse: 0.0079 - r_square: 0.8951 - val_loss: 0.0057 - val_acc: 0.8817 - val_rmse: 0.0672 - val_mse: 0.0057 - val_r_square: 0.9640\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0077 - acc: 0.9458 - rmse: 0.0550 - mse: 0.0077 - r_square: 0.9020 - val_loss: 0.0075 - val_acc: 0.8365 - val_rmse: 0.0797 - val_mse: 0.0075 - val_r_square: 0.9528\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0081 - acc: 0.9469 - rmse: 0.0599 - mse: 0.0081 - r_square: 0.9002 - val_loss: 0.0103 - val_acc: 0.8365 - val_rmse: 0.0963 - val_mse: 0.0103 - val_r_square: 0.9347\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0085 - acc: 0.9182 - rmse: 0.0624 - mse: 0.0085 - r_square: 0.8969 - val_loss: 0.0127 - val_acc: 0.9050 - val_rmse: 0.1063 - val_mse: 0.0127 - val_r_square: 0.9164\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0085 - acc: 0.9052 - rmse: 0.0642 - mse: 0.0085 - r_square: 0.8965 - val_loss: 0.0161 - val_acc: 0.9905 - val_rmse: 0.1177 - val_mse: 0.0161 - val_r_square: 0.8937\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0089 - acc: 0.8959 - rmse: 0.0666 - mse: 0.0089 - r_square: 0.8911 - val_loss: 0.0133 - val_acc: 0.9905 - val_rmse: 0.1083 - val_mse: 0.0133 - val_r_square: 0.9123\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0107 - acc: 0.8832 - rmse: 0.0794 - mse: 0.0107 - r_square: 0.8600 - val_loss: 0.0043 - val_acc: 0.9669 - val_rmse: 0.0568 - val_mse: 0.0043 - val_r_square: 0.9736\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0086 - acc: 0.9230 - rmse: 0.0666 - mse: 0.0086 - r_square: 0.8818 - val_loss: 0.0044 - val_acc: 0.9126 - val_rmse: 0.0566 - val_mse: 0.0044 - val_r_square: 0.9731\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 280us/step - loss: 0.0067 - acc: 0.9505 - rmse: 0.0491 - mse: 0.0067 - r_square: 0.9117 - val_loss: 0.0029 - val_acc: 0.9158 - val_rmse: 0.0412 - val_mse: 0.0029 - val_r_square: 0.9829\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0064 - acc: 0.9546 - rmse: 0.0452 - mse: 0.0064 - r_square: 0.9177 - val_loss: 0.0041 - val_acc: 0.9316 - val_rmse: 0.0535 - val_mse: 0.0041 - val_r_square: 0.9747\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0060 - acc: 0.9555 - rmse: 0.0427 - mse: 0.0060 - r_square: 0.9221 - val_loss: 0.0046 - val_acc: 0.9446 - val_rmse: 0.0576 - val_mse: 0.0046 - val_r_square: 0.9713\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0059 - acc: 0.9552 - rmse: 0.0391 - mse: 0.0059 - r_square: 0.9242 - val_loss: 0.0042 - val_acc: 0.9453 - val_rmse: 0.0547 - val_mse: 0.0042 - val_r_square: 0.9735\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 276us/step - loss: 0.0056 - acc: 0.9572 - rmse: 0.0373 - mse: 0.0056 - r_square: 0.9285 - val_loss: 0.0039 - val_acc: 0.9573 - val_rmse: 0.0519 - val_mse: 0.0039 - val_r_square: 0.9758\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0055 - acc: 0.9582 - rmse: 0.0359 - mse: 0.0055 - r_square: 0.9298 - val_loss: 0.0036 - val_acc: 0.9573 - val_rmse: 0.0495 - val_mse: 0.0036 - val_r_square: 0.9775\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0054 - acc: 0.9588 - rmse: 0.0354 - mse: 0.0054 - r_square: 0.9312 - val_loss: 0.0034 - val_acc: 0.9456 - val_rmse: 0.0470 - val_mse: 0.0034 - val_r_square: 0.9791\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 276us/step - loss: 0.0053 - acc: 0.9588 - rmse: 0.0348 - mse: 0.0053 - r_square: 0.9315 - val_loss: 0.0032 - val_acc: 0.9450 - val_rmse: 0.0453 - val_mse: 0.0032 - val_r_square: 0.9803\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0053 - acc: 0.9603 - rmse: 0.0348 - mse: 0.0053 - r_square: 0.9318 - val_loss: 0.0032 - val_acc: 0.9449 - val_rmse: 0.0455 - val_mse: 0.0032 - val_r_square: 0.9802\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0054 - acc: 0.9588 - rmse: 0.0342 - mse: 0.0054 - r_square: 0.9309 - val_loss: 0.0032 - val_acc: 0.9446 - val_rmse: 0.0450 - val_mse: 0.0032 - val_r_square: 0.9806\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0052 - acc: 0.9613 - rmse: 0.0334 - mse: 0.0052 - r_square: 0.9339 - val_loss: 0.0033 - val_acc: 0.9446 - val_rmse: 0.0462 - val_mse: 0.0033 - val_r_square: 0.9798\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0051 - acc: 0.9611 - rmse: 0.0324 - mse: 0.0051 - r_square: 0.9351 - val_loss: 0.0033 - val_acc: 0.9444 - val_rmse: 0.0465 - val_mse: 0.0033 - val_r_square: 0.9797\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0050 - acc: 0.9622 - rmse: 0.0319 - mse: 0.0050 - r_square: 0.9362 - val_loss: 0.0033 - val_acc: 0.9444 - val_rmse: 0.0469 - val_mse: 0.0033 - val_r_square: 0.9794\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9616 - rmse: 0.0317 - mse: 0.0050 - r_square: 0.9364 - val_loss: 0.0033 - val_acc: 0.9443 - val_rmse: 0.0463 - val_mse: 0.0033 - val_r_square: 0.9799\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0050 - acc: 0.9633 - rmse: 0.0320 - mse: 0.0050 - r_square: 0.9366 - val_loss: 0.0032 - val_acc: 0.9442 - val_rmse: 0.0457 - val_mse: 0.0032 - val_r_square: 0.9803\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0052 - acc: 0.9615 - rmse: 0.0326 - mse: 0.0052 - r_square: 0.9346 - val_loss: 0.0032 - val_acc: 0.9308 - val_rmse: 0.0458 - val_mse: 0.0032 - val_r_square: 0.9803\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0049 - acc: 0.9640 - rmse: 0.0319 - mse: 0.0049 - r_square: 0.9376 - val_loss: 0.0032 - val_acc: 0.9431 - val_rmse: 0.0455 - val_mse: 0.0032 - val_r_square: 0.9804\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 254us/step - loss: 0.0050 - acc: 0.9636 - rmse: 0.0336 - mse: 0.0050 - r_square: 0.9368 - val_loss: 0.0033 - val_acc: 0.9295 - val_rmse: 0.0473 - val_mse: 0.0033 - val_r_square: 0.9793\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 252us/step - loss: 0.0049 - acc: 0.9640 - rmse: 0.0333 - mse: 0.0049 - r_square: 0.9374 - val_loss: 0.0033 - val_acc: 0.9431 - val_rmse: 0.0470 - val_mse: 0.0033 - val_r_square: 0.9794\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0050 - acc: 0.9642 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9375 - val_loss: 0.0032 - val_acc: 0.9037 - val_rmse: 0.0467 - val_mse: 0.0032 - val_r_square: 0.9798\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0049 - acc: 0.9644 - rmse: 0.0339 - mse: 0.0049 - r_square: 0.9378 - val_loss: 0.0033 - val_acc: 0.9420 - val_rmse: 0.0464 - val_mse: 0.0033 - val_r_square: 0.9798\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0051 - acc: 0.9646 - rmse: 0.0348 - mse: 0.0051 - r_square: 0.9362 - val_loss: 0.0032 - val_acc: 0.8882 - val_rmse: 0.0461 - val_mse: 0.0032 - val_r_square: 0.9805\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0050 - acc: 0.9650 - rmse: 0.0333 - mse: 0.0050 - r_square: 0.9367 - val_loss: 0.0032 - val_acc: 0.9286 - val_rmse: 0.0456 - val_mse: 0.0032 - val_r_square: 0.9804\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 252us/step - loss: 0.0053 - acc: 0.9634 - rmse: 0.0349 - mse: 0.0053 - r_square: 0.9335 - val_loss: 0.0033 - val_acc: 0.8869 - val_rmse: 0.0479 - val_mse: 0.0033 - val_r_square: 0.9795\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 253us/step - loss: 0.0048 - acc: 0.9650 - rmse: 0.0310 - mse: 0.0048 - r_square: 0.9394 - val_loss: 0.0033 - val_acc: 0.9393 - val_rmse: 0.0471 - val_mse: 0.0033 - val_r_square: 0.9794\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0050 - acc: 0.9653 - rmse: 0.0350 - mse: 0.0050 - r_square: 0.9374 - val_loss: 0.0034 - val_acc: 0.9003 - val_rmse: 0.0488 - val_mse: 0.0034 - val_r_square: 0.9785\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0048 - acc: 0.9650 - rmse: 0.0332 - mse: 0.0048 - r_square: 0.9390 - val_loss: 0.0035 - val_acc: 0.9414 - val_rmse: 0.0484 - val_mse: 0.0035 - val_r_square: 0.9779\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0051 - acc: 0.9662 - rmse: 0.0367 - mse: 0.0051 - r_square: 0.9367 - val_loss: 0.0035 - val_acc: 0.9375 - val_rmse: 0.0487 - val_mse: 0.0035 - val_r_square: 0.9784\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9647 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9394 - val_loss: 0.0034 - val_acc: 0.9416 - val_rmse: 0.0472 - val_mse: 0.0034 - val_r_square: 0.9791\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0051 - acc: 0.9665 - rmse: 0.0360 - mse: 0.0051 - r_square: 0.9368 - val_loss: 0.0033 - val_acc: 0.9384 - val_rmse: 0.0479 - val_mse: 0.0033 - val_r_square: 0.9791\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0050 - acc: 0.9642 - rmse: 0.0338 - mse: 0.0050 - r_square: 0.9375 - val_loss: 0.0035 - val_acc: 0.9424 - val_rmse: 0.0488 - val_mse: 0.0035 - val_r_square: 0.9778\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0051 - acc: 0.9663 - rmse: 0.0356 - mse: 0.0051 - r_square: 0.9373 - val_loss: 0.0039 - val_acc: 0.9870 - val_rmse: 0.0523 - val_mse: 0.0039 - val_r_square: 0.9753\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0051 - acc: 0.9651 - rmse: 0.0367 - mse: 0.0051 - r_square: 0.9366 - val_loss: 0.0040 - val_acc: 0.9902 - val_rmse: 0.0524 - val_mse: 0.0040 - val_r_square: 0.9747\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0051 - acc: 0.9659 - rmse: 0.0378 - mse: 0.0051 - r_square: 0.9357 - val_loss: 0.0031 - val_acc: 0.9917 - val_rmse: 0.0436 - val_mse: 0.0031 - val_r_square: 0.9812\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0050 - acc: 0.9649 - rmse: 0.0367 - mse: 0.0050 - r_square: 0.9358 - val_loss: 0.0024 - val_acc: 0.9922 - val_rmse: 0.0365 - val_mse: 0.0024 - val_r_square: 0.9853\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0050 - acc: 0.9657 - rmse: 0.0360 - mse: 0.0050 - r_square: 0.9354 - val_loss: 0.0022 - val_acc: 0.9915 - val_rmse: 0.0342 - val_mse: 0.0022 - val_r_square: 0.9868\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9655 - rmse: 0.0347 - mse: 0.0050 - r_square: 0.9363 - val_loss: 0.0023 - val_acc: 0.9888 - val_rmse: 0.0355 - val_mse: 0.0023 - val_r_square: 0.9863\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0049 - acc: 0.9669 - rmse: 0.0345 - mse: 0.0049 - r_square: 0.9369 - val_loss: 0.0023 - val_acc: 0.9765 - val_rmse: 0.0351 - val_mse: 0.0023 - val_r_square: 0.9866\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0049 - acc: 0.9661 - rmse: 0.0348 - mse: 0.0049 - r_square: 0.9362 - val_loss: 0.0021 - val_acc: 0.9400 - val_rmse: 0.0314 - val_mse: 0.0021 - val_r_square: 0.9880\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9669 - rmse: 0.0354 - mse: 0.0049 - r_square: 0.9355 - val_loss: 0.0018 - val_acc: 0.9262 - val_rmse: 0.0257 - val_mse: 0.0018 - val_r_square: 0.9897\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9612 - rmse: 0.0362 - mse: 0.0049 - r_square: 0.9340 - val_loss: 0.0018 - val_acc: 0.8874 - val_rmse: 0.0241 - val_mse: 0.0018 - val_r_square: 0.9901\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9509 - rmse: 0.0361 - mse: 0.0049 - r_square: 0.9333 - val_loss: 0.0019 - val_acc: 0.8872 - val_rmse: 0.0278 - val_mse: 0.0019 - val_r_square: 0.9891\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0049 - acc: 0.9478 - rmse: 0.0361 - mse: 0.0049 - r_square: 0.9329 - val_loss: 0.0022 - val_acc: 0.8873 - val_rmse: 0.0338 - val_mse: 0.0022 - val_r_square: 0.9869\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0049 - acc: 0.9567 - rmse: 0.0342 - mse: 0.0049 - r_square: 0.9342 - val_loss: 0.0027 - val_acc: 0.8873 - val_rmse: 0.0407 - val_mse: 0.0027 - val_r_square: 0.9835\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0049 - acc: 0.9665 - rmse: 0.0340 - mse: 0.0049 - r_square: 0.9348 - val_loss: 0.0031 - val_acc: 0.8876 - val_rmse: 0.0454 - val_mse: 0.0031 - val_r_square: 0.9806\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0047 - acc: 0.9679 - rmse: 0.0305 - mse: 0.0047 - r_square: 0.9387 - val_loss: 0.0031 - val_acc: 0.9021 - val_rmse: 0.0451 - val_mse: 0.0031 - val_r_square: 0.9806\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9679 - rmse: 0.0286 - mse: 0.0045 - r_square: 0.9409 - val_loss: 0.0028 - val_acc: 0.9168 - val_rmse: 0.0416 - val_mse: 0.0028 - val_r_square: 0.9827\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0045 - acc: 0.9681 - rmse: 0.0276 - mse: 0.0045 - r_square: 0.9427 - val_loss: 0.0024 - val_acc: 0.9298 - val_rmse: 0.0370 - val_mse: 0.0024 - val_r_square: 0.9852\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0045 - acc: 0.9681 - rmse: 0.0292 - mse: 0.0045 - r_square: 0.9418 - val_loss: 0.0023 - val_acc: 0.9302 - val_rmse: 0.0352 - val_mse: 0.0023 - val_r_square: 0.9861\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9683 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9420 - val_loss: 0.0022 - val_acc: 0.9302 - val_rmse: 0.0341 - val_mse: 0.0022 - val_r_square: 0.9866\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 254us/step - loss: 0.0046 - acc: 0.9679 - rmse: 0.0281 - mse: 0.0046 - r_square: 0.9412 - val_loss: 0.0024 - val_acc: 0.9303 - val_rmse: 0.0370 - val_mse: 0.0024 - val_r_square: 0.9853\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0045 - acc: 0.9683 - rmse: 0.0262 - mse: 0.0045 - r_square: 0.9437 - val_loss: 0.0026 - val_acc: 0.9303 - val_rmse: 0.0396 - val_mse: 0.0026 - val_r_square: 0.9840\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 252us/step - loss: 0.0045 - acc: 0.9678 - rmse: 0.0273 - mse: 0.0045 - r_square: 0.9429 - val_loss: 0.0029 - val_acc: 0.9306 - val_rmse: 0.0422 - val_mse: 0.0029 - val_r_square: 0.9824\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0044 - acc: 0.9693 - rmse: 0.0255 - mse: 0.0044 - r_square: 0.9443 - val_loss: 0.0026 - val_acc: 0.9427 - val_rmse: 0.0385 - val_mse: 0.0026 - val_r_square: 0.9844\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0045 - acc: 0.9676 - rmse: 0.0278 - mse: 0.0045 - r_square: 0.9433 - val_loss: 0.0023 - val_acc: 0.9303 - val_rmse: 0.0351 - val_mse: 0.0023 - val_r_square: 0.9861\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 251us/step - loss: 0.0045 - acc: 0.9689 - rmse: 0.0280 - mse: 0.0045 - r_square: 0.9431 - val_loss: 0.0022 - val_acc: 0.9431 - val_rmse: 0.0336 - val_mse: 0.0022 - val_r_square: 0.9867\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0045 - acc: 0.9687 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9432 - val_loss: 0.0024 - val_acc: 0.9429 - val_rmse: 0.0355 - val_mse: 0.0024 - val_r_square: 0.9858\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0044 - acc: 0.9689 - rmse: 0.0258 - mse: 0.0044 - r_square: 0.9444 - val_loss: 0.0024 - val_acc: 0.9436 - val_rmse: 0.0368 - val_mse: 0.0024 - val_r_square: 0.9852\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0045 - acc: 0.9688 - rmse: 0.0268 - mse: 0.0045 - r_square: 0.9437 - val_loss: 0.0027 - val_acc: 0.9419 - val_rmse: 0.0407 - val_mse: 0.0027 - val_r_square: 0.9832\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0045 - acc: 0.9693 - rmse: 0.0271 - mse: 0.0045 - r_square: 0.9432 - val_loss: 0.0028 - val_acc: 0.9420 - val_rmse: 0.0412 - val_mse: 0.0028 - val_r_square: 0.9830\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0045 - acc: 0.9677 - rmse: 0.0276 - mse: 0.0045 - r_square: 0.9437 - val_loss: 0.0025 - val_acc: 0.9419 - val_rmse: 0.0378 - val_mse: 0.0025 - val_r_square: 0.9848\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0044 - acc: 0.9691 - rmse: 0.0269 - mse: 0.0044 - r_square: 0.9443 - val_loss: 0.0023 - val_acc: 0.9433 - val_rmse: 0.0347 - val_mse: 0.0023 - val_r_square: 0.9862\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0045 - acc: 0.9687 - rmse: 0.0294 - mse: 0.0045 - r_square: 0.9431 - val_loss: 0.0024 - val_acc: 0.9426 - val_rmse: 0.0357 - val_mse: 0.0024 - val_r_square: 0.9856\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0044 - acc: 0.9694 - rmse: 0.0269 - mse: 0.0044 - r_square: 0.9441 - val_loss: 0.0024 - val_acc: 0.9430 - val_rmse: 0.0363 - val_mse: 0.0024 - val_r_square: 0.9854\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0044 - acc: 0.9692 - rmse: 0.0279 - mse: 0.0044 - r_square: 0.9437 - val_loss: 0.0026 - val_acc: 0.9426 - val_rmse: 0.0389 - val_mse: 0.0026 - val_r_square: 0.9841\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0045 - acc: 0.9690 - rmse: 0.0271 - mse: 0.0045 - r_square: 0.9437 - val_loss: 0.0026 - val_acc: 0.9426 - val_rmse: 0.0397 - val_mse: 0.0026 - val_r_square: 0.9839\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9681 - rmse: 0.0295 - mse: 0.0047 - r_square: 0.9404 - val_loss: 0.0028 - val_acc: 0.9433 - val_rmse: 0.0418 - val_mse: 0.0028 - val_r_square: 0.9826\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 255us/step - loss: 0.0045 - acc: 0.9689 - rmse: 0.0273 - mse: 0.0045 - r_square: 0.9437 - val_loss: 0.0024 - val_acc: 0.9547 - val_rmse: 0.0361 - val_mse: 0.0024 - val_r_square: 0.9856\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0045 - acc: 0.9692 - rmse: 0.0289 - mse: 0.0045 - r_square: 0.9435 - val_loss: 0.0023 - val_acc: 0.9429 - val_rmse: 0.0348 - val_mse: 0.0023 - val_r_square: 0.9861\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0045 - acc: 0.9687 - rmse: 0.0291 - mse: 0.0045 - r_square: 0.9435 - val_loss: 0.0024 - val_acc: 0.9298 - val_rmse: 0.0358 - val_mse: 0.0024 - val_r_square: 0.9857\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0044 - acc: 0.9697 - rmse: 0.0285 - mse: 0.0044 - r_square: 0.9441 - val_loss: 0.0026 - val_acc: 0.9302 - val_rmse: 0.0393 - val_mse: 0.0026 - val_r_square: 0.9839\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0044 - acc: 0.9687 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9449 - val_loss: 0.0028 - val_acc: 0.9440 - val_rmse: 0.0409 - val_mse: 0.0028 - val_r_square: 0.9830\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0046 - acc: 0.9694 - rmse: 0.0292 - mse: 0.0046 - r_square: 0.9430 - val_loss: 0.0028 - val_acc: 0.9550 - val_rmse: 0.0412 - val_mse: 0.0028 - val_r_square: 0.9829\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9666 - rmse: 0.0317 - mse: 0.0047 - r_square: 0.9411 - val_loss: 0.0026 - val_acc: 0.9537 - val_rmse: 0.0397 - val_mse: 0.0026 - val_r_square: 0.9839\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0045 - acc: 0.9698 - rmse: 0.0286 - mse: 0.0045 - r_square: 0.9435 - val_loss: 0.0024 - val_acc: 0.9541 - val_rmse: 0.0362 - val_mse: 0.0024 - val_r_square: 0.9855\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0045 - acc: 0.9696 - rmse: 0.0290 - mse: 0.0045 - r_square: 0.9439 - val_loss: 0.0026 - val_acc: 0.9421 - val_rmse: 0.0389 - val_mse: 0.0026 - val_r_square: 0.9841\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9696 - rmse: 0.0296 - mse: 0.0045 - r_square: 0.9429 - val_loss: 0.0026 - val_acc: 0.9303 - val_rmse: 0.0388 - val_mse: 0.0026 - val_r_square: 0.9842\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0045 - acc: 0.9685 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9427 - val_loss: 0.0027 - val_acc: 0.9557 - val_rmse: 0.0402 - val_mse: 0.0027 - val_r_square: 0.9834\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0045 - acc: 0.9675 - rmse: 0.0295 - mse: 0.0045 - r_square: 0.9433 - val_loss: 0.0026 - val_acc: 0.9676 - val_rmse: 0.0389 - val_mse: 0.0026 - val_r_square: 0.9843\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0046 - acc: 0.9681 - rmse: 0.0316 - mse: 0.0046 - r_square: 0.9420 - val_loss: 0.0028 - val_acc: 0.9657 - val_rmse: 0.0412 - val_mse: 0.0028 - val_r_square: 0.9829\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9693 - rmse: 0.0280 - mse: 0.0044 - r_square: 0.9444 - val_loss: 0.0025 - val_acc: 0.9419 - val_rmse: 0.0379 - val_mse: 0.0025 - val_r_square: 0.9848\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 273us/step - loss: 0.0045 - acc: 0.9685 - rmse: 0.0295 - mse: 0.0045 - r_square: 0.9435 - val_loss: 0.0026 - val_acc: 0.9423 - val_rmse: 0.0392 - val_mse: 0.0026 - val_r_square: 0.9840\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0045 - acc: 0.9689 - rmse: 0.0295 - mse: 0.0045 - r_square: 0.9427 - val_loss: 0.0025 - val_acc: 0.9439 - val_rmse: 0.0380 - val_mse: 0.0025 - val_r_square: 0.9848\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0046 - acc: 0.9674 - rmse: 0.0288 - mse: 0.0046 - r_square: 0.9413 - val_loss: 0.0025 - val_acc: 0.9555 - val_rmse: 0.0372 - val_mse: 0.0025 - val_r_square: 0.9851\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 6s 890us/step - loss: 0.0298 - acc: 0.6744 - rmse: 0.1466 - mse: 0.0298 - r_square: 0.5662 - val_loss: 0.0069 - val_acc: 0.8365 - val_rmse: 0.0743 - val_mse: 0.0069 - val_r_square: 0.9579\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0124 - acc: 0.8840 - rmse: 0.0843 - mse: 0.0124 - r_square: 0.8288 - val_loss: 0.0051 - val_acc: 0.8859 - val_rmse: 0.0627 - val_mse: 0.0051 - val_r_square: 0.9682\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0085 - acc: 0.9104 - rmse: 0.0557 - mse: 0.0085 - r_square: 0.8905 - val_loss: 0.0028 - val_acc: 0.8365 - val_rmse: 0.0369 - val_mse: 0.0028 - val_r_square: 0.9837\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0076 - acc: 0.9138 - rmse: 0.0529 - mse: 0.0076 - r_square: 0.9002 - val_loss: 0.0030 - val_acc: 0.8382 - val_rmse: 0.0420 - val_mse: 0.0030 - val_r_square: 0.9822\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0067 - acc: 0.9422 - rmse: 0.0436 - mse: 0.0067 - r_square: 0.9137 - val_loss: 0.0028 - val_acc: 0.8365 - val_rmse: 0.0387 - val_mse: 0.0028 - val_r_square: 0.9835\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0064 - acc: 0.9396 - rmse: 0.0438 - mse: 0.0064 - r_square: 0.9165 - val_loss: 0.0026 - val_acc: 0.9134 - val_rmse: 0.0376 - val_mse: 0.0026 - val_r_square: 0.9845\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0060 - acc: 0.9505 - rmse: 0.0397 - mse: 0.0060 - r_square: 0.9225 - val_loss: 0.0028 - val_acc: 0.8509 - val_rmse: 0.0393 - val_mse: 0.0028 - val_r_square: 0.9835\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0060 - acc: 0.9440 - rmse: 0.0398 - mse: 0.0060 - r_square: 0.9231 - val_loss: 0.0026 - val_acc: 0.9683 - val_rmse: 0.0368 - val_mse: 0.0026 - val_r_square: 0.9849\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0057 - acc: 0.9563 - rmse: 0.0381 - mse: 0.0057 - r_square: 0.9266 - val_loss: 0.0027 - val_acc: 0.8872 - val_rmse: 0.0390 - val_mse: 0.0027 - val_r_square: 0.9838\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0057 - acc: 0.9477 - rmse: 0.0370 - mse: 0.0057 - r_square: 0.9269 - val_loss: 0.0029 - val_acc: 0.9799 - val_rmse: 0.0413 - val_mse: 0.0029 - val_r_square: 0.9828\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0055 - acc: 0.9573 - rmse: 0.0359 - mse: 0.0055 - r_square: 0.9299 - val_loss: 0.0028 - val_acc: 0.8528 - val_rmse: 0.0402 - val_mse: 0.0028 - val_r_square: 0.9833\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0056 - acc: 0.9561 - rmse: 0.0347 - mse: 0.0056 - r_square: 0.9299 - val_loss: 0.0029 - val_acc: 0.9577 - val_rmse: 0.0427 - val_mse: 0.0029 - val_r_square: 0.9822\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0053 - acc: 0.9580 - rmse: 0.0345 - mse: 0.0053 - r_square: 0.9326 - val_loss: 0.0031 - val_acc: 0.8523 - val_rmse: 0.0438 - val_mse: 0.0031 - val_r_square: 0.9813\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0054 - acc: 0.9538 - rmse: 0.0333 - mse: 0.0054 - r_square: 0.9324 - val_loss: 0.0032 - val_acc: 0.9696 - val_rmse: 0.0457 - val_mse: 0.0032 - val_r_square: 0.9805\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0052 - acc: 0.9582 - rmse: 0.0349 - mse: 0.0052 - r_square: 0.9337 - val_loss: 0.0031 - val_acc: 0.8673 - val_rmse: 0.0446 - val_mse: 0.0031 - val_r_square: 0.9807\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0053 - acc: 0.9531 - rmse: 0.0332 - mse: 0.0053 - r_square: 0.9337 - val_loss: 0.0032 - val_acc: 0.9682 - val_rmse: 0.0466 - val_mse: 0.0032 - val_r_square: 0.9800\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0052 - acc: 0.9582 - rmse: 0.0366 - mse: 0.0052 - r_square: 0.9338 - val_loss: 0.0031 - val_acc: 0.8628 - val_rmse: 0.0443 - val_mse: 0.0031 - val_r_square: 0.9809\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0053 - acc: 0.9612 - rmse: 0.0332 - mse: 0.0053 - r_square: 0.9345 - val_loss: 0.0033 - val_acc: 0.8926 - val_rmse: 0.0472 - val_mse: 0.0033 - val_r_square: 0.9796\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0052 - acc: 0.9584 - rmse: 0.0361 - mse: 0.0052 - r_square: 0.9347 - val_loss: 0.0032 - val_acc: 0.8660 - val_rmse: 0.0452 - val_mse: 0.0032 - val_r_square: 0.9803\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0051 - acc: 0.9617 - rmse: 0.0308 - mse: 0.0051 - r_square: 0.9363 - val_loss: 0.0032 - val_acc: 0.8936 - val_rmse: 0.0462 - val_mse: 0.0032 - val_r_square: 0.9800\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0050 - acc: 0.9589 - rmse: 0.0336 - mse: 0.0050 - r_square: 0.9360 - val_loss: 0.0031 - val_acc: 0.8910 - val_rmse: 0.0439 - val_mse: 0.0031 - val_r_square: 0.9810\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0049 - acc: 0.9623 - rmse: 0.0295 - mse: 0.0049 - r_square: 0.9381 - val_loss: 0.0030 - val_acc: 0.9062 - val_rmse: 0.0443 - val_mse: 0.0030 - val_r_square: 0.9812\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0049 - acc: 0.9605 - rmse: 0.0322 - mse: 0.0049 - r_square: 0.9384 - val_loss: 0.0031 - val_acc: 0.8666 - val_rmse: 0.0445 - val_mse: 0.0031 - val_r_square: 0.9807\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0049 - acc: 0.9631 - rmse: 0.0298 - mse: 0.0049 - r_square: 0.9391 - val_loss: 0.0033 - val_acc: 0.8666 - val_rmse: 0.0474 - val_mse: 0.0033 - val_r_square: 0.9795\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0049 - acc: 0.9616 - rmse: 0.0325 - mse: 0.0049 - r_square: 0.9387 - val_loss: 0.0036 - val_acc: 0.8404 - val_rmse: 0.0501 - val_mse: 0.0036 - val_r_square: 0.9771\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0048 - acc: 0.9636 - rmse: 0.0292 - mse: 0.0048 - r_square: 0.9397 - val_loss: 0.0036 - val_acc: 0.8536 - val_rmse: 0.0505 - val_mse: 0.0036 - val_r_square: 0.9772\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0048 - acc: 0.9609 - rmse: 0.0332 - mse: 0.0048 - r_square: 0.9387 - val_loss: 0.0036 - val_acc: 0.8401 - val_rmse: 0.0501 - val_mse: 0.0036 - val_r_square: 0.9771\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0048 - acc: 0.9641 - rmse: 0.0313 - mse: 0.0048 - r_square: 0.9388 - val_loss: 0.0034 - val_acc: 0.8794 - val_rmse: 0.0486 - val_mse: 0.0034 - val_r_square: 0.9785\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0049 - acc: 0.9611 - rmse: 0.0339 - mse: 0.0049 - r_square: 0.9381 - val_loss: 0.0034 - val_acc: 0.8523 - val_rmse: 0.0475 - val_mse: 0.0034 - val_r_square: 0.9787\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0048 - acc: 0.9648 - rmse: 0.0313 - mse: 0.0048 - r_square: 0.9389 - val_loss: 0.0036 - val_acc: 0.8539 - val_rmse: 0.0503 - val_mse: 0.0036 - val_r_square: 0.9775\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0050 - acc: 0.9613 - rmse: 0.0344 - mse: 0.0050 - r_square: 0.9379 - val_loss: 0.0039 - val_acc: 0.8526 - val_rmse: 0.0523 - val_mse: 0.0039 - val_r_square: 0.9753\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0049 - acc: 0.9648 - rmse: 0.0319 - mse: 0.0049 - r_square: 0.9392 - val_loss: 0.0043 - val_acc: 0.8398 - val_rmse: 0.0567 - val_mse: 0.0043 - val_r_square: 0.9728\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0050 - acc: 0.9619 - rmse: 0.0356 - mse: 0.0050 - r_square: 0.9378 - val_loss: 0.0042 - val_acc: 0.8775 - val_rmse: 0.0549 - val_mse: 0.0042 - val_r_square: 0.9731\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0048 - acc: 0.9643 - rmse: 0.0321 - mse: 0.0048 - r_square: 0.9395 - val_loss: 0.0043 - val_acc: 0.8394 - val_rmse: 0.0569 - val_mse: 0.0043 - val_r_square: 0.9724\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0049 - acc: 0.9624 - rmse: 0.0366 - mse: 0.0049 - r_square: 0.9379 - val_loss: 0.0040 - val_acc: 0.9149 - val_rmse: 0.0529 - val_mse: 0.0040 - val_r_square: 0.9746\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0049 - acc: 0.9637 - rmse: 0.0354 - mse: 0.0049 - r_square: 0.9377 - val_loss: 0.0042 - val_acc: 0.8389 - val_rmse: 0.0556 - val_mse: 0.0042 - val_r_square: 0.9735\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0050 - acc: 0.9588 - rmse: 0.0366 - mse: 0.0050 - r_square: 0.9376 - val_loss: 0.0041 - val_acc: 0.9167 - val_rmse: 0.0540 - val_mse: 0.0041 - val_r_square: 0.9743\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0050 - acc: 0.9630 - rmse: 0.0364 - mse: 0.0050 - r_square: 0.9371 - val_loss: 0.0048 - val_acc: 0.8890 - val_rmse: 0.0604 - val_mse: 0.0048 - val_r_square: 0.9697\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0050 - acc: 0.9602 - rmse: 0.0365 - mse: 0.0050 - r_square: 0.9376 - val_loss: 0.0054 - val_acc: 0.9421 - val_rmse: 0.0652 - val_mse: 0.0054 - val_r_square: 0.9650\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0053 - acc: 0.9627 - rmse: 0.0399 - mse: 0.0053 - r_square: 0.9351 - val_loss: 0.0058 - val_acc: 0.9159 - val_rmse: 0.0683 - val_mse: 0.0058 - val_r_square: 0.9625\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0051 - acc: 0.9581 - rmse: 0.0368 - mse: 0.0051 - r_square: 0.9370 - val_loss: 0.0054 - val_acc: 0.9685 - val_rmse: 0.0652 - val_mse: 0.0054 - val_r_square: 0.9653\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0053 - acc: 0.9590 - rmse: 0.0404 - mse: 0.0053 - r_square: 0.9336 - val_loss: 0.0049 - val_acc: 0.9670 - val_rmse: 0.0609 - val_mse: 0.0049 - val_r_square: 0.9692\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0056 - acc: 0.9492 - rmse: 0.0442 - mse: 0.0056 - r_square: 0.9272 - val_loss: 0.0042 - val_acc: 0.9691 - val_rmse: 0.0555 - val_mse: 0.0042 - val_r_square: 0.9740\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0058 - acc: 0.9499 - rmse: 0.0471 - mse: 0.0058 - r_square: 0.9216 - val_loss: 0.0033 - val_acc: 0.9691 - val_rmse: 0.0474 - val_mse: 0.0033 - val_r_square: 0.9797\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0057 - acc: 0.9509 - rmse: 0.0456 - mse: 0.0057 - r_square: 0.9221 - val_loss: 0.0026 - val_acc: 0.9557 - val_rmse: 0.0396 - val_mse: 0.0026 - val_r_square: 0.9844\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0056 - acc: 0.9581 - rmse: 0.0445 - mse: 0.0056 - r_square: 0.9248 - val_loss: 0.0023 - val_acc: 0.9427 - val_rmse: 0.0354 - val_mse: 0.0023 - val_r_square: 0.9864\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0050 - acc: 0.9635 - rmse: 0.0363 - mse: 0.0050 - r_square: 0.9351 - val_loss: 0.0021 - val_acc: 0.9417 - val_rmse: 0.0315 - val_mse: 0.0021 - val_r_square: 0.9881\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0048 - acc: 0.9661 - rmse: 0.0333 - mse: 0.0048 - r_square: 0.9380 - val_loss: 0.0017 - val_acc: 0.9283 - val_rmse: 0.0250 - val_mse: 0.0017 - val_r_square: 0.9902\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0047 - acc: 0.9661 - rmse: 0.0327 - mse: 0.0047 - r_square: 0.9393 - val_loss: 0.0016 - val_acc: 0.9162 - val_rmse: 0.0228 - val_mse: 0.0016 - val_r_square: 0.9909\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0047 - acc: 0.9659 - rmse: 0.0323 - mse: 0.0047 - r_square: 0.9396 - val_loss: 0.0017 - val_acc: 0.9164 - val_rmse: 0.0239 - val_mse: 0.0017 - val_r_square: 0.9905\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9655 - rmse: 0.0305 - mse: 0.0046 - r_square: 0.9412 - val_loss: 0.0017 - val_acc: 0.9285 - val_rmse: 0.0247 - val_mse: 0.0017 - val_r_square: 0.9903\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0045 - acc: 0.9680 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9427 - val_loss: 0.0019 - val_acc: 0.9414 - val_rmse: 0.0276 - val_mse: 0.0019 - val_r_square: 0.9893\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0046 - acc: 0.9674 - rmse: 0.0283 - mse: 0.0046 - r_square: 0.9424 - val_loss: 0.0018 - val_acc: 0.9429 - val_rmse: 0.0258 - val_mse: 0.0018 - val_r_square: 0.9899\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0045 - acc: 0.9691 - rmse: 0.0263 - mse: 0.0045 - r_square: 0.9438 - val_loss: 0.0019 - val_acc: 0.9429 - val_rmse: 0.0275 - val_mse: 0.0019 - val_r_square: 0.9893\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0045 - acc: 0.9676 - rmse: 0.0275 - mse: 0.0045 - r_square: 0.9429 - val_loss: 0.0017 - val_acc: 0.9430 - val_rmse: 0.0241 - val_mse: 0.0017 - val_r_square: 0.9903\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9687 - rmse: 0.0264 - mse: 0.0044 - r_square: 0.9442 - val_loss: 0.0017 - val_acc: 0.9424 - val_rmse: 0.0247 - val_mse: 0.0017 - val_r_square: 0.9901\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9677 - rmse: 0.0272 - mse: 0.0044 - r_square: 0.9440 - val_loss: 0.0017 - val_acc: 0.9426 - val_rmse: 0.0240 - val_mse: 0.0017 - val_r_square: 0.9904\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0044 - acc: 0.9683 - rmse: 0.0264 - mse: 0.0044 - r_square: 0.9443 - val_loss: 0.0017 - val_acc: 0.9424 - val_rmse: 0.0247 - val_mse: 0.0017 - val_r_square: 0.9901\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0044 - acc: 0.9685 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9445 - val_loss: 0.0017 - val_acc: 0.9429 - val_rmse: 0.0246 - val_mse: 0.0017 - val_r_square: 0.9902\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9690 - rmse: 0.0258 - mse: 0.0044 - r_square: 0.9450 - val_loss: 0.0018 - val_acc: 0.9424 - val_rmse: 0.0259 - val_mse: 0.0018 - val_r_square: 0.9897\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9685 - rmse: 0.0259 - mse: 0.0044 - r_square: 0.9451 - val_loss: 0.0018 - val_acc: 0.9427 - val_rmse: 0.0253 - val_mse: 0.0018 - val_r_square: 0.9899\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0044 - acc: 0.9695 - rmse: 0.0253 - mse: 0.0044 - r_square: 0.9449 - val_loss: 0.0018 - val_acc: 0.9416 - val_rmse: 0.0265 - val_mse: 0.0018 - val_r_square: 0.9895\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0045 - acc: 0.9684 - rmse: 0.0268 - mse: 0.0045 - r_square: 0.9433 - val_loss: 0.0017 - val_acc: 0.9419 - val_rmse: 0.0248 - val_mse: 0.0017 - val_r_square: 0.9901\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0045 - acc: 0.9691 - rmse: 0.0262 - mse: 0.0045 - r_square: 0.9436 - val_loss: 0.0018 - val_acc: 0.9171 - val_rmse: 0.0262 - val_mse: 0.0018 - val_r_square: 0.9897\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9683 - rmse: 0.0275 - mse: 0.0045 - r_square: 0.9429 - val_loss: 0.0017 - val_acc: 0.9419 - val_rmse: 0.0251 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9681 - rmse: 0.0262 - mse: 0.0044 - r_square: 0.9445 - val_loss: 0.0018 - val_acc: 0.9408 - val_rmse: 0.0266 - val_mse: 0.0018 - val_r_square: 0.9895\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0044 - acc: 0.9688 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9447 - val_loss: 0.0018 - val_acc: 0.9550 - val_rmse: 0.0265 - val_mse: 0.0018 - val_r_square: 0.9895\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0044 - acc: 0.9685 - rmse: 0.0262 - mse: 0.0044 - r_square: 0.9450 - val_loss: 0.0019 - val_acc: 0.9416 - val_rmse: 0.0271 - val_mse: 0.0019 - val_r_square: 0.9893\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0044 - acc: 0.9695 - rmse: 0.0260 - mse: 0.0044 - r_square: 0.9452 - val_loss: 0.0018 - val_acc: 0.9416 - val_rmse: 0.0268 - val_mse: 0.0018 - val_r_square: 0.9894\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0044 - acc: 0.9692 - rmse: 0.0258 - mse: 0.0044 - r_square: 0.9451 - val_loss: 0.0019 - val_acc: 0.9161 - val_rmse: 0.0279 - val_mse: 0.0019 - val_r_square: 0.9892\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0045 - acc: 0.9694 - rmse: 0.0276 - mse: 0.0045 - r_square: 0.9440 - val_loss: 0.0018 - val_acc: 0.9157 - val_rmse: 0.0277 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0045 - acc: 0.9689 - rmse: 0.0281 - mse: 0.0045 - r_square: 0.9433 - val_loss: 0.0019 - val_acc: 0.9030 - val_rmse: 0.0288 - val_mse: 0.0019 - val_r_square: 0.9889\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9674 - rmse: 0.0293 - mse: 0.0046 - r_square: 0.9418 - val_loss: 0.0018 - val_acc: 0.9162 - val_rmse: 0.0271 - val_mse: 0.0018 - val_r_square: 0.9894\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0045 - acc: 0.9676 - rmse: 0.0283 - mse: 0.0045 - r_square: 0.9431 - val_loss: 0.0019 - val_acc: 0.9541 - val_rmse: 0.0282 - val_mse: 0.0019 - val_r_square: 0.9889\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0045 - acc: 0.9683 - rmse: 0.0293 - mse: 0.0045 - r_square: 0.9434 - val_loss: 0.0019 - val_acc: 0.9555 - val_rmse: 0.0283 - val_mse: 0.0019 - val_r_square: 0.9889\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0045 - acc: 0.9701 - rmse: 0.0290 - mse: 0.0045 - r_square: 0.9439 - val_loss: 0.0020 - val_acc: 0.9417 - val_rmse: 0.0299 - val_mse: 0.0020 - val_r_square: 0.9884\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0045 - acc: 0.9698 - rmse: 0.0275 - mse: 0.0045 - r_square: 0.9445 - val_loss: 0.0019 - val_acc: 0.9280 - val_rmse: 0.0295 - val_mse: 0.0019 - val_r_square: 0.9887\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0045 - acc: 0.9695 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9434 - val_loss: 0.0020 - val_acc: 0.9026 - val_rmse: 0.0312 - val_mse: 0.0020 - val_r_square: 0.9881\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0046 - acc: 0.9651 - rmse: 0.0311 - mse: 0.0046 - r_square: 0.9418 - val_loss: 0.0020 - val_acc: 0.8792 - val_rmse: 0.0305 - val_mse: 0.0020 - val_r_square: 0.9885\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9649 - rmse: 0.0313 - mse: 0.0046 - r_square: 0.9421 - val_loss: 0.0020 - val_acc: 0.9162 - val_rmse: 0.0306 - val_mse: 0.0020 - val_r_square: 0.9882\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0045 - acc: 0.9659 - rmse: 0.0302 - mse: 0.0045 - r_square: 0.9427 - val_loss: 0.0020 - val_acc: 0.9683 - val_rmse: 0.0295 - val_mse: 0.0020 - val_r_square: 0.9885\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0047 - acc: 0.9662 - rmse: 0.0331 - mse: 0.0047 - r_square: 0.9412 - val_loss: 0.0021 - val_acc: 0.9799 - val_rmse: 0.0316 - val_mse: 0.0021 - val_r_square: 0.9878\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0047 - acc: 0.9691 - rmse: 0.0328 - mse: 0.0047 - r_square: 0.9414 - val_loss: 0.0020 - val_acc: 0.9555 - val_rmse: 0.0303 - val_mse: 0.0020 - val_r_square: 0.9885\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9699 - rmse: 0.0298 - mse: 0.0046 - r_square: 0.9420 - val_loss: 0.0020 - val_acc: 0.9659 - val_rmse: 0.0306 - val_mse: 0.0020 - val_r_square: 0.9884\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9670 - rmse: 0.0310 - mse: 0.0046 - r_square: 0.9418 - val_loss: 0.0020 - val_acc: 0.9410 - val_rmse: 0.0310 - val_mse: 0.0020 - val_r_square: 0.9882\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9657 - rmse: 0.0306 - mse: 0.0046 - r_square: 0.9426 - val_loss: 0.0021 - val_acc: 0.9562 - val_rmse: 0.0328 - val_mse: 0.0021 - val_r_square: 0.9874\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0044 - acc: 0.9651 - rmse: 0.0282 - mse: 0.0044 - r_square: 0.9440 - val_loss: 0.0021 - val_acc: 0.9688 - val_rmse: 0.0316 - val_mse: 0.0021 - val_r_square: 0.9876\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0045 - acc: 0.9684 - rmse: 0.0306 - mse: 0.0045 - r_square: 0.9432 - val_loss: 0.0021 - val_acc: 0.9691 - val_rmse: 0.0319 - val_mse: 0.0021 - val_r_square: 0.9875\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0046 - acc: 0.9694 - rmse: 0.0304 - mse: 0.0046 - r_square: 0.9434 - val_loss: 0.0021 - val_acc: 0.9669 - val_rmse: 0.0314 - val_mse: 0.0021 - val_r_square: 0.9878\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0045 - acc: 0.9698 - rmse: 0.0276 - mse: 0.0045 - r_square: 0.9442 - val_loss: 0.0021 - val_acc: 0.9685 - val_rmse: 0.0315 - val_mse: 0.0021 - val_r_square: 0.9878\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0045 - acc: 0.9690 - rmse: 0.0282 - mse: 0.0045 - r_square: 0.9437 - val_loss: 0.0021 - val_acc: 0.9558 - val_rmse: 0.0327 - val_mse: 0.0021 - val_r_square: 0.9872\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0045 - acc: 0.9698 - rmse: 0.0281 - mse: 0.0045 - r_square: 0.9433 - val_loss: 0.0022 - val_acc: 0.9558 - val_rmse: 0.0336 - val_mse: 0.0022 - val_r_square: 0.9868\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9663 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9448 - val_loss: 0.0022 - val_acc: 0.9558 - val_rmse: 0.0334 - val_mse: 0.0022 - val_r_square: 0.9866\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9704 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9455 - val_loss: 0.0022 - val_acc: 0.9683 - val_rmse: 0.0326 - val_mse: 0.0022 - val_r_square: 0.9869\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9696 - rmse: 0.0274 - mse: 0.0044 - r_square: 0.9453 - val_loss: 0.0021 - val_acc: 0.9555 - val_rmse: 0.0322 - val_mse: 0.0021 - val_r_square: 0.9872\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0044 - acc: 0.9702 - rmse: 0.0258 - mse: 0.0044 - r_square: 0.9459 - val_loss: 0.0022 - val_acc: 0.9558 - val_rmse: 0.0326 - val_mse: 0.0022 - val_r_square: 0.9871\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0044 - acc: 0.9697 - rmse: 0.0250 - mse: 0.0044 - r_square: 0.9457 - val_loss: 0.0022 - val_acc: 0.9552 - val_rmse: 0.0325 - val_mse: 0.0022 - val_r_square: 0.9871\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9706 - rmse: 0.0261 - mse: 0.0044 - r_square: 0.9444 - val_loss: 0.0022 - val_acc: 0.9423 - val_rmse: 0.0335 - val_mse: 0.0022 - val_r_square: 0.9868\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0044 - acc: 0.9674 - rmse: 0.0263 - mse: 0.0044 - r_square: 0.9450 - val_loss: 0.0022 - val_acc: 0.9426 - val_rmse: 0.0337 - val_mse: 0.0022 - val_r_square: 0.9867\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0043 - acc: 0.9700 - rmse: 0.0257 - mse: 0.0043 - r_square: 0.9459 - val_loss: 0.0023 - val_acc: 0.9560 - val_rmse: 0.0339 - val_mse: 0.0023 - val_r_square: 0.9864\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 4s 557us/step - loss: 0.0165 - acc: 0.8669 - mse: 0.0165 - rmse: 0.1082 - r_square: 0.7476 - val_loss: 0.0131 - val_acc: 0.9552 - val_mse: 0.0131 - val_rmse: 0.1084 - val_r_square: 0.9138\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0133 - acc: 0.9074 - mse: 0.0133 - rmse: 0.0927 - r_square: 0.7867 - val_loss: 0.0139 - val_acc: 0.9819 - val_mse: 0.0139 - val_rmse: 0.1118 - val_r_square: 0.9079\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0145 - acc: 0.9262 - mse: 0.0145 - rmse: 0.0948 - r_square: 0.7455 - val_loss: 0.0075 - val_acc: 0.9942 - val_mse: 0.0075 - val_rmse: 0.0790 - val_r_square: 0.9514\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0113 - acc: 0.9276 - mse: 0.0113 - rmse: 0.0757 - r_square: 0.8169 - val_loss: 0.0062 - val_acc: 0.9942 - val_mse: 0.0062 - val_rmse: 0.0712 - val_r_square: 0.9613\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0123 - acc: 0.8816 - mse: 0.0123 - rmse: 0.0869 - r_square: 0.7964 - val_loss: 0.0085 - val_acc: 0.9942 - val_mse: 0.0085 - val_rmse: 0.0870 - val_r_square: 0.9453\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0098 - acc: 0.9625 - mse: 0.0098 - rmse: 0.0776 - r_square: 0.8628 - val_loss: 0.0062 - val_acc: 0.8877 - val_mse: 0.0062 - val_rmse: 0.0726 - val_r_square: 0.9599\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0126 - acc: 0.8980 - mse: 0.0126 - rmse: 0.0858 - r_square: 0.8348 - val_loss: 0.0103 - val_acc: 0.8365 - val_mse: 0.0103 - val_rmse: 0.0971 - val_r_square: 0.9339\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0128 - acc: 0.9384 - mse: 0.0128 - rmse: 0.0768 - r_square: 0.8321 - val_loss: 0.0188 - val_acc: 0.8617 - val_mse: 0.0188 - val_rmse: 0.1326 - val_r_square: 0.8759\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0083 - acc: 0.9328 - mse: 0.0083 - rmse: 0.0636 - r_square: 0.8771 - val_loss: 0.0041 - val_acc: 0.8365 - val_mse: 0.0041 - val_rmse: 0.0562 - val_r_square: 0.9750\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0098 - acc: 0.9398 - mse: 0.0098 - rmse: 0.0728 - r_square: 0.8573 - val_loss: 0.0061 - val_acc: 0.8879 - val_mse: 0.0061 - val_rmse: 0.0721 - val_r_square: 0.9614\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0092 - acc: 0.9342 - mse: 0.0092 - rmse: 0.0682 - r_square: 0.8607 - val_loss: 0.0032 - val_acc: 0.9275 - val_mse: 0.0032 - val_rmse: 0.0433 - val_r_square: 0.9815\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0085 - acc: 0.9650 - mse: 0.0085 - rmse: 0.0665 - r_square: 0.8608 - val_loss: 0.0027 - val_acc: 0.8879 - val_mse: 0.0027 - val_rmse: 0.0407 - val_r_square: 0.9842\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0073 - acc: 0.9675 - mse: 0.0073 - rmse: 0.0579 - r_square: 0.8919 - val_loss: 0.0035 - val_acc: 0.8886 - val_mse: 0.0035 - val_rmse: 0.0502 - val_r_square: 0.9791\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0075 - acc: 0.9587 - mse: 0.0075 - rmse: 0.0620 - r_square: 0.8969 - val_loss: 0.0086 - val_acc: 0.8885 - val_mse: 0.0086 - val_rmse: 0.0877 - val_r_square: 0.9442\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0071 - acc: 0.9458 - mse: 0.0071 - rmse: 0.0568 - r_square: 0.9089 - val_loss: 0.0057 - val_acc: 0.8877 - val_mse: 0.0057 - val_rmse: 0.0693 - val_r_square: 0.9644\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0073 - acc: 0.9406 - mse: 0.0073 - rmse: 0.0598 - r_square: 0.9042 - val_loss: 0.0040 - val_acc: 0.8885 - val_mse: 0.0040 - val_rmse: 0.0541 - val_r_square: 0.9755\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0072 - acc: 0.9141 - mse: 0.0072 - rmse: 0.0563 - r_square: 0.9009 - val_loss: 0.0048 - val_acc: 0.9942 - val_mse: 0.0048 - val_rmse: 0.0605 - val_r_square: 0.9707\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0062 - acc: 0.9439 - mse: 0.0062 - rmse: 0.0505 - r_square: 0.9141 - val_loss: 0.0030 - val_acc: 0.9938 - val_mse: 0.0030 - val_rmse: 0.0434 - val_r_square: 0.9820\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0081 - acc: 0.9412 - mse: 0.0081 - rmse: 0.0647 - r_square: 0.8903 - val_loss: 0.0046 - val_acc: 0.9420 - val_mse: 0.0046 - val_rmse: 0.0588 - val_r_square: 0.9719\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0071 - acc: 0.9665 - mse: 0.0071 - rmse: 0.0571 - r_square: 0.9062 - val_loss: 0.0023 - val_acc: 0.8877 - val_mse: 0.0023 - val_rmse: 0.0342 - val_r_square: 0.9870\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0077 - acc: 0.9457 - mse: 0.0077 - rmse: 0.0631 - r_square: 0.8782 - val_loss: 0.0031 - val_acc: 0.8877 - val_mse: 0.0031 - val_rmse: 0.0452 - val_r_square: 0.9814\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0066 - acc: 0.9329 - mse: 0.0066 - rmse: 0.0554 - r_square: 0.9058 - val_loss: 0.0023 - val_acc: 0.9005 - val_mse: 0.0023 - val_rmse: 0.0328 - val_r_square: 0.9869\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0084 - acc: 0.9390 - mse: 0.0084 - rmse: 0.0640 - r_square: 0.8974 - val_loss: 0.0055 - val_acc: 0.9942 - val_mse: 0.0055 - val_rmse: 0.0672 - val_r_square: 0.9657\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0069 - acc: 0.9698 - mse: 0.0069 - rmse: 0.0558 - r_square: 0.9082 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0436 - val_r_square: 0.9829\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0070 - acc: 0.9535 - mse: 0.0070 - rmse: 0.0575 - r_square: 0.9010 - val_loss: 0.0052 - val_acc: 0.8365 - val_mse: 0.0052 - val_rmse: 0.0650 - val_r_square: 0.9674\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0059 - acc: 0.9362 - mse: 0.0059 - rmse: 0.0494 - r_square: 0.9230 - val_loss: 0.0024 - val_acc: 0.8732 - val_mse: 0.0024 - val_rmse: 0.0347 - val_r_square: 0.9864\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0099 - acc: 0.9345 - mse: 0.0099 - rmse: 0.0760 - r_square: 0.8710 - val_loss: 0.0082 - val_acc: 0.9159 - val_mse: 0.0082 - val_rmse: 0.0866 - val_r_square: 0.9466\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0066 - acc: 0.9684 - mse: 0.0066 - rmse: 0.0546 - r_square: 0.9159 - val_loss: 0.0060 - val_acc: 0.8366 - val_mse: 0.0060 - val_rmse: 0.0688 - val_r_square: 0.9620\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0079 - acc: 0.9537 - mse: 0.0079 - rmse: 0.0658 - r_square: 0.8868 - val_loss: 0.0031 - val_acc: 0.8365 - val_mse: 0.0031 - val_rmse: 0.0434 - val_r_square: 0.9822\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0084 - acc: 0.8849 - mse: 0.0084 - rmse: 0.0676 - r_square: 0.8850 - val_loss: 0.0038 - val_acc: 0.9942 - val_mse: 0.0038 - val_rmse: 0.0522 - val_r_square: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0064 - acc: 0.9679 - mse: 0.0064 - rmse: 0.0531 - r_square: 0.9082 - val_loss: 0.0029 - val_acc: 0.9917 - val_mse: 0.0029 - val_rmse: 0.0397 - val_r_square: 0.9829\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0071 - acc: 0.9643 - mse: 0.0071 - rmse: 0.0602 - r_square: 0.8898 - val_loss: 0.0038 - val_acc: 0.9942 - val_mse: 0.0038 - val_rmse: 0.0463 - val_r_square: 0.9780\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0089 - acc: 0.9479 - mse: 0.0089 - rmse: 0.0672 - r_square: 0.8335 - val_loss: 0.0022 - val_acc: 0.9424 - val_mse: 0.0022 - val_rmse: 0.0251 - val_r_square: 0.9880\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 203us/step - loss: 0.0062 - acc: 0.9699 - mse: 0.0062 - rmse: 0.0515 - r_square: 0.9118 - val_loss: 0.0028 - val_acc: 0.9213 - val_mse: 0.0028 - val_rmse: 0.0385 - val_r_square: 0.9839\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0068 - acc: 0.9610 - mse: 0.0068 - rmse: 0.0566 - r_square: 0.9054 - val_loss: 0.0029 - val_acc: 0.8385 - val_mse: 0.0029 - val_rmse: 0.0421 - val_r_square: 0.9828\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0058 - acc: 0.9696 - mse: 0.0058 - rmse: 0.0492 - r_square: 0.9201 - val_loss: 0.0036 - val_acc: 0.8880 - val_mse: 0.0036 - val_rmse: 0.0491 - val_r_square: 0.9785\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0057 - acc: 0.9380 - mse: 0.0057 - rmse: 0.0459 - r_square: 0.9186 - val_loss: 0.0031 - val_acc: 0.8754 - val_mse: 0.0031 - val_rmse: 0.0417 - val_r_square: 0.9819\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0060 - acc: 0.9698 - mse: 0.0060 - rmse: 0.0484 - r_square: 0.9182 - val_loss: 0.0033 - val_acc: 0.8883 - val_mse: 0.0033 - val_rmse: 0.0475 - val_r_square: 0.9803\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0061 - acc: 0.9707 - mse: 0.0061 - rmse: 0.0502 - r_square: 0.9094 - val_loss: 0.0045 - val_acc: 0.9158 - val_mse: 0.0045 - val_rmse: 0.0586 - val_r_square: 0.9713\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0059 - acc: 0.9683 - mse: 0.0059 - rmse: 0.0475 - r_square: 0.9114 - val_loss: 0.0035 - val_acc: 0.9289 - val_mse: 0.0035 - val_rmse: 0.0486 - val_r_square: 0.9783\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0054 - acc: 0.9703 - mse: 0.0054 - rmse: 0.0418 - r_square: 0.9240 - val_loss: 0.0033 - val_acc: 0.9020 - val_mse: 0.0033 - val_rmse: 0.0451 - val_r_square: 0.9804\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0052 - acc: 0.9685 - mse: 0.0052 - rmse: 0.0387 - r_square: 0.9329 - val_loss: 0.0023 - val_acc: 0.8880 - val_mse: 0.0023 - val_rmse: 0.0312 - val_r_square: 0.9873\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0050 - acc: 0.9629 - mse: 0.0050 - rmse: 0.0370 - r_square: 0.9379 - val_loss: 0.0022 - val_acc: 0.9142 - val_mse: 0.0022 - val_rmse: 0.0287 - val_r_square: 0.9876\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0051 - acc: 0.9639 - mse: 0.0051 - rmse: 0.0387 - r_square: 0.9360 - val_loss: 0.0021 - val_acc: 0.8877 - val_mse: 0.0021 - val_rmse: 0.0300 - val_r_square: 0.9883\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0053 - acc: 0.9704 - mse: 0.0053 - rmse: 0.0411 - r_square: 0.9334 - val_loss: 0.0024 - val_acc: 0.9135 - val_mse: 0.0024 - val_rmse: 0.0337 - val_r_square: 0.9862\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0056 - acc: 0.9615 - mse: 0.0056 - rmse: 0.0441 - r_square: 0.9232 - val_loss: 0.0027 - val_acc: 0.8877 - val_mse: 0.0027 - val_rmse: 0.0376 - val_r_square: 0.9848\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0060 - acc: 0.9373 - mse: 0.0060 - rmse: 0.0463 - r_square: 0.9223 - val_loss: 0.0031 - val_acc: 0.8880 - val_mse: 0.0031 - val_rmse: 0.0379 - val_r_square: 0.9826\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0063 - acc: 0.9621 - mse: 0.0063 - rmse: 0.0489 - r_square: 0.9167 - val_loss: 0.0036 - val_acc: 0.8877 - val_mse: 0.0036 - val_rmse: 0.0496 - val_r_square: 0.9789\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0055 - acc: 0.9682 - mse: 0.0055 - rmse: 0.0426 - r_square: 0.9259 - val_loss: 0.0028 - val_acc: 0.8758 - val_mse: 0.0028 - val_rmse: 0.0374 - val_r_square: 0.9837\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0057 - acc: 0.9509 - mse: 0.0057 - rmse: 0.0420 - r_square: 0.9197 - val_loss: 0.0038 - val_acc: 0.8877 - val_mse: 0.0038 - val_rmse: 0.0515 - val_r_square: 0.9772\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0059 - acc: 0.9383 - mse: 0.0059 - rmse: 0.0473 - r_square: 0.9176 - val_loss: 0.0035 - val_acc: 0.8877 - val_mse: 0.0035 - val_rmse: 0.0477 - val_r_square: 0.9793\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0056 - acc: 0.9496 - mse: 0.0056 - rmse: 0.0433 - r_square: 0.9226 - val_loss: 0.0034 - val_acc: 0.8860 - val_mse: 0.0034 - val_rmse: 0.0450 - val_r_square: 0.9803\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0057 - acc: 0.9689 - mse: 0.0057 - rmse: 0.0436 - r_square: 0.9280 - val_loss: 0.0032 - val_acc: 0.8877 - val_mse: 0.0032 - val_rmse: 0.0369 - val_r_square: 0.9823\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0051 - acc: 0.9603 - mse: 0.0051 - rmse: 0.0378 - r_square: 0.9352 - val_loss: 0.0027 - val_acc: 0.8876 - val_mse: 0.0027 - val_rmse: 0.0311 - val_r_square: 0.9851\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0054 - acc: 0.9626 - mse: 0.0054 - rmse: 0.0401 - r_square: 0.9339 - val_loss: 0.0031 - val_acc: 0.9378 - val_mse: 0.0031 - val_rmse: 0.0390 - val_r_square: 0.9824\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0053 - acc: 0.9663 - mse: 0.0053 - rmse: 0.0404 - r_square: 0.9352 - val_loss: 0.0022 - val_acc: 0.8995 - val_mse: 0.0022 - val_rmse: 0.0297 - val_r_square: 0.9878\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0055 - acc: 0.9672 - mse: 0.0055 - rmse: 0.0418 - r_square: 0.9317 - val_loss: 0.0030 - val_acc: 0.8863 - val_mse: 0.0030 - val_rmse: 0.0431 - val_r_square: 0.9820\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0053 - acc: 0.9612 - mse: 0.0053 - rmse: 0.0400 - r_square: 0.9336 - val_loss: 0.0030 - val_acc: 0.9236 - val_mse: 0.0030 - val_rmse: 0.0416 - val_r_square: 0.9824\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0058 - acc: 0.9598 - mse: 0.0058 - rmse: 0.0447 - r_square: 0.9309 - val_loss: 0.0023 - val_acc: 0.9889 - val_mse: 0.0023 - val_rmse: 0.0313 - val_r_square: 0.9868\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0062 - acc: 0.9577 - mse: 0.0062 - rmse: 0.0507 - r_square: 0.9193 - val_loss: 0.0023 - val_acc: 0.9739 - val_mse: 0.0023 - val_rmse: 0.0309 - val_r_square: 0.9870\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0057 - acc: 0.9408 - mse: 0.0057 - rmse: 0.0475 - r_square: 0.9258 - val_loss: 0.0041 - val_acc: 0.9937 - val_mse: 0.0041 - val_rmse: 0.0524 - val_r_square: 0.9748\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0065 - acc: 0.9608 - mse: 0.0065 - rmse: 0.0547 - r_square: 0.9112 - val_loss: 0.0059 - val_acc: 0.9937 - val_mse: 0.0059 - val_rmse: 0.0682 - val_r_square: 0.9631\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0060 - acc: 0.9688 - mse: 0.0060 - rmse: 0.0491 - r_square: 0.9194 - val_loss: 0.0032 - val_acc: 0.9906 - val_mse: 0.0032 - val_rmse: 0.0451 - val_r_square: 0.9806\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0066 - acc: 0.9663 - mse: 0.0066 - rmse: 0.0546 - r_square: 0.9106 - val_loss: 0.0043 - val_acc: 0.9362 - val_mse: 0.0043 - val_rmse: 0.0567 - val_r_square: 0.9732\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 203us/step - loss: 0.0064 - acc: 0.9660 - mse: 0.0064 - rmse: 0.0541 - r_square: 0.9087 - val_loss: 0.0050 - val_acc: 0.9941 - val_mse: 0.0050 - val_rmse: 0.0590 - val_r_square: 0.9697\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0063 - acc: 0.9572 - mse: 0.0063 - rmse: 0.0530 - r_square: 0.9167 - val_loss: 0.0091 - val_acc: 0.9942 - val_mse: 0.0091 - val_rmse: 0.0867 - val_r_square: 0.9425\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0057 - acc: 0.9704 - mse: 0.0057 - rmse: 0.0453 - r_square: 0.9261 - val_loss: 0.0033 - val_acc: 0.9855 - val_mse: 0.0033 - val_rmse: 0.0419 - val_r_square: 0.9808\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0060 - acc: 0.9341 - mse: 0.0060 - rmse: 0.0480 - r_square: 0.9192 - val_loss: 0.0041 - val_acc: 0.9924 - val_mse: 0.0041 - val_rmse: 0.0549 - val_r_square: 0.9746\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0065 - acc: 0.9608 - mse: 0.0065 - rmse: 0.0538 - r_square: 0.9038 - val_loss: 0.0043 - val_acc: 0.9820 - val_mse: 0.0043 - val_rmse: 0.0540 - val_r_square: 0.9739\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0066 - acc: 0.9575 - mse: 0.0066 - rmse: 0.0539 - r_square: 0.8961 - val_loss: 0.0034 - val_acc: 0.9909 - val_mse: 0.0034 - val_rmse: 0.0463 - val_r_square: 0.9797\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0050 - acc: 0.9514 - mse: 0.0050 - rmse: 0.0368 - r_square: 0.9288 - val_loss: 0.0033 - val_acc: 0.9246 - val_mse: 0.0033 - val_rmse: 0.0456 - val_r_square: 0.9802\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0050 - acc: 0.9473 - mse: 0.0050 - rmse: 0.0360 - r_square: 0.9304 - val_loss: 0.0033 - val_acc: 0.9666 - val_mse: 0.0033 - val_rmse: 0.0457 - val_r_square: 0.9804\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0058 - acc: 0.9697 - mse: 0.0058 - rmse: 0.0480 - r_square: 0.9124 - val_loss: 0.0036 - val_acc: 0.9544 - val_mse: 0.0036 - val_rmse: 0.0489 - val_r_square: 0.9782\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0057 - acc: 0.9705 - mse: 0.0057 - rmse: 0.0450 - r_square: 0.9243 - val_loss: 0.0024 - val_acc: 0.9017 - val_mse: 0.0024 - val_rmse: 0.0329 - val_r_square: 0.9862\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0059 - acc: 0.9451 - mse: 0.0059 - rmse: 0.0469 - r_square: 0.9163 - val_loss: 0.0029 - val_acc: 0.9134 - val_mse: 0.0029 - val_rmse: 0.0417 - val_r_square: 0.9829\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0072 - acc: 0.9257 - mse: 0.0072 - rmse: 0.0581 - r_square: 0.8781 - val_loss: 0.0040 - val_acc: 0.9942 - val_mse: 0.0040 - val_rmse: 0.0527 - val_r_square: 0.9754\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0067 - acc: 0.9503 - mse: 0.0067 - rmse: 0.0558 - r_square: 0.9057 - val_loss: 0.0053 - val_acc: 0.8879 - val_mse: 0.0053 - val_rmse: 0.0647 - val_r_square: 0.9662\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0066 - acc: 0.9564 - mse: 0.0066 - rmse: 0.0528 - r_square: 0.8960 - val_loss: 0.0049 - val_acc: 0.9901 - val_mse: 0.0049 - val_rmse: 0.0597 - val_r_square: 0.9687\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0068 - acc: 0.9287 - mse: 0.0068 - rmse: 0.0565 - r_square: 0.8907 - val_loss: 0.0046 - val_acc: 0.9942 - val_mse: 0.0046 - val_rmse: 0.0585 - val_r_square: 0.9714\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0058 - acc: 0.9684 - mse: 0.0058 - rmse: 0.0474 - r_square: 0.9103 - val_loss: 0.0049 - val_acc: 0.9545 - val_mse: 0.0049 - val_rmse: 0.0603 - val_r_square: 0.9686\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0051 - acc: 0.9708 - mse: 0.0051 - rmse: 0.0377 - r_square: 0.9315 - val_loss: 0.0036 - val_acc: 0.9525 - val_mse: 0.0036 - val_rmse: 0.0488 - val_r_square: 0.9780\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0051 - acc: 0.9381 - mse: 0.0051 - rmse: 0.0398 - r_square: 0.9286 - val_loss: 0.0029 - val_acc: 0.9558 - val_mse: 0.0029 - val_rmse: 0.0410 - val_r_square: 0.9827\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0053 - acc: 0.9613 - mse: 0.0053 - rmse: 0.0408 - r_square: 0.9246 - val_loss: 0.0028 - val_acc: 0.9050 - val_mse: 0.0028 - val_rmse: 0.0387 - val_r_square: 0.9839\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0054 - acc: 0.9714 - mse: 0.0054 - rmse: 0.0426 - r_square: 0.9224 - val_loss: 0.0051 - val_acc: 0.9158 - val_mse: 0.0051 - val_rmse: 0.0615 - val_r_square: 0.9674\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0054 - acc: 0.9707 - mse: 0.0054 - rmse: 0.0416 - r_square: 0.9167 - val_loss: 0.0036 - val_acc: 0.8533 - val_mse: 0.0036 - val_rmse: 0.0495 - val_r_square: 0.9776\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0053 - acc: 0.9713 - mse: 0.0053 - rmse: 0.0393 - r_square: 0.9193 - val_loss: 0.0050 - val_acc: 0.9407 - val_mse: 0.0050 - val_rmse: 0.0602 - val_r_square: 0.9680\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0049 - acc: 0.9537 - mse: 0.0049 - rmse: 0.0348 - r_square: 0.9297 - val_loss: 0.0052 - val_acc: 0.8633 - val_mse: 0.0052 - val_rmse: 0.0612 - val_r_square: 0.9672\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0048 - acc: 0.9684 - mse: 0.0048 - rmse: 0.0339 - r_square: 0.9358 - val_loss: 0.0037 - val_acc: 0.9554 - val_mse: 0.0037 - val_rmse: 0.0500 - val_r_square: 0.9768\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0047 - acc: 0.9681 - mse: 0.0047 - rmse: 0.0319 - r_square: 0.9405 - val_loss: 0.0030 - val_acc: 0.9030 - val_mse: 0.0030 - val_rmse: 0.0438 - val_r_square: 0.9816\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0048 - acc: 0.9481 - mse: 0.0048 - rmse: 0.0331 - r_square: 0.9366 - val_loss: 0.0031 - val_acc: 0.8774 - val_mse: 0.0031 - val_rmse: 0.0428 - val_r_square: 0.9817\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0049 - acc: 0.9689 - mse: 0.0049 - rmse: 0.0350 - r_square: 0.9357 - val_loss: 0.0029 - val_acc: 0.9558 - val_mse: 0.0029 - val_rmse: 0.0419 - val_r_square: 0.9825\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0046 - acc: 0.9685 - mse: 0.0046 - rmse: 0.0311 - r_square: 0.9409 - val_loss: 0.0041 - val_acc: 0.9801 - val_mse: 0.0041 - val_rmse: 0.0540 - val_r_square: 0.9739\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0047 - acc: 0.9683 - mse: 0.0047 - rmse: 0.0330 - r_square: 0.9407 - val_loss: 0.0040 - val_acc: 0.9809 - val_mse: 0.0040 - val_rmse: 0.0524 - val_r_square: 0.9751\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0050 - acc: 0.9703 - mse: 0.0050 - rmse: 0.0366 - r_square: 0.9338 - val_loss: 0.0029 - val_acc: 0.9139 - val_mse: 0.0029 - val_rmse: 0.0433 - val_r_square: 0.9823\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0049 - acc: 0.9703 - mse: 0.0049 - rmse: 0.0361 - r_square: 0.9364 - val_loss: 0.0033 - val_acc: 0.9931 - val_mse: 0.0033 - val_rmse: 0.0464 - val_r_square: 0.9795\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0051 - acc: 0.9633 - mse: 0.0051 - rmse: 0.0371 - r_square: 0.9292 - val_loss: 0.0031 - val_acc: 0.9257 - val_mse: 0.0031 - val_rmse: 0.0449 - val_r_square: 0.9810\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 203us/step - loss: 0.0048 - acc: 0.9685 - mse: 0.0048 - rmse: 0.0343 - r_square: 0.9367 - val_loss: 0.0027 - val_acc: 0.9499 - val_mse: 0.0027 - val_rmse: 0.0390 - val_r_square: 0.9841\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0052 - acc: 0.9435 - mse: 0.0052 - rmse: 0.0400 - r_square: 0.9288 - val_loss: 0.0042 - val_acc: 0.9250 - val_mse: 0.0042 - val_rmse: 0.0550 - val_r_square: 0.9738\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0048 - acc: 0.9701 - mse: 0.0048 - rmse: 0.0345 - r_square: 0.9359 - val_loss: 0.0026 - val_acc: 0.9259 - val_mse: 0.0026 - val_rmse: 0.0382 - val_r_square: 0.9843\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0048 - acc: 0.9699 - mse: 0.0048 - rmse: 0.0358 - r_square: 0.9355 - val_loss: 0.0028 - val_acc: 0.9801 - val_mse: 0.0028 - val_rmse: 0.0390 - val_r_square: 0.9833\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastline (coast/area ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Coastline (coast/area ratio)','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 5s 748us/step - loss: 0.0323 - acc: 0.4842 - rmse: 0.1460 - mse: 0.0323 - r_square: 0.3872 - val_loss: 0.0266 - val_acc: 0.8365 - val_rmse: 0.1505 - val_mse: 0.0266 - val_r_square: 0.8149\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0237 - acc: 0.9143 - rmse: 0.1168 - mse: 0.0237 - r_square: 0.5564 - val_loss: 0.0177 - val_acc: 0.8365 - val_rmse: 0.1254 - val_mse: 0.0177 - val_r_square: 0.8773\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0216 - acc: 0.9327 - rmse: 0.1125 - mse: 0.0216 - r_square: 0.6254 - val_loss: 0.0113 - val_acc: 0.8365 - val_rmse: 0.0946 - val_mse: 0.0113 - val_r_square: 0.9232\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0178 - acc: 0.9302 - rmse: 0.1000 - mse: 0.0178 - r_square: 0.7074 - val_loss: 0.0089 - val_acc: 0.8621 - val_rmse: 0.0838 - val_mse: 0.0089 - val_r_square: 0.9390\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 297us/step - loss: 0.0125 - acc: 0.9305 - rmse: 0.0744 - mse: 0.0125 - r_square: 0.7848 - val_loss: 0.0069 - val_acc: 0.8746 - val_rmse: 0.0736 - val_mse: 0.0069 - val_r_square: 0.9528\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 296us/step - loss: 0.0093 - acc: 0.9218 - rmse: 0.0582 - mse: 0.0093 - r_square: 0.8174 - val_loss: 0.0051 - val_acc: 0.8755 - val_rmse: 0.0555 - val_mse: 0.0051 - val_r_square: 0.9655\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0080 - acc: 0.9259 - rmse: 0.0513 - mse: 0.0080 - r_square: 0.8347 - val_loss: 0.0037 - val_acc: 0.8637 - val_rmse: 0.0450 - val_mse: 0.0037 - val_r_square: 0.9758\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 293us/step - loss: 0.0073 - acc: 0.9360 - rmse: 0.0475 - mse: 0.0073 - r_square: 0.8484 - val_loss: 0.0031 - val_acc: 0.8407 - val_rmse: 0.0442 - val_mse: 0.0031 - val_r_square: 0.9804\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0069 - acc: 0.9415 - rmse: 0.0448 - mse: 0.0069 - r_square: 0.8565 - val_loss: 0.0027 - val_acc: 0.8423 - val_rmse: 0.0419 - val_mse: 0.0027 - val_r_square: 0.9830\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 297us/step - loss: 0.0065 - acc: 0.9466 - rmse: 0.0408 - mse: 0.0065 - r_square: 0.8660 - val_loss: 0.0019 - val_acc: 0.8387 - val_rmse: 0.0307 - val_mse: 0.0019 - val_r_square: 0.9888\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0063 - acc: 0.9475 - rmse: 0.0403 - mse: 0.0063 - r_square: 0.8691 - val_loss: 0.0019 - val_acc: 0.8377 - val_rmse: 0.0285 - val_mse: 0.0019 - val_r_square: 0.9892\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0062 - acc: 0.9485 - rmse: 0.0400 - mse: 0.0062 - r_square: 0.8709 - val_loss: 0.0020 - val_acc: 0.8371 - val_rmse: 0.0301 - val_mse: 0.0020 - val_r_square: 0.9886\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 341us/step - loss: 0.0061 - acc: 0.9493 - rmse: 0.0397 - mse: 0.0061 - r_square: 0.8735 - val_loss: 0.0021 - val_acc: 0.8368 - val_rmse: 0.0297 - val_mse: 0.0021 - val_r_square: 0.9885\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0061 - acc: 0.9500 - rmse: 0.0401 - mse: 0.0061 - r_square: 0.8760 - val_loss: 0.0022 - val_acc: 0.8365 - val_rmse: 0.0307 - val_mse: 0.0022 - val_r_square: 0.9879\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0061 - acc: 0.9508 - rmse: 0.0409 - mse: 0.0061 - r_square: 0.8773 - val_loss: 0.0024 - val_acc: 0.8365 - val_rmse: 0.0351 - val_mse: 0.0024 - val_r_square: 0.9863\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0062 - acc: 0.9513 - rmse: 0.0422 - mse: 0.0062 - r_square: 0.8781 - val_loss: 0.0029 - val_acc: 0.8365 - val_rmse: 0.0425 - val_mse: 0.0029 - val_r_square: 0.9830\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0063 - acc: 0.9501 - rmse: 0.0435 - mse: 0.0063 - r_square: 0.8777 - val_loss: 0.0030 - val_acc: 0.8365 - val_rmse: 0.0455 - val_mse: 0.0030 - val_r_square: 0.9814\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 342us/step - loss: 0.0063 - acc: 0.9486 - rmse: 0.0443 - mse: 0.0063 - r_square: 0.8774 - val_loss: 0.0025 - val_acc: 0.8366 - val_rmse: 0.0392 - val_mse: 0.0025 - val_r_square: 0.9849\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 352us/step - loss: 0.0063 - acc: 0.9485 - rmse: 0.0445 - mse: 0.0063 - r_square: 0.8786 - val_loss: 0.0018 - val_acc: 0.8369 - val_rmse: 0.0308 - val_mse: 0.0018 - val_r_square: 0.9891\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0063 - acc: 0.9481 - rmse: 0.0447 - mse: 0.0063 - r_square: 0.8802 - val_loss: 0.0023 - val_acc: 0.8631 - val_rmse: 0.0379 - val_mse: 0.0023 - val_r_square: 0.9857\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0062 - acc: 0.9434 - rmse: 0.0443 - mse: 0.0062 - r_square: 0.8830 - val_loss: 0.0031 - val_acc: 0.9545 - val_rmse: 0.0474 - val_mse: 0.0031 - val_r_square: 0.9794\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0061 - acc: 0.9244 - rmse: 0.0430 - mse: 0.0061 - r_square: 0.8863 - val_loss: 0.0032 - val_acc: 0.9925 - val_rmse: 0.0483 - val_mse: 0.0032 - val_r_square: 0.9786\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0059 - acc: 0.9337 - rmse: 0.0416 - mse: 0.0059 - r_square: 0.8866 - val_loss: 0.0023 - val_acc: 0.9924 - val_rmse: 0.0370 - val_mse: 0.0023 - val_r_square: 0.9855\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0059 - acc: 0.9304 - rmse: 0.0408 - mse: 0.0059 - r_square: 0.8836 - val_loss: 0.0013 - val_acc: 0.9501 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0065 - acc: 0.9184 - rmse: 0.0455 - mse: 0.0065 - r_square: 0.8664 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0295 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0058 - acc: 0.9211 - rmse: 0.0414 - mse: 0.0058 - r_square: 0.8752 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9917\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 277us/step - loss: 0.0053 - acc: 0.9483 - rmse: 0.0357 - mse: 0.0053 - r_square: 0.8895 - val_loss: 0.0012 - val_acc: 0.8374 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 276us/step - loss: 0.0051 - acc: 0.9573 - rmse: 0.0320 - mse: 0.0051 - r_square: 0.8942 - val_loss: 0.0013 - val_acc: 0.9041 - val_rmse: 0.0205 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 276us/step - loss: 0.0051 - acc: 0.9578 - rmse: 0.0319 - mse: 0.0051 - r_square: 0.8956 - val_loss: 0.0014 - val_acc: 0.9431 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0051 - acc: 0.9583 - rmse: 0.0311 - mse: 0.0051 - r_square: 0.8976 - val_loss: 0.0014 - val_acc: 0.9431 - val_rmse: 0.0228 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0051 - acc: 0.9603 - rmse: 0.0316 - mse: 0.0051 - r_square: 0.8973 - val_loss: 0.0014 - val_acc: 0.9433 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 277us/step - loss: 0.0050 - acc: 0.9605 - rmse: 0.0306 - mse: 0.0050 - r_square: 0.8986 - val_loss: 0.0013 - val_acc: 0.9429 - val_rmse: 0.0204 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0051 - acc: 0.9579 - rmse: 0.0311 - mse: 0.0051 - r_square: 0.8967 - val_loss: 0.0013 - val_acc: 0.9427 - val_rmse: 0.0205 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9614 - rmse: 0.0300 - mse: 0.0049 - r_square: 0.9001 - val_loss: 0.0012 - val_acc: 0.9423 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9605 - rmse: 0.0297 - mse: 0.0048 - r_square: 0.9014 - val_loss: 0.0012 - val_acc: 0.9424 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9623 - rmse: 0.0289 - mse: 0.0048 - r_square: 0.9024 - val_loss: 0.0012 - val_acc: 0.9423 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0048 - acc: 0.9625 - rmse: 0.0286 - mse: 0.0048 - r_square: 0.9028 - val_loss: 0.0012 - val_acc: 0.9423 - val_rmse: 0.0198 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0048 - acc: 0.9629 - rmse: 0.0279 - mse: 0.0048 - r_square: 0.9028 - val_loss: 0.0012 - val_acc: 0.9424 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0050 - acc: 0.9613 - rmse: 0.0288 - mse: 0.0050 - r_square: 0.8981 - val_loss: 0.0013 - val_acc: 0.9424 - val_rmse: 0.0203 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9626 - rmse: 0.0273 - mse: 0.0047 - r_square: 0.9035 - val_loss: 0.0012 - val_acc: 0.9430 - val_rmse: 0.0199 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9638 - rmse: 0.0277 - mse: 0.0047 - r_square: 0.9038 - val_loss: 0.0012 - val_acc: 0.9423 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9623 - rmse: 0.0269 - mse: 0.0047 - r_square: 0.9038 - val_loss: 0.0013 - val_acc: 0.9552 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9627 - rmse: 0.0277 - mse: 0.0047 - r_square: 0.9035 - val_loss: 0.0012 - val_acc: 0.9182 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9635 - rmse: 0.0265 - mse: 0.0047 - r_square: 0.9052 - val_loss: 0.0013 - val_acc: 0.9557 - val_rmse: 0.0205 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9643 - rmse: 0.0264 - mse: 0.0046 - r_square: 0.9067 - val_loss: 0.0012 - val_acc: 0.9427 - val_rmse: 0.0200 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9646 - rmse: 0.0261 - mse: 0.0046 - r_square: 0.9076 - val_loss: 0.0013 - val_acc: 0.9560 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0046 - acc: 0.9650 - rmse: 0.0259 - mse: 0.0046 - r_square: 0.9079 - val_loss: 0.0013 - val_acc: 0.9551 - val_rmse: 0.0207 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9645 - rmse: 0.0265 - mse: 0.0046 - r_square: 0.9076 - val_loss: 0.0013 - val_acc: 0.9560 - val_rmse: 0.0209 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9645 - rmse: 0.0260 - mse: 0.0046 - r_square: 0.9071 - val_loss: 0.0013 - val_acc: 0.9555 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9632 - rmse: 0.0280 - mse: 0.0048 - r_square: 0.9024 - val_loss: 0.0013 - val_acc: 0.9682 - val_rmse: 0.0216 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0046 - acc: 0.9628 - rmse: 0.0266 - mse: 0.0046 - r_square: 0.9073 - val_loss: 0.0013 - val_acc: 0.9561 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9641 - rmse: 0.0272 - mse: 0.0046 - r_square: 0.9075 - val_loss: 0.0013 - val_acc: 0.9558 - val_rmse: 0.0210 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0046 - acc: 0.9635 - rmse: 0.0270 - mse: 0.0046 - r_square: 0.9084 - val_loss: 0.0013 - val_acc: 0.9562 - val_rmse: 0.0215 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9639 - rmse: 0.0275 - mse: 0.0046 - r_square: 0.9083 - val_loss: 0.0013 - val_acc: 0.9558 - val_rmse: 0.0215 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9621 - rmse: 0.0278 - mse: 0.0046 - r_square: 0.9086 - val_loss: 0.0013 - val_acc: 0.9558 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9634 - rmse: 0.0284 - mse: 0.0047 - r_square: 0.9081 - val_loss: 0.0013 - val_acc: 0.9443 - val_rmse: 0.0219 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9618 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9081 - val_loss: 0.0013 - val_acc: 0.9440 - val_rmse: 0.0224 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0047 - acc: 0.9649 - rmse: 0.0300 - mse: 0.0047 - r_square: 0.9067 - val_loss: 0.0014 - val_acc: 0.9433 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0048 - acc: 0.9615 - rmse: 0.0313 - mse: 0.0048 - r_square: 0.9060 - val_loss: 0.0014 - val_acc: 0.9193 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9650 - rmse: 0.0324 - mse: 0.0050 - r_square: 0.9013 - val_loss: 0.0014 - val_acc: 0.9325 - val_rmse: 0.0233 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9606 - rmse: 0.0357 - mse: 0.0052 - r_square: 0.9002 - val_loss: 0.0014 - val_acc: 0.8676 - val_rmse: 0.0242 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9646 - rmse: 0.0327 - mse: 0.0050 - r_square: 0.9013 - val_loss: 0.0014 - val_acc: 0.9216 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0054 - acc: 0.9598 - rmse: 0.0392 - mse: 0.0054 - r_square: 0.8943 - val_loss: 0.0017 - val_acc: 0.8670 - val_rmse: 0.0301 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0052 - acc: 0.9631 - rmse: 0.0364 - mse: 0.0052 - r_square: 0.8999 - val_loss: 0.0018 - val_acc: 0.9067 - val_rmse: 0.0313 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0056 - acc: 0.9624 - rmse: 0.0413 - mse: 0.0056 - r_square: 0.8903 - val_loss: 0.0020 - val_acc: 0.9465 - val_rmse: 0.0339 - val_mse: 0.0020 - val_r_square: 0.9877\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0054 - acc: 0.9563 - rmse: 0.0394 - mse: 0.0054 - r_square: 0.8954 - val_loss: 0.0016 - val_acc: 0.8568 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0057 - acc: 0.9389 - rmse: 0.0427 - mse: 0.0057 - r_square: 0.8937 - val_loss: 0.0022 - val_acc: 0.8388 - val_rmse: 0.0378 - val_mse: 0.0022 - val_r_square: 0.9862\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0058 - acc: 0.9369 - rmse: 0.0434 - mse: 0.0058 - r_square: 0.8914 - val_loss: 0.0015 - val_acc: 0.8375 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9916\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0058 - acc: 0.9233 - rmse: 0.0446 - mse: 0.0058 - r_square: 0.8866 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0059 - acc: 0.9416 - rmse: 0.0442 - mse: 0.0059 - r_square: 0.8891 - val_loss: 0.0018 - val_acc: 0.8369 - val_rmse: 0.0302 - val_mse: 0.0018 - val_r_square: 0.9896\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0060 - acc: 0.9477 - rmse: 0.0454 - mse: 0.0060 - r_square: 0.8869 - val_loss: 0.0018 - val_acc: 0.8369 - val_rmse: 0.0312 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0055 - acc: 0.9575 - rmse: 0.0402 - mse: 0.0055 - r_square: 0.8955 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0283 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9546 - rmse: 0.0343 - mse: 0.0050 - r_square: 0.9008 - val_loss: 0.0013 - val_acc: 0.8502 - val_rmse: 0.0227 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0047 - acc: 0.9595 - rmse: 0.0286 - mse: 0.0047 - r_square: 0.9068 - val_loss: 0.0012 - val_acc: 0.9542 - val_rmse: 0.0192 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0045 - acc: 0.9603 - rmse: 0.0263 - mse: 0.0045 - r_square: 0.9087 - val_loss: 0.0012 - val_acc: 0.9685 - val_rmse: 0.0194 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9638 - rmse: 0.0249 - mse: 0.0045 - r_square: 0.9091 - val_loss: 0.0012 - val_acc: 0.9673 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0045 - acc: 0.9655 - rmse: 0.0247 - mse: 0.0045 - r_square: 0.9085 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0174 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9662 - rmse: 0.0242 - mse: 0.0045 - r_square: 0.9094 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0174 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9663 - rmse: 0.0240 - mse: 0.0044 - r_square: 0.9103 - val_loss: 0.0011 - val_acc: 0.9557 - val_rmse: 0.0172 - val_mse: 0.0011 - val_r_square: 0.9936\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9669 - rmse: 0.0235 - mse: 0.0044 - r_square: 0.9112 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0044 - acc: 0.9671 - rmse: 0.0236 - mse: 0.0044 - r_square: 0.9111 - val_loss: 0.0011 - val_acc: 0.9557 - val_rmse: 0.0173 - val_mse: 0.0011 - val_r_square: 0.9936\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0044 - acc: 0.9667 - rmse: 0.0235 - mse: 0.0044 - r_square: 0.9113 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0044 - acc: 0.9671 - rmse: 0.0237 - mse: 0.0044 - r_square: 0.9102 - val_loss: 0.0011 - val_acc: 0.9557 - val_rmse: 0.0173 - val_mse: 0.0011 - val_r_square: 0.9936\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0045 - acc: 0.9660 - rmse: 0.0241 - mse: 0.0045 - r_square: 0.9078 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9666 - rmse: 0.0240 - mse: 0.0045 - r_square: 0.9088 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0174 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9663 - rmse: 0.0237 - mse: 0.0044 - r_square: 0.9106 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9674 - rmse: 0.0237 - mse: 0.0044 - r_square: 0.9112 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9670 - rmse: 0.0233 - mse: 0.0044 - r_square: 0.9116 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9671 - rmse: 0.0234 - mse: 0.0044 - r_square: 0.9118 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9669 - rmse: 0.0234 - mse: 0.0044 - r_square: 0.9119 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9672 - rmse: 0.0234 - mse: 0.0044 - r_square: 0.9121 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0177 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0044 - acc: 0.9667 - rmse: 0.0236 - mse: 0.0044 - r_square: 0.9119 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9675 - rmse: 0.0237 - mse: 0.0044 - r_square: 0.9111 - val_loss: 0.0012 - val_acc: 0.9560 - val_rmse: 0.0179 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0046 - acc: 0.9661 - rmse: 0.0244 - mse: 0.0046 - r_square: 0.9069 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0177 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0045 - acc: 0.9672 - rmse: 0.0242 - mse: 0.0045 - r_square: 0.9092 - val_loss: 0.0012 - val_acc: 0.9557 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0044 - acc: 0.9669 - rmse: 0.0242 - mse: 0.0044 - r_square: 0.9098 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0184 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9670 - rmse: 0.0242 - mse: 0.0044 - r_square: 0.9107 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0180 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9677 - rmse: 0.0238 - mse: 0.0044 - r_square: 0.9113 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0178 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9670 - rmse: 0.0240 - mse: 0.0044 - r_square: 0.9112 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0178 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0044 - acc: 0.9677 - rmse: 0.0239 - mse: 0.0044 - r_square: 0.9112 - val_loss: 0.0012 - val_acc: 0.9558 - val_rmse: 0.0178 - val_mse: 0.0012 - val_r_square: 0.9934\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 7s 1ms/step - loss: 0.0225 - acc: 0.6095 - rmse: 0.1180 - mse: 0.0225 - r_square: 0.5365 - val_loss: 0.0083 - val_acc: 0.9809 - val_rmse: 0.0852 - val_mse: 0.0083 - val_r_square: 0.9424\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0133 - acc: 0.9043 - rmse: 0.0860 - mse: 0.0133 - r_square: 0.6875 - val_loss: 0.0070 - val_acc: 0.8365 - val_rmse: 0.0788 - val_mse: 0.0070 - val_r_square: 0.9525\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0104 - acc: 0.9112 - rmse: 0.0689 - mse: 0.0104 - r_square: 0.7960 - val_loss: 0.0039 - val_acc: 0.8365 - val_rmse: 0.0541 - val_mse: 0.0039 - val_r_square: 0.9754\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0083 - acc: 0.9129 - rmse: 0.0570 - mse: 0.0083 - r_square: 0.8434 - val_loss: 0.0030 - val_acc: 0.8365 - val_rmse: 0.0458 - val_mse: 0.0030 - val_r_square: 0.9809\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0066 - acc: 0.9313 - rmse: 0.0407 - mse: 0.0066 - r_square: 0.8720 - val_loss: 0.0019 - val_acc: 0.8365 - val_rmse: 0.0313 - val_mse: 0.0019 - val_r_square: 0.9885\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0060 - acc: 0.9421 - rmse: 0.0352 - mse: 0.0060 - r_square: 0.8815 - val_loss: 0.0017 - val_acc: 0.8389 - val_rmse: 0.0276 - val_mse: 0.0017 - val_r_square: 0.9901\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0058 - acc: 0.9523 - rmse: 0.0321 - mse: 0.0058 - r_square: 0.8851 - val_loss: 0.0016 - val_acc: 0.8417 - val_rmse: 0.0263 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0056 - acc: 0.9528 - rmse: 0.0313 - mse: 0.0056 - r_square: 0.8866 - val_loss: 0.0015 - val_acc: 0.8425 - val_rmse: 0.0250 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0055 - acc: 0.9534 - rmse: 0.0311 - mse: 0.0055 - r_square: 0.8870 - val_loss: 0.0016 - val_acc: 0.8431 - val_rmse: 0.0266 - val_mse: 0.0016 - val_r_square: 0.9908\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0053 - acc: 0.9536 - rmse: 0.0304 - mse: 0.0053 - r_square: 0.8892 - val_loss: 0.0015 - val_acc: 0.8430 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0053 - acc: 0.9559 - rmse: 0.0297 - mse: 0.0053 - r_square: 0.8904 - val_loss: 0.0015 - val_acc: 0.8431 - val_rmse: 0.0248 - val_mse: 0.0015 - val_r_square: 0.9915\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0052 - acc: 0.9582 - rmse: 0.0291 - mse: 0.0052 - r_square: 0.8921 - val_loss: 0.0014 - val_acc: 0.8425 - val_rmse: 0.0237 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0051 - acc: 0.9597 - rmse: 0.0286 - mse: 0.0051 - r_square: 0.8930 - val_loss: 0.0013 - val_acc: 0.8418 - val_rmse: 0.0225 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0052 - acc: 0.9602 - rmse: 0.0290 - mse: 0.0052 - r_square: 0.8902 - val_loss: 0.0013 - val_acc: 0.8410 - val_rmse: 0.0226 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0053 - acc: 0.9607 - rmse: 0.0302 - mse: 0.0053 - r_square: 0.8882 - val_loss: 0.0013 - val_acc: 0.8411 - val_rmse: 0.0227 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0055 - acc: 0.9604 - rmse: 0.0307 - mse: 0.0055 - r_square: 0.8822 - val_loss: 0.0013 - val_acc: 0.8404 - val_rmse: 0.0228 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0051 - acc: 0.9624 - rmse: 0.0294 - mse: 0.0051 - r_square: 0.8928 - val_loss: 0.0013 - val_acc: 0.8542 - val_rmse: 0.0221 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0049 - acc: 0.9630 - rmse: 0.0280 - mse: 0.0049 - r_square: 0.8956 - val_loss: 0.0013 - val_acc: 0.8520 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0049 - acc: 0.9635 - rmse: 0.0274 - mse: 0.0049 - r_square: 0.8976 - val_loss: 0.0012 - val_acc: 0.8531 - val_rmse: 0.0203 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0048 - acc: 0.9636 - rmse: 0.0269 - mse: 0.0048 - r_square: 0.8986 - val_loss: 0.0012 - val_acc: 0.8392 - val_rmse: 0.0184 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0048 - acc: 0.9643 - rmse: 0.0266 - mse: 0.0048 - r_square: 0.8999 - val_loss: 0.0012 - val_acc: 0.8391 - val_rmse: 0.0172 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0048 - acc: 0.9643 - rmse: 0.0267 - mse: 0.0048 - r_square: 0.9002 - val_loss: 0.0012 - val_acc: 0.8388 - val_rmse: 0.0169 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0047 - acc: 0.9646 - rmse: 0.0268 - mse: 0.0047 - r_square: 0.9006 - val_loss: 0.0012 - val_acc: 0.8385 - val_rmse: 0.0169 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0048 - acc: 0.9647 - rmse: 0.0275 - mse: 0.0048 - r_square: 0.9000 - val_loss: 0.0012 - val_acc: 0.8382 - val_rmse: 0.0174 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0048 - acc: 0.9650 - rmse: 0.0278 - mse: 0.0048 - r_square: 0.8996 - val_loss: 0.0012 - val_acc: 0.8382 - val_rmse: 0.0179 - val_mse: 0.0012 - val_r_square: 0.9935\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0048 - acc: 0.9651 - rmse: 0.0283 - mse: 0.0048 - r_square: 0.8993 - val_loss: 0.0012 - val_acc: 0.8507 - val_rmse: 0.0188 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0047 - acc: 0.9652 - rmse: 0.0275 - mse: 0.0047 - r_square: 0.9006 - val_loss: 0.0011 - val_acc: 0.8646 - val_rmse: 0.0169 - val_mse: 0.0011 - val_r_square: 0.9938\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0047 - acc: 0.9656 - rmse: 0.0268 - mse: 0.0047 - r_square: 0.9024 - val_loss: 0.0011 - val_acc: 0.8512 - val_rmse: 0.0142 - val_mse: 0.0011 - val_r_square: 0.9943\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0046 - acc: 0.9652 - rmse: 0.0265 - mse: 0.0046 - r_square: 0.9038 - val_loss: 0.0011 - val_acc: 0.8378 - val_rmse: 0.0124 - val_mse: 0.0011 - val_r_square: 0.9943\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0047 - acc: 0.9659 - rmse: 0.0272 - mse: 0.0047 - r_square: 0.9035 - val_loss: 0.0012 - val_acc: 0.8374 - val_rmse: 0.0159 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0049 - acc: 0.9647 - rmse: 0.0288 - mse: 0.0049 - r_square: 0.8998 - val_loss: 0.0013 - val_acc: 0.8372 - val_rmse: 0.0169 - val_mse: 0.0013 - val_r_square: 0.9932\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0048 - acc: 0.9633 - rmse: 0.0298 - mse: 0.0048 - r_square: 0.9017 - val_loss: 0.0014 - val_acc: 0.8369 - val_rmse: 0.0219 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0048 - acc: 0.9657 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9015 - val_loss: 0.0013 - val_acc: 0.8371 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9930\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0047 - acc: 0.9666 - rmse: 0.0286 - mse: 0.0047 - r_square: 0.9029 - val_loss: 0.0013 - val_acc: 0.8369 - val_rmse: 0.0169 - val_mse: 0.0013 - val_r_square: 0.9933\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0047 - acc: 0.9664 - rmse: 0.0298 - mse: 0.0047 - r_square: 0.9025 - val_loss: 0.0013 - val_acc: 0.8368 - val_rmse: 0.0193 - val_mse: 0.0013 - val_r_square: 0.9930\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0048 - acc: 0.9670 - rmse: 0.0303 - mse: 0.0048 - r_square: 0.9026 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0213 - val_mse: 0.0014 - val_r_square: 0.9924\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9655 - rmse: 0.0318 - mse: 0.0048 - r_square: 0.9031 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9912\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0049 - acc: 0.9661 - rmse: 0.0338 - mse: 0.0049 - r_square: 0.9016 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0288 - val_mse: 0.0018 - val_r_square: 0.9900\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0050 - acc: 0.9653 - rmse: 0.0355 - mse: 0.0050 - r_square: 0.8989 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0288 - val_mse: 0.0018 - val_r_square: 0.9900\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0052 - acc: 0.9642 - rmse: 0.0389 - mse: 0.0052 - r_square: 0.8916 - val_loss: 0.0018 - val_acc: 0.8366 - val_rmse: 0.0294 - val_mse: 0.0018 - val_r_square: 0.9899\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0054 - acc: 0.9641 - rmse: 0.0416 - mse: 0.0054 - r_square: 0.8804 - val_loss: 0.0016 - val_acc: 0.8369 - val_rmse: 0.0271 - val_mse: 0.0016 - val_r_square: 0.9908\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0058 - acc: 0.9622 - rmse: 0.0449 - mse: 0.0058 - r_square: 0.8827 - val_loss: 0.0026 - val_acc: 0.8794 - val_rmse: 0.0429 - val_mse: 0.0026 - val_r_square: 0.9837\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0054 - acc: 0.9620 - rmse: 0.0398 - mse: 0.0054 - r_square: 0.8911 - val_loss: 0.0015 - val_acc: 0.9547 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0057 - acc: 0.9576 - rmse: 0.0433 - mse: 0.0057 - r_square: 0.8948 - val_loss: 0.0015 - val_acc: 0.9171 - val_rmse: 0.0269 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0052 - acc: 0.9606 - rmse: 0.0374 - mse: 0.0052 - r_square: 0.8949 - val_loss: 0.0015 - val_acc: 0.9172 - val_rmse: 0.0262 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0051 - acc: 0.9576 - rmse: 0.0365 - mse: 0.0051 - r_square: 0.8910 - val_loss: 0.0015 - val_acc: 0.9560 - val_rmse: 0.0264 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0049 - acc: 0.9611 - rmse: 0.0326 - mse: 0.0049 - r_square: 0.9021 - val_loss: 0.0015 - val_acc: 0.9928 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9651 - rmse: 0.0317 - mse: 0.0048 - r_square: 0.9056 - val_loss: 0.0015 - val_acc: 0.9932 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0050 - acc: 0.9664 - rmse: 0.0339 - mse: 0.0050 - r_square: 0.9051 - val_loss: 0.0018 - val_acc: 0.9934 - val_rmse: 0.0307 - val_mse: 0.0018 - val_r_square: 0.9891\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0050 - acc: 0.9653 - rmse: 0.0342 - mse: 0.0050 - r_square: 0.9051 - val_loss: 0.0013 - val_acc: 0.9918 - val_rmse: 0.0214 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0050 - acc: 0.9347 - rmse: 0.0346 - mse: 0.0050 - r_square: 0.9022 - val_loss: 0.0011 - val_acc: 0.8634 - val_rmse: 0.0151 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0049 - acc: 0.9318 - rmse: 0.0337 - mse: 0.0049 - r_square: 0.9002 - val_loss: 0.0011 - val_acc: 0.8365 - val_rmse: 0.0164 - val_mse: 0.0011 - val_r_square: 0.9938\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0049 - acc: 0.9295 - rmse: 0.0336 - mse: 0.0049 - r_square: 0.9010 - val_loss: 0.0011 - val_acc: 0.8365 - val_rmse: 0.0152 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0047 - acc: 0.9374 - rmse: 0.0314 - mse: 0.0047 - r_square: 0.9046 - val_loss: 0.0011 - val_acc: 0.8365 - val_rmse: 0.0160 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0047 - acc: 0.9493 - rmse: 0.0303 - mse: 0.0047 - r_square: 0.9063 - val_loss: 0.0011 - val_acc: 0.8365 - val_rmse: 0.0155 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0046 - acc: 0.9608 - rmse: 0.0288 - mse: 0.0046 - r_square: 0.9085 - val_loss: 0.0011 - val_acc: 0.8368 - val_rmse: 0.0171 - val_mse: 0.0011 - val_r_square: 0.9937\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0046 - acc: 0.9676 - rmse: 0.0291 - mse: 0.0046 - r_square: 0.9087 - val_loss: 0.0012 - val_acc: 0.8368 - val_rmse: 0.0174 - val_mse: 0.0012 - val_r_square: 0.9936\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0046 - acc: 0.9686 - rmse: 0.0286 - mse: 0.0046 - r_square: 0.9092 - val_loss: 0.0012 - val_acc: 0.8507 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0047 - acc: 0.9681 - rmse: 0.0299 - mse: 0.0047 - r_square: 0.9074 - val_loss: 0.0012 - val_acc: 0.8372 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0047 - acc: 0.9688 - rmse: 0.0295 - mse: 0.0047 - r_square: 0.9083 - val_loss: 0.0012 - val_acc: 0.8641 - val_rmse: 0.0201 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0048 - acc: 0.9684 - rmse: 0.0311 - mse: 0.0048 - r_square: 0.9062 - val_loss: 0.0012 - val_acc: 0.8375 - val_rmse: 0.0193 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0047 - acc: 0.9674 - rmse: 0.0308 - mse: 0.0047 - r_square: 0.9078 - val_loss: 0.0013 - val_acc: 0.8377 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0048 - acc: 0.9688 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9059 - val_loss: 0.0013 - val_acc: 0.8372 - val_rmse: 0.0209 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0048 - acc: 0.9674 - rmse: 0.0325 - mse: 0.0048 - r_square: 0.9064 - val_loss: 0.0014 - val_acc: 0.8374 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9690 - rmse: 0.0342 - mse: 0.0049 - r_square: 0.9033 - val_loss: 0.0014 - val_acc: 0.8372 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9666 - rmse: 0.0348 - mse: 0.0050 - r_square: 0.9029 - val_loss: 0.0015 - val_acc: 0.8374 - val_rmse: 0.0258 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0052 - acc: 0.9625 - rmse: 0.0367 - mse: 0.0052 - r_square: 0.9000 - val_loss: 0.0016 - val_acc: 0.8372 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0052 - acc: 0.9645 - rmse: 0.0373 - mse: 0.0052 - r_square: 0.9002 - val_loss: 0.0016 - val_acc: 0.8371 - val_rmse: 0.0284 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0053 - acc: 0.9603 - rmse: 0.0383 - mse: 0.0053 - r_square: 0.8999 - val_loss: 0.0017 - val_acc: 0.8374 - val_rmse: 0.0301 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0053 - acc: 0.9663 - rmse: 0.0387 - mse: 0.0053 - r_square: 0.8987 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0276 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0051 - acc: 0.9633 - rmse: 0.0372 - mse: 0.0051 - r_square: 0.9010 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0278 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0051 - acc: 0.9654 - rmse: 0.0373 - mse: 0.0051 - r_square: 0.9001 - val_loss: 0.0015 - val_acc: 0.8374 - val_rmse: 0.0258 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0051 - acc: 0.9600 - rmse: 0.0368 - mse: 0.0051 - r_square: 0.9018 - val_loss: 0.0014 - val_acc: 0.8374 - val_rmse: 0.0238 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0049 - acc: 0.9567 - rmse: 0.0354 - mse: 0.0049 - r_square: 0.9008 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9602 - rmse: 0.0339 - mse: 0.0049 - r_square: 0.9046 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0214 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0047 - acc: 0.9566 - rmse: 0.0320 - mse: 0.0047 - r_square: 0.9049 - val_loss: 0.0012 - val_acc: 0.8378 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0047 - acc: 0.9573 - rmse: 0.0308 - mse: 0.0047 - r_square: 0.9069 - val_loss: 0.0012 - val_acc: 0.8384 - val_rmse: 0.0198 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0047 - acc: 0.9562 - rmse: 0.0297 - mse: 0.0047 - r_square: 0.9053 - val_loss: 0.0012 - val_acc: 0.8654 - val_rmse: 0.0187 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9594 - rmse: 0.0283 - mse: 0.0046 - r_square: 0.9085 - val_loss: 0.0013 - val_acc: 0.8790 - val_rmse: 0.0208 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9589 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9088 - val_loss: 0.0012 - val_acc: 0.9165 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9652 - rmse: 0.0269 - mse: 0.0045 - r_square: 0.9111 - val_loss: 0.0013 - val_acc: 0.9180 - val_rmse: 0.0213 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9620 - rmse: 0.0274 - mse: 0.0045 - r_square: 0.9091 - val_loss: 0.0013 - val_acc: 0.9184 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9676 - rmse: 0.0265 - mse: 0.0046 - r_square: 0.9095 - val_loss: 0.0013 - val_acc: 0.9185 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0045 - acc: 0.9638 - rmse: 0.0265 - mse: 0.0045 - r_square: 0.9107 - val_loss: 0.0012 - val_acc: 0.9175 - val_rmse: 0.0205 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0045 - acc: 0.9666 - rmse: 0.0260 - mse: 0.0045 - r_square: 0.9120 - val_loss: 0.0012 - val_acc: 0.9167 - val_rmse: 0.0204 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9656 - rmse: 0.0261 - mse: 0.0044 - r_square: 0.9124 - val_loss: 0.0012 - val_acc: 0.9161 - val_rmse: 0.0199 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9679 - rmse: 0.0257 - mse: 0.0045 - r_square: 0.9120 - val_loss: 0.0012 - val_acc: 0.9037 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9668 - rmse: 0.0256 - mse: 0.0045 - r_square: 0.9104 - val_loss: 0.0012 - val_acc: 0.9157 - val_rmse: 0.0193 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0045 - acc: 0.9639 - rmse: 0.0254 - mse: 0.0045 - r_square: 0.9108 - val_loss: 0.0012 - val_acc: 0.9033 - val_rmse: 0.0190 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0044 - acc: 0.9669 - rmse: 0.0249 - mse: 0.0044 - r_square: 0.9129 - val_loss: 0.0012 - val_acc: 0.9158 - val_rmse: 0.0188 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0044 - acc: 0.9686 - rmse: 0.0243 - mse: 0.0044 - r_square: 0.9131 - val_loss: 0.0012 - val_acc: 0.9161 - val_rmse: 0.0187 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0044 - acc: 0.9666 - rmse: 0.0241 - mse: 0.0044 - r_square: 0.9126 - val_loss: 0.0012 - val_acc: 0.9168 - val_rmse: 0.0186 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9665 - rmse: 0.0242 - mse: 0.0045 - r_square: 0.9104 - val_loss: 0.0012 - val_acc: 0.9171 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0045 - acc: 0.9671 - rmse: 0.0237 - mse: 0.0045 - r_square: 0.9108 - val_loss: 0.0012 - val_acc: 0.9180 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0044 - acc: 0.9649 - rmse: 0.0238 - mse: 0.0044 - r_square: 0.9115 - val_loss: 0.0012 - val_acc: 0.9172 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0044 - acc: 0.9672 - rmse: 0.0233 - mse: 0.0044 - r_square: 0.9127 - val_loss: 0.0012 - val_acc: 0.9236 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9662 - rmse: 0.0231 - mse: 0.0044 - r_square: 0.9131 - val_loss: 0.0012 - val_acc: 0.9203 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0044 - acc: 0.9669 - rmse: 0.0230 - mse: 0.0044 - r_square: 0.9133 - val_loss: 0.0012 - val_acc: 0.9311 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0043 - acc: 0.9663 - rmse: 0.0228 - mse: 0.0043 - r_square: 0.9136 - val_loss: 0.0012 - val_acc: 0.9311 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0043 - acc: 0.9671 - rmse: 0.0229 - mse: 0.0043 - r_square: 0.9134 - val_loss: 0.0012 - val_acc: 0.9431 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9932\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_7 (RepeatVecto (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 5s 717us/step - loss: 0.0137 - acc: 0.8818 - mse: 0.0137 - rmse: 0.0902 - r_square: 0.6572 - val_loss: 0.0088 - val_acc: 0.9934 - val_mse: 0.0088 - val_rmse: 0.0899 - val_r_square: 0.9401\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0111 - acc: 0.8978 - mse: 0.0111 - rmse: 0.0834 - r_square: 0.6434 - val_loss: 0.0049 - val_acc: 0.9942 - val_mse: 0.0049 - val_rmse: 0.0641 - val_r_square: 0.9685\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0099 - acc: 0.8996 - mse: 0.0099 - rmse: 0.0746 - r_square: 0.7015 - val_loss: 0.0030 - val_acc: 0.8496 - val_mse: 0.0030 - val_rmse: 0.0475 - val_r_square: 0.9810\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0091 - acc: 0.9390 - mse: 0.0091 - rmse: 0.0715 - r_square: 0.6924 - val_loss: 0.0034 - val_acc: 0.8365 - val_mse: 0.0034 - val_rmse: 0.0506 - val_r_square: 0.9776\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0087 - acc: 0.9539 - mse: 0.0087 - rmse: 0.0624 - r_square: 0.7859 - val_loss: 0.0047 - val_acc: 0.9937 - val_mse: 0.0047 - val_rmse: 0.0625 - val_r_square: 0.9688\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0095 - acc: 0.9557 - mse: 0.0095 - rmse: 0.0685 - r_square: 0.7506 - val_loss: 0.0052 - val_acc: 0.9793 - val_mse: 0.0052 - val_rmse: 0.0579 - val_r_square: 0.9695\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0093 - acc: 0.9570 - mse: 0.0093 - rmse: 0.0652 - r_square: 0.7143 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0368 - val_r_square: 0.9862\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0079 - acc: 0.9008 - mse: 0.0079 - rmse: 0.0585 - r_square: 0.7637 - val_loss: 0.0019 - val_acc: 0.9161 - val_mse: 0.0019 - val_rmse: 0.0313 - val_r_square: 0.9887\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0086 - acc: 0.9051 - mse: 0.0086 - rmse: 0.0557 - r_square: 0.8166 - val_loss: 0.0014 - val_acc: 0.8371 - val_mse: 0.0014 - val_rmse: 0.0223 - val_r_square: 0.9920\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0234 - acc: 0.9183 - mse: 0.0234 - rmse: 0.0945 - r_square: -2.3727 - val_loss: 0.0022 - val_acc: 0.9928 - val_mse: 0.0022 - val_rmse: 0.0344 - val_r_square: 0.9872\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0083 - acc: 0.8767 - mse: 0.0083 - rmse: 0.0668 - r_square: 0.7161 - val_loss: 0.0016 - val_acc: 0.9937 - val_mse: 0.0016 - val_rmse: 0.0261 - val_r_square: 0.9909\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0090 - acc: 0.9241 - mse: 0.0090 - rmse: 0.0666 - r_square: 0.8258 - val_loss: 0.0051 - val_acc: 0.8365 - val_mse: 0.0051 - val_rmse: 0.0656 - val_r_square: 0.9670\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0109 - acc: 0.8301 - mse: 0.0109 - rmse: 0.0710 - r_square: 0.7102 - val_loss: 0.0071 - val_acc: 0.8365 - val_mse: 0.0071 - val_rmse: 0.0804 - val_r_square: 0.9497\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0070 - acc: 0.9184 - mse: 0.0070 - rmse: 0.0538 - r_square: 0.8486 - val_loss: 0.0031 - val_acc: 0.9938 - val_mse: 0.0031 - val_rmse: 0.0489 - val_r_square: 0.9794\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0069 - acc: 0.9631 - mse: 0.0069 - rmse: 0.0497 - r_square: 0.8210 - val_loss: 0.0024 - val_acc: 0.9154 - val_mse: 0.0024 - val_rmse: 0.0391 - val_r_square: 0.9845\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0062 - acc: 0.9517 - mse: 0.0062 - rmse: 0.0430 - r_square: 0.8530 - val_loss: 0.0011 - val_acc: 0.9427 - val_mse: 0.0011 - val_rmse: 0.0133 - val_r_square: 0.9942\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0054 - acc: 0.9502 - mse: 0.0054 - rmse: 0.0387 - r_square: 0.8856 - val_loss: 0.0013 - val_acc: 0.9429 - val_mse: 0.0013 - val_rmse: 0.0196 - val_r_square: 0.9930\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0056 - acc: 0.9624 - mse: 0.0056 - rmse: 0.0417 - r_square: 0.8813 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0250 - val_r_square: 0.9919\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0057 - acc: 0.9438 - mse: 0.0057 - rmse: 0.0421 - r_square: 0.8675 - val_loss: 0.0021 - val_acc: 0.9942 - val_mse: 0.0021 - val_rmse: 0.0359 - val_r_square: 0.9864\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0057 - acc: 0.9619 - mse: 0.0057 - rmse: 0.0419 - r_square: 0.8698 - val_loss: 0.0011 - val_acc: 0.8509 - val_mse: 0.0011 - val_rmse: 0.0132 - val_r_square: 0.9943\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0055 - acc: 0.9646 - mse: 0.0055 - rmse: 0.0387 - r_square: 0.8678 - val_loss: 0.0012 - val_acc: 0.8371 - val_mse: 0.0012 - val_rmse: 0.0199 - val_r_square: 0.9931\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0056 - acc: 0.9575 - mse: 0.0056 - rmse: 0.0408 - r_square: 0.8867 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0400 - val_r_square: 0.9847\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0050 - acc: 0.9494 - mse: 0.0050 - rmse: 0.0349 - r_square: 0.8847 - val_loss: 0.0013 - val_acc: 0.9561 - val_mse: 0.0013 - val_rmse: 0.0222 - val_r_square: 0.9921\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0050 - acc: 0.9590 - mse: 0.0050 - rmse: 0.0354 - r_square: 0.8903 - val_loss: 0.0011 - val_acc: 0.8777 - val_mse: 0.0011 - val_rmse: 0.0159 - val_r_square: 0.9939\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0055 - acc: 0.9149 - mse: 0.0055 - rmse: 0.0405 - r_square: 0.8728 - val_loss: 0.0013 - val_acc: 0.9942 - val_mse: 0.0013 - val_rmse: 0.0211 - val_r_square: 0.9926\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0048 - acc: 0.9594 - mse: 0.0048 - rmse: 0.0331 - r_square: 0.8962 - val_loss: 0.0020 - val_acc: 0.9689 - val_mse: 0.0020 - val_rmse: 0.0333 - val_r_square: 0.9875\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0054 - acc: 0.9401 - mse: 0.0054 - rmse: 0.0422 - r_square: 0.8785 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0266 - val_r_square: 0.9911\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0052 - acc: 0.9117 - mse: 0.0052 - rmse: 0.0386 - r_square: 0.8583 - val_loss: 0.0012 - val_acc: 0.9695 - val_mse: 0.0012 - val_rmse: 0.0175 - val_r_square: 0.9936\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0050 - acc: 0.9601 - mse: 0.0050 - rmse: 0.0333 - r_square: 0.9009 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0342 - val_r_square: 0.9876\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0050 - acc: 0.9617 - mse: 0.0050 - rmse: 0.0340 - r_square: 0.8914 - val_loss: 0.0014 - val_acc: 0.8366 - val_mse: 0.0014 - val_rmse: 0.0236 - val_r_square: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0051 - acc: 0.9277 - mse: 0.0051 - rmse: 0.0363 - r_square: 0.8820 - val_loss: 0.0012 - val_acc: 0.8507 - val_mse: 0.0012 - val_rmse: 0.0185 - val_r_square: 0.9933\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0054 - acc: 0.9250 - mse: 0.0054 - rmse: 0.0390 - r_square: 0.8835 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0225 - val_r_square: 0.9922\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0050 - acc: 0.9649 - mse: 0.0050 - rmse: 0.0352 - r_square: 0.8922 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0393 - val_r_square: 0.9851\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0059 - acc: 0.9141 - mse: 0.0059 - rmse: 0.0448 - r_square: 0.8645 - val_loss: 0.0012 - val_acc: 0.8368 - val_mse: 0.0012 - val_rmse: 0.0185 - val_r_square: 0.9932\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0051 - acc: 0.9080 - mse: 0.0051 - rmse: 0.0384 - r_square: 0.8680 - val_loss: 0.0012 - val_acc: 0.9941 - val_mse: 0.0012 - val_rmse: 0.0159 - val_r_square: 0.9937\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0067 - acc: 0.9602 - mse: 0.0067 - rmse: 0.0484 - r_square: 0.8776 - val_loss: 0.0015 - val_acc: 0.9932 - val_mse: 0.0015 - val_rmse: 0.0255 - val_r_square: 0.9915\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0061 - acc: 0.9593 - mse: 0.0061 - rmse: 0.0486 - r_square: 0.8525 - val_loss: 0.0029 - val_acc: 0.8365 - val_mse: 0.0029 - val_rmse: 0.0467 - val_r_square: 0.9805\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0078 - acc: 0.8810 - mse: 0.0078 - rmse: 0.0586 - r_square: 0.8051 - val_loss: 0.0014 - val_acc: 0.8371 - val_mse: 0.0014 - val_rmse: 0.0237 - val_r_square: 0.9918\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0055 - acc: 0.9132 - mse: 0.0055 - rmse: 0.0417 - r_square: 0.8501 - val_loss: 0.0013 - val_acc: 0.9898 - val_mse: 0.0013 - val_rmse: 0.0196 - val_r_square: 0.9929\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0068 - acc: 0.9120 - mse: 0.0068 - rmse: 0.0530 - r_square: 0.8667 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0233 - val_r_square: 0.9919\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0054 - acc: 0.9658 - mse: 0.0054 - rmse: 0.0404 - r_square: 0.8728 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0385 - val_r_square: 0.9852\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0068 - acc: 0.9288 - mse: 0.0068 - rmse: 0.0530 - r_square: 0.8409 - val_loss: 0.0028 - val_acc: 0.8365 - val_mse: 0.0028 - val_rmse: 0.0452 - val_r_square: 0.9821\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0054 - acc: 0.9117 - mse: 0.0054 - rmse: 0.0400 - r_square: 0.8790 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0269 - val_r_square: 0.9906\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0070 - acc: 0.8669 - mse: 0.0070 - rmse: 0.0526 - r_square: 0.8673 - val_loss: 0.0036 - val_acc: 0.9942 - val_mse: 0.0036 - val_rmse: 0.0530 - val_r_square: 0.9755\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0055 - acc: 0.9676 - mse: 0.0055 - rmse: 0.0425 - r_square: 0.8657 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0300 - val_r_square: 0.9893\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0066 - acc: 0.9557 - mse: 0.0066 - rmse: 0.0547 - r_square: 0.8327 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0302 - val_r_square: 0.9897\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0062 - acc: 0.9674 - mse: 0.0062 - rmse: 0.0492 - r_square: 0.8476 - val_loss: 0.0033 - val_acc: 0.8365 - val_mse: 0.0033 - val_rmse: 0.0511 - val_r_square: 0.9779\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0072 - acc: 0.9663 - mse: 0.0072 - rmse: 0.0565 - r_square: 0.8507 - val_loss: 0.0020 - val_acc: 0.8893 - val_mse: 0.0020 - val_rmse: 0.0343 - val_r_square: 0.9876\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0061 - acc: 0.9590 - mse: 0.0061 - rmse: 0.0473 - r_square: 0.8502 - val_loss: 0.0024 - val_acc: 0.9419 - val_mse: 0.0024 - val_rmse: 0.0392 - val_r_square: 0.9839\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0054 - acc: 0.9681 - mse: 0.0054 - rmse: 0.0441 - r_square: 0.8496 - val_loss: 0.0016 - val_acc: 0.9557 - val_mse: 0.0016 - val_rmse: 0.0260 - val_r_square: 0.9907\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0059 - acc: 0.9676 - mse: 0.0059 - rmse: 0.0485 - r_square: 0.8735 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0286 - val_r_square: 0.9897\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0055 - acc: 0.9681 - mse: 0.0055 - rmse: 0.0417 - r_square: 0.8893 - val_loss: 0.0019 - val_acc: 0.9659 - val_mse: 0.0019 - val_rmse: 0.0325 - val_r_square: 0.9880\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0056 - acc: 0.9636 - mse: 0.0056 - rmse: 0.0471 - r_square: 0.8509 - val_loss: 0.0013 - val_acc: 0.9429 - val_mse: 0.0013 - val_rmse: 0.0203 - val_r_square: 0.9925\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0060 - acc: 0.9683 - mse: 0.0060 - rmse: 0.0450 - r_square: 0.8724 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0333 - val_r_square: 0.9879\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0061 - acc: 0.9625 - mse: 0.0061 - rmse: 0.0443 - r_square: 0.8671 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0338 - val_r_square: 0.9874\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0053 - acc: 0.9390 - mse: 0.0053 - rmse: 0.0432 - r_square: 0.8635 - val_loss: 0.0012 - val_acc: 0.9921 - val_mse: 0.0012 - val_rmse: 0.0169 - val_r_square: 0.9934\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0054 - acc: 0.9684 - mse: 0.0054 - rmse: 0.0401 - r_square: 0.8800 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0297 - val_r_square: 0.9894\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0050 - acc: 0.9649 - mse: 0.0050 - rmse: 0.0374 - r_square: 0.8905 - val_loss: 0.0013 - val_acc: 0.9942 - val_mse: 0.0013 - val_rmse: 0.0206 - val_r_square: 0.9923\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0049 - acc: 0.9630 - mse: 0.0049 - rmse: 0.0357 - r_square: 0.8858 - val_loss: 0.0011 - val_acc: 0.9940 - val_mse: 0.0011 - val_rmse: 0.0143 - val_r_square: 0.9941\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0051 - acc: 0.9650 - mse: 0.0051 - rmse: 0.0379 - r_square: 0.8710 - val_loss: 0.0013 - val_acc: 0.9675 - val_mse: 0.0013 - val_rmse: 0.0212 - val_r_square: 0.9925\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0049 - acc: 0.9681 - mse: 0.0049 - rmse: 0.0333 - r_square: 0.8925 - val_loss: 0.0012 - val_acc: 0.9429 - val_mse: 0.0012 - val_rmse: 0.0189 - val_r_square: 0.9932\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0049 - acc: 0.9693 - mse: 0.0049 - rmse: 0.0338 - r_square: 0.8881 - val_loss: 0.0012 - val_acc: 0.9008 - val_mse: 0.0012 - val_rmse: 0.0201 - val_r_square: 0.9930\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0049 - acc: 0.9676 - mse: 0.0049 - rmse: 0.0304 - r_square: 0.8930 - val_loss: 0.0011 - val_acc: 0.9017 - val_mse: 0.0011 - val_rmse: 0.0161 - val_r_square: 0.9939\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0049 - acc: 0.9575 - mse: 0.0049 - rmse: 0.0343 - r_square: 0.8789 - val_loss: 0.0012 - val_acc: 0.9542 - val_mse: 0.0012 - val_rmse: 0.0176 - val_r_square: 0.9937\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0049 - acc: 0.9654 - mse: 0.0049 - rmse: 0.0330 - r_square: 0.8847 - val_loss: 0.0013 - val_acc: 0.9157 - val_mse: 0.0013 - val_rmse: 0.0219 - val_r_square: 0.9924\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0050 - acc: 0.9633 - mse: 0.0050 - rmse: 0.0357 - r_square: 0.8926 - val_loss: 0.0013 - val_acc: 0.8762 - val_mse: 0.0013 - val_rmse: 0.0222 - val_r_square: 0.9922\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0053 - acc: 0.9677 - mse: 0.0053 - rmse: 0.0401 - r_square: 0.8732 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0204 - val_r_square: 0.9924\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0055 - acc: 0.9666 - mse: 0.0055 - rmse: 0.0422 - r_square: 0.8819 - val_loss: 0.0019 - val_acc: 0.8384 - val_mse: 0.0019 - val_rmse: 0.0336 - val_r_square: 0.9877\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0057 - acc: 0.9459 - mse: 0.0057 - rmse: 0.0411 - r_square: 0.8851 - val_loss: 0.0037 - val_acc: 0.9942 - val_mse: 0.0037 - val_rmse: 0.0547 - val_r_square: 0.9754\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0052 - acc: 0.9636 - mse: 0.0052 - rmse: 0.0395 - r_square: 0.8718 - val_loss: 0.0016 - val_acc: 0.9652 - val_mse: 0.0016 - val_rmse: 0.0272 - val_r_square: 0.9902\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 205us/step - loss: 0.0053 - acc: 0.9638 - mse: 0.0053 - rmse: 0.0400 - r_square: 0.8792 - val_loss: 0.0012 - val_acc: 0.9309 - val_mse: 0.0012 - val_rmse: 0.0180 - val_r_square: 0.9935\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0051 - acc: 0.9697 - mse: 0.0051 - rmse: 0.0368 - r_square: 0.8893 - val_loss: 0.0017 - val_acc: 0.8608 - val_mse: 0.0017 - val_rmse: 0.0298 - val_r_square: 0.9894\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0053 - acc: 0.9523 - mse: 0.0053 - rmse: 0.0378 - r_square: 0.8980 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0334 - val_r_square: 0.9882\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0054 - acc: 0.9610 - mse: 0.0054 - rmse: 0.0429 - r_square: 0.8698 - val_loss: 0.0013 - val_acc: 0.9135 - val_mse: 0.0013 - val_rmse: 0.0205 - val_r_square: 0.9928\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0063 - acc: 0.9593 - mse: 0.0063 - rmse: 0.0520 - r_square: 0.8272 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0302 - val_r_square: 0.9895\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0059 - acc: 0.9664 - mse: 0.0059 - rmse: 0.0450 - r_square: 0.8694 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0303 - val_r_square: 0.9898\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.9448 - mse: 0.0057 - rmse: 0.0408 - r_square: 0.8825 - val_loss: 0.0030 - val_acc: 0.9942 - val_mse: 0.0030 - val_rmse: 0.0468 - val_r_square: 0.9797\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0053 - acc: 0.9685 - mse: 0.0053 - rmse: 0.0394 - r_square: 0.8852 - val_loss: 0.0012 - val_acc: 0.9896 - val_mse: 0.0012 - val_rmse: 0.0178 - val_r_square: 0.9931\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0052 - acc: 0.9642 - mse: 0.0052 - rmse: 0.0378 - r_square: 0.8863 - val_loss: 0.0013 - val_acc: 0.9935 - val_mse: 0.0013 - val_rmse: 0.0205 - val_r_square: 0.9928\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0057 - acc: 0.9174 - mse: 0.0057 - rmse: 0.0456 - r_square: 0.8640 - val_loss: 0.0015 - val_acc: 0.9876 - val_mse: 0.0015 - val_rmse: 0.0242 - val_r_square: 0.9915\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0058 - acc: 0.9660 - mse: 0.0058 - rmse: 0.0468 - r_square: 0.8549 - val_loss: 0.0013 - val_acc: 0.9898 - val_mse: 0.0013 - val_rmse: 0.0207 - val_r_square: 0.9924\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0056 - acc: 0.9481 - mse: 0.0056 - rmse: 0.0433 - r_square: 0.8710 - val_loss: 0.0015 - val_acc: 0.9665 - val_mse: 0.0015 - val_rmse: 0.0260 - val_r_square: 0.9907\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0062 - acc: 0.9565 - mse: 0.0062 - rmse: 0.0482 - r_square: 0.8281 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0253 - val_r_square: 0.9910\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0069 - acc: 0.9614 - mse: 0.0069 - rmse: 0.0414 - r_square: 0.8552 - val_loss: 0.0012 - val_acc: 0.9430 - val_mse: 0.0012 - val_rmse: 0.0196 - val_r_square: 0.9929\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0063 - acc: 0.9667 - mse: 0.0063 - rmse: 0.0470 - r_square: 0.8601 - val_loss: 0.0022 - val_acc: 0.8371 - val_mse: 0.0022 - val_rmse: 0.0379 - val_r_square: 0.9865\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0060 - acc: 0.9445 - mse: 0.0060 - rmse: 0.0425 - r_square: 0.8657 - val_loss: 0.0014 - val_acc: 0.9662 - val_mse: 0.0014 - val_rmse: 0.0228 - val_r_square: 0.9919\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0062 - acc: 0.9358 - mse: 0.0062 - rmse: 0.0415 - r_square: 0.8563 - val_loss: 0.0014 - val_acc: 0.9434 - val_mse: 0.0014 - val_rmse: 0.0224 - val_r_square: 0.9918\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0056 - acc: 0.9624 - mse: 0.0056 - rmse: 0.0446 - r_square: 0.8706 - val_loss: 0.0015 - val_acc: 0.9921 - val_mse: 0.0015 - val_rmse: 0.0238 - val_r_square: 0.9916\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0057 - acc: 0.9678 - mse: 0.0057 - rmse: 0.0423 - r_square: 0.8659 - val_loss: 0.0017 - val_acc: 0.9937 - val_mse: 0.0017 - val_rmse: 0.0285 - val_r_square: 0.9896\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0057 - acc: 0.9620 - mse: 0.0057 - rmse: 0.0423 - r_square: 0.8825 - val_loss: 0.0017 - val_acc: 0.8637 - val_mse: 0.0017 - val_rmse: 0.0304 - val_r_square: 0.9894\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0051 - acc: 0.9558 - mse: 0.0051 - rmse: 0.0376 - r_square: 0.8904 - val_loss: 0.0013 - val_acc: 0.8382 - val_mse: 0.0013 - val_rmse: 0.0199 - val_r_square: 0.9929\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0059 - acc: 0.9527 - mse: 0.0059 - rmse: 0.0453 - r_square: 0.8602 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0389 - val_r_square: 0.9857\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0054 - acc: 0.9680 - mse: 0.0054 - rmse: 0.0427 - r_square: 0.8656 - val_loss: 0.0019 - val_acc: 0.9912 - val_mse: 0.0019 - val_rmse: 0.0323 - val_r_square: 0.9877\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0053 - acc: 0.9632 - mse: 0.0053 - rmse: 0.0409 - r_square: 0.8680 - val_loss: 0.0012 - val_acc: 0.9675 - val_mse: 0.0012 - val_rmse: 0.0192 - val_r_square: 0.9930\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0050 - acc: 0.9669 - mse: 0.0050 - rmse: 0.0356 - r_square: 0.8939 - val_loss: 0.0012 - val_acc: 0.9430 - val_mse: 0.0012 - val_rmse: 0.0178 - val_r_square: 0.9933\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0051 - acc: 0.9462 - mse: 0.0051 - rmse: 0.0395 - r_square: 0.8765 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0243 - val_r_square: 0.9917\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0054 - acc: 0.9674 - mse: 0.0054 - rmse: 0.0433 - r_square: 0.8563 - val_loss: 0.0015 - val_acc: 0.8749 - val_mse: 0.0015 - val_rmse: 0.0264 - val_r_square: 0.9908\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0058 - acc: 0.9679 - mse: 0.0058 - rmse: 0.0457 - r_square: 0.8464 - val_loss: 0.0013 - val_acc: 0.9162 - val_mse: 0.0013 - val_rmse: 0.0207 - val_r_square: 0.9928\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0051 - acc: 0.9681 - mse: 0.0051 - rmse: 0.0373 - r_square: 0.8890 - val_loss: 0.0015 - val_acc: 0.8664 - val_mse: 0.0015 - val_rmse: 0.0261 - val_r_square: 0.9911\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 204us/step - loss: 0.0054 - acc: 0.9190 - mse: 0.0054 - rmse: 0.0421 - r_square: 0.8653 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0299 - val_r_square: 0.9896\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Net migration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Net migration','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 6s 867us/step - loss: 0.0461 - acc: 0.6296 - rmse: 0.1849 - mse: 0.0461 - r_square: 0.2817 - val_loss: 0.0247 - val_acc: 0.9308 - val_rmse: 0.1405 - val_mse: 0.0247 - val_r_square: 0.8267\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0296 - acc: 0.5149 - rmse: 0.1432 - mse: 0.0296 - r_square: 0.5490 - val_loss: 0.0207 - val_acc: 0.8365 - val_rmse: 0.1332 - val_mse: 0.0207 - val_r_square: 0.8564\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0202 - acc: 0.5414 - rmse: 0.1142 - mse: 0.0202 - r_square: 0.6968 - val_loss: 0.0160 - val_acc: 0.8365 - val_rmse: 0.1186 - val_mse: 0.0160 - val_r_square: 0.8872\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 297us/step - loss: 0.0146 - acc: 0.9005 - rmse: 0.0902 - mse: 0.0146 - r_square: 0.7971 - val_loss: 0.0112 - val_acc: 0.8365 - val_rmse: 0.0993 - val_mse: 0.0112 - val_r_square: 0.9208\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0117 - acc: 0.8952 - rmse: 0.0769 - mse: 0.0117 - r_square: 0.8309 - val_loss: 0.0066 - val_acc: 0.8365 - val_rmse: 0.0733 - val_mse: 0.0066 - val_r_square: 0.9556\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0095 - acc: 0.9052 - rmse: 0.0667 - mse: 0.0095 - r_square: 0.8609 - val_loss: 0.0044 - val_acc: 0.8365 - val_rmse: 0.0556 - val_mse: 0.0044 - val_r_square: 0.9717\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 354us/step - loss: 0.0088 - acc: 0.9116 - rmse: 0.0626 - mse: 0.0088 - r_square: 0.8702 - val_loss: 0.0036 - val_acc: 0.8365 - val_rmse: 0.0441 - val_mse: 0.0036 - val_r_square: 0.9786\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0089 - acc: 0.8827 - rmse: 0.0646 - mse: 0.0089 - r_square: 0.8634 - val_loss: 0.0038 - val_acc: 0.9193 - val_rmse: 0.0544 - val_mse: 0.0038 - val_r_square: 0.9741\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0075 - acc: 0.8975 - rmse: 0.0532 - mse: 0.0075 - r_square: 0.8914 - val_loss: 0.0025 - val_acc: 0.9560 - val_rmse: 0.0391 - val_mse: 0.0025 - val_r_square: 0.9838\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0072 - acc: 0.9284 - rmse: 0.0519 - mse: 0.0072 - r_square: 0.8976 - val_loss: 0.0020 - val_acc: 0.8397 - val_rmse: 0.0277 - val_mse: 0.0020 - val_r_square: 0.9882\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0072 - acc: 0.9274 - rmse: 0.0520 - mse: 0.0072 - r_square: 0.8917 - val_loss: 0.0023 - val_acc: 0.8424 - val_rmse: 0.0382 - val_mse: 0.0023 - val_r_square: 0.9849\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0065 - acc: 0.9314 - rmse: 0.0467 - mse: 0.0065 - r_square: 0.9068 - val_loss: 0.0020 - val_acc: 0.8411 - val_rmse: 0.0329 - val_mse: 0.0020 - val_r_square: 0.9876\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0064 - acc: 0.9320 - rmse: 0.0459 - mse: 0.0064 - r_square: 0.9093 - val_loss: 0.0020 - val_acc: 0.8394 - val_rmse: 0.0318 - val_mse: 0.0020 - val_r_square: 0.9878\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0063 - acc: 0.9299 - rmse: 0.0459 - mse: 0.0063 - r_square: 0.9105 - val_loss: 0.0017 - val_acc: 0.8402 - val_rmse: 0.0284 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 3s 406us/step - loss: 0.0062 - acc: 0.9337 - rmse: 0.0438 - mse: 0.0062 - r_square: 0.9146 - val_loss: 0.0022 - val_acc: 0.8368 - val_rmse: 0.0366 - val_mse: 0.0022 - val_r_square: 0.9860\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0062 - acc: 0.9334 - rmse: 0.0449 - mse: 0.0062 - r_square: 0.9150 - val_loss: 0.0023 - val_acc: 0.8374 - val_rmse: 0.0369 - val_mse: 0.0023 - val_r_square: 0.9859\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 358us/step - loss: 0.0065 - acc: 0.9332 - rmse: 0.0481 - mse: 0.0065 - r_square: 0.9128 - val_loss: 0.0029 - val_acc: 0.8384 - val_rmse: 0.0454 - val_mse: 0.0029 - val_r_square: 0.9815\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0064 - acc: 0.9345 - rmse: 0.0479 - mse: 0.0064 - r_square: 0.9141 - val_loss: 0.0031 - val_acc: 0.8385 - val_rmse: 0.0478 - val_mse: 0.0031 - val_r_square: 0.9798\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0070 - acc: 0.9266 - rmse: 0.0534 - mse: 0.0070 - r_square: 0.9068 - val_loss: 0.0032 - val_acc: 0.8528 - val_rmse: 0.0485 - val_mse: 0.0032 - val_r_square: 0.9788\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0071 - acc: 0.9203 - rmse: 0.0539 - mse: 0.0071 - r_square: 0.9053 - val_loss: 0.0035 - val_acc: 0.9561 - val_rmse: 0.0511 - val_mse: 0.0035 - val_r_square: 0.9758\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0071 - acc: 0.9349 - rmse: 0.0550 - mse: 0.0071 - r_square: 0.8986 - val_loss: 0.0045 - val_acc: 0.9496 - val_rmse: 0.0597 - val_mse: 0.0045 - val_r_square: 0.9679\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0070 - acc: 0.9154 - rmse: 0.0547 - mse: 0.0070 - r_square: 0.9037 - val_loss: 0.0046 - val_acc: 0.9547 - val_rmse: 0.0603 - val_mse: 0.0046 - val_r_square: 0.9672\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 296us/step - loss: 0.0066 - acc: 0.9126 - rmse: 0.0516 - mse: 0.0066 - r_square: 0.9105 - val_loss: 0.0035 - val_acc: 0.9925 - val_rmse: 0.0509 - val_mse: 0.0035 - val_r_square: 0.9760\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 294us/step - loss: 0.0063 - acc: 0.9059 - rmse: 0.0486 - mse: 0.0063 - r_square: 0.9127 - val_loss: 0.0017 - val_acc: 0.9901 - val_rmse: 0.0283 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0060 - acc: 0.9157 - rmse: 0.0450 - mse: 0.0060 - r_square: 0.9154 - val_loss: 0.0015 - val_acc: 0.8752 - val_rmse: 0.0264 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0058 - acc: 0.9363 - rmse: 0.0434 - mse: 0.0058 - r_square: 0.9169 - val_loss: 0.0013 - val_acc: 0.8765 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0053 - acc: 0.9406 - rmse: 0.0391 - mse: 0.0053 - r_square: 0.9265 - val_loss: 0.0013 - val_acc: 0.8649 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0053 - acc: 0.9410 - rmse: 0.0368 - mse: 0.0053 - r_square: 0.9260 - val_loss: 0.0012 - val_acc: 0.9037 - val_rmse: 0.0193 - val_mse: 0.0012 - val_r_square: 0.9926\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0054 - acc: 0.9416 - rmse: 0.0351 - mse: 0.0054 - r_square: 0.9237 - val_loss: 0.0013 - val_acc: 0.9028 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 283us/step - loss: 0.0055 - acc: 0.9389 - rmse: 0.0351 - mse: 0.0055 - r_square: 0.9202 - val_loss: 0.0014 - val_acc: 0.9669 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0052 - acc: 0.9421 - rmse: 0.0343 - mse: 0.0052 - r_square: 0.9279 - val_loss: 0.0014 - val_acc: 0.9646 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0050 - acc: 0.9430 - rmse: 0.0329 - mse: 0.0050 - r_square: 0.9317 - val_loss: 0.0014 - val_acc: 0.9413 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0049 - acc: 0.9430 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9335 - val_loss: 0.0014 - val_acc: 0.9414 - val_rmse: 0.0228 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9436 - rmse: 0.0326 - mse: 0.0049 - r_square: 0.9335 - val_loss: 0.0014 - val_acc: 0.9535 - val_rmse: 0.0237 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9439 - rmse: 0.0323 - mse: 0.0048 - r_square: 0.9346 - val_loss: 0.0014 - val_acc: 0.9401 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9439 - rmse: 0.0316 - mse: 0.0048 - r_square: 0.9354 - val_loss: 0.0014 - val_acc: 0.9408 - val_rmse: 0.0240 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9441 - rmse: 0.0318 - mse: 0.0048 - r_square: 0.9358 - val_loss: 0.0014 - val_acc: 0.9419 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9451 - rmse: 0.0317 - mse: 0.0048 - r_square: 0.9361 - val_loss: 0.0014 - val_acc: 0.9410 - val_rmse: 0.0246 - val_mse: 0.0014 - val_r_square: 0.9911\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9453 - rmse: 0.0314 - mse: 0.0047 - r_square: 0.9368 - val_loss: 0.0014 - val_acc: 0.9401 - val_rmse: 0.0250 - val_mse: 0.0014 - val_r_square: 0.9910\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0047 - acc: 0.9457 - rmse: 0.0315 - mse: 0.0047 - r_square: 0.9370 - val_loss: 0.0015 - val_acc: 0.9413 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9458 - rmse: 0.0317 - mse: 0.0047 - r_square: 0.9371 - val_loss: 0.0014 - val_acc: 0.9423 - val_rmse: 0.0244 - val_mse: 0.0014 - val_r_square: 0.9910\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9451 - rmse: 0.0319 - mse: 0.0048 - r_square: 0.9361 - val_loss: 0.0015 - val_acc: 0.9417 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9460 - rmse: 0.0329 - mse: 0.0050 - r_square: 0.9315 - val_loss: 0.0015 - val_acc: 0.9390 - val_rmse: 0.0268 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0051 - acc: 0.9457 - rmse: 0.0336 - mse: 0.0051 - r_square: 0.9298 - val_loss: 0.0016 - val_acc: 0.9411 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9454 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9365 - val_loss: 0.0016 - val_acc: 0.9424 - val_rmse: 0.0271 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0048 - acc: 0.9463 - rmse: 0.0325 - mse: 0.0048 - r_square: 0.9366 - val_loss: 0.0016 - val_acc: 0.9768 - val_rmse: 0.0279 - val_mse: 0.0016 - val_r_square: 0.9896\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0047 - acc: 0.9471 - rmse: 0.0328 - mse: 0.0047 - r_square: 0.9363 - val_loss: 0.0016 - val_acc: 0.9410 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9477 - rmse: 0.0328 - mse: 0.0047 - r_square: 0.9368 - val_loss: 0.0016 - val_acc: 0.9403 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9500 - rmse: 0.0330 - mse: 0.0047 - r_square: 0.9370 - val_loss: 0.0016 - val_acc: 0.9429 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9898\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0047 - acc: 0.9505 - rmse: 0.0330 - mse: 0.0047 - r_square: 0.9366 - val_loss: 0.0016 - val_acc: 0.9790 - val_rmse: 0.0264 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0047 - acc: 0.9481 - rmse: 0.0331 - mse: 0.0047 - r_square: 0.9362 - val_loss: 0.0015 - val_acc: 0.9888 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9490 - rmse: 0.0328 - mse: 0.0048 - r_square: 0.9354 - val_loss: 0.0015 - val_acc: 0.9632 - val_rmse: 0.0258 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0048 - acc: 0.9511 - rmse: 0.0327 - mse: 0.0048 - r_square: 0.9344 - val_loss: 0.0013 - val_acc: 0.9277 - val_rmse: 0.0225 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0047 - acc: 0.9520 - rmse: 0.0315 - mse: 0.0047 - r_square: 0.9354 - val_loss: 0.0013 - val_acc: 0.9210 - val_rmse: 0.0217 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0047 - acc: 0.9529 - rmse: 0.0323 - mse: 0.0047 - r_square: 0.9365 - val_loss: 0.0013 - val_acc: 0.9659 - val_rmse: 0.0222 - val_mse: 0.0013 - val_r_square: 0.9917\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0046 - acc: 0.9532 - rmse: 0.0309 - mse: 0.0046 - r_square: 0.9381 - val_loss: 0.0013 - val_acc: 0.9421 - val_rmse: 0.0217 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0046 - acc: 0.9522 - rmse: 0.0310 - mse: 0.0046 - r_square: 0.9376 - val_loss: 0.0014 - val_acc: 0.9005 - val_rmse: 0.0242 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9525 - rmse: 0.0305 - mse: 0.0046 - r_square: 0.9385 - val_loss: 0.0013 - val_acc: 0.8375 - val_rmse: 0.0225 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0046 - acc: 0.9544 - rmse: 0.0297 - mse: 0.0046 - r_square: 0.9388 - val_loss: 0.0013 - val_acc: 0.8496 - val_rmse: 0.0213 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0046 - acc: 0.9534 - rmse: 0.0301 - mse: 0.0046 - r_square: 0.9378 - val_loss: 0.0013 - val_acc: 0.9427 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9918\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9555 - rmse: 0.0301 - mse: 0.0046 - r_square: 0.9382 - val_loss: 0.0013 - val_acc: 0.9247 - val_rmse: 0.0223 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0046 - acc: 0.9546 - rmse: 0.0300 - mse: 0.0046 - r_square: 0.9386 - val_loss: 0.0014 - val_acc: 0.8744 - val_rmse: 0.0244 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0045 - acc: 0.9536 - rmse: 0.0297 - mse: 0.0045 - r_square: 0.9396 - val_loss: 0.0014 - val_acc: 0.8371 - val_rmse: 0.0238 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0045 - acc: 0.9529 - rmse: 0.0292 - mse: 0.0045 - r_square: 0.9396 - val_loss: 0.0013 - val_acc: 0.8500 - val_rmse: 0.0227 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0046 - acc: 0.9463 - rmse: 0.0300 - mse: 0.0046 - r_square: 0.9386 - val_loss: 0.0013 - val_acc: 0.9293 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9531 - rmse: 0.0298 - mse: 0.0046 - r_square: 0.9381 - val_loss: 0.0013 - val_acc: 0.9254 - val_rmse: 0.0229 - val_mse: 0.0013 - val_r_square: 0.9918\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0046 - acc: 0.9542 - rmse: 0.0303 - mse: 0.0046 - r_square: 0.9387 - val_loss: 0.0014 - val_acc: 0.8872 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0045 - acc: 0.9555 - rmse: 0.0303 - mse: 0.0045 - r_square: 0.9399 - val_loss: 0.0015 - val_acc: 0.8372 - val_rmse: 0.0262 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0045 - acc: 0.9510 - rmse: 0.0302 - mse: 0.0045 - r_square: 0.9399 - val_loss: 0.0014 - val_acc: 0.8372 - val_rmse: 0.0248 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9434 - rmse: 0.0307 - mse: 0.0045 - r_square: 0.9397 - val_loss: 0.0015 - val_acc: 0.8374 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9411 - rmse: 0.0314 - mse: 0.0046 - r_square: 0.9391 - val_loss: 0.0015 - val_acc: 0.8378 - val_rmse: 0.0263 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0046 - acc: 0.9402 - rmse: 0.0321 - mse: 0.0046 - r_square: 0.9381 - val_loss: 0.0016 - val_acc: 0.8377 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9375 - rmse: 0.0330 - mse: 0.0047 - r_square: 0.9362 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0285 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0048 - acc: 0.9375 - rmse: 0.0337 - mse: 0.0048 - r_square: 0.9349 - val_loss: 0.0016 - val_acc: 0.8371 - val_rmse: 0.0283 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9355 - rmse: 0.0338 - mse: 0.0047 - r_square: 0.9371 - val_loss: 0.0017 - val_acc: 0.8387 - val_rmse: 0.0291 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9374 - rmse: 0.0335 - mse: 0.0047 - r_square: 0.9380 - val_loss: 0.0016 - val_acc: 0.8385 - val_rmse: 0.0280 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9406 - rmse: 0.0335 - mse: 0.0047 - r_square: 0.9381 - val_loss: 0.0015 - val_acc: 0.8640 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9423 - rmse: 0.0328 - mse: 0.0047 - r_square: 0.9387 - val_loss: 0.0014 - val_acc: 0.9023 - val_rmse: 0.0248 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9508 - rmse: 0.0321 - mse: 0.0046 - r_square: 0.9387 - val_loss: 0.0013 - val_acc: 0.9014 - val_rmse: 0.0221 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9553 - rmse: 0.0322 - mse: 0.0047 - r_square: 0.9369 - val_loss: 0.0013 - val_acc: 0.9010 - val_rmse: 0.0225 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9569 - rmse: 0.0321 - mse: 0.0047 - r_square: 0.9364 - val_loss: 0.0014 - val_acc: 0.8489 - val_rmse: 0.0240 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0046 - acc: 0.9549 - rmse: 0.0305 - mse: 0.0046 - r_square: 0.9388 - val_loss: 0.0014 - val_acc: 0.8489 - val_rmse: 0.0243 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 275us/step - loss: 0.0045 - acc: 0.9568 - rmse: 0.0295 - mse: 0.0045 - r_square: 0.9408 - val_loss: 0.0013 - val_acc: 0.8369 - val_rmse: 0.0221 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0044 - acc: 0.9525 - rmse: 0.0288 - mse: 0.0044 - r_square: 0.9414 - val_loss: 0.0013 - val_acc: 0.9013 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0044 - acc: 0.9555 - rmse: 0.0287 - mse: 0.0044 - r_square: 0.9414 - val_loss: 0.0013 - val_acc: 0.9267 - val_rmse: 0.0226 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9567 - rmse: 0.0289 - mse: 0.0044 - r_square: 0.9415 - val_loss: 0.0014 - val_acc: 0.9011 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9558 - rmse: 0.0286 - mse: 0.0044 - r_square: 0.9416 - val_loss: 0.0014 - val_acc: 0.9028 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0045 - acc: 0.9541 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9402 - val_loss: 0.0013 - val_acc: 0.9014 - val_rmse: 0.0224 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9522 - rmse: 0.0286 - mse: 0.0046 - r_square: 0.9387 - val_loss: 0.0013 - val_acc: 0.9423 - val_rmse: 0.0219 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0048 - acc: 0.9537 - rmse: 0.0302 - mse: 0.0048 - r_square: 0.9341 - val_loss: 0.0014 - val_acc: 0.9411 - val_rmse: 0.0241 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0046 - acc: 0.9520 - rmse: 0.0284 - mse: 0.0046 - r_square: 0.9376 - val_loss: 0.0013 - val_acc: 0.9426 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0047 - acc: 0.9512 - rmse: 0.0326 - mse: 0.0047 - r_square: 0.9364 - val_loss: 0.0020 - val_acc: 0.8369 - val_rmse: 0.0342 - val_mse: 0.0020 - val_r_square: 0.9872\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0045 - acc: 0.9475 - rmse: 0.0289 - mse: 0.0045 - r_square: 0.9410 - val_loss: 0.0013 - val_acc: 0.8538 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0044 - acc: 0.9473 - rmse: 0.0272 - mse: 0.0044 - r_square: 0.9429 - val_loss: 0.0013 - val_acc: 0.9429 - val_rmse: 0.0208 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9518 - rmse: 0.0273 - mse: 0.0044 - r_square: 0.9426 - val_loss: 0.0012 - val_acc: 0.9660 - val_rmse: 0.0196 - val_mse: 0.0012 - val_r_square: 0.9926\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9508 - rmse: 0.0290 - mse: 0.0044 - r_square: 0.9414 - val_loss: 0.0015 - val_acc: 0.9391 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9494 - rmse: 0.0282 - mse: 0.0044 - r_square: 0.9429 - val_loss: 0.0015 - val_acc: 0.8369 - val_rmse: 0.0254 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0044 - acc: 0.9509 - rmse: 0.0277 - mse: 0.0044 - r_square: 0.9429 - val_loss: 0.0013 - val_acc: 0.8798 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0044 - acc: 0.9553 - rmse: 0.0265 - mse: 0.0044 - r_square: 0.9435 - val_loss: 0.0012 - val_acc: 0.9442 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9924\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0045 - acc: 0.9499 - rmse: 0.0282 - mse: 0.0045 - r_square: 0.9398 - val_loss: 0.0013 - val_acc: 0.9646 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9921\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 8s 1ms/step - loss: 0.0289 - acc: 0.7525 - rmse: 0.1406 - mse: 0.0289 - r_square: 0.5213 - val_loss: 0.0046 - val_acc: 0.8365 - val_rmse: 0.0556 - val_mse: 0.0046 - val_r_square: 0.9712\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0145 - acc: 0.7475 - rmse: 0.0936 - mse: 0.0145 - r_square: 0.7753 - val_loss: 0.0034 - val_acc: 0.8365 - val_rmse: 0.0500 - val_mse: 0.0034 - val_r_square: 0.9775\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0103 - acc: 0.8586 - rmse: 0.0664 - mse: 0.0103 - r_square: 0.8526 - val_loss: 0.0019 - val_acc: 0.8365 - val_rmse: 0.0271 - val_mse: 0.0019 - val_r_square: 0.9887\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0074 - acc: 0.9139 - rmse: 0.0520 - mse: 0.0074 - r_square: 0.8934 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0230 - val_mse: 0.0017 - val_r_square: 0.9902\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0064 - acc: 0.9233 - rmse: 0.0420 - mse: 0.0064 - r_square: 0.9125 - val_loss: 0.0017 - val_acc: 0.8388 - val_rmse: 0.0260 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0060 - acc: 0.9305 - rmse: 0.0388 - mse: 0.0060 - r_square: 0.9164 - val_loss: 0.0017 - val_acc: 0.9018 - val_rmse: 0.0275 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0057 - acc: 0.9340 - rmse: 0.0361 - mse: 0.0057 - r_square: 0.9218 - val_loss: 0.0016 - val_acc: 0.8903 - val_rmse: 0.0251 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0056 - acc: 0.9358 - rmse: 0.0350 - mse: 0.0056 - r_square: 0.9240 - val_loss: 0.0016 - val_acc: 0.8454 - val_rmse: 0.0251 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0054 - acc: 0.9366 - rmse: 0.0340 - mse: 0.0054 - r_square: 0.9258 - val_loss: 0.0015 - val_acc: 0.8447 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0053 - acc: 0.9426 - rmse: 0.0330 - mse: 0.0053 - r_square: 0.9274 - val_loss: 0.0014 - val_acc: 0.8446 - val_rmse: 0.0236 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0052 - acc: 0.9434 - rmse: 0.0325 - mse: 0.0052 - r_square: 0.9283 - val_loss: 0.0014 - val_acc: 0.8437 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0052 - acc: 0.9442 - rmse: 0.0314 - mse: 0.0052 - r_square: 0.9295 - val_loss: 0.0014 - val_acc: 0.8433 - val_rmse: 0.0223 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0051 - acc: 0.9455 - rmse: 0.0313 - mse: 0.0051 - r_square: 0.9301 - val_loss: 0.0013 - val_acc: 0.8428 - val_rmse: 0.0209 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0051 - acc: 0.9464 - rmse: 0.0308 - mse: 0.0051 - r_square: 0.9305 - val_loss: 0.0013 - val_acc: 0.8423 - val_rmse: 0.0205 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0051 - acc: 0.9474 - rmse: 0.0311 - mse: 0.0051 - r_square: 0.9285 - val_loss: 0.0013 - val_acc: 0.8414 - val_rmse: 0.0204 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0050 - acc: 0.9477 - rmse: 0.0304 - mse: 0.0050 - r_square: 0.9316 - val_loss: 0.0013 - val_acc: 0.8411 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0050 - acc: 0.9484 - rmse: 0.0306 - mse: 0.0050 - r_square: 0.9305 - val_loss: 0.0013 - val_acc: 0.8405 - val_rmse: 0.0195 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0049 - acc: 0.9511 - rmse: 0.0304 - mse: 0.0049 - r_square: 0.9329 - val_loss: 0.0013 - val_acc: 0.8400 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0048 - acc: 0.9512 - rmse: 0.0298 - mse: 0.0048 - r_square: 0.9333 - val_loss: 0.0012 - val_acc: 0.8398 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0048 - acc: 0.9521 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9341 - val_loss: 0.0012 - val_acc: 0.8389 - val_rmse: 0.0188 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0048 - acc: 0.9516 - rmse: 0.0298 - mse: 0.0048 - r_square: 0.9342 - val_loss: 0.0012 - val_acc: 0.8394 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0047 - acc: 0.9524 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9349 - val_loss: 0.0012 - val_acc: 0.8391 - val_rmse: 0.0177 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0047 - acc: 0.9517 - rmse: 0.0297 - mse: 0.0047 - r_square: 0.9347 - val_loss: 0.0012 - val_acc: 0.8392 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0047 - acc: 0.9535 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9348 - val_loss: 0.0012 - val_acc: 0.8384 - val_rmse: 0.0177 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0049 - acc: 0.9516 - rmse: 0.0301 - mse: 0.0049 - r_square: 0.9318 - val_loss: 0.0012 - val_acc: 0.8510 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0047 - acc: 0.9530 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9347 - val_loss: 0.0012 - val_acc: 0.8388 - val_rmse: 0.0168 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0048 - acc: 0.9525 - rmse: 0.0308 - mse: 0.0048 - r_square: 0.9338 - val_loss: 0.0012 - val_acc: 0.8503 - val_rmse: 0.0194 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0046 - acc: 0.9535 - rmse: 0.0299 - mse: 0.0046 - r_square: 0.9369 - val_loss: 0.0011 - val_acc: 0.8649 - val_rmse: 0.0155 - val_mse: 0.0011 - val_r_square: 0.9936\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0046 - acc: 0.9542 - rmse: 0.0295 - mse: 0.0046 - r_square: 0.9371 - val_loss: 0.0012 - val_acc: 0.8379 - val_rmse: 0.0174 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0046 - acc: 0.9545 - rmse: 0.0292 - mse: 0.0046 - r_square: 0.9384 - val_loss: 0.0011 - val_acc: 0.8507 - val_rmse: 0.0146 - val_mse: 0.0011 - val_r_square: 0.9937\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0046 - acc: 0.9567 - rmse: 0.0284 - mse: 0.0046 - r_square: 0.9381 - val_loss: 0.0012 - val_acc: 0.8377 - val_rmse: 0.0157 - val_mse: 0.0012 - val_r_square: 0.9934\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0045 - acc: 0.9529 - rmse: 0.0287 - mse: 0.0045 - r_square: 0.9391 - val_loss: 0.0011 - val_acc: 0.8377 - val_rmse: 0.0147 - val_mse: 0.0011 - val_r_square: 0.9935\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0046 - acc: 0.9573 - rmse: 0.0288 - mse: 0.0046 - r_square: 0.9385 - val_loss: 0.0012 - val_acc: 0.8372 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0045 - acc: 0.9555 - rmse: 0.0284 - mse: 0.0045 - r_square: 0.9389 - val_loss: 0.0012 - val_acc: 0.8372 - val_rmse: 0.0162 - val_mse: 0.0012 - val_r_square: 0.9933\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0046 - acc: 0.9561 - rmse: 0.0289 - mse: 0.0046 - r_square: 0.9387 - val_loss: 0.0013 - val_acc: 0.8371 - val_rmse: 0.0195 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0045 - acc: 0.9549 - rmse: 0.0280 - mse: 0.0045 - r_square: 0.9392 - val_loss: 0.0012 - val_acc: 0.8371 - val_rmse: 0.0172 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9495 - rmse: 0.0287 - mse: 0.0045 - r_square: 0.9391 - val_loss: 0.0013 - val_acc: 0.8366 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0045 - acc: 0.9504 - rmse: 0.0280 - mse: 0.0045 - r_square: 0.9395 - val_loss: 0.0012 - val_acc: 0.8366 - val_rmse: 0.0177 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0045 - acc: 0.9404 - rmse: 0.0287 - mse: 0.0045 - r_square: 0.9395 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0185 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9480 - rmse: 0.0285 - mse: 0.0045 - r_square: 0.9395 - val_loss: 0.0012 - val_acc: 0.8365 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9452 - rmse: 0.0285 - mse: 0.0045 - r_square: 0.9401 - val_loss: 0.0012 - val_acc: 0.8365 - val_rmse: 0.0157 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9479 - rmse: 0.0287 - mse: 0.0045 - r_square: 0.9398 - val_loss: 0.0012 - val_acc: 0.8366 - val_rmse: 0.0172 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0044 - acc: 0.9498 - rmse: 0.0279 - mse: 0.0044 - r_square: 0.9411 - val_loss: 0.0011 - val_acc: 0.8368 - val_rmse: 0.0140 - val_mse: 0.0011 - val_r_square: 0.9936\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9511 - rmse: 0.0283 - mse: 0.0045 - r_square: 0.9407 - val_loss: 0.0012 - val_acc: 0.8368 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9577 - rmse: 0.0286 - mse: 0.0045 - r_square: 0.9411 - val_loss: 0.0012 - val_acc: 0.8366 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9584 - rmse: 0.0299 - mse: 0.0046 - r_square: 0.9395 - val_loss: 0.0013 - val_acc: 0.8366 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9535 - rmse: 0.0307 - mse: 0.0046 - r_square: 0.9392 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9556 - rmse: 0.0310 - mse: 0.0046 - r_square: 0.9380 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0204 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9393 - rmse: 0.0322 - mse: 0.0046 - r_square: 0.9382 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0212 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0047 - acc: 0.9493 - rmse: 0.0345 - mse: 0.0047 - r_square: 0.9365 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0269 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0049 - acc: 0.9379 - rmse: 0.0373 - mse: 0.0049 - r_square: 0.9337 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0277 - val_mse: 0.0018 - val_r_square: 0.9896\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0052 - acc: 0.9472 - rmse: 0.0414 - mse: 0.0052 - r_square: 0.9273 - val_loss: 0.0022 - val_acc: 0.8365 - val_rmse: 0.0346 - val_mse: 0.0022 - val_r_square: 0.9868\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0055 - acc: 0.9341 - rmse: 0.0456 - mse: 0.0055 - r_square: 0.9199 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0303 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0054 - acc: 0.9267 - rmse: 0.0440 - mse: 0.0054 - r_square: 0.9203 - val_loss: 0.0022 - val_acc: 0.9557 - val_rmse: 0.0370 - val_mse: 0.0022 - val_r_square: 0.9854\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0051 - acc: 0.9531 - rmse: 0.0407 - mse: 0.0051 - r_square: 0.9324 - val_loss: 0.0014 - val_acc: 0.9293 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0050 - acc: 0.9474 - rmse: 0.0392 - mse: 0.0050 - r_square: 0.9311 - val_loss: 0.0012 - val_acc: 0.8764 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9381 - rmse: 0.0336 - mse: 0.0047 - r_square: 0.9370 - val_loss: 0.0012 - val_acc: 0.8902 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9503 - rmse: 0.0335 - mse: 0.0048 - r_square: 0.9376 - val_loss: 0.0013 - val_acc: 0.9417 - val_rmse: 0.0217 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9483 - rmse: 0.0318 - mse: 0.0047 - r_square: 0.9377 - val_loss: 0.0013 - val_acc: 0.9669 - val_rmse: 0.0208 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0046 - acc: 0.9572 - rmse: 0.0305 - mse: 0.0046 - r_square: 0.9405 - val_loss: 0.0013 - val_acc: 0.9680 - val_rmse: 0.0221 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0048 - acc: 0.9500 - rmse: 0.0326 - mse: 0.0048 - r_square: 0.9394 - val_loss: 0.0015 - val_acc: 0.9928 - val_rmse: 0.0265 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0047 - acc: 0.9478 - rmse: 0.0328 - mse: 0.0047 - r_square: 0.9400 - val_loss: 0.0016 - val_acc: 0.9935 - val_rmse: 0.0284 - val_mse: 0.0016 - val_r_square: 0.9897\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0048 - acc: 0.9469 - rmse: 0.0345 - mse: 0.0048 - r_square: 0.9385 - val_loss: 0.0015 - val_acc: 0.9934 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9487 - rmse: 0.0355 - mse: 0.0048 - r_square: 0.9375 - val_loss: 0.0013 - val_acc: 0.9922 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9492 - rmse: 0.0367 - mse: 0.0049 - r_square: 0.9352 - val_loss: 0.0012 - val_acc: 0.9665 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9927\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9483 - rmse: 0.0365 - mse: 0.0049 - r_square: 0.9337 - val_loss: 0.0012 - val_acc: 0.8892 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0049 - acc: 0.9465 - rmse: 0.0371 - mse: 0.0049 - r_square: 0.9324 - val_loss: 0.0012 - val_acc: 0.9021 - val_rmse: 0.0195 - val_mse: 0.0012 - val_r_square: 0.9926\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0048 - acc: 0.9483 - rmse: 0.0362 - mse: 0.0048 - r_square: 0.9357 - val_loss: 0.0013 - val_acc: 0.9282 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9434 - rmse: 0.0360 - mse: 0.0048 - r_square: 0.9362 - val_loss: 0.0014 - val_acc: 0.9673 - val_rmse: 0.0237 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0050 - acc: 0.9394 - rmse: 0.0376 - mse: 0.0050 - r_square: 0.9351 - val_loss: 0.0016 - val_acc: 0.9676 - val_rmse: 0.0268 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0050 - acc: 0.9380 - rmse: 0.0385 - mse: 0.0050 - r_square: 0.9334 - val_loss: 0.0016 - val_acc: 0.9783 - val_rmse: 0.0267 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0053 - acc: 0.9359 - rmse: 0.0403 - mse: 0.0053 - r_square: 0.9304 - val_loss: 0.0017 - val_acc: 0.9675 - val_rmse: 0.0304 - val_mse: 0.0017 - val_r_square: 0.9890\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0053 - acc: 0.9313 - rmse: 0.0416 - mse: 0.0053 - r_square: 0.9282 - val_loss: 0.0017 - val_acc: 0.9678 - val_rmse: 0.0301 - val_mse: 0.0017 - val_r_square: 0.9891\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0053 - acc: 0.9341 - rmse: 0.0415 - mse: 0.0053 - r_square: 0.9305 - val_loss: 0.0019 - val_acc: 0.9675 - val_rmse: 0.0329 - val_mse: 0.0019 - val_r_square: 0.9879\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0052 - acc: 0.9309 - rmse: 0.0414 - mse: 0.0052 - r_square: 0.9299 - val_loss: 0.0017 - val_acc: 0.9423 - val_rmse: 0.0290 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0053 - acc: 0.9347 - rmse: 0.0415 - mse: 0.0053 - r_square: 0.9320 - val_loss: 0.0017 - val_acc: 0.8769 - val_rmse: 0.0297 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0052 - acc: 0.9223 - rmse: 0.0415 - mse: 0.0052 - r_square: 0.9307 - val_loss: 0.0014 - val_acc: 0.8369 - val_rmse: 0.0236 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0053 - acc: 0.9292 - rmse: 0.0413 - mse: 0.0053 - r_square: 0.9316 - val_loss: 0.0015 - val_acc: 0.8369 - val_rmse: 0.0257 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0051 - acc: 0.9243 - rmse: 0.0399 - mse: 0.0051 - r_square: 0.9326 - val_loss: 0.0014 - val_acc: 0.8368 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0052 - acc: 0.9299 - rmse: 0.0396 - mse: 0.0052 - r_square: 0.9327 - val_loss: 0.0014 - val_acc: 0.8368 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9282 - rmse: 0.0378 - mse: 0.0050 - r_square: 0.9345 - val_loss: 0.0013 - val_acc: 0.8368 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9325 - rmse: 0.0373 - mse: 0.0050 - r_square: 0.9357 - val_loss: 0.0013 - val_acc: 0.8368 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9353 - rmse: 0.0356 - mse: 0.0048 - r_square: 0.9372 - val_loss: 0.0013 - val_acc: 0.8369 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9575 - rmse: 0.0353 - mse: 0.0048 - r_square: 0.9372 - val_loss: 0.0013 - val_acc: 0.8371 - val_rmse: 0.0223 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9359 - rmse: 0.0334 - mse: 0.0047 - r_square: 0.9382 - val_loss: 0.0012 - val_acc: 0.8638 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9927\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0048 - acc: 0.9572 - rmse: 0.0342 - mse: 0.0048 - r_square: 0.9375 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0208 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0046 - acc: 0.9445 - rmse: 0.0319 - mse: 0.0046 - r_square: 0.9402 - val_loss: 0.0012 - val_acc: 0.8905 - val_rmse: 0.0190 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9523 - rmse: 0.0331 - mse: 0.0046 - r_square: 0.9394 - val_loss: 0.0012 - val_acc: 0.8507 - val_rmse: 0.0200 - val_mse: 0.0012 - val_r_square: 0.9926\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0045 - acc: 0.9589 - rmse: 0.0300 - mse: 0.0045 - r_square: 0.9421 - val_loss: 0.0012 - val_acc: 0.9037 - val_rmse: 0.0190 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0046 - acc: 0.9509 - rmse: 0.0312 - mse: 0.0046 - r_square: 0.9402 - val_loss: 0.0012 - val_acc: 0.8771 - val_rmse: 0.0199 - val_mse: 0.0012 - val_r_square: 0.9927\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0045 - acc: 0.9591 - rmse: 0.0288 - mse: 0.0045 - r_square: 0.9410 - val_loss: 0.0012 - val_acc: 0.9293 - val_rmse: 0.0187 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0045 - acc: 0.9523 - rmse: 0.0294 - mse: 0.0045 - r_square: 0.9400 - val_loss: 0.0012 - val_acc: 0.8906 - val_rmse: 0.0193 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0044 - acc: 0.9516 - rmse: 0.0277 - mse: 0.0044 - r_square: 0.9425 - val_loss: 0.0012 - val_acc: 0.9170 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0044 - acc: 0.9515 - rmse: 0.0279 - mse: 0.0044 - r_square: 0.9429 - val_loss: 0.0012 - val_acc: 0.8906 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0043 - acc: 0.9532 - rmse: 0.0267 - mse: 0.0043 - r_square: 0.9441 - val_loss: 0.0012 - val_acc: 0.9044 - val_rmse: 0.0180 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0043 - acc: 0.9510 - rmse: 0.0267 - mse: 0.0043 - r_square: 0.9440 - val_loss: 0.0012 - val_acc: 0.8906 - val_rmse: 0.0185 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0043 - acc: 0.9530 - rmse: 0.0261 - mse: 0.0043 - r_square: 0.9445 - val_loss: 0.0012 - val_acc: 0.9036 - val_rmse: 0.0176 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0044 - acc: 0.9520 - rmse: 0.0261 - mse: 0.0044 - r_square: 0.9432 - val_loss: 0.0012 - val_acc: 0.9135 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0045 - acc: 0.9535 - rmse: 0.0264 - mse: 0.0045 - r_square: 0.9403 - val_loss: 0.0012 - val_acc: 0.9152 - val_rmse: 0.0175 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0043 - acc: 0.9529 - rmse: 0.0254 - mse: 0.0043 - r_square: 0.9434 - val_loss: 0.0012 - val_acc: 0.9158 - val_rmse: 0.0177 - val_mse: 0.0012 - val_r_square: 0.9931\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_9 (RepeatVecto (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 6s 870us/step - loss: 0.0184 - acc: 0.7153 - mse: 0.0184 - rmse: 0.1101 - r_square: 0.6973 - val_loss: 0.0089 - val_acc: 0.9934 - val_mse: 0.0089 - val_rmse: 0.0894 - val_r_square: 0.9372\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0111 - acc: 0.7607 - mse: 0.0111 - rmse: 0.0812 - r_square: 0.7915 - val_loss: 0.0029 - val_acc: 0.8765 - val_mse: 0.0029 - val_rmse: 0.0459 - val_r_square: 0.9803\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0147 - acc: 0.7921 - mse: 0.0147 - rmse: 0.0941 - r_square: 0.7334 - val_loss: 0.0052 - val_acc: 0.8365 - val_mse: 0.0052 - val_rmse: 0.0600 - val_r_square: 0.9671\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0118 - acc: 0.9143 - mse: 0.0118 - rmse: 0.0838 - r_square: 0.8058 - val_loss: 0.0042 - val_acc: 0.9942 - val_mse: 0.0042 - val_rmse: 0.0580 - val_r_square: 0.9723\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0097 - acc: 0.9390 - mse: 0.0097 - rmse: 0.0717 - r_square: 0.8396 - val_loss: 0.0028 - val_acc: 0.8624 - val_mse: 0.0028 - val_rmse: 0.0411 - val_r_square: 0.9828\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0095 - acc: 0.9390 - mse: 0.0095 - rmse: 0.0704 - r_square: 0.8535 - val_loss: 0.0037 - val_acc: 0.8365 - val_mse: 0.0037 - val_rmse: 0.0540 - val_r_square: 0.9757\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0100 - acc: 0.9172 - mse: 0.0100 - rmse: 0.0736 - r_square: 0.8364 - val_loss: 0.0043 - val_acc: 0.8366 - val_mse: 0.0043 - val_rmse: 0.0608 - val_r_square: 0.9707\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0097 - acc: 0.9402 - mse: 0.0097 - rmse: 0.0748 - r_square: 0.8443 - val_loss: 0.0064 - val_acc: 0.8366 - val_mse: 0.0064 - val_rmse: 0.0763 - val_r_square: 0.9547\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0091 - acc: 0.9212 - mse: 0.0091 - rmse: 0.0687 - r_square: 0.8542 - val_loss: 0.0040 - val_acc: 0.8366 - val_mse: 0.0040 - val_rmse: 0.0576 - val_r_square: 0.9730\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0082 - acc: 0.9308 - mse: 0.0082 - rmse: 0.0615 - r_square: 0.8824 - val_loss: 0.0023 - val_acc: 0.8366 - val_mse: 0.0023 - val_rmse: 0.0394 - val_r_square: 0.9851\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0067 - acc: 0.9514 - mse: 0.0067 - rmse: 0.0557 - r_square: 0.8945 - val_loss: 0.0022 - val_acc: 0.8365 - val_mse: 0.0022 - val_rmse: 0.0363 - val_r_square: 0.9863\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0063 - acc: 0.9266 - mse: 0.0063 - rmse: 0.0497 - r_square: 0.8999 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0307 - val_r_square: 0.9888\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0060 - acc: 0.9192 - mse: 0.0060 - rmse: 0.0475 - r_square: 0.9172 - val_loss: 0.0031 - val_acc: 0.9942 - val_mse: 0.0031 - val_rmse: 0.0471 - val_r_square: 0.9788\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0059 - acc: 0.9504 - mse: 0.0059 - rmse: 0.0481 - r_square: 0.9130 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0274 - val_r_square: 0.9901\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0056 - acc: 0.9303 - mse: 0.0056 - rmse: 0.0460 - r_square: 0.9130 - val_loss: 0.0016 - val_acc: 0.8906 - val_mse: 0.0016 - val_rmse: 0.0288 - val_r_square: 0.9900\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0050 - acc: 0.9535 - mse: 0.0050 - rmse: 0.0356 - r_square: 0.9293 - val_loss: 0.0022 - val_acc: 0.8493 - val_mse: 0.0022 - val_rmse: 0.0375 - val_r_square: 0.9856\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0051 - acc: 0.9486 - mse: 0.0051 - rmse: 0.0373 - r_square: 0.9287 - val_loss: 0.0017 - val_acc: 0.9928 - val_mse: 0.0017 - val_rmse: 0.0289 - val_r_square: 0.9894\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0049 - acc: 0.9570 - mse: 0.0049 - rmse: 0.0347 - r_square: 0.9276 - val_loss: 0.0011 - val_acc: 0.8768 - val_mse: 0.0011 - val_rmse: 0.0140 - val_r_square: 0.9937\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0051 - acc: 0.9513 - mse: 0.0051 - rmse: 0.0360 - r_square: 0.9308 - val_loss: 0.0014 - val_acc: 0.8505 - val_mse: 0.0014 - val_rmse: 0.0188 - val_r_square: 0.9922\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0052 - acc: 0.9546 - mse: 0.0052 - rmse: 0.0390 - r_square: 0.9276 - val_loss: 0.0022 - val_acc: 0.8366 - val_mse: 0.0022 - val_rmse: 0.0390 - val_r_square: 0.9851\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0058 - acc: 0.9513 - mse: 0.0058 - rmse: 0.0468 - r_square: 0.9179 - val_loss: 0.0019 - val_acc: 0.9562 - val_mse: 0.0019 - val_rmse: 0.0322 - val_r_square: 0.9876\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0060 - acc: 0.9401 - mse: 0.0060 - rmse: 0.0484 - r_square: 0.9144 - val_loss: 0.0014 - val_acc: 0.8369 - val_mse: 0.0014 - val_rmse: 0.0226 - val_r_square: 0.9918\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0064 - acc: 0.9520 - mse: 0.0064 - rmse: 0.0514 - r_square: 0.9109 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0301 - val_r_square: 0.9892\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0063 - acc: 0.9488 - mse: 0.0063 - rmse: 0.0513 - r_square: 0.9044 - val_loss: 0.0043 - val_acc: 0.8365 - val_mse: 0.0043 - val_rmse: 0.0601 - val_r_square: 0.9696\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0065 - acc: 0.9047 - mse: 0.0065 - rmse: 0.0521 - r_square: 0.9036 - val_loss: 0.0024 - val_acc: 0.9158 - val_mse: 0.0024 - val_rmse: 0.0407 - val_r_square: 0.9841\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0061 - acc: 0.9475 - mse: 0.0061 - rmse: 0.0497 - r_square: 0.9096 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0326 - val_r_square: 0.9880\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0069 - acc: 0.8929 - mse: 0.0069 - rmse: 0.0587 - r_square: 0.8982 - val_loss: 0.0026 - val_acc: 0.9942 - val_mse: 0.0026 - val_rmse: 0.0416 - val_r_square: 0.9827\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0062 - acc: 0.9403 - mse: 0.0062 - rmse: 0.0515 - r_square: 0.9033 - val_loss: 0.0028 - val_acc: 0.8365 - val_mse: 0.0028 - val_rmse: 0.0460 - val_r_square: 0.9814\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0056 - acc: 0.9527 - mse: 0.0056 - rmse: 0.0422 - r_square: 0.9204 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0268 - val_r_square: 0.9903\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0050 - acc: 0.9476 - mse: 0.0050 - rmse: 0.0356 - r_square: 0.9310 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0221 - val_r_square: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0056 - acc: 0.9242 - mse: 0.0056 - rmse: 0.0417 - r_square: 0.9258 - val_loss: 0.0040 - val_acc: 0.9942 - val_mse: 0.0040 - val_rmse: 0.0566 - val_r_square: 0.9717\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0053 - acc: 0.9492 - mse: 0.0053 - rmse: 0.0413 - r_square: 0.9241 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0384 - val_r_square: 0.9844\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0052 - acc: 0.9407 - mse: 0.0052 - rmse: 0.0389 - r_square: 0.9271 - val_loss: 0.0020 - val_acc: 0.9430 - val_mse: 0.0020 - val_rmse: 0.0347 - val_r_square: 0.9866\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0049 - acc: 0.9511 - mse: 0.0049 - rmse: 0.0356 - r_square: 0.9346 - val_loss: 0.0012 - val_acc: 0.8489 - val_mse: 0.0012 - val_rmse: 0.0183 - val_r_square: 0.9930\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0057 - acc: 0.9538 - mse: 0.0057 - rmse: 0.0445 - r_square: 0.9225 - val_loss: 0.0017 - val_acc: 0.9430 - val_mse: 0.0017 - val_rmse: 0.0309 - val_r_square: 0.9890\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0054 - acc: 0.9487 - mse: 0.0054 - rmse: 0.0443 - r_square: 0.9207 - val_loss: 0.0023 - val_acc: 0.9940 - val_mse: 0.0023 - val_rmse: 0.0382 - val_r_square: 0.9843\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0056 - acc: 0.9469 - mse: 0.0056 - rmse: 0.0448 - r_square: 0.9177 - val_loss: 0.0015 - val_acc: 0.8487 - val_mse: 0.0015 - val_rmse: 0.0261 - val_r_square: 0.9904\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0055 - acc: 0.9448 - mse: 0.0055 - rmse: 0.0442 - r_square: 0.9272 - val_loss: 0.0015 - val_acc: 0.8489 - val_mse: 0.0015 - val_rmse: 0.0266 - val_r_square: 0.9905\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0062 - acc: 0.9585 - mse: 0.0062 - rmse: 0.0498 - r_square: 0.9175 - val_loss: 0.0014 - val_acc: 0.8368 - val_mse: 0.0014 - val_rmse: 0.0244 - val_r_square: 0.9915\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0054 - acc: 0.9473 - mse: 0.0054 - rmse: 0.0430 - r_square: 0.9160 - val_loss: 0.0024 - val_acc: 0.9360 - val_mse: 0.0024 - val_rmse: 0.0388 - val_r_square: 0.9839\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0055 - acc: 0.9526 - mse: 0.0055 - rmse: 0.0448 - r_square: 0.9223 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0337 - val_r_square: 0.9877\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0054 - acc: 0.9477 - mse: 0.0054 - rmse: 0.0441 - r_square: 0.9274 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0308 - val_r_square: 0.9891\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0055 - acc: 0.9477 - mse: 0.0055 - rmse: 0.0435 - r_square: 0.9259 - val_loss: 0.0013 - val_acc: 0.8739 - val_mse: 0.0013 - val_rmse: 0.0222 - val_r_square: 0.9919\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0057 - acc: 0.9527 - mse: 0.0057 - rmse: 0.0473 - r_square: 0.9204 - val_loss: 0.0025 - val_acc: 0.8365 - val_mse: 0.0025 - val_rmse: 0.0401 - val_r_square: 0.9837\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0072 - acc: 0.9001 - mse: 0.0072 - rmse: 0.0581 - r_square: 0.8951 - val_loss: 0.0022 - val_acc: 0.9413 - val_mse: 0.0022 - val_rmse: 0.0377 - val_r_square: 0.9857\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0058 - acc: 0.9505 - mse: 0.0058 - rmse: 0.0462 - r_square: 0.9175 - val_loss: 0.0020 - val_acc: 0.8371 - val_mse: 0.0020 - val_rmse: 0.0336 - val_r_square: 0.9874\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0063 - acc: 0.9500 - mse: 0.0063 - rmse: 0.0493 - r_square: 0.9094 - val_loss: 0.0021 - val_acc: 0.9426 - val_mse: 0.0021 - val_rmse: 0.0364 - val_r_square: 0.9861\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0060 - acc: 0.9487 - mse: 0.0060 - rmse: 0.0490 - r_square: 0.9151 - val_loss: 0.0020 - val_acc: 0.8368 - val_mse: 0.0020 - val_rmse: 0.0327 - val_r_square: 0.9869\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0063 - acc: 0.9198 - mse: 0.0063 - rmse: 0.0509 - r_square: 0.9036 - val_loss: 0.0036 - val_acc: 0.9942 - val_mse: 0.0036 - val_rmse: 0.0527 - val_r_square: 0.9754\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0055 - acc: 0.9415 - mse: 0.0055 - rmse: 0.0443 - r_square: 0.9131 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0232 - val_r_square: 0.9913\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0065 - acc: 0.9446 - mse: 0.0065 - rmse: 0.0529 - r_square: 0.9026 - val_loss: 0.0025 - val_acc: 0.9942 - val_mse: 0.0025 - val_rmse: 0.0411 - val_r_square: 0.9836\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0055 - acc: 0.9429 - mse: 0.0055 - rmse: 0.0441 - r_square: 0.9154 - val_loss: 0.0013 - val_acc: 0.9942 - val_mse: 0.0013 - val_rmse: 0.0219 - val_r_square: 0.9918\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0058 - acc: 0.9423 - mse: 0.0058 - rmse: 0.0445 - r_square: 0.9112 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0381 - val_r_square: 0.9846\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0053 - acc: 0.9460 - mse: 0.0053 - rmse: 0.0451 - r_square: 0.9188 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0218 - val_r_square: 0.9913\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0055 - acc: 0.9405 - mse: 0.0055 - rmse: 0.0417 - r_square: 0.9197 - val_loss: 0.0017 - val_acc: 0.9679 - val_mse: 0.0017 - val_rmse: 0.0292 - val_r_square: 0.9894\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 227us/step - loss: 0.0053 - acc: 0.9538 - mse: 0.0053 - rmse: 0.0433 - r_square: 0.9207 - val_loss: 0.0014 - val_acc: 0.9803 - val_mse: 0.0014 - val_rmse: 0.0232 - val_r_square: 0.9915\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0055 - acc: 0.9321 - mse: 0.0055 - rmse: 0.0444 - r_square: 0.9193 - val_loss: 0.0027 - val_acc: 0.9431 - val_mse: 0.0027 - val_rmse: 0.0438 - val_r_square: 0.9817\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0054 - acc: 0.9538 - mse: 0.0054 - rmse: 0.0430 - r_square: 0.9273 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0269 - val_r_square: 0.9900\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0053 - acc: 0.9400 - mse: 0.0053 - rmse: 0.0429 - r_square: 0.9230 - val_loss: 0.0019 - val_acc: 0.9905 - val_mse: 0.0019 - val_rmse: 0.0331 - val_r_square: 0.9874\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0052 - acc: 0.8672 - mse: 0.0052 - rmse: 0.0433 - r_square: 0.9159 - val_loss: 0.0012 - val_acc: 0.9934 - val_mse: 0.0012 - val_rmse: 0.0181 - val_r_square: 0.9926\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0052 - acc: 0.9529 - mse: 0.0052 - rmse: 0.0405 - r_square: 0.9281 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0385 - val_r_square: 0.9851\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 233us/step - loss: 0.0051 - acc: 0.9502 - mse: 0.0051 - rmse: 0.0403 - r_square: 0.9284 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0256 - val_r_square: 0.9903\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0053 - acc: 0.9498 - mse: 0.0053 - rmse: 0.0432 - r_square: 0.9154 - val_loss: 0.0018 - val_acc: 0.8624 - val_mse: 0.0018 - val_rmse: 0.0322 - val_r_square: 0.9879\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0055 - acc: 0.9445 - mse: 0.0055 - rmse: 0.0455 - r_square: 0.9222 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0256 - val_r_square: 0.9906\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0051 - acc: 0.9468 - mse: 0.0051 - rmse: 0.0397 - r_square: 0.9267 - val_loss: 0.0016 - val_acc: 0.9911 - val_mse: 0.0016 - val_rmse: 0.0282 - val_r_square: 0.9896\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0053 - acc: 0.9450 - mse: 0.0053 - rmse: 0.0447 - r_square: 0.9219 - val_loss: 0.0018 - val_acc: 0.9663 - val_mse: 0.0018 - val_rmse: 0.0295 - val_r_square: 0.9886\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0061 - acc: 0.9325 - mse: 0.0061 - rmse: 0.0505 - r_square: 0.9029 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0341 - val_r_square: 0.9876\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0056 - acc: 0.9415 - mse: 0.0056 - rmse: 0.0468 - r_square: 0.9137 - val_loss: 0.0017 - val_acc: 0.9801 - val_mse: 0.0017 - val_rmse: 0.0282 - val_r_square: 0.9888\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0060 - acc: 0.9494 - mse: 0.0060 - rmse: 0.0486 - r_square: 0.9124 - val_loss: 0.0018 - val_acc: 0.9522 - val_mse: 0.0018 - val_rmse: 0.0310 - val_r_square: 0.9883\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0051 - acc: 0.9456 - mse: 0.0051 - rmse: 0.0412 - r_square: 0.9256 - val_loss: 0.0016 - val_acc: 0.9545 - val_mse: 0.0016 - val_rmse: 0.0276 - val_r_square: 0.9899\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0054 - acc: 0.9481 - mse: 0.0054 - rmse: 0.0431 - r_square: 0.9246 - val_loss: 0.0014 - val_acc: 0.9545 - val_mse: 0.0014 - val_rmse: 0.0224 - val_r_square: 0.9917\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0051 - acc: 0.9435 - mse: 0.0051 - rmse: 0.0390 - r_square: 0.9262 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0324 - val_r_square: 0.9879\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0051 - acc: 0.9500 - mse: 0.0051 - rmse: 0.0410 - r_square: 0.9290 - val_loss: 0.0017 - val_acc: 0.9928 - val_mse: 0.0017 - val_rmse: 0.0271 - val_r_square: 0.9896\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0053 - acc: 0.9114 - mse: 0.0053 - rmse: 0.0440 - r_square: 0.9171 - val_loss: 0.0011 - val_acc: 0.9906 - val_mse: 0.0011 - val_rmse: 0.0123 - val_r_square: 0.9938\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0057 - acc: 0.9363 - mse: 0.0057 - rmse: 0.0461 - r_square: 0.9194 - val_loss: 0.0026 - val_acc: 0.9942 - val_mse: 0.0026 - val_rmse: 0.0426 - val_r_square: 0.9830\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0051 - acc: 0.8614 - mse: 0.0051 - rmse: 0.0420 - r_square: 0.9245 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0241 - val_r_square: 0.9909\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0050 - acc: 0.9420 - mse: 0.0050 - rmse: 0.0406 - r_square: 0.9225 - val_loss: 0.0012 - val_acc: 0.9814 - val_mse: 0.0012 - val_rmse: 0.0179 - val_r_square: 0.9929\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0051 - acc: 0.9448 - mse: 0.0051 - rmse: 0.0387 - r_square: 0.9243 - val_loss: 0.0012 - val_acc: 0.9942 - val_mse: 0.0012 - val_rmse: 0.0166 - val_r_square: 0.9932\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0051 - acc: 0.9516 - mse: 0.0051 - rmse: 0.0398 - r_square: 0.9255 - val_loss: 0.0014 - val_acc: 0.9701 - val_mse: 0.0014 - val_rmse: 0.0242 - val_r_square: 0.9911\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0054 - acc: 0.9545 - mse: 0.0054 - rmse: 0.0427 - r_square: 0.9203 - val_loss: 0.0016 - val_acc: 0.8374 - val_mse: 0.0016 - val_rmse: 0.0271 - val_r_square: 0.9903\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0052 - acc: 0.9488 - mse: 0.0052 - rmse: 0.0409 - r_square: 0.9255 - val_loss: 0.0014 - val_acc: 0.9437 - val_mse: 0.0014 - val_rmse: 0.0239 - val_r_square: 0.9911\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0052 - acc: 0.9525 - mse: 0.0052 - rmse: 0.0410 - r_square: 0.9253 - val_loss: 0.0012 - val_acc: 0.9942 - val_mse: 0.0012 - val_rmse: 0.0187 - val_r_square: 0.9927\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0053 - acc: 0.9521 - mse: 0.0053 - rmse: 0.0437 - r_square: 0.9239 - val_loss: 0.0015 - val_acc: 0.9904 - val_mse: 0.0015 - val_rmse: 0.0244 - val_r_square: 0.9908\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0055 - acc: 0.9345 - mse: 0.0055 - rmse: 0.0461 - r_square: 0.9104 - val_loss: 0.0019 - val_acc: 0.9896 - val_mse: 0.0019 - val_rmse: 0.0322 - val_r_square: 0.9873\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0051 - acc: 0.9513 - mse: 0.0051 - rmse: 0.0400 - r_square: 0.9229 - val_loss: 0.0013 - val_acc: 0.9942 - val_mse: 0.0013 - val_rmse: 0.0201 - val_r_square: 0.9924\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0051 - acc: 0.9536 - mse: 0.0051 - rmse: 0.0390 - r_square: 0.9260 - val_loss: 0.0014 - val_acc: 0.9937 - val_mse: 0.0014 - val_rmse: 0.0228 - val_r_square: 0.9910\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0050 - acc: 0.9095 - mse: 0.0050 - rmse: 0.0351 - r_square: 0.9291 - val_loss: 0.0014 - val_acc: 0.9676 - val_mse: 0.0014 - val_rmse: 0.0238 - val_r_square: 0.9915\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0049 - acc: 0.9492 - mse: 0.0049 - rmse: 0.0369 - r_square: 0.9307 - val_loss: 0.0015 - val_acc: 0.8487 - val_mse: 0.0015 - val_rmse: 0.0249 - val_r_square: 0.9909\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0053 - acc: 0.9541 - mse: 0.0053 - rmse: 0.0396 - r_square: 0.9247 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0220 - val_r_square: 0.9919\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0058 - acc: 0.9502 - mse: 0.0058 - rmse: 0.0434 - r_square: 0.9171 - val_loss: 0.0023 - val_acc: 0.9908 - val_mse: 0.0023 - val_rmse: 0.0398 - val_r_square: 0.9847\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0051 - acc: 0.9509 - mse: 0.0051 - rmse: 0.0399 - r_square: 0.9240 - val_loss: 0.0019 - val_acc: 0.9725 - val_mse: 0.0019 - val_rmse: 0.0308 - val_r_square: 0.9881\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0058 - acc: 0.9364 - mse: 0.0058 - rmse: 0.0458 - r_square: 0.9117 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0259 - val_r_square: 0.9907\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0061 - acc: 0.9492 - mse: 0.0061 - rmse: 0.0450 - r_square: 0.9092 - val_loss: 0.0022 - val_acc: 0.9531 - val_mse: 0.0022 - val_rmse: 0.0382 - val_r_square: 0.9855\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0062 - acc: 0.9349 - mse: 0.0062 - rmse: 0.0476 - r_square: 0.9035 - val_loss: 0.0013 - val_acc: 0.9942 - val_mse: 0.0013 - val_rmse: 0.0192 - val_r_square: 0.9925\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0066 - acc: 0.9463 - mse: 0.0066 - rmse: 0.0515 - r_square: 0.8908 - val_loss: 0.0017 - val_acc: 0.9898 - val_mse: 0.0017 - val_rmse: 0.0290 - val_r_square: 0.9895\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0058 - acc: 0.9448 - mse: 0.0058 - rmse: 0.0447 - r_square: 0.9100 - val_loss: 0.0016 - val_acc: 0.9092 - val_mse: 0.0016 - val_rmse: 0.0283 - val_r_square: 0.9900\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0071 - acc: 0.8859 - mse: 0.0071 - rmse: 0.0511 - r_square: 0.8787 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0255 - val_r_square: 0.9907\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0059 - acc: 0.9427 - mse: 0.0059 - rmse: 0.0465 - r_square: 0.9031 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0247 - val_r_square: 0.9911\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0067 - acc: 0.8900 - mse: 0.0067 - rmse: 0.0507 - r_square: 0.8934 - val_loss: 0.0033 - val_acc: 0.9942 - val_mse: 0.0033 - val_rmse: 0.0503 - val_r_square: 0.9773\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0068 - acc: 0.9244 - mse: 0.0068 - rmse: 0.0562 - r_square: 0.8910 - val_loss: 0.0021 - val_acc: 0.9799 - val_mse: 0.0021 - val_rmse: 0.0351 - val_r_square: 0.9859\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infant mortality (per 1000 births)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed_x',\n",
       "       'Deaths', 'Recovered', 'Confirmed_y', 'Country', 'Region', 'Population',\n",
       "       'Area (sq. mi.)', 'Pop. Density (per sq. mi.)',\n",
       "       'Coastline (coast/area ratio)', 'Net migration',\n",
       "       'Infant mortality (per 1000 births)', 'GDP ($ per capita)',\n",
       "       'Literacy (%)', 'Phones (per 1000)', 'Arable (%)', 'Crops (%)',\n",
       "       'Climate', 'Birthrate', 'Deathrate', 'Agriculture', 'Industry',\n",
       "       'Service', 'Month', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Infant mortality (per 1000 births)','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 7s 1ms/step - loss: 0.0397 - acc: 0.5193 - rmse: 0.1632 - mse: 0.0397 - r_square: 0.3101 - val_loss: 0.0245 - val_acc: 0.8365 - val_rmse: 0.1422 - val_mse: 0.0245 - val_r_square: 0.8278\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0242 - acc: 0.8929 - rmse: 0.1238 - mse: 0.0242 - r_square: 0.5625 - val_loss: 0.0211 - val_acc: 0.8365 - val_rmse: 0.1387 - val_mse: 0.0211 - val_r_square: 0.8500\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0201 - acc: 0.8998 - rmse: 0.1093 - mse: 0.0201 - r_square: 0.6528 - val_loss: 0.0161 - val_acc: 0.8365 - val_rmse: 0.1209 - val_mse: 0.0161 - val_r_square: 0.8853\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0162 - acc: 0.8385 - rmse: 0.0961 - mse: 0.0162 - r_square: 0.7307 - val_loss: 0.0135 - val_acc: 0.8365 - val_rmse: 0.1113 - val_mse: 0.0135 - val_r_square: 0.9024\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0116 - acc: 0.9318 - rmse: 0.0738 - mse: 0.0116 - r_square: 0.7976 - val_loss: 0.0075 - val_acc: 0.8365 - val_rmse: 0.0816 - val_mse: 0.0075 - val_r_square: 0.9473\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0097 - acc: 0.9088 - rmse: 0.0662 - mse: 0.0097 - r_square: 0.8166 - val_loss: 0.0053 - val_acc: 0.8372 - val_rmse: 0.0645 - val_mse: 0.0053 - val_r_square: 0.9636\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 292us/step - loss: 0.0084 - acc: 0.9054 - rmse: 0.0577 - mse: 0.0084 - r_square: 0.8403 - val_loss: 0.0038 - val_acc: 0.8384 - val_rmse: 0.0515 - val_mse: 0.0038 - val_r_square: 0.9755\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0079 - acc: 0.9309 - rmse: 0.0558 - mse: 0.0079 - r_square: 0.8470 - val_loss: 0.0031 - val_acc: 0.8382 - val_rmse: 0.0450 - val_mse: 0.0031 - val_r_square: 0.9807\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0079 - acc: 0.9151 - rmse: 0.0562 - mse: 0.0079 - r_square: 0.8490 - val_loss: 0.0033 - val_acc: 0.8407 - val_rmse: 0.0511 - val_mse: 0.0033 - val_r_square: 0.9776\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0076 - acc: 0.9103 - rmse: 0.0539 - mse: 0.0076 - r_square: 0.8584 - val_loss: 0.0037 - val_acc: 0.8414 - val_rmse: 0.0544 - val_mse: 0.0037 - val_r_square: 0.9747\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0074 - acc: 0.9117 - rmse: 0.0536 - mse: 0.0074 - r_square: 0.8642 - val_loss: 0.0029 - val_acc: 0.8381 - val_rmse: 0.0451 - val_mse: 0.0029 - val_r_square: 0.9817\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0076 - acc: 0.9088 - rmse: 0.0557 - mse: 0.0076 - r_square: 0.8594 - val_loss: 0.0035 - val_acc: 0.8404 - val_rmse: 0.0519 - val_mse: 0.0035 - val_r_square: 0.9764\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0074 - acc: 0.9112 - rmse: 0.0543 - mse: 0.0074 - r_square: 0.8653 - val_loss: 0.0027 - val_acc: 0.8412 - val_rmse: 0.0428 - val_mse: 0.0027 - val_r_square: 0.9824\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 284us/step - loss: 0.0074 - acc: 0.9128 - rmse: 0.0539 - mse: 0.0074 - r_square: 0.8692 - val_loss: 0.0030 - val_acc: 0.8387 - val_rmse: 0.0469 - val_mse: 0.0030 - val_r_square: 0.9802\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0075 - acc: 0.9186 - rmse: 0.0549 - mse: 0.0075 - r_square: 0.8680 - val_loss: 0.0043 - val_acc: 0.8391 - val_rmse: 0.0596 - val_mse: 0.0043 - val_r_square: 0.9703\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0079 - acc: 0.8767 - rmse: 0.0580 - mse: 0.0079 - r_square: 0.8648 - val_loss: 0.0053 - val_acc: 0.9678 - val_rmse: 0.0662 - val_mse: 0.0053 - val_r_square: 0.9627\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0076 - acc: 0.8745 - rmse: 0.0556 - mse: 0.0076 - r_square: 0.8699 - val_loss: 0.0045 - val_acc: 0.9911 - val_rmse: 0.0584 - val_mse: 0.0045 - val_r_square: 0.9687\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0069 - acc: 0.9131 - rmse: 0.0508 - mse: 0.0069 - r_square: 0.8754 - val_loss: 0.0024 - val_acc: 0.9777 - val_rmse: 0.0373 - val_mse: 0.0024 - val_r_square: 0.9845\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0063 - acc: 0.9546 - rmse: 0.0448 - mse: 0.0063 - r_square: 0.8825 - val_loss: 0.0014 - val_acc: 0.9039 - val_rmse: 0.0211 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0061 - acc: 0.9260 - rmse: 0.0444 - mse: 0.0061 - r_square: 0.8844 - val_loss: 0.0014 - val_acc: 0.8660 - val_rmse: 0.0217 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0058 - acc: 0.9562 - rmse: 0.0407 - mse: 0.0058 - r_square: 0.8900 - val_loss: 0.0014 - val_acc: 0.8661 - val_rmse: 0.0199 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0056 - acc: 0.9371 - rmse: 0.0391 - mse: 0.0056 - r_square: 0.8933 - val_loss: 0.0014 - val_acc: 0.9147 - val_rmse: 0.0214 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0055 - acc: 0.9562 - rmse: 0.0366 - mse: 0.0055 - r_square: 0.8967 - val_loss: 0.0015 - val_acc: 0.9416 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0055 - acc: 0.9170 - rmse: 0.0382 - mse: 0.0055 - r_square: 0.8971 - val_loss: 0.0014 - val_acc: 0.9162 - val_rmse: 0.0226 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0053 - acc: 0.9570 - rmse: 0.0358 - mse: 0.0053 - r_square: 0.8996 - val_loss: 0.0015 - val_acc: 0.9030 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0054 - acc: 0.9371 - rmse: 0.0375 - mse: 0.0054 - r_square: 0.8997 - val_loss: 0.0014 - val_acc: 0.8746 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 3s 371us/step - loss: 0.0054 - acc: 0.9572 - rmse: 0.0366 - mse: 0.0054 - r_square: 0.8995 - val_loss: 0.0015 - val_acc: 0.8392 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 276us/step - loss: 0.0053 - acc: 0.9566 - rmse: 0.0373 - mse: 0.0053 - r_square: 0.9013 - val_loss: 0.0014 - val_acc: 0.8385 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 341us/step - loss: 0.0054 - acc: 0.9571 - rmse: 0.0376 - mse: 0.0054 - r_square: 0.9015 - val_loss: 0.0015 - val_acc: 0.8385 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 339us/step - loss: 0.0054 - acc: 0.9572 - rmse: 0.0381 - mse: 0.0054 - r_square: 0.9021 - val_loss: 0.0014 - val_acc: 0.8387 - val_rmse: 0.0240 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0055 - acc: 0.9574 - rmse: 0.0390 - mse: 0.0055 - r_square: 0.9018 - val_loss: 0.0015 - val_acc: 0.8771 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0055 - acc: 0.9577 - rmse: 0.0400 - mse: 0.0055 - r_square: 0.9009 - val_loss: 0.0016 - val_acc: 0.9393 - val_rmse: 0.0276 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0057 - acc: 0.9568 - rmse: 0.0410 - mse: 0.0057 - r_square: 0.8993 - val_loss: 0.0019 - val_acc: 0.9647 - val_rmse: 0.0322 - val_mse: 0.0019 - val_r_square: 0.9882\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0056 - acc: 0.9570 - rmse: 0.0416 - mse: 0.0056 - r_square: 0.8998 - val_loss: 0.0022 - val_acc: 0.9891 - val_rmse: 0.0374 - val_mse: 0.0022 - val_r_square: 0.9857\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0055 - acc: 0.9563 - rmse: 0.0405 - mse: 0.0055 - r_square: 0.9014 - val_loss: 0.0019 - val_acc: 0.9899 - val_rmse: 0.0334 - val_mse: 0.0019 - val_r_square: 0.9877\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 3s 361us/step - loss: 0.0053 - acc: 0.9593 - rmse: 0.0384 - mse: 0.0053 - r_square: 0.9028 - val_loss: 0.0015 - val_acc: 0.9885 - val_rmse: 0.0258 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0053 - acc: 0.9582 - rmse: 0.0387 - mse: 0.0053 - r_square: 0.9006 - val_loss: 0.0014 - val_acc: 0.9403 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0053 - acc: 0.9522 - rmse: 0.0396 - mse: 0.0053 - r_square: 0.8985 - val_loss: 0.0015 - val_acc: 0.9008 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0053 - acc: 0.9540 - rmse: 0.0387 - mse: 0.0053 - r_square: 0.8974 - val_loss: 0.0014 - val_acc: 0.9024 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 279us/step - loss: 0.0051 - acc: 0.9536 - rmse: 0.0355 - mse: 0.0051 - r_square: 0.9031 - val_loss: 0.0013 - val_acc: 0.9017 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0050 - acc: 0.9589 - rmse: 0.0352 - mse: 0.0050 - r_square: 0.9036 - val_loss: 0.0013 - val_acc: 0.9145 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0049 - acc: 0.9638 - rmse: 0.0333 - mse: 0.0049 - r_square: 0.9060 - val_loss: 0.0013 - val_acc: 0.9154 - val_rmse: 0.0219 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0048 - acc: 0.9636 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9092 - val_loss: 0.0013 - val_acc: 0.9289 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9639 - rmse: 0.0309 - mse: 0.0048 - r_square: 0.9094 - val_loss: 0.0014 - val_acc: 0.9420 - val_rmse: 0.0223 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0048 - acc: 0.9633 - rmse: 0.0302 - mse: 0.0048 - r_square: 0.9093 - val_loss: 0.0013 - val_acc: 0.9421 - val_rmse: 0.0213 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0047 - acc: 0.9630 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9123 - val_loss: 0.0014 - val_acc: 0.9423 - val_rmse: 0.0223 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0047 - acc: 0.9648 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9134 - val_loss: 0.0014 - val_acc: 0.9426 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0047 - acc: 0.9631 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9145 - val_loss: 0.0014 - val_acc: 0.9424 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0046 - acc: 0.9644 - rmse: 0.0289 - mse: 0.0046 - r_square: 0.9145 - val_loss: 0.0014 - val_acc: 0.9431 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0046 - acc: 0.9632 - rmse: 0.0287 - mse: 0.0046 - r_square: 0.9153 - val_loss: 0.0014 - val_acc: 0.9424 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0047 - acc: 0.9647 - rmse: 0.0291 - mse: 0.0047 - r_square: 0.9139 - val_loss: 0.0014 - val_acc: 0.9545 - val_rmse: 0.0220 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0047 - acc: 0.9612 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9133 - val_loss: 0.0014 - val_acc: 0.9420 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0047 - acc: 0.9657 - rmse: 0.0293 - mse: 0.0047 - r_square: 0.9124 - val_loss: 0.0014 - val_acc: 0.9550 - val_rmse: 0.0226 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0047 - acc: 0.9622 - rmse: 0.0291 - mse: 0.0047 - r_square: 0.9149 - val_loss: 0.0014 - val_acc: 0.9542 - val_rmse: 0.0220 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9648 - rmse: 0.0286 - mse: 0.0046 - r_square: 0.9153 - val_loss: 0.0014 - val_acc: 0.9551 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0047 - acc: 0.9627 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9135 - val_loss: 0.0014 - val_acc: 0.9551 - val_rmse: 0.0216 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0047 - acc: 0.9625 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9138 - val_loss: 0.0014 - val_acc: 0.9544 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0048 - acc: 0.9639 - rmse: 0.0297 - mse: 0.0048 - r_square: 0.9121 - val_loss: 0.0014 - val_acc: 0.9668 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9615 - rmse: 0.0290 - mse: 0.0046 - r_square: 0.9160 - val_loss: 0.0014 - val_acc: 0.9548 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9658 - rmse: 0.0285 - mse: 0.0046 - r_square: 0.9167 - val_loss: 0.0014 - val_acc: 0.9552 - val_rmse: 0.0224 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0046 - acc: 0.9630 - rmse: 0.0289 - mse: 0.0046 - r_square: 0.9166 - val_loss: 0.0014 - val_acc: 0.9550 - val_rmse: 0.0226 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0046 - acc: 0.9656 - rmse: 0.0285 - mse: 0.0046 - r_square: 0.9174 - val_loss: 0.0014 - val_acc: 0.9548 - val_rmse: 0.0226 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0046 - acc: 0.9633 - rmse: 0.0291 - mse: 0.0046 - r_square: 0.9169 - val_loss: 0.0014 - val_acc: 0.9548 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0046 - acc: 0.9648 - rmse: 0.0289 - mse: 0.0046 - r_square: 0.9166 - val_loss: 0.0014 - val_acc: 0.9547 - val_rmse: 0.0227 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0047 - acc: 0.9635 - rmse: 0.0300 - mse: 0.0047 - r_square: 0.9140 - val_loss: 0.0014 - val_acc: 0.9670 - val_rmse: 0.0233 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0047 - acc: 0.9650 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9154 - val_loss: 0.0014 - val_acc: 0.9547 - val_rmse: 0.0228 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0047 - acc: 0.9645 - rmse: 0.0300 - mse: 0.0047 - r_square: 0.9152 - val_loss: 0.0014 - val_acc: 0.9659 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9638 - rmse: 0.0300 - mse: 0.0047 - r_square: 0.9162 - val_loss: 0.0015 - val_acc: 0.9547 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0046 - acc: 0.9660 - rmse: 0.0298 - mse: 0.0046 - r_square: 0.9165 - val_loss: 0.0014 - val_acc: 0.9547 - val_rmse: 0.0231 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9646 - rmse: 0.0304 - mse: 0.0047 - r_square: 0.9161 - val_loss: 0.0015 - val_acc: 0.9547 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0047 - acc: 0.9653 - rmse: 0.0306 - mse: 0.0047 - r_square: 0.9150 - val_loss: 0.0014 - val_acc: 0.9547 - val_rmse: 0.0231 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9657 - rmse: 0.0310 - mse: 0.0047 - r_square: 0.9147 - val_loss: 0.0015 - val_acc: 0.9420 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0047 - acc: 0.9646 - rmse: 0.0312 - mse: 0.0047 - r_square: 0.9141 - val_loss: 0.0014 - val_acc: 0.9542 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0047 - acc: 0.9658 - rmse: 0.0311 - mse: 0.0047 - r_square: 0.9159 - val_loss: 0.0014 - val_acc: 0.9417 - val_rmse: 0.0237 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0047 - acc: 0.9667 - rmse: 0.0309 - mse: 0.0047 - r_square: 0.9165 - val_loss: 0.0014 - val_acc: 0.9417 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0047 - acc: 0.9661 - rmse: 0.0314 - mse: 0.0047 - r_square: 0.9160 - val_loss: 0.0014 - val_acc: 0.9292 - val_rmse: 0.0237 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0048 - acc: 0.9670 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9144 - val_loss: 0.0015 - val_acc: 0.9283 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0048 - acc: 0.9634 - rmse: 0.0325 - mse: 0.0048 - r_square: 0.9131 - val_loss: 0.0014 - val_acc: 0.8759 - val_rmse: 0.0240 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9627 - rmse: 0.0338 - mse: 0.0048 - r_square: 0.9121 - val_loss: 0.0015 - val_acc: 0.8636 - val_rmse: 0.0248 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9557 - rmse: 0.0341 - mse: 0.0048 - r_square: 0.9139 - val_loss: 0.0015 - val_acc: 0.8375 - val_rmse: 0.0251 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0048 - acc: 0.9574 - rmse: 0.0347 - mse: 0.0048 - r_square: 0.9122 - val_loss: 0.0014 - val_acc: 0.8375 - val_rmse: 0.0242 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0050 - acc: 0.9451 - rmse: 0.0364 - mse: 0.0050 - r_square: 0.9109 - val_loss: 0.0015 - val_acc: 0.8374 - val_rmse: 0.0264 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0051 - acc: 0.9433 - rmse: 0.0381 - mse: 0.0051 - r_square: 0.9075 - val_loss: 0.0015 - val_acc: 0.8374 - val_rmse: 0.0258 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9377 - rmse: 0.0398 - mse: 0.0053 - r_square: 0.9047 - val_loss: 0.0016 - val_acc: 0.8369 - val_rmse: 0.0268 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0056 - acc: 0.9299 - rmse: 0.0420 - mse: 0.0056 - r_square: 0.8942 - val_loss: 0.0015 - val_acc: 0.8372 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0052 - acc: 0.9411 - rmse: 0.0381 - mse: 0.0052 - r_square: 0.9052 - val_loss: 0.0014 - val_acc: 0.8368 - val_rmse: 0.0240 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0054 - acc: 0.9438 - rmse: 0.0410 - mse: 0.0054 - r_square: 0.9046 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0265 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0055 - acc: 0.8917 - rmse: 0.0424 - mse: 0.0055 - r_square: 0.9004 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0053 - acc: 0.8617 - rmse: 0.0400 - mse: 0.0053 - r_square: 0.9040 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9638 - rmse: 0.0385 - mse: 0.0052 - r_square: 0.9097 - val_loss: 0.0016 - val_acc: 0.8365 - val_rmse: 0.0262 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9326 - rmse: 0.0362 - mse: 0.0050 - r_square: 0.9107 - val_loss: 0.0015 - val_acc: 0.8371 - val_rmse: 0.0244 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0048 - acc: 0.9486 - rmse: 0.0329 - mse: 0.0048 - r_square: 0.9157 - val_loss: 0.0013 - val_acc: 0.8641 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0047 - acc: 0.9317 - rmse: 0.0317 - mse: 0.0047 - r_square: 0.9160 - val_loss: 0.0014 - val_acc: 0.9544 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0048 - acc: 0.9379 - rmse: 0.0309 - mse: 0.0048 - r_square: 0.9157 - val_loss: 0.0017 - val_acc: 0.9931 - val_rmse: 0.0277 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0047 - acc: 0.9364 - rmse: 0.0301 - mse: 0.0047 - r_square: 0.9159 - val_loss: 0.0017 - val_acc: 0.9935 - val_rmse: 0.0274 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0046 - acc: 0.9335 - rmse: 0.0294 - mse: 0.0046 - r_square: 0.9171 - val_loss: 0.0016 - val_acc: 0.9934 - val_rmse: 0.0254 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0046 - acc: 0.9439 - rmse: 0.0285 - mse: 0.0046 - r_square: 0.9191 - val_loss: 0.0014 - val_acc: 0.9925 - val_rmse: 0.0220 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0045 - acc: 0.9548 - rmse: 0.0282 - mse: 0.0045 - r_square: 0.9192 - val_loss: 0.0013 - val_acc: 0.9672 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0045 - acc: 0.9644 - rmse: 0.0277 - mse: 0.0045 - r_square: 0.9198 - val_loss: 0.0012 - val_acc: 0.9290 - val_rmse: 0.0183 - val_mse: 0.0012 - val_r_square: 0.9928\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0045 - acc: 0.9650 - rmse: 0.0269 - mse: 0.0045 - r_square: 0.9200 - val_loss: 0.0012 - val_acc: 0.9158 - val_rmse: 0.0180 - val_mse: 0.0012 - val_r_square: 0.9929\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 9s 1ms/step - loss: 0.0286 - acc: 0.6195 - rmse: 0.1385 - mse: 0.0286 - r_square: 0.3898 - val_loss: 0.0086 - val_acc: 0.8365 - val_rmse: 0.0867 - val_mse: 0.0086 - val_r_square: 0.9396\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0145 - acc: 0.8841 - rmse: 0.0956 - mse: 0.0145 - r_square: 0.7010 - val_loss: 0.0062 - val_acc: 0.8365 - val_rmse: 0.0734 - val_mse: 0.0062 - val_r_square: 0.9570\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0102 - acc: 0.8839 - rmse: 0.0668 - mse: 0.0102 - r_square: 0.8059 - val_loss: 0.0024 - val_acc: 0.8365 - val_rmse: 0.0367 - val_mse: 0.0024 - val_r_square: 0.9850\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0079 - acc: 0.8969 - rmse: 0.0558 - mse: 0.0079 - r_square: 0.8545 - val_loss: 0.0025 - val_acc: 0.8385 - val_rmse: 0.0386 - val_mse: 0.0025 - val_r_square: 0.9841\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0071 - acc: 0.9030 - rmse: 0.0476 - mse: 0.0071 - r_square: 0.8724 - val_loss: 0.0023 - val_acc: 0.8398 - val_rmse: 0.0360 - val_mse: 0.0023 - val_r_square: 0.9856\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0065 - acc: 0.9085 - rmse: 0.0420 - mse: 0.0065 - r_square: 0.8841 - val_loss: 0.0018 - val_acc: 0.8424 - val_rmse: 0.0290 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0061 - acc: 0.9419 - rmse: 0.0391 - mse: 0.0061 - r_square: 0.8900 - val_loss: 0.0017 - val_acc: 0.8420 - val_rmse: 0.0266 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0059 - acc: 0.9119 - rmse: 0.0373 - mse: 0.0059 - r_square: 0.8922 - val_loss: 0.0017 - val_acc: 0.8427 - val_rmse: 0.0274 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0057 - acc: 0.9131 - rmse: 0.0364 - mse: 0.0057 - r_square: 0.8941 - val_loss: 0.0016 - val_acc: 0.8425 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0056 - acc: 0.9311 - rmse: 0.0354 - mse: 0.0056 - r_square: 0.8962 - val_loss: 0.0016 - val_acc: 0.8428 - val_rmse: 0.0264 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0055 - acc: 0.9462 - rmse: 0.0346 - mse: 0.0055 - r_square: 0.8980 - val_loss: 0.0015 - val_acc: 0.8418 - val_rmse: 0.0253 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0054 - acc: 0.9509 - rmse: 0.0338 - mse: 0.0054 - r_square: 0.8997 - val_loss: 0.0015 - val_acc: 0.8417 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0053 - acc: 0.9515 - rmse: 0.0333 - mse: 0.0053 - r_square: 0.9011 - val_loss: 0.0015 - val_acc: 0.8407 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0052 - acc: 0.9529 - rmse: 0.0329 - mse: 0.0052 - r_square: 0.9018 - val_loss: 0.0015 - val_acc: 0.8404 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0053 - acc: 0.9527 - rmse: 0.0331 - mse: 0.0053 - r_square: 0.8996 - val_loss: 0.0014 - val_acc: 0.8394 - val_rmse: 0.0241 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0052 - acc: 0.9499 - rmse: 0.0331 - mse: 0.0052 - r_square: 0.9024 - val_loss: 0.0015 - val_acc: 0.8397 - val_rmse: 0.0253 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0052 - acc: 0.9541 - rmse: 0.0329 - mse: 0.0052 - r_square: 0.9015 - val_loss: 0.0015 - val_acc: 0.8385 - val_rmse: 0.0259 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0051 - acc: 0.9560 - rmse: 0.0333 - mse: 0.0051 - r_square: 0.9043 - val_loss: 0.0014 - val_acc: 0.8387 - val_rmse: 0.0246 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0051 - acc: 0.9554 - rmse: 0.0325 - mse: 0.0051 - r_square: 0.9048 - val_loss: 0.0015 - val_acc: 0.8385 - val_rmse: 0.0254 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0050 - acc: 0.9568 - rmse: 0.0327 - mse: 0.0050 - r_square: 0.9057 - val_loss: 0.0014 - val_acc: 0.8382 - val_rmse: 0.0238 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0050 - acc: 0.9556 - rmse: 0.0323 - mse: 0.0050 - r_square: 0.9054 - val_loss: 0.0014 - val_acc: 0.8509 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0050 - acc: 0.9576 - rmse: 0.0322 - mse: 0.0050 - r_square: 0.9069 - val_loss: 0.0014 - val_acc: 0.8379 - val_rmse: 0.0241 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0050 - acc: 0.9561 - rmse: 0.0318 - mse: 0.0050 - r_square: 0.9071 - val_loss: 0.0013 - val_acc: 0.8507 - val_rmse: 0.0217 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0049 - acc: 0.9577 - rmse: 0.0314 - mse: 0.0049 - r_square: 0.9092 - val_loss: 0.0014 - val_acc: 0.8375 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0049 - acc: 0.9565 - rmse: 0.0312 - mse: 0.0049 - r_square: 0.9095 - val_loss: 0.0013 - val_acc: 0.8378 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0048 - acc: 0.9583 - rmse: 0.0307 - mse: 0.0048 - r_square: 0.9109 - val_loss: 0.0013 - val_acc: 0.8372 - val_rmse: 0.0213 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0048 - acc: 0.9573 - rmse: 0.0310 - mse: 0.0048 - r_square: 0.9106 - val_loss: 0.0014 - val_acc: 0.8374 - val_rmse: 0.0218 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0048 - acc: 0.9584 - rmse: 0.0310 - mse: 0.0048 - r_square: 0.9110 - val_loss: 0.0013 - val_acc: 0.8369 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 3s 377us/step - loss: 0.0049 - acc: 0.9581 - rmse: 0.0312 - mse: 0.0049 - r_square: 0.9096 - val_loss: 0.0014 - val_acc: 0.8369 - val_rmse: 0.0219 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 3s 383us/step - loss: 0.0048 - acc: 0.9587 - rmse: 0.0316 - mse: 0.0048 - r_square: 0.9108 - val_loss: 0.0013 - val_acc: 0.8368 - val_rmse: 0.0194 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 356us/step - loss: 0.0049 - acc: 0.9594 - rmse: 0.0316 - mse: 0.0049 - r_square: 0.9105 - val_loss: 0.0015 - val_acc: 0.8366 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 355us/step - loss: 0.0048 - acc: 0.9590 - rmse: 0.0323 - mse: 0.0048 - r_square: 0.9112 - val_loss: 0.0013 - val_acc: 0.8366 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 358us/step - loss: 0.0049 - acc: 0.9603 - rmse: 0.0321 - mse: 0.0049 - r_square: 0.9113 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0049 - acc: 0.9595 - rmse: 0.0330 - mse: 0.0049 - r_square: 0.9112 - val_loss: 0.0013 - val_acc: 0.8365 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0049 - acc: 0.9606 - rmse: 0.0328 - mse: 0.0049 - r_square: 0.9109 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9916\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0049 - acc: 0.9602 - rmse: 0.0340 - mse: 0.0049 - r_square: 0.9104 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0217 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0049 - acc: 0.9617 - rmse: 0.0340 - mse: 0.0049 - r_square: 0.9095 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0227 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9630 - rmse: 0.0354 - mse: 0.0049 - r_square: 0.9086 - val_loss: 0.0013 - val_acc: 0.8366 - val_rmse: 0.0212 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0049 - acc: 0.9641 - rmse: 0.0353 - mse: 0.0049 - r_square: 0.9075 - val_loss: 0.0013 - val_acc: 0.8486 - val_rmse: 0.0203 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0050 - acc: 0.9651 - rmse: 0.0357 - mse: 0.0050 - r_square: 0.9088 - val_loss: 0.0013 - val_acc: 0.8633 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9649 - rmse: 0.0349 - mse: 0.0050 - r_square: 0.9102 - val_loss: 0.0014 - val_acc: 0.8755 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9656 - rmse: 0.0343 - mse: 0.0049 - r_square: 0.9125 - val_loss: 0.0014 - val_acc: 0.9013 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0049 - acc: 0.9653 - rmse: 0.0346 - mse: 0.0049 - r_square: 0.9109 - val_loss: 0.0012 - val_acc: 0.8887 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0049 - acc: 0.9642 - rmse: 0.0342 - mse: 0.0049 - r_square: 0.9114 - val_loss: 0.0013 - val_acc: 0.8883 - val_rmse: 0.0227 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9642 - rmse: 0.0322 - mse: 0.0048 - r_square: 0.9133 - val_loss: 0.0013 - val_acc: 0.8767 - val_rmse: 0.0204 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9658 - rmse: 0.0312 - mse: 0.0048 - r_square: 0.9142 - val_loss: 0.0011 - val_acc: 0.8762 - val_rmse: 0.0153 - val_mse: 0.0011 - val_r_square: 0.9937\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9648 - rmse: 0.0309 - mse: 0.0048 - r_square: 0.9142 - val_loss: 0.0011 - val_acc: 0.8630 - val_rmse: 0.0140 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9651 - rmse: 0.0308 - mse: 0.0048 - r_square: 0.9156 - val_loss: 0.0011 - val_acc: 0.8633 - val_rmse: 0.0145 - val_mse: 0.0011 - val_r_square: 0.9938\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0048 - acc: 0.9653 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9156 - val_loss: 0.0011 - val_acc: 0.8631 - val_rmse: 0.0158 - val_mse: 0.0011 - val_r_square: 0.9936\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0047 - acc: 0.9658 - rmse: 0.0305 - mse: 0.0047 - r_square: 0.9163 - val_loss: 0.0011 - val_acc: 0.8768 - val_rmse: 0.0137 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9653 - rmse: 0.0303 - mse: 0.0047 - r_square: 0.9159 - val_loss: 0.0011 - val_acc: 0.8887 - val_rmse: 0.0135 - val_mse: 0.0011 - val_r_square: 0.9939\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0048 - acc: 0.9656 - rmse: 0.0312 - mse: 0.0048 - r_square: 0.9160 - val_loss: 0.0011 - val_acc: 0.9265 - val_rmse: 0.0125 - val_mse: 0.0011 - val_r_square: 0.9940\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9648 - rmse: 0.0318 - mse: 0.0049 - r_square: 0.9162 - val_loss: 0.0012 - val_acc: 0.9275 - val_rmse: 0.0171 - val_mse: 0.0012 - val_r_square: 0.9932\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9650 - rmse: 0.0334 - mse: 0.0049 - r_square: 0.9154 - val_loss: 0.0014 - val_acc: 0.9669 - val_rmse: 0.0216 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9638 - rmse: 0.0340 - mse: 0.0049 - r_square: 0.9139 - val_loss: 0.0014 - val_acc: 0.9778 - val_rmse: 0.0216 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0050 - acc: 0.9635 - rmse: 0.0366 - mse: 0.0050 - r_square: 0.9099 - val_loss: 0.0014 - val_acc: 0.9917 - val_rmse: 0.0208 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0051 - acc: 0.9609 - rmse: 0.0395 - mse: 0.0051 - r_square: 0.9054 - val_loss: 0.0017 - val_acc: 0.9935 - val_rmse: 0.0278 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0054 - acc: 0.9596 - rmse: 0.0410 - mse: 0.0054 - r_square: 0.9075 - val_loss: 0.0029 - val_acc: 0.9942 - val_rmse: 0.0454 - val_mse: 0.0029 - val_r_square: 0.9804\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0051 - acc: 0.9610 - rmse: 0.0364 - mse: 0.0051 - r_square: 0.9129 - val_loss: 0.0017 - val_acc: 0.9937 - val_rmse: 0.0291 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0052 - acc: 0.9627 - rmse: 0.0396 - mse: 0.0052 - r_square: 0.9097 - val_loss: 0.0014 - val_acc: 0.9544 - val_rmse: 0.0227 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0051 - acc: 0.9577 - rmse: 0.0377 - mse: 0.0051 - r_square: 0.9070 - val_loss: 0.0016 - val_acc: 0.8748 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9583 - rmse: 0.0359 - mse: 0.0049 - r_square: 0.9095 - val_loss: 0.0012 - val_acc: 0.8633 - val_rmse: 0.0189 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0047 - acc: 0.9602 - rmse: 0.0322 - mse: 0.0047 - r_square: 0.9162 - val_loss: 0.0012 - val_acc: 0.8502 - val_rmse: 0.0182 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0047 - acc: 0.9648 - rmse: 0.0308 - mse: 0.0047 - r_square: 0.9170 - val_loss: 0.0013 - val_acc: 0.8758 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0047 - acc: 0.9647 - rmse: 0.0301 - mse: 0.0047 - r_square: 0.9162 - val_loss: 0.0013 - val_acc: 0.8777 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9927\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0047 - acc: 0.9636 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9164 - val_loss: 0.0013 - val_acc: 0.9306 - val_rmse: 0.0211 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9635 - rmse: 0.0289 - mse: 0.0046 - r_square: 0.9171 - val_loss: 0.0013 - val_acc: 0.9154 - val_rmse: 0.0207 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9647 - rmse: 0.0283 - mse: 0.0046 - r_square: 0.9193 - val_loss: 0.0013 - val_acc: 0.9427 - val_rmse: 0.0203 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9650 - rmse: 0.0281 - mse: 0.0046 - r_square: 0.9197 - val_loss: 0.0013 - val_acc: 0.9305 - val_rmse: 0.0202 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9645 - rmse: 0.0280 - mse: 0.0045 - r_square: 0.9206 - val_loss: 0.0013 - val_acc: 0.9306 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0045 - acc: 0.9651 - rmse: 0.0282 - mse: 0.0045 - r_square: 0.9203 - val_loss: 0.0013 - val_acc: 0.9302 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0045 - acc: 0.9652 - rmse: 0.0282 - mse: 0.0045 - r_square: 0.9203 - val_loss: 0.0013 - val_acc: 0.9419 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0046 - acc: 0.9654 - rmse: 0.0290 - mse: 0.0046 - r_square: 0.9183 - val_loss: 0.0013 - val_acc: 0.9299 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0046 - acc: 0.9659 - rmse: 0.0287 - mse: 0.0046 - r_square: 0.9190 - val_loss: 0.0013 - val_acc: 0.9426 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0046 - acc: 0.9668 - rmse: 0.0299 - mse: 0.0046 - r_square: 0.9163 - val_loss: 0.0013 - val_acc: 0.9306 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0046 - acc: 0.9657 - rmse: 0.0294 - mse: 0.0046 - r_square: 0.9193 - val_loss: 0.0013 - val_acc: 0.9302 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9675 - rmse: 0.0304 - mse: 0.0046 - r_square: 0.9157 - val_loss: 0.0013 - val_acc: 0.9429 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0047 - acc: 0.9647 - rmse: 0.0312 - mse: 0.0047 - r_square: 0.9175 - val_loss: 0.0013 - val_acc: 0.9426 - val_rmse: 0.0210 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9651 - rmse: 0.0327 - mse: 0.0048 - r_square: 0.9093 - val_loss: 0.0013 - val_acc: 0.9159 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9657 - rmse: 0.0345 - mse: 0.0048 - r_square: 0.9148 - val_loss: 0.0014 - val_acc: 0.9430 - val_rmse: 0.0231 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0046 - acc: 0.9663 - rmse: 0.0314 - mse: 0.0046 - r_square: 0.9158 - val_loss: 0.0013 - val_acc: 0.9426 - val_rmse: 0.0216 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9658 - rmse: 0.0369 - mse: 0.0050 - r_square: 0.9114 - val_loss: 0.0015 - val_acc: 0.9431 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9663 - rmse: 0.0341 - mse: 0.0048 - r_square: 0.9112 - val_loss: 0.0014 - val_acc: 0.9424 - val_rmse: 0.0226 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0055 - acc: 0.9659 - rmse: 0.0423 - mse: 0.0055 - r_square: 0.9041 - val_loss: 0.0018 - val_acc: 0.8913 - val_rmse: 0.0316 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0049 - acc: 0.9660 - rmse: 0.0371 - mse: 0.0049 - r_square: 0.9080 - val_loss: 0.0014 - val_acc: 0.9417 - val_rmse: 0.0224 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0058 - acc: 0.9536 - rmse: 0.0459 - mse: 0.0058 - r_square: 0.8976 - val_loss: 0.0021 - val_acc: 0.8505 - val_rmse: 0.0364 - val_mse: 0.0021 - val_r_square: 0.9865\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0050 - acc: 0.9653 - rmse: 0.0379 - mse: 0.0050 - r_square: 0.9054 - val_loss: 0.0013 - val_acc: 0.9161 - val_rmse: 0.0218 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0059 - acc: 0.9599 - rmse: 0.0459 - mse: 0.0059 - r_square: 0.8981 - val_loss: 0.0020 - val_acc: 0.8374 - val_rmse: 0.0347 - val_mse: 0.0020 - val_r_square: 0.9873\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0053 - acc: 0.9612 - rmse: 0.0409 - mse: 0.0053 - r_square: 0.9029 - val_loss: 0.0014 - val_acc: 0.8374 - val_rmse: 0.0228 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0053 - acc: 0.9617 - rmse: 0.0411 - mse: 0.0053 - r_square: 0.9064 - val_loss: 0.0016 - val_acc: 0.8371 - val_rmse: 0.0268 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0054 - acc: 0.9628 - rmse: 0.0419 - mse: 0.0054 - r_square: 0.9038 - val_loss: 0.0017 - val_acc: 0.8372 - val_rmse: 0.0284 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0053 - acc: 0.9276 - rmse: 0.0414 - mse: 0.0053 - r_square: 0.9047 - val_loss: 0.0016 - val_acc: 0.8369 - val_rmse: 0.0265 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0055 - acc: 0.9645 - rmse: 0.0427 - mse: 0.0055 - r_square: 0.9023 - val_loss: 0.0018 - val_acc: 0.8372 - val_rmse: 0.0306 - val_mse: 0.0018 - val_r_square: 0.9892\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0055 - acc: 0.8434 - rmse: 0.0425 - mse: 0.0055 - r_square: 0.9023 - val_loss: 0.0018 - val_acc: 0.8374 - val_rmse: 0.0313 - val_mse: 0.0018 - val_r_square: 0.9888\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0056 - acc: 0.9645 - rmse: 0.0429 - mse: 0.0056 - r_square: 0.9014 - val_loss: 0.0020 - val_acc: 0.8492 - val_rmse: 0.0340 - val_mse: 0.0020 - val_r_square: 0.9876\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0056 - acc: 0.9642 - rmse: 0.0429 - mse: 0.0056 - r_square: 0.9053 - val_loss: 0.0021 - val_acc: 0.8374 - val_rmse: 0.0358 - val_mse: 0.0021 - val_r_square: 0.9867\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0057 - acc: 0.9486 - rmse: 0.0434 - mse: 0.0057 - r_square: 0.9056 - val_loss: 0.0022 - val_acc: 0.8788 - val_rmse: 0.0371 - val_mse: 0.0022 - val_r_square: 0.9861\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0055 - acc: 0.9640 - rmse: 0.0416 - mse: 0.0055 - r_square: 0.9075 - val_loss: 0.0018 - val_acc: 0.8754 - val_rmse: 0.0319 - val_mse: 0.0018 - val_r_square: 0.9885\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0053 - acc: 0.9623 - rmse: 0.0390 - mse: 0.0053 - r_square: 0.9108 - val_loss: 0.0017 - val_acc: 0.8896 - val_rmse: 0.0296 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0051 - acc: 0.9346 - rmse: 0.0364 - mse: 0.0051 - r_square: 0.9116 - val_loss: 0.0014 - val_acc: 0.8902 - val_rmse: 0.0243 - val_mse: 0.0014 - val_r_square: 0.9913\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_11 (GRU)                 (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_11 (RepeatVect (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 7s 1ms/step - loss: 0.0155 - acc: 0.7048 - mse: 0.0155 - rmse: 0.0966 - r_square: 0.6888 - val_loss: 0.0065 - val_acc: 0.9934 - val_mse: 0.0065 - val_rmse: 0.0751 - val_r_square: 0.9553\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0136 - acc: 0.8598 - mse: 0.0136 - rmse: 0.0980 - r_square: 0.6007 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0524 - val_r_square: 0.9761\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0130 - acc: 0.7982 - mse: 0.0130 - rmse: 0.0896 - r_square: 0.6449 - val_loss: 0.0050 - val_acc: 0.8365 - val_mse: 0.0050 - val_rmse: 0.0647 - val_r_square: 0.9655\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0101 - acc: 0.8081 - mse: 0.0101 - rmse: 0.0769 - r_square: 0.7211 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0522 - val_r_square: 0.9767\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0102 - acc: 0.8437 - mse: 0.0102 - rmse: 0.0750 - r_square: 0.7846 - val_loss: 0.0043 - val_acc: 0.8641 - val_mse: 0.0043 - val_rmse: 0.0605 - val_r_square: 0.9708\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0126 - acc: 0.8791 - mse: 0.0126 - rmse: 0.0817 - r_square: 0.7396 - val_loss: 0.0050 - val_acc: 0.8377 - val_mse: 0.0050 - val_rmse: 0.0631 - val_r_square: 0.9681\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0100 - acc: 0.8322 - mse: 0.0100 - rmse: 0.0734 - r_square: 0.7446 - val_loss: 0.0030 - val_acc: 0.8369 - val_mse: 0.0030 - val_rmse: 0.0479 - val_r_square: 0.9804\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0082 - acc: 0.9558 - mse: 0.0082 - rmse: 0.0619 - r_square: 0.8400 - val_loss: 0.0047 - val_acc: 0.8384 - val_mse: 0.0047 - val_rmse: 0.0630 - val_r_square: 0.9675\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0089 - acc: 0.9014 - mse: 0.0089 - rmse: 0.0644 - r_square: 0.7837 - val_loss: 0.0028 - val_acc: 0.9573 - val_mse: 0.0028 - val_rmse: 0.0445 - val_r_square: 0.9808\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0110 - acc: 0.7497 - mse: 0.0110 - rmse: 0.0745 - r_square: 0.7385 - val_loss: 0.0044 - val_acc: 0.9426 - val_mse: 0.0044 - val_rmse: 0.0620 - val_r_square: 0.9697\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0084 - acc: 0.9374 - mse: 0.0084 - rmse: 0.0647 - r_square: 0.7694 - val_loss: 0.0048 - val_acc: 0.8634 - val_mse: 0.0048 - val_rmse: 0.0621 - val_r_square: 0.9665\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0065 - acc: 0.9636 - mse: 0.0065 - rmse: 0.0458 - r_square: 0.8814 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0307 - val_r_square: 0.9891\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0112 - acc: 0.7990 - mse: 0.0112 - rmse: 0.0588 - r_square: 0.8173 - val_loss: 0.0039 - val_acc: 0.9105 - val_mse: 0.0039 - val_rmse: 0.0540 - val_r_square: 0.9753\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0117 - acc: 0.7925 - mse: 0.0117 - rmse: 0.0832 - r_square: 0.6817 - val_loss: 0.0043 - val_acc: 0.8615 - val_mse: 0.0043 - val_rmse: 0.0578 - val_r_square: 0.9728\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0102 - acc: 0.8824 - mse: 0.0102 - rmse: 0.0788 - r_square: 0.6758 - val_loss: 0.0027 - val_acc: 0.8735 - val_mse: 0.0027 - val_rmse: 0.0426 - val_r_square: 0.9830\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0097 - acc: 0.9362 - mse: 0.0097 - rmse: 0.0737 - r_square: 0.7550 - val_loss: 0.0021 - val_acc: 0.8365 - val_mse: 0.0021 - val_rmse: 0.0322 - val_r_square: 0.9878\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0107 - acc: 0.9122 - mse: 0.0107 - rmse: 0.0736 - r_square: 0.7876 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0372 - val_r_square: 0.9861\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0101 - acc: 0.8704 - mse: 0.0101 - rmse: 0.0742 - r_square: 0.7498 - val_loss: 0.0030 - val_acc: 0.8371 - val_mse: 0.0030 - val_rmse: 0.0465 - val_r_square: 0.9797\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0101 - acc: 0.9597 - mse: 0.0101 - rmse: 0.0731 - r_square: 0.8086 - val_loss: 0.0036 - val_acc: 0.9942 - val_mse: 0.0036 - val_rmse: 0.0531 - val_r_square: 0.9760\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0076 - acc: 0.9388 - mse: 0.0076 - rmse: 0.0566 - r_square: 0.8430 - val_loss: 0.0017 - val_acc: 0.9886 - val_mse: 0.0017 - val_rmse: 0.0270 - val_r_square: 0.9898\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0080 - acc: 0.8494 - mse: 0.0080 - rmse: 0.0650 - r_square: 0.7799 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0250 - val_r_square: 0.9910\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0070 - acc: 0.8466 - mse: 0.0070 - rmse: 0.0522 - r_square: 0.8574 - val_loss: 0.0024 - val_acc: 0.9918 - val_mse: 0.0024 - val_rmse: 0.0400 - val_r_square: 0.9837\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0074 - acc: 0.9062 - mse: 0.0074 - rmse: 0.0543 - r_square: 0.8649 - val_loss: 0.0030 - val_acc: 0.9942 - val_mse: 0.0030 - val_rmse: 0.0467 - val_r_square: 0.9803\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0071 - acc: 0.9576 - mse: 0.0071 - rmse: 0.0554 - r_square: 0.8528 - val_loss: 0.0015 - val_acc: 0.8765 - val_mse: 0.0015 - val_rmse: 0.0270 - val_r_square: 0.9905\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0079 - acc: 0.8356 - mse: 0.0079 - rmse: 0.0550 - r_square: 0.8279 - val_loss: 0.0020 - val_acc: 0.9400 - val_mse: 0.0020 - val_rmse: 0.0345 - val_r_square: 0.9870\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0068 - acc: 0.7912 - mse: 0.0068 - rmse: 0.0482 - r_square: 0.8668 - val_loss: 0.0014 - val_acc: 0.8997 - val_mse: 0.0014 - val_rmse: 0.0233 - val_r_square: 0.9918\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0064 - acc: 0.9588 - mse: 0.0064 - rmse: 0.0454 - r_square: 0.8633 - val_loss: 0.0016 - val_acc: 0.9531 - val_mse: 0.0016 - val_rmse: 0.0277 - val_r_square: 0.9896\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0056 - acc: 0.8741 - mse: 0.0056 - rmse: 0.0398 - r_square: 0.8786 - val_loss: 0.0011 - val_acc: 0.9922 - val_mse: 0.0011 - val_rmse: 0.0151 - val_r_square: 0.9936\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0050 - acc: 0.9621 - mse: 0.0050 - rmse: 0.0292 - r_square: 0.9076 - val_loss: 0.0011 - val_acc: 0.9417 - val_mse: 0.0011 - val_rmse: 0.0149 - val_r_square: 0.9937\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0052 - acc: 0.9657 - mse: 0.0052 - rmse: 0.0315 - r_square: 0.9028 - val_loss: 0.0012 - val_acc: 0.9262 - val_mse: 0.0012 - val_rmse: 0.0185 - val_r_square: 0.9929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0052 - acc: 0.9653 - mse: 0.0052 - rmse: 0.0316 - r_square: 0.9005 - val_loss: 0.0011 - val_acc: 0.9525 - val_mse: 0.0011 - val_rmse: 0.0149 - val_r_square: 0.9937\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0050 - acc: 0.9636 - mse: 0.0050 - rmse: 0.0292 - r_square: 0.9061 - val_loss: 0.0011 - val_acc: 0.9408 - val_mse: 0.0011 - val_rmse: 0.0156 - val_r_square: 0.9936\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0048 - acc: 0.9654 - mse: 0.0048 - rmse: 0.0294 - r_square: 0.9107 - val_loss: 0.0012 - val_acc: 0.9406 - val_mse: 0.0012 - val_rmse: 0.0171 - val_r_square: 0.9933\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0048 - acc: 0.9672 - mse: 0.0048 - rmse: 0.0300 - r_square: 0.9084 - val_loss: 0.0011 - val_acc: 0.9394 - val_mse: 0.0011 - val_rmse: 0.0156 - val_r_square: 0.9936\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0056 - acc: 0.9649 - mse: 0.0056 - rmse: 0.0314 - r_square: 0.8867 - val_loss: 0.0011 - val_acc: 0.9542 - val_mse: 0.0011 - val_rmse: 0.0151 - val_r_square: 0.9937\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0052 - acc: 0.9624 - mse: 0.0052 - rmse: 0.0327 - r_square: 0.8965 - val_loss: 0.0012 - val_acc: 0.9535 - val_mse: 0.0012 - val_rmse: 0.0184 - val_r_square: 0.9930\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0050 - acc: 0.9652 - mse: 0.0050 - rmse: 0.0328 - r_square: 0.9101 - val_loss: 0.0012 - val_acc: 0.8759 - val_mse: 0.0012 - val_rmse: 0.0182 - val_r_square: 0.9930\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0052 - acc: 0.9667 - mse: 0.0052 - rmse: 0.0327 - r_square: 0.9020 - val_loss: 0.0012 - val_acc: 0.8791 - val_mse: 0.0012 - val_rmse: 0.0189 - val_r_square: 0.9930\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0063 - acc: 0.9666 - mse: 0.0063 - rmse: 0.0367 - r_square: 0.8709 - val_loss: 0.0013 - val_acc: 0.9560 - val_mse: 0.0013 - val_rmse: 0.0199 - val_r_square: 0.9925\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0071 - acc: 0.9618 - mse: 0.0071 - rmse: 0.0403 - r_square: 0.8422 - val_loss: 0.0015 - val_acc: 0.9378 - val_mse: 0.0015 - val_rmse: 0.0244 - val_r_square: 0.9911\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0053 - acc: 0.9525 - mse: 0.0053 - rmse: 0.0393 - r_square: 0.8888 - val_loss: 0.0013 - val_acc: 0.9421 - val_mse: 0.0013 - val_rmse: 0.0196 - val_r_square: 0.9927\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0068 - acc: 0.9349 - mse: 0.0068 - rmse: 0.0475 - r_square: 0.8509 - val_loss: 0.0014 - val_acc: 0.9803 - val_mse: 0.0014 - val_rmse: 0.0220 - val_r_square: 0.9921\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0054 - acc: 0.9667 - mse: 0.0054 - rmse: 0.0378 - r_square: 0.8989 - val_loss: 0.0019 - val_acc: 0.9407 - val_mse: 0.0019 - val_rmse: 0.0327 - val_r_square: 0.9879\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0058 - acc: 0.9654 - mse: 0.0058 - rmse: 0.0474 - r_square: 0.8850 - val_loss: 0.0012 - val_acc: 0.8759 - val_mse: 0.0012 - val_rmse: 0.0161 - val_r_square: 0.9934\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0055 - acc: 0.9674 - mse: 0.0055 - rmse: 0.0425 - r_square: 0.8920 - val_loss: 0.0014 - val_acc: 0.8371 - val_mse: 0.0014 - val_rmse: 0.0226 - val_r_square: 0.9920\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0059 - acc: 0.7931 - mse: 0.0059 - rmse: 0.0461 - r_square: 0.8896 - val_loss: 0.0033 - val_acc: 0.9942 - val_mse: 0.0033 - val_rmse: 0.0502 - val_r_square: 0.9780\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0058 - acc: 0.9566 - mse: 0.0058 - rmse: 0.0483 - r_square: 0.8782 - val_loss: 0.0019 - val_acc: 0.8366 - val_mse: 0.0019 - val_rmse: 0.0325 - val_r_square: 0.9879\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0059 - acc: 0.8441 - mse: 0.0059 - rmse: 0.0467 - r_square: 0.8872 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0193 - val_r_square: 0.9920\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0057 - acc: 0.8280 - mse: 0.0057 - rmse: 0.0427 - r_square: 0.9012 - val_loss: 0.0028 - val_acc: 0.9942 - val_mse: 0.0028 - val_rmse: 0.0441 - val_r_square: 0.9813\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0053 - acc: 0.9560 - mse: 0.0053 - rmse: 0.0402 - r_square: 0.8997 - val_loss: 0.0013 - val_acc: 0.9922 - val_mse: 0.0013 - val_rmse: 0.0211 - val_r_square: 0.9921\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0048 - acc: 0.9514 - mse: 0.0048 - rmse: 0.0353 - r_square: 0.9055 - val_loss: 0.0012 - val_acc: 0.9770 - val_mse: 0.0012 - val_rmse: 0.0164 - val_r_square: 0.9932\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0048 - acc: 0.9321 - mse: 0.0048 - rmse: 0.0358 - r_square: 0.9075 - val_loss: 0.0011 - val_acc: 0.9886 - val_mse: 0.0011 - val_rmse: 0.0117 - val_r_square: 0.9941\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0049 - acc: 0.9653 - mse: 0.0049 - rmse: 0.0337 - r_square: 0.9112 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0234 - val_r_square: 0.9913\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0047 - acc: 0.9675 - mse: 0.0047 - rmse: 0.0336 - r_square: 0.9147 - val_loss: 0.0012 - val_acc: 0.9882 - val_mse: 0.0012 - val_rmse: 0.0174 - val_r_square: 0.9929\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0047 - acc: 0.9445 - mse: 0.0047 - rmse: 0.0319 - r_square: 0.9147 - val_loss: 0.0012 - val_acc: 0.9889 - val_mse: 0.0012 - val_rmse: 0.0163 - val_r_square: 0.9932\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0048 - acc: 0.9437 - mse: 0.0048 - rmse: 0.0319 - r_square: 0.9107 - val_loss: 0.0013 - val_acc: 0.9942 - val_mse: 0.0013 - val_rmse: 0.0211 - val_r_square: 0.9921\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0048 - acc: 0.9585 - mse: 0.0048 - rmse: 0.0333 - r_square: 0.9099 - val_loss: 0.0013 - val_acc: 0.9885 - val_mse: 0.0013 - val_rmse: 0.0188 - val_r_square: 0.9927\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0048 - acc: 0.9651 - mse: 0.0048 - rmse: 0.0324 - r_square: 0.9116 - val_loss: 0.0012 - val_acc: 0.9506 - val_mse: 0.0012 - val_rmse: 0.0171 - val_r_square: 0.9931\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0047 - acc: 0.9653 - mse: 0.0047 - rmse: 0.0310 - r_square: 0.9149 - val_loss: 0.0012 - val_acc: 0.9414 - val_mse: 0.0012 - val_rmse: 0.0163 - val_r_square: 0.9934\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0047 - acc: 0.9639 - mse: 0.0047 - rmse: 0.0311 - r_square: 0.9149 - val_loss: 0.0013 - val_acc: 0.9424 - val_mse: 0.0013 - val_rmse: 0.0204 - val_r_square: 0.9925\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0048 - acc: 0.9609 - mse: 0.0048 - rmse: 0.0336 - r_square: 0.9108 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0260 - val_r_square: 0.9908\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0047 - acc: 0.9573 - mse: 0.0047 - rmse: 0.0319 - r_square: 0.9148 - val_loss: 0.0012 - val_acc: 0.8365 - val_mse: 0.0012 - val_rmse: 0.0186 - val_r_square: 0.9930\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0048 - acc: 0.9540 - mse: 0.0048 - rmse: 0.0330 - r_square: 0.9133 - val_loss: 0.0013 - val_acc: 0.8365 - val_mse: 0.0013 - val_rmse: 0.0193 - val_r_square: 0.9928\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0047 - acc: 0.9579 - mse: 0.0047 - rmse: 0.0330 - r_square: 0.9135 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0300 - val_r_square: 0.9894\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0050 - acc: 0.9580 - mse: 0.0050 - rmse: 0.0363 - r_square: 0.9107 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0335 - val_r_square: 0.9879\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0050 - acc: 0.8345 - mse: 0.0050 - rmse: 0.0360 - r_square: 0.9073 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0271 - val_r_square: 0.9903\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0049 - acc: 0.9572 - mse: 0.0049 - rmse: 0.0340 - r_square: 0.9136 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0323 - val_r_square: 0.9885\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0049 - acc: 0.9661 - mse: 0.0049 - rmse: 0.0366 - r_square: 0.9062 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0288 - val_r_square: 0.9897\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0048 - acc: 0.8307 - mse: 0.0048 - rmse: 0.0335 - r_square: 0.9089 - val_loss: 0.0012 - val_acc: 0.8365 - val_mse: 0.0012 - val_rmse: 0.0192 - val_r_square: 0.9929\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0051 - acc: 0.9642 - mse: 0.0051 - rmse: 0.0379 - r_square: 0.9071 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0317 - val_r_square: 0.9887\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0047 - acc: 0.9341 - mse: 0.0047 - rmse: 0.0320 - r_square: 0.9156 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0329 - val_r_square: 0.9881\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0050 - acc: 0.9526 - mse: 0.0050 - rmse: 0.0377 - r_square: 0.9048 - val_loss: 0.0031 - val_acc: 0.8365 - val_mse: 0.0031 - val_rmse: 0.0487 - val_r_square: 0.9793\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0050 - acc: 0.9614 - mse: 0.0050 - rmse: 0.0379 - r_square: 0.9061 - val_loss: 0.0018 - val_acc: 0.8365 - val_mse: 0.0018 - val_rmse: 0.0307 - val_r_square: 0.9890\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0050 - acc: 0.9626 - mse: 0.0050 - rmse: 0.0375 - r_square: 0.9082 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0386 - val_r_square: 0.9854\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0058 - acc: 0.9631 - mse: 0.0058 - rmse: 0.0448 - r_square: 0.8959 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0523 - val_r_square: 0.9769\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0050 - acc: 0.9255 - mse: 0.0050 - rmse: 0.0373 - r_square: 0.9062 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0263 - val_r_square: 0.9906\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0051 - acc: 0.9609 - mse: 0.0051 - rmse: 0.0374 - r_square: 0.9042 - val_loss: 0.0015 - val_acc: 0.8483 - val_mse: 0.0015 - val_rmse: 0.0259 - val_r_square: 0.9906\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0052 - acc: 0.9662 - mse: 0.0052 - rmse: 0.0395 - r_square: 0.9052 - val_loss: 0.0025 - val_acc: 0.8365 - val_mse: 0.0025 - val_rmse: 0.0407 - val_r_square: 0.9836\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0052 - acc: 0.9489 - mse: 0.0052 - rmse: 0.0408 - r_square: 0.9040 - val_loss: 0.0028 - val_acc: 0.8365 - val_mse: 0.0028 - val_rmse: 0.0448 - val_r_square: 0.9815\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0054 - acc: 0.9499 - mse: 0.0054 - rmse: 0.0442 - r_square: 0.8870 - val_loss: 0.0013 - val_acc: 0.9495 - val_mse: 0.0013 - val_rmse: 0.0185 - val_r_square: 0.9927\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0053 - acc: 0.9575 - mse: 0.0053 - rmse: 0.0398 - r_square: 0.9068 - val_loss: 0.0022 - val_acc: 0.8365 - val_mse: 0.0022 - val_rmse: 0.0368 - val_r_square: 0.9861\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0062 - acc: 0.9516 - mse: 0.0062 - rmse: 0.0491 - r_square: 0.8880 - val_loss: 0.0049 - val_acc: 0.8365 - val_mse: 0.0049 - val_rmse: 0.0650 - val_r_square: 0.9660\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0052 - acc: 0.9239 - mse: 0.0052 - rmse: 0.0393 - r_square: 0.8974 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0311 - val_r_square: 0.9887\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0060 - acc: 0.9511 - mse: 0.0060 - rmse: 0.0481 - r_square: 0.8769 - val_loss: 0.0019 - val_acc: 0.9849 - val_mse: 0.0019 - val_rmse: 0.0310 - val_r_square: 0.9877\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0053 - acc: 0.9333 - mse: 0.0053 - rmse: 0.0412 - r_square: 0.8966 - val_loss: 0.0031 - val_acc: 0.8365 - val_mse: 0.0031 - val_rmse: 0.0481 - val_r_square: 0.9793\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0055 - acc: 0.9441 - mse: 0.0055 - rmse: 0.0443 - r_square: 0.8784 - val_loss: 0.0014 - val_acc: 0.9935 - val_mse: 0.0014 - val_rmse: 0.0226 - val_r_square: 0.9919\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0052 - acc: 0.9621 - mse: 0.0052 - rmse: 0.0408 - r_square: 0.8940 - val_loss: 0.0014 - val_acc: 0.9931 - val_mse: 0.0014 - val_rmse: 0.0225 - val_r_square: 0.9917\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0056 - acc: 0.9129 - mse: 0.0056 - rmse: 0.0435 - r_square: 0.8879 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0314 - val_r_square: 0.9881\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0051 - acc: 0.9586 - mse: 0.0051 - rmse: 0.0413 - r_square: 0.8996 - val_loss: 0.0012 - val_acc: 0.8387 - val_mse: 0.0012 - val_rmse: 0.0171 - val_r_square: 0.9933\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0054 - acc: 0.9279 - mse: 0.0054 - rmse: 0.0424 - r_square: 0.8589 - val_loss: 0.0012 - val_acc: 0.8375 - val_mse: 0.0012 - val_rmse: 0.0161 - val_r_square: 0.9935\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0056 - acc: 0.9634 - mse: 0.0056 - rmse: 0.0441 - r_square: 0.8807 - val_loss: 0.0012 - val_acc: 0.9941 - val_mse: 0.0012 - val_rmse: 0.0166 - val_r_square: 0.9933\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0052 - acc: 0.9456 - mse: 0.0052 - rmse: 0.0413 - r_square: 0.8961 - val_loss: 0.0015 - val_acc: 0.9911 - val_mse: 0.0015 - val_rmse: 0.0245 - val_r_square: 0.9912\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0052 - acc: 0.9504 - mse: 0.0052 - rmse: 0.0407 - r_square: 0.8924 - val_loss: 0.0014 - val_acc: 0.9921 - val_mse: 0.0014 - val_rmse: 0.0229 - val_r_square: 0.9918\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0052 - acc: 0.9128 - mse: 0.0052 - rmse: 0.0401 - r_square: 0.8955 - val_loss: 0.0019 - val_acc: 0.9587 - val_mse: 0.0019 - val_rmse: 0.0336 - val_r_square: 0.9878\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0052 - acc: 0.8564 - mse: 0.0052 - rmse: 0.0407 - r_square: 0.8933 - val_loss: 0.0014 - val_acc: 0.8368 - val_mse: 0.0014 - val_rmse: 0.0224 - val_r_square: 0.9920\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0058 - acc: 0.8669 - mse: 0.0058 - rmse: 0.0450 - r_square: 0.8261 - val_loss: 0.0012 - val_acc: 0.8392 - val_mse: 0.0012 - val_rmse: 0.0174 - val_r_square: 0.9933\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0052 - acc: 0.9609 - mse: 0.0052 - rmse: 0.0394 - r_square: 0.8923 - val_loss: 0.0011 - val_acc: 0.9164 - val_mse: 0.0011 - val_rmse: 0.0157 - val_r_square: 0.9935\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0051 - acc: 0.9266 - mse: 0.0051 - rmse: 0.0416 - r_square: 0.8910 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0335 - val_r_square: 0.9879\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0051 - acc: 0.9575 - mse: 0.0051 - rmse: 0.0402 - r_square: 0.8888 - val_loss: 0.0014 - val_acc: 0.8486 - val_mse: 0.0014 - val_rmse: 0.0225 - val_r_square: 0.9917\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0053 - acc: 0.8717 - mse: 0.0053 - rmse: 0.0426 - r_square: 0.8819 - val_loss: 0.0012 - val_acc: 0.8365 - val_mse: 0.0012 - val_rmse: 0.0169 - val_r_square: 0.9933\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'GDP ($ per capita)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','GDP ($ per capita)','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 9s 1ms/step - loss: 0.0490 - acc: 0.4882 - rmse: 0.1831 - mse: 0.0490 - r_square: 0.2735 - val_loss: 0.0321 - val_acc: 0.8585 - val_rmse: 0.1680 - val_mse: 0.0321 - val_r_square: 0.8079\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0346 - acc: 0.7694 - rmse: 0.1541 - mse: 0.0346 - r_square: 0.5074 - val_loss: 0.0224 - val_acc: 0.9089 - val_rmse: 0.1236 - val_mse: 0.0224 - val_r_square: 0.8672\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0256 - acc: 0.7854 - rmse: 0.1269 - mse: 0.0256 - r_square: 0.6618 - val_loss: 0.0177 - val_acc: 0.8365 - val_rmse: 0.1215 - val_mse: 0.0177 - val_r_square: 0.8949\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0192 - acc: 0.8485 - rmse: 0.1080 - mse: 0.0192 - r_square: 0.7375 - val_loss: 0.0136 - val_acc: 0.8365 - val_rmse: 0.1061 - val_mse: 0.0136 - val_r_square: 0.9197\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 276us/step - loss: 0.0142 - acc: 0.9131 - rmse: 0.0886 - mse: 0.0142 - r_square: 0.7996 - val_loss: 0.0098 - val_acc: 0.8365 - val_rmse: 0.0854 - val_mse: 0.0098 - val_r_square: 0.9427\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0115 - acc: 0.8961 - rmse: 0.0745 - mse: 0.0115 - r_square: 0.8324 - val_loss: 0.0070 - val_acc: 0.8365 - val_rmse: 0.0722 - val_mse: 0.0070 - val_r_square: 0.9590\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 353us/step - loss: 0.0092 - acc: 0.9219 - rmse: 0.0620 - mse: 0.0092 - r_square: 0.8670 - val_loss: 0.0051 - val_acc: 0.8381 - val_rmse: 0.0567 - val_mse: 0.0051 - val_r_square: 0.9704\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0084 - acc: 0.9174 - rmse: 0.0555 - mse: 0.0084 - r_square: 0.8762 - val_loss: 0.0033 - val_acc: 0.8427 - val_rmse: 0.0437 - val_mse: 0.0033 - val_r_square: 0.9812\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0077 - acc: 0.9198 - rmse: 0.0531 - mse: 0.0077 - r_square: 0.8893 - val_loss: 0.0034 - val_acc: 0.8437 - val_rmse: 0.0467 - val_mse: 0.0034 - val_r_square: 0.9808\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 294us/step - loss: 0.0074 - acc: 0.9318 - rmse: 0.0502 - mse: 0.0074 - r_square: 0.8982 - val_loss: 0.0029 - val_acc: 0.8443 - val_rmse: 0.0409 - val_mse: 0.0029 - val_r_square: 0.9839\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0074 - acc: 0.9037 - rmse: 0.0502 - mse: 0.0074 - r_square: 0.8980 - val_loss: 0.0030 - val_acc: 0.8377 - val_rmse: 0.0409 - val_mse: 0.0030 - val_r_square: 0.9836\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 292us/step - loss: 0.0074 - acc: 0.9379 - rmse: 0.0517 - mse: 0.0074 - r_square: 0.9008 - val_loss: 0.0037 - val_acc: 0.8365 - val_rmse: 0.0421 - val_mse: 0.0037 - val_r_square: 0.9799\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0075 - acc: 0.9134 - rmse: 0.0535 - mse: 0.0075 - r_square: 0.8912 - val_loss: 0.0050 - val_acc: 0.8365 - val_rmse: 0.0614 - val_mse: 0.0050 - val_r_square: 0.9717\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0074 - acc: 0.9025 - rmse: 0.0545 - mse: 0.0074 - r_square: 0.8906 - val_loss: 0.0035 - val_acc: 0.9909 - val_rmse: 0.0474 - val_mse: 0.0035 - val_r_square: 0.9796\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0068 - acc: 0.9391 - rmse: 0.0472 - mse: 0.0068 - r_square: 0.9090 - val_loss: 0.0031 - val_acc: 0.8369 - val_rmse: 0.0449 - val_mse: 0.0031 - val_r_square: 0.9825\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0066 - acc: 0.9306 - rmse: 0.0445 - mse: 0.0066 - r_square: 0.9082 - val_loss: 0.0025 - val_acc: 0.8382 - val_rmse: 0.0389 - val_mse: 0.0025 - val_r_square: 0.9857\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0064 - acc: 0.9392 - rmse: 0.0438 - mse: 0.0064 - r_square: 0.9101 - val_loss: 0.0033 - val_acc: 0.8372 - val_rmse: 0.0467 - val_mse: 0.0033 - val_r_square: 0.9816\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0062 - acc: 0.9412 - rmse: 0.0432 - mse: 0.0062 - r_square: 0.9159 - val_loss: 0.0035 - val_acc: 0.8371 - val_rmse: 0.0496 - val_mse: 0.0035 - val_r_square: 0.9804\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0063 - acc: 0.9367 - rmse: 0.0425 - mse: 0.0063 - r_square: 0.9152 - val_loss: 0.0029 - val_acc: 0.8365 - val_rmse: 0.0399 - val_mse: 0.0029 - val_r_square: 0.9841\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0062 - acc: 0.9383 - rmse: 0.0438 - mse: 0.0062 - r_square: 0.9150 - val_loss: 0.0039 - val_acc: 0.8365 - val_rmse: 0.0531 - val_mse: 0.0039 - val_r_square: 0.9780\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0062 - acc: 0.9391 - rmse: 0.0432 - mse: 0.0062 - r_square: 0.9186 - val_loss: 0.0034 - val_acc: 0.8365 - val_rmse: 0.0463 - val_mse: 0.0034 - val_r_square: 0.9809\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0065 - acc: 0.9353 - rmse: 0.0468 - mse: 0.0065 - r_square: 0.9150 - val_loss: 0.0051 - val_acc: 0.8365 - val_rmse: 0.0656 - val_mse: 0.0051 - val_r_square: 0.9700\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0067 - acc: 0.9319 - rmse: 0.0488 - mse: 0.0067 - r_square: 0.9107 - val_loss: 0.0030 - val_acc: 0.8866 - val_rmse: 0.0452 - val_mse: 0.0030 - val_r_square: 0.9827\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0073 - acc: 0.9341 - rmse: 0.0546 - mse: 0.0073 - r_square: 0.9072 - val_loss: 0.0074 - val_acc: 0.8365 - val_rmse: 0.0813 - val_mse: 0.0074 - val_r_square: 0.9560\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0072 - acc: 0.8937 - rmse: 0.0557 - mse: 0.0072 - r_square: 0.8936 - val_loss: 0.0057 - val_acc: 0.9929 - val_rmse: 0.0663 - val_mse: 0.0057 - val_r_square: 0.9663\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0072 - acc: 0.8952 - rmse: 0.0542 - mse: 0.0072 - r_square: 0.9078 - val_loss: 0.0069 - val_acc: 0.9931 - val_rmse: 0.0771 - val_mse: 0.0069 - val_r_square: 0.9587\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0065 - acc: 0.9026 - rmse: 0.0492 - mse: 0.0065 - r_square: 0.9121 - val_loss: 0.0025 - val_acc: 0.9489 - val_rmse: 0.0392 - val_mse: 0.0025 - val_r_square: 0.9856\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0067 - acc: 0.9368 - rmse: 0.0485 - mse: 0.0067 - r_square: 0.9114 - val_loss: 0.0025 - val_acc: 0.8374 - val_rmse: 0.0372 - val_mse: 0.0025 - val_r_square: 0.9858\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0061 - acc: 0.9388 - rmse: 0.0456 - mse: 0.0061 - r_square: 0.9132 - val_loss: 0.0026 - val_acc: 0.9109 - val_rmse: 0.0391 - val_mse: 0.0026 - val_r_square: 0.9849\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0057 - acc: 0.9423 - rmse: 0.0408 - mse: 0.0057 - r_square: 0.9193 - val_loss: 0.0024 - val_acc: 0.9368 - val_rmse: 0.0370 - val_mse: 0.0024 - val_r_square: 0.9861\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0055 - acc: 0.9440 - rmse: 0.0372 - mse: 0.0055 - r_square: 0.9273 - val_loss: 0.0022 - val_acc: 0.9269 - val_rmse: 0.0350 - val_mse: 0.0022 - val_r_square: 0.9872\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0054 - acc: 0.9470 - rmse: 0.0360 - mse: 0.0054 - r_square: 0.9273 - val_loss: 0.0023 - val_acc: 0.9377 - val_rmse: 0.0358 - val_mse: 0.0023 - val_r_square: 0.9867\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0053 - acc: 0.9519 - rmse: 0.0345 - mse: 0.0053 - r_square: 0.9306 - val_loss: 0.0025 - val_acc: 0.9542 - val_rmse: 0.0376 - val_mse: 0.0025 - val_r_square: 0.9857\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0052 - acc: 0.9527 - rmse: 0.0331 - mse: 0.0052 - r_square: 0.9335 - val_loss: 0.0024 - val_acc: 0.9655 - val_rmse: 0.0370 - val_mse: 0.0024 - val_r_square: 0.9864\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0052 - acc: 0.9543 - rmse: 0.0327 - mse: 0.0052 - r_square: 0.9333 - val_loss: 0.0025 - val_acc: 0.9752 - val_rmse: 0.0383 - val_mse: 0.0025 - val_r_square: 0.9857\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0052 - acc: 0.9526 - rmse: 0.0330 - mse: 0.0052 - r_square: 0.9296 - val_loss: 0.0027 - val_acc: 0.9787 - val_rmse: 0.0391 - val_mse: 0.0027 - val_r_square: 0.9846\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0052 - acc: 0.9462 - rmse: 0.0335 - mse: 0.0052 - r_square: 0.9322 - val_loss: 0.0028 - val_acc: 0.9932 - val_rmse: 0.0409 - val_mse: 0.0028 - val_r_square: 0.9837\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0052 - acc: 0.9540 - rmse: 0.0326 - mse: 0.0052 - r_square: 0.9325 - val_loss: 0.0026 - val_acc: 0.9919 - val_rmse: 0.0398 - val_mse: 0.0026 - val_r_square: 0.9849\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0051 - acc: 0.9522 - rmse: 0.0324 - mse: 0.0051 - r_square: 0.9336 - val_loss: 0.0026 - val_acc: 0.9912 - val_rmse: 0.0399 - val_mse: 0.0026 - val_r_square: 0.9847\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0051 - acc: 0.9477 - rmse: 0.0324 - mse: 0.0051 - r_square: 0.9316 - val_loss: 0.0029 - val_acc: 0.9797 - val_rmse: 0.0409 - val_mse: 0.0029 - val_r_square: 0.9832\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0051 - acc: 0.9466 - rmse: 0.0328 - mse: 0.0051 - r_square: 0.9350 - val_loss: 0.0029 - val_acc: 0.9935 - val_rmse: 0.0415 - val_mse: 0.0029 - val_r_square: 0.9833\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0051 - acc: 0.9561 - rmse: 0.0321 - mse: 0.0051 - r_square: 0.9358 - val_loss: 0.0027 - val_acc: 0.9934 - val_rmse: 0.0416 - val_mse: 0.0027 - val_r_square: 0.9840\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0052 - acc: 0.9517 - rmse: 0.0337 - mse: 0.0052 - r_square: 0.9311 - val_loss: 0.0027 - val_acc: 0.9931 - val_rmse: 0.0406 - val_mse: 0.0027 - val_r_square: 0.9842\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0051 - acc: 0.9467 - rmse: 0.0330 - mse: 0.0051 - r_square: 0.9310 - val_loss: 0.0032 - val_acc: 0.9924 - val_rmse: 0.0435 - val_mse: 0.0032 - val_r_square: 0.9813\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0050 - acc: 0.9476 - rmse: 0.0329 - mse: 0.0050 - r_square: 0.9363 - val_loss: 0.0028 - val_acc: 0.9935 - val_rmse: 0.0414 - val_mse: 0.0028 - val_r_square: 0.9835\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0051 - acc: 0.9557 - rmse: 0.0334 - mse: 0.0051 - r_square: 0.9363 - val_loss: 0.0028 - val_acc: 0.9937 - val_rmse: 0.0422 - val_mse: 0.0028 - val_r_square: 0.9836\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0051 - acc: 0.9537 - rmse: 0.0341 - mse: 0.0051 - r_square: 0.9324 - val_loss: 0.0027 - val_acc: 0.9934 - val_rmse: 0.0402 - val_mse: 0.0027 - val_r_square: 0.9840\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9487 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9341 - val_loss: 0.0031 - val_acc: 0.9935 - val_rmse: 0.0429 - val_mse: 0.0031 - val_r_square: 0.9820\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9550 - rmse: 0.0327 - mse: 0.0050 - r_square: 0.9364 - val_loss: 0.0028 - val_acc: 0.9938 - val_rmse: 0.0413 - val_mse: 0.0028 - val_r_square: 0.9838\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0052 - acc: 0.9565 - rmse: 0.0342 - mse: 0.0052 - r_square: 0.9347 - val_loss: 0.0028 - val_acc: 0.9940 - val_rmse: 0.0407 - val_mse: 0.0028 - val_r_square: 0.9839\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9545 - rmse: 0.0326 - mse: 0.0050 - r_square: 0.9331 - val_loss: 0.0029 - val_acc: 0.9937 - val_rmse: 0.0415 - val_mse: 0.0029 - val_r_square: 0.9833\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9576 - rmse: 0.0321 - mse: 0.0050 - r_square: 0.9379 - val_loss: 0.0028 - val_acc: 0.9938 - val_rmse: 0.0405 - val_mse: 0.0028 - val_r_square: 0.9839\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0050 - acc: 0.9574 - rmse: 0.0334 - mse: 0.0050 - r_square: 0.9371 - val_loss: 0.0029 - val_acc: 0.9941 - val_rmse: 0.0421 - val_mse: 0.0029 - val_r_square: 0.9832\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0050 - acc: 0.9574 - rmse: 0.0327 - mse: 0.0050 - r_square: 0.9364 - val_loss: 0.0028 - val_acc: 0.9941 - val_rmse: 0.0411 - val_mse: 0.0028 - val_r_square: 0.9839\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0049 - acc: 0.9543 - rmse: 0.0321 - mse: 0.0049 - r_square: 0.9377 - val_loss: 0.0026 - val_acc: 0.9941 - val_rmse: 0.0394 - val_mse: 0.0026 - val_r_square: 0.9846\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0049 - acc: 0.9585 - rmse: 0.0316 - mse: 0.0049 - r_square: 0.9380 - val_loss: 0.0028 - val_acc: 0.9941 - val_rmse: 0.0410 - val_mse: 0.0028 - val_r_square: 0.9837\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0051 - acc: 0.9564 - rmse: 0.0334 - mse: 0.0051 - r_square: 0.9351 - val_loss: 0.0027 - val_acc: 0.9941 - val_rmse: 0.0395 - val_mse: 0.0027 - val_r_square: 0.9844\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9567 - rmse: 0.0316 - mse: 0.0050 - r_square: 0.9357 - val_loss: 0.0026 - val_acc: 0.9941 - val_rmse: 0.0397 - val_mse: 0.0026 - val_r_square: 0.9847\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0050 - acc: 0.9530 - rmse: 0.0319 - mse: 0.0050 - r_square: 0.9359 - val_loss: 0.0025 - val_acc: 0.9937 - val_rmse: 0.0380 - val_mse: 0.0025 - val_r_square: 0.9853\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0050 - acc: 0.9578 - rmse: 0.0318 - mse: 0.0050 - r_square: 0.9384 - val_loss: 0.0027 - val_acc: 0.9941 - val_rmse: 0.0396 - val_mse: 0.0027 - val_r_square: 0.9844\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0049 - acc: 0.9562 - rmse: 0.0312 - mse: 0.0049 - r_square: 0.9373 - val_loss: 0.0026 - val_acc: 0.9941 - val_rmse: 0.0387 - val_mse: 0.0026 - val_r_square: 0.9851\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0049 - acc: 0.9566 - rmse: 0.0302 - mse: 0.0049 - r_square: 0.9393 - val_loss: 0.0025 - val_acc: 0.9941 - val_rmse: 0.0381 - val_mse: 0.0025 - val_r_square: 0.9854\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0049 - acc: 0.9566 - rmse: 0.0308 - mse: 0.0049 - r_square: 0.9383 - val_loss: 0.0026 - val_acc: 0.9941 - val_rmse: 0.0388 - val_mse: 0.0026 - val_r_square: 0.9847\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0049 - acc: 0.9592 - rmse: 0.0313 - mse: 0.0049 - r_square: 0.9387 - val_loss: 0.0026 - val_acc: 0.9941 - val_rmse: 0.0383 - val_mse: 0.0026 - val_r_square: 0.9852\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9534 - rmse: 0.0302 - mse: 0.0048 - r_square: 0.9393 - val_loss: 0.0025 - val_acc: 0.9938 - val_rmse: 0.0378 - val_mse: 0.0025 - val_r_square: 0.9856\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0049 - acc: 0.9577 - rmse: 0.0305 - mse: 0.0049 - r_square: 0.9385 - val_loss: 0.0025 - val_acc: 0.9813 - val_rmse: 0.0374 - val_mse: 0.0025 - val_r_square: 0.9855\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9581 - rmse: 0.0316 - mse: 0.0050 - r_square: 0.9375 - val_loss: 0.0026 - val_acc: 0.9830 - val_rmse: 0.0381 - val_mse: 0.0026 - val_r_square: 0.9851\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0049 - acc: 0.9554 - rmse: 0.0305 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0024 - val_acc: 0.9823 - val_rmse: 0.0373 - val_mse: 0.0024 - val_r_square: 0.9859\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9572 - rmse: 0.0297 - mse: 0.0048 - r_square: 0.9403 - val_loss: 0.0025 - val_acc: 0.9688 - val_rmse: 0.0373 - val_mse: 0.0025 - val_r_square: 0.9857\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0049 - acc: 0.9575 - rmse: 0.0310 - mse: 0.0049 - r_square: 0.9393 - val_loss: 0.0026 - val_acc: 0.9689 - val_rmse: 0.0380 - val_mse: 0.0026 - val_r_square: 0.9850\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9595 - rmse: 0.0307 - mse: 0.0048 - r_square: 0.9394 - val_loss: 0.0025 - val_acc: 0.9693 - val_rmse: 0.0377 - val_mse: 0.0025 - val_r_square: 0.9858\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9508 - rmse: 0.0304 - mse: 0.0048 - r_square: 0.9399 - val_loss: 0.0024 - val_acc: 0.9683 - val_rmse: 0.0369 - val_mse: 0.0024 - val_r_square: 0.9861\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0049 - acc: 0.9551 - rmse: 0.0316 - mse: 0.0049 - r_square: 0.9362 - val_loss: 0.0027 - val_acc: 0.9444 - val_rmse: 0.0396 - val_mse: 0.0027 - val_r_square: 0.9843\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9567 - rmse: 0.0331 - mse: 0.0050 - r_square: 0.9360 - val_loss: 0.0024 - val_acc: 0.9325 - val_rmse: 0.0361 - val_mse: 0.0024 - val_r_square: 0.9865\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9527 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9393 - val_loss: 0.0025 - val_acc: 0.9679 - val_rmse: 0.0378 - val_mse: 0.0025 - val_r_square: 0.9857\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9561 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9389 - val_loss: 0.0025 - val_acc: 0.9433 - val_rmse: 0.0374 - val_mse: 0.0025 - val_r_square: 0.9855\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9512 - rmse: 0.0327 - mse: 0.0050 - r_square: 0.9382 - val_loss: 0.0025 - val_acc: 0.9430 - val_rmse: 0.0371 - val_mse: 0.0025 - val_r_square: 0.9858\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9545 - rmse: 0.0304 - mse: 0.0048 - r_square: 0.9385 - val_loss: 0.0024 - val_acc: 0.9168 - val_rmse: 0.0371 - val_mse: 0.0024 - val_r_square: 0.9862\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0049 - acc: 0.9541 - rmse: 0.0317 - mse: 0.0049 - r_square: 0.9374 - val_loss: 0.0026 - val_acc: 0.9430 - val_rmse: 0.0387 - val_mse: 0.0026 - val_r_square: 0.9850\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9457 - rmse: 0.0344 - mse: 0.0050 - r_square: 0.9367 - val_loss: 0.0024 - val_acc: 0.9309 - val_rmse: 0.0366 - val_mse: 0.0024 - val_r_square: 0.9860\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9562 - rmse: 0.0316 - mse: 0.0048 - r_square: 0.9388 - val_loss: 0.0025 - val_acc: 0.8905 - val_rmse: 0.0386 - val_mse: 0.0025 - val_r_square: 0.9857\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9521 - rmse: 0.0311 - mse: 0.0048 - r_square: 0.9401 - val_loss: 0.0025 - val_acc: 0.9427 - val_rmse: 0.0378 - val_mse: 0.0025 - val_r_square: 0.9855\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9337 - rmse: 0.0355 - mse: 0.0051 - r_square: 0.9359 - val_loss: 0.0026 - val_acc: 0.9151 - val_rmse: 0.0389 - val_mse: 0.0026 - val_r_square: 0.9851\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 272us/step - loss: 0.0050 - acc: 0.9463 - rmse: 0.0331 - mse: 0.0050 - r_square: 0.9356 - val_loss: 0.0023 - val_acc: 0.8503 - val_rmse: 0.0364 - val_mse: 0.0023 - val_r_square: 0.9869\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0051 - acc: 0.9445 - rmse: 0.0345 - mse: 0.0051 - r_square: 0.9345 - val_loss: 0.0028 - val_acc: 0.9167 - val_rmse: 0.0412 - val_mse: 0.0028 - val_r_square: 0.9839\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9224 - rmse: 0.0379 - mse: 0.0053 - r_square: 0.9331 - val_loss: 0.0024 - val_acc: 0.8372 - val_rmse: 0.0368 - val_mse: 0.0024 - val_r_square: 0.9867\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0050 - acc: 0.9413 - rmse: 0.0340 - mse: 0.0050 - r_square: 0.9371 - val_loss: 0.0024 - val_acc: 0.8751 - val_rmse: 0.0376 - val_mse: 0.0024 - val_r_square: 0.9862\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0052 - acc: 0.9303 - rmse: 0.0367 - mse: 0.0052 - r_square: 0.9348 - val_loss: 0.0028 - val_acc: 0.8614 - val_rmse: 0.0425 - val_mse: 0.0028 - val_r_square: 0.9837\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0053 - acc: 0.9278 - rmse: 0.0382 - mse: 0.0053 - r_square: 0.9343 - val_loss: 0.0022 - val_acc: 0.8371 - val_rmse: 0.0340 - val_mse: 0.0022 - val_r_square: 0.9878\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0054 - acc: 0.9353 - rmse: 0.0390 - mse: 0.0054 - r_square: 0.9316 - val_loss: 0.0031 - val_acc: 0.9008 - val_rmse: 0.0449 - val_mse: 0.0031 - val_r_square: 0.9822\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0053 - acc: 0.9249 - rmse: 0.0377 - mse: 0.0053 - r_square: 0.9335 - val_loss: 0.0021 - val_acc: 0.8371 - val_rmse: 0.0322 - val_mse: 0.0021 - val_r_square: 0.9886\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0056 - acc: 0.9271 - rmse: 0.0403 - mse: 0.0056 - r_square: 0.9276 - val_loss: 0.0029 - val_acc: 0.8371 - val_rmse: 0.0433 - val_mse: 0.0029 - val_r_square: 0.9837\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0061 - acc: 0.9118 - rmse: 0.0461 - mse: 0.0061 - r_square: 0.9238 - val_loss: 0.0026 - val_acc: 0.8371 - val_rmse: 0.0390 - val_mse: 0.0026 - val_r_square: 0.9855\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0062 - acc: 0.9111 - rmse: 0.0467 - mse: 0.0062 - r_square: 0.9232 - val_loss: 0.0029 - val_acc: 0.8371 - val_rmse: 0.0418 - val_mse: 0.0029 - val_r_square: 0.9839\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0060 - acc: 0.9192 - rmse: 0.0451 - mse: 0.0060 - r_square: 0.9247 - val_loss: 0.0030 - val_acc: 0.8371 - val_rmse: 0.0447 - val_mse: 0.0030 - val_r_square: 0.9831\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0059 - acc: 0.9202 - rmse: 0.0452 - mse: 0.0059 - r_square: 0.9266 - val_loss: 0.0023 - val_acc: 0.8371 - val_rmse: 0.0355 - val_mse: 0.0023 - val_r_square: 0.9873\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0059 - acc: 0.9299 - rmse: 0.0445 - mse: 0.0059 - r_square: 0.9258 - val_loss: 0.0021 - val_acc: 0.8617 - val_rmse: 0.0334 - val_mse: 0.0021 - val_r_square: 0.9881\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0053 - acc: 0.9304 - rmse: 0.0376 - mse: 0.0053 - r_square: 0.9330 - val_loss: 0.0018 - val_acc: 0.8621 - val_rmse: 0.0286 - val_mse: 0.0018 - val_r_square: 0.9898\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9466 - rmse: 0.0318 - mse: 0.0050 - r_square: 0.9380 - val_loss: 0.0021 - val_acc: 0.9547 - val_rmse: 0.0324 - val_mse: 0.0021 - val_r_square: 0.9881\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9585 - rmse: 0.0319 - mse: 0.0049 - r_square: 0.9365 - val_loss: 0.0020 - val_acc: 0.9552 - val_rmse: 0.0304 - val_mse: 0.0020 - val_r_square: 0.9888\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 11s 2ms/step - loss: 0.0291 - acc: 0.5711 - rmse: 0.1430 - mse: 0.0291 - r_square: 0.3864 - val_loss: 0.0077 - val_acc: 0.8830 - val_rmse: 0.0781 - val_mse: 0.0077 - val_r_square: 0.9561\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0159 - acc: 0.8033 - rmse: 0.0954 - mse: 0.0159 - r_square: 0.7515 - val_loss: 0.0101 - val_acc: 0.8365 - val_rmse: 0.0960 - val_mse: 0.0101 - val_r_square: 0.9399\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0134 - acc: 0.8460 - rmse: 0.0841 - mse: 0.0134 - r_square: 0.8148 - val_loss: 0.0054 - val_acc: 0.8365 - val_rmse: 0.0660 - val_mse: 0.0054 - val_r_square: 0.9685\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0081 - acc: 0.9161 - rmse: 0.0541 - mse: 0.0081 - r_square: 0.8907 - val_loss: 0.0022 - val_acc: 0.8365 - val_rmse: 0.0297 - val_mse: 0.0022 - val_r_square: 0.9879\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0069 - acc: 0.9261 - rmse: 0.0413 - mse: 0.0069 - r_square: 0.9103 - val_loss: 0.0025 - val_acc: 0.8725 - val_rmse: 0.0358 - val_mse: 0.0025 - val_r_square: 0.9860\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0066 - acc: 0.9314 - rmse: 0.0420 - mse: 0.0066 - r_square: 0.9118 - val_loss: 0.0025 - val_acc: 0.8520 - val_rmse: 0.0366 - val_mse: 0.0025 - val_r_square: 0.9860\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0062 - acc: 0.9380 - rmse: 0.0391 - mse: 0.0062 - r_square: 0.9196 - val_loss: 0.0019 - val_acc: 0.8427 - val_rmse: 0.0258 - val_mse: 0.0019 - val_r_square: 0.9900\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0062 - acc: 0.9374 - rmse: 0.0383 - mse: 0.0062 - r_square: 0.9198 - val_loss: 0.0021 - val_acc: 0.8387 - val_rmse: 0.0304 - val_mse: 0.0021 - val_r_square: 0.9886\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0062 - acc: 0.9338 - rmse: 0.0402 - mse: 0.0062 - r_square: 0.9122 - val_loss: 0.0031 - val_acc: 0.9413 - val_rmse: 0.0448 - val_mse: 0.0031 - val_r_square: 0.9819\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0058 - acc: 0.9414 - rmse: 0.0373 - mse: 0.0058 - r_square: 0.9243 - val_loss: 0.0021 - val_acc: 0.8818 - val_rmse: 0.0318 - val_mse: 0.0021 - val_r_square: 0.9884\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0058 - acc: 0.9385 - rmse: 0.0353 - mse: 0.0058 - r_square: 0.9265 - val_loss: 0.0020 - val_acc: 0.8395 - val_rmse: 0.0287 - val_mse: 0.0020 - val_r_square: 0.9893\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0058 - acc: 0.9433 - rmse: 0.0367 - mse: 0.0058 - r_square: 0.9193 - val_loss: 0.0025 - val_acc: 0.8523 - val_rmse: 0.0389 - val_mse: 0.0025 - val_r_square: 0.9857\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0057 - acc: 0.9435 - rmse: 0.0382 - mse: 0.0057 - r_square: 0.9219 - val_loss: 0.0029 - val_acc: 0.9691 - val_rmse: 0.0426 - val_mse: 0.0029 - val_r_square: 0.9833\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0054 - acc: 0.9472 - rmse: 0.0336 - mse: 0.0054 - r_square: 0.9316 - val_loss: 0.0020 - val_acc: 0.8434 - val_rmse: 0.0309 - val_mse: 0.0020 - val_r_square: 0.9892\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0056 - acc: 0.9439 - rmse: 0.0351 - mse: 0.0056 - r_square: 0.9271 - val_loss: 0.0021 - val_acc: 0.8384 - val_rmse: 0.0318 - val_mse: 0.0021 - val_r_square: 0.9887\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0056 - acc: 0.9496 - rmse: 0.0373 - mse: 0.0056 - r_square: 0.9221 - val_loss: 0.0028 - val_acc: 0.9430 - val_rmse: 0.0423 - val_mse: 0.0028 - val_r_square: 0.9838\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0052 - acc: 0.9521 - rmse: 0.0331 - mse: 0.0052 - r_square: 0.9344 - val_loss: 0.0022 - val_acc: 0.8805 - val_rmse: 0.0349 - val_mse: 0.0022 - val_r_square: 0.9878\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0053 - acc: 0.9497 - rmse: 0.0327 - mse: 0.0053 - r_square: 0.9326 - val_loss: 0.0020 - val_acc: 0.8394 - val_rmse: 0.0326 - val_mse: 0.0020 - val_r_square: 0.9886\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0054 - acc: 0.9534 - rmse: 0.0346 - mse: 0.0054 - r_square: 0.9246 - val_loss: 0.0023 - val_acc: 0.8659 - val_rmse: 0.0370 - val_mse: 0.0023 - val_r_square: 0.9867\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0056 - acc: 0.9539 - rmse: 0.0343 - mse: 0.0056 - r_square: 0.9244 - val_loss: 0.0021 - val_acc: 0.8919 - val_rmse: 0.0339 - val_mse: 0.0021 - val_r_square: 0.9881\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0059 - acc: 0.9509 - rmse: 0.0334 - mse: 0.0059 - r_square: 0.9176 - val_loss: 0.0022 - val_acc: 0.8397 - val_rmse: 0.0353 - val_mse: 0.0022 - val_r_square: 0.9878\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0055 - acc: 0.9529 - rmse: 0.0328 - mse: 0.0055 - r_square: 0.9217 - val_loss: 0.0018 - val_acc: 0.8392 - val_rmse: 0.0293 - val_mse: 0.0018 - val_r_square: 0.9898\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0052 - acc: 0.9533 - rmse: 0.0330 - mse: 0.0052 - r_square: 0.9308 - val_loss: 0.0020 - val_acc: 0.8647 - val_rmse: 0.0311 - val_mse: 0.0020 - val_r_square: 0.9891\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0051 - acc: 0.9556 - rmse: 0.0306 - mse: 0.0051 - r_square: 0.9367 - val_loss: 0.0022 - val_acc: 0.8395 - val_rmse: 0.0354 - val_mse: 0.0022 - val_r_square: 0.9878\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0051 - acc: 0.9512 - rmse: 0.0308 - mse: 0.0051 - r_square: 0.9333 - val_loss: 0.0019 - val_acc: 0.8385 - val_rmse: 0.0307 - val_mse: 0.0019 - val_r_square: 0.9895\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0051 - acc: 0.9508 - rmse: 0.0322 - mse: 0.0051 - r_square: 0.9315 - val_loss: 0.0018 - val_acc: 0.8388 - val_rmse: 0.0282 - val_mse: 0.0018 - val_r_square: 0.9901\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0049 - acc: 0.9566 - rmse: 0.0299 - mse: 0.0049 - r_square: 0.9381 - val_loss: 0.0019 - val_acc: 0.8388 - val_rmse: 0.0311 - val_mse: 0.0019 - val_r_square: 0.9894\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0050 - acc: 0.9514 - rmse: 0.0299 - mse: 0.0050 - r_square: 0.9370 - val_loss: 0.0020 - val_acc: 0.8384 - val_rmse: 0.0323 - val_mse: 0.0020 - val_r_square: 0.9890\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0050 - acc: 0.9502 - rmse: 0.0305 - mse: 0.0050 - r_square: 0.9343 - val_loss: 0.0017 - val_acc: 0.8375 - val_rmse: 0.0256 - val_mse: 0.0017 - val_r_square: 0.9910\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0049 - acc: 0.9571 - rmse: 0.0303 - mse: 0.0049 - r_square: 0.9379 - val_loss: 0.0017 - val_acc: 0.8382 - val_rmse: 0.0267 - val_mse: 0.0017 - val_r_square: 0.9907\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 323us/step - loss: 0.0049 - acc: 0.9542 - rmse: 0.0303 - mse: 0.0049 - r_square: 0.9375 - val_loss: 0.0020 - val_acc: 0.8372 - val_rmse: 0.0332 - val_mse: 0.0020 - val_r_square: 0.9887\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0049 - acc: 0.9490 - rmse: 0.0312 - mse: 0.0049 - r_square: 0.9350 - val_loss: 0.0016 - val_acc: 0.8372 - val_rmse: 0.0236 - val_mse: 0.0016 - val_r_square: 0.9915\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0050 - acc: 0.9509 - rmse: 0.0320 - mse: 0.0050 - r_square: 0.9368 - val_loss: 0.0017 - val_acc: 0.8372 - val_rmse: 0.0268 - val_mse: 0.0017 - val_r_square: 0.9907\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0049 - acc: 0.9546 - rmse: 0.0308 - mse: 0.0049 - r_square: 0.9379 - val_loss: 0.0020 - val_acc: 0.8369 - val_rmse: 0.0322 - val_mse: 0.0020 - val_r_square: 0.9891\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0050 - acc: 0.9458 - rmse: 0.0323 - mse: 0.0050 - r_square: 0.9354 - val_loss: 0.0017 - val_acc: 0.8368 - val_rmse: 0.0260 - val_mse: 0.0017 - val_r_square: 0.9910\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0050 - acc: 0.9503 - rmse: 0.0338 - mse: 0.0050 - r_square: 0.9359 - val_loss: 0.0016 - val_acc: 0.8369 - val_rmse: 0.0244 - val_mse: 0.0016 - val_r_square: 0.9914\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0049 - acc: 0.9551 - rmse: 0.0313 - mse: 0.0049 - r_square: 0.9381 - val_loss: 0.0021 - val_acc: 0.8365 - val_rmse: 0.0340 - val_mse: 0.0021 - val_r_square: 0.9884\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9445 - rmse: 0.0339 - mse: 0.0050 - r_square: 0.9342 - val_loss: 0.0015 - val_acc: 0.8365 - val_rmse: 0.0226 - val_mse: 0.0015 - val_r_square: 0.9917\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0052 - acc: 0.9448 - rmse: 0.0363 - mse: 0.0052 - r_square: 0.9342 - val_loss: 0.0020 - val_acc: 0.8365 - val_rmse: 0.0335 - val_mse: 0.0020 - val_r_square: 0.9886\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9529 - rmse: 0.0326 - mse: 0.0050 - r_square: 0.9377 - val_loss: 0.0019 - val_acc: 0.8365 - val_rmse: 0.0316 - val_mse: 0.0019 - val_r_square: 0.9892\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0051 - acc: 0.9435 - rmse: 0.0358 - mse: 0.0051 - r_square: 0.9333 - val_loss: 0.0019 - val_acc: 0.8365 - val_rmse: 0.0288 - val_mse: 0.0019 - val_r_square: 0.9898\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0054 - acc: 0.9512 - rmse: 0.0383 - mse: 0.0054 - r_square: 0.9344 - val_loss: 0.0023 - val_acc: 0.8365 - val_rmse: 0.0374 - val_mse: 0.0023 - val_r_square: 0.9869\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0052 - acc: 0.9488 - rmse: 0.0359 - mse: 0.0052 - r_square: 0.9354 - val_loss: 0.0026 - val_acc: 0.8365 - val_rmse: 0.0402 - val_mse: 0.0026 - val_r_square: 0.9856\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0056 - acc: 0.9371 - rmse: 0.0412 - mse: 0.0056 - r_square: 0.9267 - val_loss: 0.0019 - val_acc: 0.8990 - val_rmse: 0.0294 - val_mse: 0.0019 - val_r_square: 0.9897\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0058 - acc: 0.9463 - rmse: 0.0422 - mse: 0.0058 - r_square: 0.9278 - val_loss: 0.0032 - val_acc: 0.8365 - val_rmse: 0.0477 - val_mse: 0.0032 - val_r_square: 0.9818\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0060 - acc: 0.9378 - rmse: 0.0448 - mse: 0.0060 - r_square: 0.9212 - val_loss: 0.0020 - val_acc: 0.9665 - val_rmse: 0.0310 - val_mse: 0.0020 - val_r_square: 0.9888\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0060 - acc: 0.9414 - rmse: 0.0456 - mse: 0.0060 - r_square: 0.9259 - val_loss: 0.0029 - val_acc: 0.9365 - val_rmse: 0.0444 - val_mse: 0.0029 - val_r_square: 0.9834\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0060 - acc: 0.9435 - rmse: 0.0456 - mse: 0.0060 - r_square: 0.9264 - val_loss: 0.0030 - val_acc: 0.9940 - val_rmse: 0.0446 - val_mse: 0.0030 - val_r_square: 0.9830\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0057 - acc: 0.9182 - rmse: 0.0431 - mse: 0.0057 - r_square: 0.9285 - val_loss: 0.0025 - val_acc: 0.9940 - val_rmse: 0.0382 - val_mse: 0.0025 - val_r_square: 0.9860\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0059 - acc: 0.9165 - rmse: 0.0456 - mse: 0.0059 - r_square: 0.9254 - val_loss: 0.0024 - val_acc: 0.9912 - val_rmse: 0.0369 - val_mse: 0.0024 - val_r_square: 0.9866\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0059 - acc: 0.9355 - rmse: 0.0458 - mse: 0.0059 - r_square: 0.9235 - val_loss: 0.0021 - val_acc: 0.9519 - val_rmse: 0.0331 - val_mse: 0.0021 - val_r_square: 0.9882\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0056 - acc: 0.9383 - rmse: 0.0417 - mse: 0.0056 - r_square: 0.9287 - val_loss: 0.0019 - val_acc: 0.8623 - val_rmse: 0.0277 - val_mse: 0.0019 - val_r_square: 0.9899\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0054 - acc: 0.9412 - rmse: 0.0399 - mse: 0.0054 - r_square: 0.9320 - val_loss: 0.0018 - val_acc: 0.8368 - val_rmse: 0.0281 - val_mse: 0.0018 - val_r_square: 0.9900\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0052 - acc: 0.9462 - rmse: 0.0366 - mse: 0.0052 - r_square: 0.9356 - val_loss: 0.0019 - val_acc: 0.8371 - val_rmse: 0.0311 - val_mse: 0.0019 - val_r_square: 0.9893\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0050 - acc: 0.9486 - rmse: 0.0345 - mse: 0.0050 - r_square: 0.9371 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0271 - val_mse: 0.0017 - val_r_square: 0.9905\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9521 - rmse: 0.0322 - mse: 0.0049 - r_square: 0.9387 - val_loss: 0.0017 - val_acc: 0.8368 - val_rmse: 0.0269 - val_mse: 0.0017 - val_r_square: 0.9906\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0049 - acc: 0.9514 - rmse: 0.0310 - mse: 0.0049 - r_square: 0.9404 - val_loss: 0.0018 - val_acc: 0.8368 - val_rmse: 0.0284 - val_mse: 0.0018 - val_r_square: 0.9902\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9532 - rmse: 0.0310 - mse: 0.0049 - r_square: 0.9404 - val_loss: 0.0019 - val_acc: 0.8375 - val_rmse: 0.0299 - val_mse: 0.0019 - val_r_square: 0.9896\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0049 - acc: 0.9495 - rmse: 0.0312 - mse: 0.0049 - r_square: 0.9387 - val_loss: 0.0017 - val_acc: 0.8371 - val_rmse: 0.0274 - val_mse: 0.0017 - val_r_square: 0.9904\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 3s 412us/step - loss: 0.0049 - acc: 0.9488 - rmse: 0.0301 - mse: 0.0049 - r_square: 0.9384 - val_loss: 0.0018 - val_acc: 0.8509 - val_rmse: 0.0276 - val_mse: 0.0018 - val_r_square: 0.9903\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 3s 389us/step - loss: 0.0049 - acc: 0.9520 - rmse: 0.0301 - mse: 0.0049 - r_square: 0.9392 - val_loss: 0.0019 - val_acc: 0.8377 - val_rmse: 0.0299 - val_mse: 0.0019 - val_r_square: 0.9896\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 3s 418us/step - loss: 0.0049 - acc: 0.9585 - rmse: 0.0309 - mse: 0.0049 - r_square: 0.9378 - val_loss: 0.0018 - val_acc: 0.8398 - val_rmse: 0.0288 - val_mse: 0.0018 - val_r_square: 0.9899\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 346us/step - loss: 0.0048 - acc: 0.9545 - rmse: 0.0294 - mse: 0.0048 - r_square: 0.9408 - val_loss: 0.0018 - val_acc: 0.8752 - val_rmse: 0.0289 - val_mse: 0.0018 - val_r_square: 0.9898\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 343us/step - loss: 0.0048 - acc: 0.9518 - rmse: 0.0294 - mse: 0.0048 - r_square: 0.9415 - val_loss: 0.0019 - val_acc: 0.8630 - val_rmse: 0.0296 - val_mse: 0.0019 - val_r_square: 0.9896\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 344us/step - loss: 0.0048 - acc: 0.9596 - rmse: 0.0295 - mse: 0.0048 - r_square: 0.9415 - val_loss: 0.0019 - val_acc: 0.8631 - val_rmse: 0.0300 - val_mse: 0.0019 - val_r_square: 0.9894\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0048 - acc: 0.9580 - rmse: 0.0297 - mse: 0.0048 - r_square: 0.9403 - val_loss: 0.0019 - val_acc: 0.8755 - val_rmse: 0.0297 - val_mse: 0.0019 - val_r_square: 0.9895\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0048 - acc: 0.9580 - rmse: 0.0295 - mse: 0.0048 - r_square: 0.9405 - val_loss: 0.0019 - val_acc: 0.8756 - val_rmse: 0.0307 - val_mse: 0.0019 - val_r_square: 0.9892\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0049 - acc: 0.9585 - rmse: 0.0304 - mse: 0.0049 - r_square: 0.9384 - val_loss: 0.0019 - val_acc: 0.8631 - val_rmse: 0.0308 - val_mse: 0.0019 - val_r_square: 0.9891\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0048 - acc: 0.9596 - rmse: 0.0298 - mse: 0.0048 - r_square: 0.9409 - val_loss: 0.0020 - val_acc: 0.8756 - val_rmse: 0.0313 - val_mse: 0.0020 - val_r_square: 0.9889\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0048 - acc: 0.9602 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9410 - val_loss: 0.0020 - val_acc: 0.8759 - val_rmse: 0.0312 - val_mse: 0.0020 - val_r_square: 0.9889\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9604 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9416 - val_loss: 0.0020 - val_acc: 0.8756 - val_rmse: 0.0321 - val_mse: 0.0020 - val_r_square: 0.9886\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0048 - acc: 0.9603 - rmse: 0.0301 - mse: 0.0048 - r_square: 0.9415 - val_loss: 0.0020 - val_acc: 0.8761 - val_rmse: 0.0320 - val_mse: 0.0020 - val_r_square: 0.9886\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0048 - acc: 0.9604 - rmse: 0.0303 - mse: 0.0048 - r_square: 0.9415 - val_loss: 0.0021 - val_acc: 0.8771 - val_rmse: 0.0328 - val_mse: 0.0021 - val_r_square: 0.9883\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9602 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9411 - val_loss: 0.0021 - val_acc: 0.8889 - val_rmse: 0.0327 - val_mse: 0.0021 - val_r_square: 0.9883\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9607 - rmse: 0.0308 - mse: 0.0048 - r_square: 0.9408 - val_loss: 0.0021 - val_acc: 0.8889 - val_rmse: 0.0336 - val_mse: 0.0021 - val_r_square: 0.9880\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0049 - acc: 0.9587 - rmse: 0.0313 - mse: 0.0049 - r_square: 0.9397 - val_loss: 0.0021 - val_acc: 0.9007 - val_rmse: 0.0332 - val_mse: 0.0021 - val_r_square: 0.9880\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0049 - acc: 0.9610 - rmse: 0.0316 - mse: 0.0049 - r_square: 0.9393 - val_loss: 0.0022 - val_acc: 0.8893 - val_rmse: 0.0342 - val_mse: 0.0022 - val_r_square: 0.9877\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0049 - acc: 0.9593 - rmse: 0.0318 - mse: 0.0049 - r_square: 0.9392 - val_loss: 0.0022 - val_acc: 0.9014 - val_rmse: 0.0336 - val_mse: 0.0022 - val_r_square: 0.9879\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0049 - acc: 0.9607 - rmse: 0.0319 - mse: 0.0049 - r_square: 0.9402 - val_loss: 0.0022 - val_acc: 0.9013 - val_rmse: 0.0345 - val_mse: 0.0022 - val_r_square: 0.9875\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0049 - acc: 0.9598 - rmse: 0.0318 - mse: 0.0049 - r_square: 0.9405 - val_loss: 0.0022 - val_acc: 0.8899 - val_rmse: 0.0340 - val_mse: 0.0022 - val_r_square: 0.9878\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0049 - acc: 0.9598 - rmse: 0.0318 - mse: 0.0049 - r_square: 0.9404 - val_loss: 0.0022 - val_acc: 0.8899 - val_rmse: 0.0344 - val_mse: 0.0022 - val_r_square: 0.9876\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0049 - acc: 0.9598 - rmse: 0.0315 - mse: 0.0049 - r_square: 0.9403 - val_loss: 0.0021 - val_acc: 0.8900 - val_rmse: 0.0337 - val_mse: 0.0021 - val_r_square: 0.9879\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0049 - acc: 0.9594 - rmse: 0.0310 - mse: 0.0049 - r_square: 0.9399 - val_loss: 0.0022 - val_acc: 0.8896 - val_rmse: 0.0340 - val_mse: 0.0022 - val_r_square: 0.9878\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9589 - rmse: 0.0306 - mse: 0.0048 - r_square: 0.9403 - val_loss: 0.0021 - val_acc: 0.8898 - val_rmse: 0.0330 - val_mse: 0.0021 - val_r_square: 0.9883\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0048 - acc: 0.9589 - rmse: 0.0295 - mse: 0.0048 - r_square: 0.9413 - val_loss: 0.0021 - val_acc: 0.8898 - val_rmse: 0.0335 - val_mse: 0.0021 - val_r_square: 0.9880\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9581 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9415 - val_loss: 0.0020 - val_acc: 0.8895 - val_rmse: 0.0326 - val_mse: 0.0020 - val_r_square: 0.9885\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9589 - rmse: 0.0283 - mse: 0.0047 - r_square: 0.9417 - val_loss: 0.0021 - val_acc: 0.8896 - val_rmse: 0.0333 - val_mse: 0.0021 - val_r_square: 0.9881\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 327us/step - loss: 0.0047 - acc: 0.9573 - rmse: 0.0286 - mse: 0.0047 - r_square: 0.9409 - val_loss: 0.0020 - val_acc: 0.8893 - val_rmse: 0.0325 - val_mse: 0.0020 - val_r_square: 0.9884\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0047 - acc: 0.9588 - rmse: 0.0276 - mse: 0.0047 - r_square: 0.9414 - val_loss: 0.0021 - val_acc: 0.9007 - val_rmse: 0.0334 - val_mse: 0.0021 - val_r_square: 0.9880\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9552 - rmse: 0.0278 - mse: 0.0047 - r_square: 0.9416 - val_loss: 0.0021 - val_acc: 0.8895 - val_rmse: 0.0327 - val_mse: 0.0021 - val_r_square: 0.9883\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0046 - acc: 0.9607 - rmse: 0.0272 - mse: 0.0046 - r_square: 0.9429 - val_loss: 0.0021 - val_acc: 0.9123 - val_rmse: 0.0336 - val_mse: 0.0021 - val_r_square: 0.9878\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0046 - acc: 0.9565 - rmse: 0.0273 - mse: 0.0046 - r_square: 0.9427 - val_loss: 0.0021 - val_acc: 0.8895 - val_rmse: 0.0334 - val_mse: 0.0021 - val_r_square: 0.9879\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0047 - acc: 0.9592 - rmse: 0.0269 - mse: 0.0047 - r_square: 0.9421 - val_loss: 0.0022 - val_acc: 0.9126 - val_rmse: 0.0343 - val_mse: 0.0022 - val_r_square: 0.9875\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0047 - acc: 0.9550 - rmse: 0.0275 - mse: 0.0047 - r_square: 0.9411 - val_loss: 0.0022 - val_acc: 0.9024 - val_rmse: 0.0341 - val_mse: 0.0022 - val_r_square: 0.9876\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9589 - rmse: 0.0273 - mse: 0.0047 - r_square: 0.9409 - val_loss: 0.0022 - val_acc: 0.9141 - val_rmse: 0.0350 - val_mse: 0.0022 - val_r_square: 0.9872\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0047 - acc: 0.9546 - rmse: 0.0272 - mse: 0.0047 - r_square: 0.9421 - val_loss: 0.0022 - val_acc: 0.9115 - val_rmse: 0.0346 - val_mse: 0.0022 - val_r_square: 0.9874\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0046 - acc: 0.9585 - rmse: 0.0272 - mse: 0.0046 - r_square: 0.9427 - val_loss: 0.0022 - val_acc: 0.9136 - val_rmse: 0.0352 - val_mse: 0.0022 - val_r_square: 0.9871\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0046 - acc: 0.9556 - rmse: 0.0273 - mse: 0.0046 - r_square: 0.9429 - val_loss: 0.0023 - val_acc: 0.9134 - val_rmse: 0.0355 - val_mse: 0.0023 - val_r_square: 0.9870\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0046 - acc: 0.9568 - rmse: 0.0274 - mse: 0.0046 - r_square: 0.9430 - val_loss: 0.0023 - val_acc: 0.9141 - val_rmse: 0.0359 - val_mse: 0.0023 - val_r_square: 0.9867\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0046 - acc: 0.9547 - rmse: 0.0277 - mse: 0.0046 - r_square: 0.9426 - val_loss: 0.0023 - val_acc: 0.9126 - val_rmse: 0.0360 - val_mse: 0.0023 - val_r_square: 0.9868\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_13 (RepeatVect (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 8s 1ms/step - loss: 0.0205 - acc: 0.8039 - mse: 0.0205 - rmse: 0.1148 - r_square: 0.6306 - val_loss: 0.0101 - val_acc: 0.9927 - val_mse: 0.0101 - val_rmse: 0.0957 - val_r_square: 0.9392\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0148 - acc: 0.8762 - mse: 0.0148 - rmse: 0.0960 - r_square: 0.7015 - val_loss: 0.0097 - val_acc: 0.9942 - val_mse: 0.0097 - val_rmse: 0.0948 - val_r_square: 0.9423\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0114 - acc: 0.8858 - mse: 0.0114 - rmse: 0.0838 - r_square: 0.7723 - val_loss: 0.0087 - val_acc: 0.9942 - val_mse: 0.0087 - val_rmse: 0.0888 - val_r_square: 0.9486\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0090 - acc: 0.9323 - mse: 0.0090 - rmse: 0.0688 - r_square: 0.8454 - val_loss: 0.0040 - val_acc: 0.9942 - val_mse: 0.0040 - val_rmse: 0.0548 - val_r_square: 0.9771\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0078 - acc: 0.9209 - mse: 0.0078 - rmse: 0.0629 - r_square: 0.8583 - val_loss: 0.0055 - val_acc: 0.8365 - val_mse: 0.0055 - val_rmse: 0.0668 - val_r_square: 0.9685\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0114 - acc: 0.9081 - mse: 0.0114 - rmse: 0.0767 - r_square: 0.8181 - val_loss: 0.0072 - val_acc: 0.8365 - val_mse: 0.0072 - val_rmse: 0.0762 - val_r_square: 0.9589\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0099 - acc: 0.9352 - mse: 0.0099 - rmse: 0.0740 - r_square: 0.8320 - val_loss: 0.0076 - val_acc: 0.8483 - val_mse: 0.0076 - val_rmse: 0.0830 - val_r_square: 0.9543\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0113 - acc: 0.8887 - mse: 0.0113 - rmse: 0.0833 - r_square: 0.7411 - val_loss: 0.0080 - val_acc: 0.8365 - val_mse: 0.0080 - val_rmse: 0.0849 - val_r_square: 0.9522\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0109 - acc: 0.9166 - mse: 0.0109 - rmse: 0.0815 - r_square: 0.7866 - val_loss: 0.0101 - val_acc: 0.8882 - val_mse: 0.0101 - val_rmse: 0.0951 - val_r_square: 0.9389\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0104 - acc: 0.8211 - mse: 0.0104 - rmse: 0.0770 - r_square: 0.8002 - val_loss: 0.0048 - val_acc: 0.8365 - val_mse: 0.0048 - val_rmse: 0.0623 - val_r_square: 0.9723\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0112 - acc: 0.8466 - mse: 0.0112 - rmse: 0.0758 - r_square: 0.7931 - val_loss: 0.0035 - val_acc: 0.8366 - val_mse: 0.0035 - val_rmse: 0.0498 - val_r_square: 0.9804\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0089 - acc: 0.9293 - mse: 0.0089 - rmse: 0.0674 - r_square: 0.8645 - val_loss: 0.0029 - val_acc: 0.8765 - val_mse: 0.0029 - val_rmse: 0.0434 - val_r_square: 0.9836\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0077 - acc: 0.9365 - mse: 0.0077 - rmse: 0.0578 - r_square: 0.8951 - val_loss: 0.0027 - val_acc: 0.8366 - val_mse: 0.0027 - val_rmse: 0.0403 - val_r_square: 0.9851\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 232us/step - loss: 0.0079 - acc: 0.8974 - mse: 0.0079 - rmse: 0.0614 - r_square: 0.8777 - val_loss: 0.0064 - val_acc: 0.9017 - val_mse: 0.0064 - val_rmse: 0.0739 - val_r_square: 0.9619\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 229us/step - loss: 0.0089 - acc: 0.8562 - mse: 0.0089 - rmse: 0.0680 - r_square: 0.8384 - val_loss: 0.0023 - val_acc: 0.8876 - val_mse: 0.0023 - val_rmse: 0.0353 - val_r_square: 0.9871\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 235us/step - loss: 0.0074 - acc: 0.9076 - mse: 0.0074 - rmse: 0.0584 - r_square: 0.8755 - val_loss: 0.0024 - val_acc: 0.8739 - val_mse: 0.0024 - val_rmse: 0.0360 - val_r_square: 0.9870\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0066 - acc: 0.9386 - mse: 0.0066 - rmse: 0.0547 - r_square: 0.8860 - val_loss: 0.0047 - val_acc: 0.8720 - val_mse: 0.0047 - val_rmse: 0.0614 - val_r_square: 0.9721\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 232us/step - loss: 0.0074 - acc: 0.9293 - mse: 0.0074 - rmse: 0.0593 - r_square: 0.8740 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0380 - val_r_square: 0.9864\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0061 - acc: 0.9361 - mse: 0.0061 - rmse: 0.0480 - r_square: 0.9063 - val_loss: 0.0021 - val_acc: 0.8365 - val_mse: 0.0021 - val_rmse: 0.0339 - val_r_square: 0.9882\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 232us/step - loss: 0.0070 - acc: 0.9418 - mse: 0.0070 - rmse: 0.0543 - r_square: 0.9107 - val_loss: 0.0026 - val_acc: 0.8365 - val_mse: 0.0026 - val_rmse: 0.0388 - val_r_square: 0.9855\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0068 - acc: 0.9248 - mse: 0.0068 - rmse: 0.0555 - r_square: 0.8852 - val_loss: 0.0050 - val_acc: 0.8365 - val_mse: 0.0050 - val_rmse: 0.0649 - val_r_square: 0.9703\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0075 - acc: 0.8962 - mse: 0.0075 - rmse: 0.0610 - r_square: 0.8800 - val_loss: 0.0031 - val_acc: 0.9226 - val_mse: 0.0031 - val_rmse: 0.0462 - val_r_square: 0.9819\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 234us/step - loss: 0.0067 - acc: 0.9047 - mse: 0.0067 - rmse: 0.0540 - r_square: 0.9103 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0442 - val_r_square: 0.9832\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 230us/step - loss: 0.0084 - acc: 0.9423 - mse: 0.0084 - rmse: 0.0649 - r_square: 0.8715 - val_loss: 0.0033 - val_acc: 0.8883 - val_mse: 0.0033 - val_rmse: 0.0477 - val_r_square: 0.9813\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0071 - acc: 0.9416 - mse: 0.0071 - rmse: 0.0602 - r_square: 0.8629 - val_loss: 0.0051 - val_acc: 0.8480 - val_mse: 0.0051 - val_rmse: 0.0645 - val_r_square: 0.9693\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0069 - acc: 0.9194 - mse: 0.0069 - rmse: 0.0536 - r_square: 0.9059 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0288 - val_r_square: 0.9896\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0067 - acc: 0.9247 - mse: 0.0067 - rmse: 0.0546 - r_square: 0.9045 - val_loss: 0.0026 - val_acc: 0.9942 - val_mse: 0.0026 - val_rmse: 0.0380 - val_r_square: 0.9856\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0066 - acc: 0.9381 - mse: 0.0066 - rmse: 0.0533 - r_square: 0.9004 - val_loss: 0.0054 - val_acc: 0.8365 - val_mse: 0.0054 - val_rmse: 0.0670 - val_r_square: 0.9678\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0057 - acc: 0.9450 - mse: 0.0057 - rmse: 0.0467 - r_square: 0.9121 - val_loss: 0.0021 - val_acc: 0.9942 - val_mse: 0.0021 - val_rmse: 0.0313 - val_r_square: 0.9884\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 232us/step - loss: 0.0062 - acc: 0.9475 - mse: 0.0062 - rmse: 0.0486 - r_square: 0.9173 - val_loss: 0.0023 - val_acc: 0.9938 - val_mse: 0.0023 - val_rmse: 0.0359 - val_r_square: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0060 - acc: 0.9369 - mse: 0.0060 - rmse: 0.0485 - r_square: 0.9161 - val_loss: 0.0047 - val_acc: 0.9430 - val_mse: 0.0047 - val_rmse: 0.0607 - val_r_square: 0.9725\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0060 - acc: 0.9048 - mse: 0.0060 - rmse: 0.0487 - r_square: 0.9090 - val_loss: 0.0023 - val_acc: 0.8883 - val_mse: 0.0023 - val_rmse: 0.0349 - val_r_square: 0.9874\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0064 - acc: 0.8628 - mse: 0.0064 - rmse: 0.0532 - r_square: 0.8959 - val_loss: 0.0022 - val_acc: 0.9940 - val_mse: 0.0022 - val_rmse: 0.0316 - val_r_square: 0.9879\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0064 - acc: 0.9428 - mse: 0.0064 - rmse: 0.0494 - r_square: 0.9129 - val_loss: 0.0040 - val_acc: 0.9942 - val_mse: 0.0040 - val_rmse: 0.0553 - val_r_square: 0.9764\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0061 - acc: 0.9429 - mse: 0.0061 - rmse: 0.0467 - r_square: 0.9083 - val_loss: 0.0050 - val_acc: 0.8889 - val_mse: 0.0050 - val_rmse: 0.0638 - val_r_square: 0.9697\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0061 - acc: 0.9165 - mse: 0.0061 - rmse: 0.0505 - r_square: 0.8958 - val_loss: 0.0018 - val_acc: 0.9937 - val_mse: 0.0018 - val_rmse: 0.0263 - val_r_square: 0.9903\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0059 - acc: 0.9585 - mse: 0.0059 - rmse: 0.0467 - r_square: 0.8975 - val_loss: 0.0027 - val_acc: 0.9634 - val_mse: 0.0027 - val_rmse: 0.0415 - val_r_square: 0.9845\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0060 - acc: 0.9478 - mse: 0.0060 - rmse: 0.0476 - r_square: 0.8980 - val_loss: 0.0036 - val_acc: 0.9942 - val_mse: 0.0036 - val_rmse: 0.0511 - val_r_square: 0.9788\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0059 - acc: 0.9480 - mse: 0.0059 - rmse: 0.0450 - r_square: 0.9184 - val_loss: 0.0032 - val_acc: 0.8365 - val_mse: 0.0032 - val_rmse: 0.0482 - val_r_square: 0.9812\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0057 - acc: 0.9503 - mse: 0.0057 - rmse: 0.0450 - r_square: 0.9165 - val_loss: 0.0025 - val_acc: 0.9686 - val_mse: 0.0025 - val_rmse: 0.0387 - val_r_square: 0.9859\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0056 - acc: 0.9462 - mse: 0.0056 - rmse: 0.0432 - r_square: 0.9087 - val_loss: 0.0025 - val_acc: 0.8885 - val_mse: 0.0025 - val_rmse: 0.0393 - val_r_square: 0.9858\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0058 - acc: 0.9356 - mse: 0.0058 - rmse: 0.0455 - r_square: 0.9119 - val_loss: 0.0037 - val_acc: 0.8365 - val_mse: 0.0037 - val_rmse: 0.0522 - val_r_square: 0.9785\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0055 - acc: 0.9400 - mse: 0.0055 - rmse: 0.0417 - r_square: 0.9162 - val_loss: 0.0029 - val_acc: 0.9431 - val_mse: 0.0029 - val_rmse: 0.0433 - val_r_square: 0.9833\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0054 - acc: 0.9546 - mse: 0.0054 - rmse: 0.0401 - r_square: 0.9208 - val_loss: 0.0026 - val_acc: 0.8877 - val_mse: 0.0026 - val_rmse: 0.0398 - val_r_square: 0.9856\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0059 - acc: 0.9445 - mse: 0.0059 - rmse: 0.0463 - r_square: 0.9142 - val_loss: 0.0031 - val_acc: 0.9942 - val_mse: 0.0031 - val_rmse: 0.0451 - val_r_square: 0.9819\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0055 - acc: 0.9467 - mse: 0.0055 - rmse: 0.0405 - r_square: 0.9285 - val_loss: 0.0037 - val_acc: 0.8886 - val_mse: 0.0037 - val_rmse: 0.0521 - val_r_square: 0.9782\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0057 - acc: 0.9413 - mse: 0.0057 - rmse: 0.0441 - r_square: 0.9187 - val_loss: 0.0036 - val_acc: 0.9430 - val_mse: 0.0036 - val_rmse: 0.0521 - val_r_square: 0.9789\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0056 - acc: 0.9336 - mse: 0.0056 - rmse: 0.0436 - r_square: 0.9145 - val_loss: 0.0032 - val_acc: 0.8873 - val_mse: 0.0032 - val_rmse: 0.0482 - val_r_square: 0.9811\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0060 - acc: 0.8974 - mse: 0.0060 - rmse: 0.0484 - r_square: 0.9065 - val_loss: 0.0065 - val_acc: 0.9942 - val_mse: 0.0065 - val_rmse: 0.0753 - val_r_square: 0.9603\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0055 - acc: 0.9472 - mse: 0.0055 - rmse: 0.0420 - r_square: 0.9144 - val_loss: 0.0057 - val_acc: 0.9901 - val_mse: 0.0057 - val_rmse: 0.0693 - val_r_square: 0.9657\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0059 - acc: 0.9423 - mse: 0.0059 - rmse: 0.0472 - r_square: 0.8953 - val_loss: 0.0039 - val_acc: 0.9942 - val_mse: 0.0039 - val_rmse: 0.0546 - val_r_square: 0.9765\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0066 - acc: 0.9263 - mse: 0.0066 - rmse: 0.0513 - r_square: 0.8974 - val_loss: 0.0044 - val_acc: 0.9942 - val_mse: 0.0044 - val_rmse: 0.0581 - val_r_square: 0.9739\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0056 - acc: 0.9475 - mse: 0.0056 - rmse: 0.0434 - r_square: 0.9086 - val_loss: 0.0031 - val_acc: 0.9571 - val_mse: 0.0031 - val_rmse: 0.0463 - val_r_square: 0.9821\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0060 - acc: 0.9458 - mse: 0.0060 - rmse: 0.0485 - r_square: 0.8515 - val_loss: 0.0040 - val_acc: 0.9929 - val_mse: 0.0040 - val_rmse: 0.0546 - val_r_square: 0.9764\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0055 - acc: 0.9403 - mse: 0.0055 - rmse: 0.0432 - r_square: 0.9202 - val_loss: 0.0019 - val_acc: 0.9420 - val_mse: 0.0019 - val_rmse: 0.0303 - val_r_square: 0.9893\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0059 - acc: 0.9112 - mse: 0.0059 - rmse: 0.0493 - r_square: 0.8921 - val_loss: 0.0019 - val_acc: 0.9039 - val_mse: 0.0019 - val_rmse: 0.0293 - val_r_square: 0.9897\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0067 - acc: 0.9561 - mse: 0.0067 - rmse: 0.0525 - r_square: 0.8892 - val_loss: 0.0039 - val_acc: 0.9942 - val_mse: 0.0039 - val_rmse: 0.0544 - val_r_square: 0.9766\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0058 - acc: 0.9167 - mse: 0.0058 - rmse: 0.0461 - r_square: 0.9096 - val_loss: 0.0041 - val_acc: 0.9942 - val_mse: 0.0041 - val_rmse: 0.0566 - val_r_square: 0.9756\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0058 - acc: 0.9286 - mse: 0.0058 - rmse: 0.0472 - r_square: 0.9110 - val_loss: 0.0034 - val_acc: 0.8482 - val_mse: 0.0034 - val_rmse: 0.0495 - val_r_square: 0.9800\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0063 - acc: 0.9468 - mse: 0.0063 - rmse: 0.0507 - r_square: 0.8933 - val_loss: 0.0033 - val_acc: 0.9942 - val_mse: 0.0033 - val_rmse: 0.0497 - val_r_square: 0.9806\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0060 - acc: 0.9423 - mse: 0.0060 - rmse: 0.0472 - r_square: 0.9099 - val_loss: 0.0037 - val_acc: 0.9636 - val_mse: 0.0037 - val_rmse: 0.0526 - val_r_square: 0.9780\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0064 - acc: 0.8780 - mse: 0.0064 - rmse: 0.0521 - r_square: 0.8716 - val_loss: 0.0022 - val_acc: 0.8509 - val_mse: 0.0022 - val_rmse: 0.0358 - val_r_square: 0.9873\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0054 - acc: 0.8683 - mse: 0.0054 - rmse: 0.0418 - r_square: 0.9034 - val_loss: 0.0029 - val_acc: 0.9296 - val_mse: 0.0029 - val_rmse: 0.0445 - val_r_square: 0.9827\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0057 - acc: 0.9440 - mse: 0.0057 - rmse: 0.0446 - r_square: 0.9176 - val_loss: 0.0028 - val_acc: 0.9940 - val_mse: 0.0028 - val_rmse: 0.0433 - val_r_square: 0.9837\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0055 - acc: 0.9472 - mse: 0.0055 - rmse: 0.0432 - r_square: 0.9248 - val_loss: 0.0036 - val_acc: 0.8831 - val_mse: 0.0036 - val_rmse: 0.0513 - val_r_square: 0.9790\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0058 - acc: 0.9507 - mse: 0.0058 - rmse: 0.0458 - r_square: 0.8952 - val_loss: 0.0037 - val_acc: 0.9942 - val_mse: 0.0037 - val_rmse: 0.0530 - val_r_square: 0.9784\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0054 - acc: 0.9328 - mse: 0.0054 - rmse: 0.0421 - r_square: 0.9172 - val_loss: 0.0021 - val_acc: 0.9431 - val_mse: 0.0021 - val_rmse: 0.0333 - val_r_square: 0.9882\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0054 - acc: 0.9495 - mse: 0.0054 - rmse: 0.0411 - r_square: 0.9286 - val_loss: 0.0025 - val_acc: 0.9816 - val_mse: 0.0025 - val_rmse: 0.0393 - val_r_square: 0.9855\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0057 - acc: 0.9445 - mse: 0.0057 - rmse: 0.0438 - r_square: 0.9117 - val_loss: 0.0062 - val_acc: 0.9941 - val_mse: 0.0062 - val_rmse: 0.0699 - val_r_square: 0.9626\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0060 - acc: 0.9182 - mse: 0.0060 - rmse: 0.0480 - r_square: 0.8901 - val_loss: 0.0050 - val_acc: 0.9906 - val_mse: 0.0050 - val_rmse: 0.0634 - val_r_square: 0.9701\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0057 - acc: 0.8947 - mse: 0.0057 - rmse: 0.0443 - r_square: 0.9097 - val_loss: 0.0020 - val_acc: 0.8365 - val_mse: 0.0020 - val_rmse: 0.0325 - val_r_square: 0.9887\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0057 - acc: 0.9417 - mse: 0.0057 - rmse: 0.0444 - r_square: 0.9107 - val_loss: 0.0047 - val_acc: 0.9942 - val_mse: 0.0047 - val_rmse: 0.0603 - val_r_square: 0.9721\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0060 - acc: 0.9312 - mse: 0.0060 - rmse: 0.0459 - r_square: 0.9102 - val_loss: 0.0096 - val_acc: 0.9942 - val_mse: 0.0096 - val_rmse: 0.0921 - val_r_square: 0.9408\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0059 - acc: 0.9422 - mse: 0.0059 - rmse: 0.0482 - r_square: 0.8972 - val_loss: 0.0018 - val_acc: 0.8752 - val_mse: 0.0018 - val_rmse: 0.0294 - val_r_square: 0.9897\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0059 - acc: 0.9278 - mse: 0.0059 - rmse: 0.0467 - r_square: 0.8996 - val_loss: 0.0018 - val_acc: 0.9147 - val_mse: 0.0018 - val_rmse: 0.0280 - val_r_square: 0.9899\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0057 - acc: 0.9494 - mse: 0.0057 - rmse: 0.0445 - r_square: 0.8958 - val_loss: 0.0048 - val_acc: 0.8509 - val_mse: 0.0048 - val_rmse: 0.0618 - val_r_square: 0.9709\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0053 - acc: 0.9533 - mse: 0.0053 - rmse: 0.0407 - r_square: 0.9262 - val_loss: 0.0054 - val_acc: 0.9941 - val_mse: 0.0054 - val_rmse: 0.0656 - val_r_square: 0.9672\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0054 - acc: 0.9424 - mse: 0.0054 - rmse: 0.0428 - r_square: 0.9133 - val_loss: 0.0030 - val_acc: 0.9942 - val_mse: 0.0030 - val_rmse: 0.0452 - val_r_square: 0.9829\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0054 - acc: 0.9484 - mse: 0.0054 - rmse: 0.0414 - r_square: 0.9062 - val_loss: 0.0027 - val_acc: 0.9928 - val_mse: 0.0027 - val_rmse: 0.0412 - val_r_square: 0.9840\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0053 - acc: 0.9288 - mse: 0.0053 - rmse: 0.0397 - r_square: 0.9251 - val_loss: 0.0029 - val_acc: 0.9005 - val_mse: 0.0029 - val_rmse: 0.0435 - val_r_square: 0.9833\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0053 - acc: 0.9532 - mse: 0.0053 - rmse: 0.0397 - r_square: 0.9112 - val_loss: 0.0022 - val_acc: 0.9267 - val_mse: 0.0022 - val_rmse: 0.0351 - val_r_square: 0.9874\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0052 - acc: 0.9525 - mse: 0.0052 - rmse: 0.0392 - r_square: 0.9249 - val_loss: 0.0023 - val_acc: 0.8375 - val_mse: 0.0023 - val_rmse: 0.0358 - val_r_square: 0.9871\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0051 - acc: 0.9320 - mse: 0.0051 - rmse: 0.0378 - r_square: 0.9349 - val_loss: 0.0031 - val_acc: 0.9942 - val_mse: 0.0031 - val_rmse: 0.0474 - val_r_square: 0.9820\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0053 - acc: 0.9462 - mse: 0.0053 - rmse: 0.0409 - r_square: 0.9162 - val_loss: 0.0026 - val_acc: 0.9942 - val_mse: 0.0026 - val_rmse: 0.0390 - val_r_square: 0.9853\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0054 - acc: 0.9466 - mse: 0.0054 - rmse: 0.0401 - r_square: 0.9218 - val_loss: 0.0028 - val_acc: 0.8869 - val_mse: 0.0028 - val_rmse: 0.0419 - val_r_square: 0.9837\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0055 - acc: 0.8539 - mse: 0.0055 - rmse: 0.0436 - r_square: 0.8982 - val_loss: 0.0025 - val_acc: 0.8623 - val_mse: 0.0025 - val_rmse: 0.0390 - val_r_square: 0.9855\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0054 - acc: 0.8529 - mse: 0.0054 - rmse: 0.0407 - r_square: 0.9100 - val_loss: 0.0023 - val_acc: 0.8984 - val_mse: 0.0023 - val_rmse: 0.0363 - val_r_square: 0.9867\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0054 - acc: 0.9436 - mse: 0.0054 - rmse: 0.0398 - r_square: 0.9263 - val_loss: 0.0036 - val_acc: 0.9942 - val_mse: 0.0036 - val_rmse: 0.0513 - val_r_square: 0.9788\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0055 - acc: 0.9296 - mse: 0.0055 - rmse: 0.0423 - r_square: 0.9249 - val_loss: 0.0043 - val_acc: 0.8899 - val_mse: 0.0043 - val_rmse: 0.0581 - val_r_square: 0.9744\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0056 - acc: 0.9225 - mse: 0.0056 - rmse: 0.0431 - r_square: 0.9156 - val_loss: 0.0064 - val_acc: 0.9942 - val_mse: 0.0064 - val_rmse: 0.0740 - val_r_square: 0.9611\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0054 - acc: 0.9443 - mse: 0.0054 - rmse: 0.0412 - r_square: 0.9207 - val_loss: 0.0030 - val_acc: 0.9410 - val_mse: 0.0030 - val_rmse: 0.0440 - val_r_square: 0.9826\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0054 - acc: 0.9491 - mse: 0.0054 - rmse: 0.0413 - r_square: 0.9228 - val_loss: 0.0036 - val_acc: 0.9388 - val_mse: 0.0036 - val_rmse: 0.0497 - val_r_square: 0.9790\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0051 - acc: 0.9467 - mse: 0.0051 - rmse: 0.0390 - r_square: 0.9305 - val_loss: 0.0055 - val_acc: 0.9942 - val_mse: 0.0055 - val_rmse: 0.0670 - val_r_square: 0.9671\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0053 - acc: 0.9591 - mse: 0.0053 - rmse: 0.0405 - r_square: 0.9106 - val_loss: 0.0031 - val_acc: 0.9937 - val_mse: 0.0031 - val_rmse: 0.0451 - val_r_square: 0.9818\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0053 - acc: 0.9264 - mse: 0.0053 - rmse: 0.0405 - r_square: 0.9219 - val_loss: 0.0023 - val_acc: 0.9005 - val_mse: 0.0023 - val_rmse: 0.0361 - val_r_square: 0.9870\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0055 - acc: 0.9091 - mse: 0.0055 - rmse: 0.0423 - r_square: 0.9057 - val_loss: 0.0016 - val_acc: 0.8371 - val_mse: 0.0016 - val_rmse: 0.0213 - val_r_square: 0.9917\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0058 - acc: 0.9489 - mse: 0.0058 - rmse: 0.0456 - r_square: 0.8813 - val_loss: 0.0033 - val_acc: 0.8366 - val_mse: 0.0033 - val_rmse: 0.0484 - val_r_square: 0.9809\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0054 - acc: 0.9593 - mse: 0.0054 - rmse: 0.0422 - r_square: 0.9224 - val_loss: 0.0040 - val_acc: 0.8915 - val_mse: 0.0040 - val_rmse: 0.0539 - val_r_square: 0.9760\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0054 - acc: 0.9110 - mse: 0.0054 - rmse: 0.0433 - r_square: 0.9189 - val_loss: 0.0043 - val_acc: 0.9941 - val_mse: 0.0043 - val_rmse: 0.0575 - val_r_square: 0.9751\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0055 - acc: 0.9538 - mse: 0.0055 - rmse: 0.0446 - r_square: 0.9068 - val_loss: 0.0042 - val_acc: 0.9940 - val_mse: 0.0042 - val_rmse: 0.0547 - val_r_square: 0.9751\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed_x',\n",
       "       'Deaths', 'Recovered', 'Confirmed_y', 'Country', 'Region', 'Population',\n",
       "       'Area (sq. mi.)', 'Pop. Density (per sq. mi.)',\n",
       "       'Coastline (coast/area ratio)', 'Net migration',\n",
       "       'Infant mortality (per 1000 births)', 'GDP ($ per capita)',\n",
       "       'Literacy (%)', 'Phones (per 1000)', 'Arable (%)', 'Crops (%)',\n",
       "       'Climate', 'Birthrate', 'Deathrate', 'Agriculture', 'Industry',\n",
       "       'Service', 'Month', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phones (per 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Phones (per 1000)','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 13s 2ms/step - loss: 0.0471 - acc: 0.6995 - rmse: 0.1883 - mse: 0.0471 - r_square: 0.3225 - val_loss: 0.0413 - val_acc: 0.8365 - val_rmse: 0.1907 - val_mse: 0.0413 - val_r_square: 0.7800\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 349us/step - loss: 0.0347 - acc: 0.7380 - rmse: 0.1525 - mse: 0.0347 - r_square: 0.5571 - val_loss: 0.0277 - val_acc: 0.8817 - val_rmse: 0.1445 - val_mse: 0.0277 - val_r_square: 0.8527\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0221 - acc: 0.7100 - rmse: 0.1188 - mse: 0.0221 - r_square: 0.7122 - val_loss: 0.0211 - val_acc: 0.8365 - val_rmse: 0.1266 - val_mse: 0.0211 - val_r_square: 0.8879\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0167 - acc: 0.8953 - rmse: 0.0982 - mse: 0.0167 - r_square: 0.7872 - val_loss: 0.0137 - val_acc: 0.8365 - val_rmse: 0.0975 - val_mse: 0.0137 - val_r_square: 0.9275\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0136 - acc: 0.9010 - rmse: 0.0858 - mse: 0.0136 - r_square: 0.8214 - val_loss: 0.0115 - val_acc: 0.8365 - val_rmse: 0.0947 - val_mse: 0.0115 - val_r_square: 0.9392\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0119 - acc: 0.9052 - rmse: 0.0801 - mse: 0.0119 - r_square: 0.8404 - val_loss: 0.0083 - val_acc: 0.8492 - val_rmse: 0.0785 - val_mse: 0.0083 - val_r_square: 0.9562\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0097 - acc: 0.9040 - rmse: 0.0655 - mse: 0.0097 - r_square: 0.8715 - val_loss: 0.0056 - val_acc: 0.8392 - val_rmse: 0.0639 - val_mse: 0.0056 - val_r_square: 0.9705\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0087 - acc: 0.9099 - rmse: 0.0594 - mse: 0.0087 - r_square: 0.8827 - val_loss: 0.0040 - val_acc: 0.8415 - val_rmse: 0.0516 - val_mse: 0.0040 - val_r_square: 0.9790\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 297us/step - loss: 0.0081 - acc: 0.9070 - rmse: 0.0555 - mse: 0.0081 - r_square: 0.8929 - val_loss: 0.0041 - val_acc: 0.8414 - val_rmse: 0.0541 - val_mse: 0.0041 - val_r_square: 0.9783\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0076 - acc: 0.9179 - rmse: 0.0515 - mse: 0.0076 - r_square: 0.9001 - val_loss: 0.0045 - val_acc: 0.8411 - val_rmse: 0.0577 - val_mse: 0.0045 - val_r_square: 0.9765\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0073 - acc: 0.9176 - rmse: 0.0499 - mse: 0.0073 - r_square: 0.9030 - val_loss: 0.0042 - val_acc: 0.8395 - val_rmse: 0.0556 - val_mse: 0.0042 - val_r_square: 0.9777\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0071 - acc: 0.9132 - rmse: 0.0487 - mse: 0.0071 - r_square: 0.9074 - val_loss: 0.0038 - val_acc: 0.8378 - val_rmse: 0.0508 - val_mse: 0.0038 - val_r_square: 0.9801\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0069 - acc: 0.9175 - rmse: 0.0477 - mse: 0.0069 - r_square: 0.9113 - val_loss: 0.0037 - val_acc: 0.8368 - val_rmse: 0.0486 - val_mse: 0.0037 - val_r_square: 0.9807\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0067 - acc: 0.9255 - rmse: 0.0463 - mse: 0.0067 - r_square: 0.9138 - val_loss: 0.0040 - val_acc: 0.8365 - val_rmse: 0.0521 - val_mse: 0.0040 - val_r_square: 0.9790\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0066 - acc: 0.9289 - rmse: 0.0460 - mse: 0.0066 - r_square: 0.9138 - val_loss: 0.0041 - val_acc: 0.8365 - val_rmse: 0.0533 - val_mse: 0.0041 - val_r_square: 0.9783\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0066 - acc: 0.9348 - rmse: 0.0461 - mse: 0.0066 - r_square: 0.9128 - val_loss: 0.0041 - val_acc: 0.8365 - val_rmse: 0.0513 - val_mse: 0.0041 - val_r_square: 0.9785\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0065 - acc: 0.9410 - rmse: 0.0465 - mse: 0.0065 - r_square: 0.9129 - val_loss: 0.0048 - val_acc: 0.8365 - val_rmse: 0.0557 - val_mse: 0.0048 - val_r_square: 0.9751\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0067 - acc: 0.9431 - rmse: 0.0482 - mse: 0.0067 - r_square: 0.9099 - val_loss: 0.0053 - val_acc: 0.8365 - val_rmse: 0.0591 - val_mse: 0.0053 - val_r_square: 0.9724\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0069 - acc: 0.9386 - rmse: 0.0505 - mse: 0.0069 - r_square: 0.9040 - val_loss: 0.0047 - val_acc: 0.8365 - val_rmse: 0.0569 - val_mse: 0.0047 - val_r_square: 0.9753\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0072 - acc: 0.9184 - rmse: 0.0529 - mse: 0.0072 - r_square: 0.8961 - val_loss: 0.0029 - val_acc: 0.8379 - val_rmse: 0.0430 - val_mse: 0.0029 - val_r_square: 0.9848\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0064 - acc: 0.9255 - rmse: 0.0465 - mse: 0.0064 - r_square: 0.9191 - val_loss: 0.0038 - val_acc: 0.9092 - val_rmse: 0.0519 - val_mse: 0.0038 - val_r_square: 0.9797\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0066 - acc: 0.9398 - rmse: 0.0492 - mse: 0.0066 - r_square: 0.9180 - val_loss: 0.0038 - val_acc: 0.8369 - val_rmse: 0.0510 - val_mse: 0.0038 - val_r_square: 0.9799\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0067 - acc: 0.9416 - rmse: 0.0495 - mse: 0.0067 - r_square: 0.9179 - val_loss: 0.0048 - val_acc: 0.8365 - val_rmse: 0.0619 - val_mse: 0.0048 - val_r_square: 0.9747\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0071 - acc: 0.9278 - rmse: 0.0540 - mse: 0.0071 - r_square: 0.9092 - val_loss: 0.0060 - val_acc: 0.9267 - val_rmse: 0.0692 - val_mse: 0.0060 - val_r_square: 0.9680\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0070 - acc: 0.9340 - rmse: 0.0542 - mse: 0.0070 - r_square: 0.9149 - val_loss: 0.0050 - val_acc: 0.9860 - val_rmse: 0.0626 - val_mse: 0.0050 - val_r_square: 0.9735\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0073 - acc: 0.8967 - rmse: 0.0560 - mse: 0.0073 - r_square: 0.9117 - val_loss: 0.0055 - val_acc: 0.9929 - val_rmse: 0.0657 - val_mse: 0.0055 - val_r_square: 0.9710\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0075 - acc: 0.8989 - rmse: 0.0575 - mse: 0.0075 - r_square: 0.9074 - val_loss: 0.0041 - val_acc: 0.9476 - val_rmse: 0.0534 - val_mse: 0.0041 - val_r_square: 0.9784\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0068 - acc: 0.9153 - rmse: 0.0523 - mse: 0.0068 - r_square: 0.9142 - val_loss: 0.0031 - val_acc: 0.8492 - val_rmse: 0.0448 - val_mse: 0.0031 - val_r_square: 0.9835\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0065 - acc: 0.9320 - rmse: 0.0485 - mse: 0.0065 - r_square: 0.9165 - val_loss: 0.0034 - val_acc: 0.8850 - val_rmse: 0.0482 - val_mse: 0.0034 - val_r_square: 0.9821\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0059 - acc: 0.9476 - rmse: 0.0424 - mse: 0.0059 - r_square: 0.9244 - val_loss: 0.0029 - val_acc: 0.8982 - val_rmse: 0.0426 - val_mse: 0.0029 - val_r_square: 0.9849\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0059 - acc: 0.9449 - rmse: 0.0409 - mse: 0.0059 - r_square: 0.9230 - val_loss: 0.0030 - val_acc: 0.9361 - val_rmse: 0.0444 - val_mse: 0.0030 - val_r_square: 0.9839\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0056 - acc: 0.9460 - rmse: 0.0392 - mse: 0.0056 - r_square: 0.9299 - val_loss: 0.0031 - val_acc: 0.9521 - val_rmse: 0.0449 - val_mse: 0.0031 - val_r_square: 0.9834\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0055 - acc: 0.9469 - rmse: 0.0375 - mse: 0.0055 - r_square: 0.9312 - val_loss: 0.0032 - val_acc: 0.9758 - val_rmse: 0.0450 - val_mse: 0.0032 - val_r_square: 0.9830\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0055 - acc: 0.9481 - rmse: 0.0366 - mse: 0.0055 - r_square: 0.9324 - val_loss: 0.0031 - val_acc: 0.9773 - val_rmse: 0.0435 - val_mse: 0.0031 - val_r_square: 0.9835\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0054 - acc: 0.9493 - rmse: 0.0357 - mse: 0.0054 - r_square: 0.9334 - val_loss: 0.0030 - val_acc: 0.9650 - val_rmse: 0.0422 - val_mse: 0.0030 - val_r_square: 0.9843\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0053 - acc: 0.9504 - rmse: 0.0349 - mse: 0.0053 - r_square: 0.9344 - val_loss: 0.0029 - val_acc: 0.9775 - val_rmse: 0.0417 - val_mse: 0.0029 - val_r_square: 0.9845\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0053 - acc: 0.9505 - rmse: 0.0346 - mse: 0.0053 - r_square: 0.9342 - val_loss: 0.0030 - val_acc: 0.9655 - val_rmse: 0.0422 - val_mse: 0.0030 - val_r_square: 0.9843\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9516 - rmse: 0.0340 - mse: 0.0053 - r_square: 0.9340 - val_loss: 0.0030 - val_acc: 0.9902 - val_rmse: 0.0422 - val_mse: 0.0030 - val_r_square: 0.9841\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0055 - acc: 0.9499 - rmse: 0.0350 - mse: 0.0055 - r_square: 0.9286 - val_loss: 0.0030 - val_acc: 0.9773 - val_rmse: 0.0431 - val_mse: 0.0030 - val_r_square: 0.9839\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9521 - rmse: 0.0339 - mse: 0.0052 - r_square: 0.9352 - val_loss: 0.0031 - val_acc: 0.9909 - val_rmse: 0.0432 - val_mse: 0.0031 - val_r_square: 0.9837\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9526 - rmse: 0.0335 - mse: 0.0052 - r_square: 0.9361 - val_loss: 0.0031 - val_acc: 0.9921 - val_rmse: 0.0438 - val_mse: 0.0031 - val_r_square: 0.9834\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9532 - rmse: 0.0334 - mse: 0.0052 - r_square: 0.9359 - val_loss: 0.0032 - val_acc: 0.9918 - val_rmse: 0.0439 - val_mse: 0.0032 - val_r_square: 0.9831\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0052 - acc: 0.9532 - rmse: 0.0330 - mse: 0.0052 - r_square: 0.9362 - val_loss: 0.0032 - val_acc: 0.9925 - val_rmse: 0.0439 - val_mse: 0.0032 - val_r_square: 0.9832\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9538 - rmse: 0.0334 - mse: 0.0052 - r_square: 0.9349 - val_loss: 0.0032 - val_acc: 0.9928 - val_rmse: 0.0435 - val_mse: 0.0032 - val_r_square: 0.9833\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9529 - rmse: 0.0333 - mse: 0.0052 - r_square: 0.9356 - val_loss: 0.0032 - val_acc: 0.9925 - val_rmse: 0.0439 - val_mse: 0.0032 - val_r_square: 0.9832\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0051 - acc: 0.9540 - rmse: 0.0328 - mse: 0.0051 - r_square: 0.9372 - val_loss: 0.0032 - val_acc: 0.9925 - val_rmse: 0.0437 - val_mse: 0.0032 - val_r_square: 0.9830\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0051 - acc: 0.9526 - rmse: 0.0328 - mse: 0.0051 - r_square: 0.9370 - val_loss: 0.0032 - val_acc: 0.9919 - val_rmse: 0.0439 - val_mse: 0.0032 - val_r_square: 0.9829\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9536 - rmse: 0.0323 - mse: 0.0051 - r_square: 0.9376 - val_loss: 0.0032 - val_acc: 0.9924 - val_rmse: 0.0440 - val_mse: 0.0032 - val_r_square: 0.9828\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9533 - rmse: 0.0331 - mse: 0.0052 - r_square: 0.9350 - val_loss: 0.0033 - val_acc: 0.9912 - val_rmse: 0.0446 - val_mse: 0.0033 - val_r_square: 0.9826\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9540 - rmse: 0.0325 - mse: 0.0051 - r_square: 0.9378 - val_loss: 0.0033 - val_acc: 0.9924 - val_rmse: 0.0446 - val_mse: 0.0033 - val_r_square: 0.9826\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9545 - rmse: 0.0326 - mse: 0.0051 - r_square: 0.9378 - val_loss: 0.0033 - val_acc: 0.9915 - val_rmse: 0.0452 - val_mse: 0.0033 - val_r_square: 0.9823\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0051 - acc: 0.9541 - rmse: 0.0323 - mse: 0.0051 - r_square: 0.9385 - val_loss: 0.0034 - val_acc: 0.9922 - val_rmse: 0.0451 - val_mse: 0.0034 - val_r_square: 0.9822\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9541 - rmse: 0.0325 - mse: 0.0051 - r_square: 0.9381 - val_loss: 0.0034 - val_acc: 0.9918 - val_rmse: 0.0456 - val_mse: 0.0034 - val_r_square: 0.9821\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9540 - rmse: 0.0324 - mse: 0.0051 - r_square: 0.9381 - val_loss: 0.0034 - val_acc: 0.9922 - val_rmse: 0.0453 - val_mse: 0.0034 - val_r_square: 0.9821\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9542 - rmse: 0.0331 - mse: 0.0052 - r_square: 0.9354 - val_loss: 0.0034 - val_acc: 0.9914 - val_rmse: 0.0461 - val_mse: 0.0034 - val_r_square: 0.9820\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0051 - acc: 0.9543 - rmse: 0.0327 - mse: 0.0051 - r_square: 0.9380 - val_loss: 0.0034 - val_acc: 0.9924 - val_rmse: 0.0455 - val_mse: 0.0034 - val_r_square: 0.9820\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0051 - acc: 0.9545 - rmse: 0.0327 - mse: 0.0051 - r_square: 0.9383 - val_loss: 0.0035 - val_acc: 0.9915 - val_rmse: 0.0464 - val_mse: 0.0035 - val_r_square: 0.9817\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9544 - rmse: 0.0325 - mse: 0.0051 - r_square: 0.9388 - val_loss: 0.0034 - val_acc: 0.9919 - val_rmse: 0.0460 - val_mse: 0.0034 - val_r_square: 0.9817\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0051 - acc: 0.9548 - rmse: 0.0327 - mse: 0.0051 - r_square: 0.9384 - val_loss: 0.0035 - val_acc: 0.9915 - val_rmse: 0.0465 - val_mse: 0.0035 - val_r_square: 0.9816\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9541 - rmse: 0.0327 - mse: 0.0051 - r_square: 0.9381 - val_loss: 0.0034 - val_acc: 0.9918 - val_rmse: 0.0458 - val_mse: 0.0034 - val_r_square: 0.9817\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0052 - acc: 0.9559 - rmse: 0.0332 - mse: 0.0052 - r_square: 0.9351 - val_loss: 0.0035 - val_acc: 0.9912 - val_rmse: 0.0469 - val_mse: 0.0035 - val_r_square: 0.9815\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0051 - acc: 0.9547 - rmse: 0.0329 - mse: 0.0051 - r_square: 0.9382 - val_loss: 0.0035 - val_acc: 0.9921 - val_rmse: 0.0465 - val_mse: 0.0035 - val_r_square: 0.9814\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9549 - rmse: 0.0328 - mse: 0.0051 - r_square: 0.9388 - val_loss: 0.0036 - val_acc: 0.9912 - val_rmse: 0.0476 - val_mse: 0.0036 - val_r_square: 0.9810\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9545 - rmse: 0.0327 - mse: 0.0051 - r_square: 0.9392 - val_loss: 0.0036 - val_acc: 0.9912 - val_rmse: 0.0474 - val_mse: 0.0036 - val_r_square: 0.9810\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0051 - acc: 0.9549 - rmse: 0.0327 - mse: 0.0051 - r_square: 0.9393 - val_loss: 0.0036 - val_acc: 0.9911 - val_rmse: 0.0477 - val_mse: 0.0036 - val_r_square: 0.9809\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0051 - acc: 0.9543 - rmse: 0.0327 - mse: 0.0051 - r_square: 0.9393 - val_loss: 0.0036 - val_acc: 0.9914 - val_rmse: 0.0476 - val_mse: 0.0036 - val_r_square: 0.9807\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9562 - rmse: 0.0329 - mse: 0.0052 - r_square: 0.9369 - val_loss: 0.0037 - val_acc: 0.9919 - val_rmse: 0.0482 - val_mse: 0.0037 - val_r_square: 0.9806\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0052 - acc: 0.9545 - rmse: 0.0331 - mse: 0.0052 - r_square: 0.9369 - val_loss: 0.0037 - val_acc: 0.9915 - val_rmse: 0.0481 - val_mse: 0.0037 - val_r_square: 0.9805\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9543 - rmse: 0.0337 - mse: 0.0052 - r_square: 0.9361 - val_loss: 0.0039 - val_acc: 0.9924 - val_rmse: 0.0500 - val_mse: 0.0039 - val_r_square: 0.9795\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0051 - acc: 0.9560 - rmse: 0.0338 - mse: 0.0051 - r_square: 0.9382 - val_loss: 0.0040 - val_acc: 0.9919 - val_rmse: 0.0508 - val_mse: 0.0040 - val_r_square: 0.9790\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9552 - rmse: 0.0334 - mse: 0.0051 - r_square: 0.9390 - val_loss: 0.0039 - val_acc: 0.9922 - val_rmse: 0.0499 - val_mse: 0.0039 - val_r_square: 0.9793\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9556 - rmse: 0.0333 - mse: 0.0051 - r_square: 0.9394 - val_loss: 0.0039 - val_acc: 0.9925 - val_rmse: 0.0499 - val_mse: 0.0039 - val_r_square: 0.9791\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9550 - rmse: 0.0332 - mse: 0.0051 - r_square: 0.9393 - val_loss: 0.0040 - val_acc: 0.9937 - val_rmse: 0.0510 - val_mse: 0.0040 - val_r_square: 0.9785\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9563 - rmse: 0.0338 - mse: 0.0051 - r_square: 0.9386 - val_loss: 0.0041 - val_acc: 0.9935 - val_rmse: 0.0517 - val_mse: 0.0041 - val_r_square: 0.9783\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0052 - acc: 0.9532 - rmse: 0.0349 - mse: 0.0052 - r_square: 0.9368 - val_loss: 0.0042 - val_acc: 0.9937 - val_rmse: 0.0532 - val_mse: 0.0042 - val_r_square: 0.9776\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9541 - rmse: 0.0360 - mse: 0.0053 - r_square: 0.9332 - val_loss: 0.0044 - val_acc: 0.9927 - val_rmse: 0.0543 - val_mse: 0.0044 - val_r_square: 0.9767\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0056 - acc: 0.9537 - rmse: 0.0368 - mse: 0.0056 - r_square: 0.9279 - val_loss: 0.0043 - val_acc: 0.9935 - val_rmse: 0.0540 - val_mse: 0.0043 - val_r_square: 0.9773\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9538 - rmse: 0.0357 - mse: 0.0052 - r_square: 0.9340 - val_loss: 0.0040 - val_acc: 0.9917 - val_rmse: 0.0514 - val_mse: 0.0040 - val_r_square: 0.9788\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0052 - acc: 0.9514 - rmse: 0.0352 - mse: 0.0052 - r_square: 0.9353 - val_loss: 0.0042 - val_acc: 0.9915 - val_rmse: 0.0541 - val_mse: 0.0042 - val_r_square: 0.9777\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9451 - rmse: 0.0354 - mse: 0.0052 - r_square: 0.9340 - val_loss: 0.0042 - val_acc: 0.9783 - val_rmse: 0.0525 - val_mse: 0.0042 - val_r_square: 0.9778\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0052 - acc: 0.9476 - rmse: 0.0349 - mse: 0.0052 - r_square: 0.9361 - val_loss: 0.0041 - val_acc: 0.9417 - val_rmse: 0.0523 - val_mse: 0.0041 - val_r_square: 0.9781\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0051 - acc: 0.9467 - rmse: 0.0342 - mse: 0.0051 - r_square: 0.9365 - val_loss: 0.0043 - val_acc: 0.9296 - val_rmse: 0.0537 - val_mse: 0.0043 - val_r_square: 0.9770\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9477 - rmse: 0.0333 - mse: 0.0051 - r_square: 0.9376 - val_loss: 0.0044 - val_acc: 0.9298 - val_rmse: 0.0542 - val_mse: 0.0044 - val_r_square: 0.9764\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9493 - rmse: 0.0324 - mse: 0.0050 - r_square: 0.9382 - val_loss: 0.0046 - val_acc: 0.9161 - val_rmse: 0.0551 - val_mse: 0.0046 - val_r_square: 0.9756\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 273us/step - loss: 0.0050 - acc: 0.9504 - rmse: 0.0313 - mse: 0.0050 - r_square: 0.9384 - val_loss: 0.0046 - val_acc: 0.9424 - val_rmse: 0.0545 - val_mse: 0.0046 - val_r_square: 0.9757\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0049 - acc: 0.9567 - rmse: 0.0303 - mse: 0.0049 - r_square: 0.9402 - val_loss: 0.0048 - val_acc: 0.9286 - val_rmse: 0.0564 - val_mse: 0.0048 - val_r_square: 0.9744\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0049 - acc: 0.9564 - rmse: 0.0291 - mse: 0.0049 - r_square: 0.9414 - val_loss: 0.0048 - val_acc: 0.9539 - val_rmse: 0.0564 - val_mse: 0.0048 - val_r_square: 0.9743\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0048 - acc: 0.9581 - rmse: 0.0288 - mse: 0.0048 - r_square: 0.9425 - val_loss: 0.0051 - val_acc: 0.9417 - val_rmse: 0.0580 - val_mse: 0.0051 - val_r_square: 0.9731\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0048 - acc: 0.9573 - rmse: 0.0282 - mse: 0.0048 - r_square: 0.9430 - val_loss: 0.0051 - val_acc: 0.9413 - val_rmse: 0.0584 - val_mse: 0.0051 - val_r_square: 0.9727\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0048 - acc: 0.9575 - rmse: 0.0281 - mse: 0.0048 - r_square: 0.9426 - val_loss: 0.0053 - val_acc: 0.9410 - val_rmse: 0.0591 - val_mse: 0.0053 - val_r_square: 0.9720\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0050 - acc: 0.9562 - rmse: 0.0287 - mse: 0.0050 - r_square: 0.9392 - val_loss: 0.0052 - val_acc: 0.9286 - val_rmse: 0.0588 - val_mse: 0.0052 - val_r_square: 0.9725\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0049 - acc: 0.9574 - rmse: 0.0285 - mse: 0.0049 - r_square: 0.9402 - val_loss: 0.0052 - val_acc: 0.9407 - val_rmse: 0.0585 - val_mse: 0.0052 - val_r_square: 0.9725\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0049 - acc: 0.9555 - rmse: 0.0291 - mse: 0.0049 - r_square: 0.9412 - val_loss: 0.0055 - val_acc: 0.9407 - val_rmse: 0.0608 - val_mse: 0.0055 - val_r_square: 0.9707\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0048 - acc: 0.9579 - rmse: 0.0289 - mse: 0.0048 - r_square: 0.9423 - val_loss: 0.0057 - val_acc: 0.9286 - val_rmse: 0.0623 - val_mse: 0.0057 - val_r_square: 0.9695\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0048 - acc: 0.9561 - rmse: 0.0292 - mse: 0.0048 - r_square: 0.9424 - val_loss: 0.0054 - val_acc: 0.9276 - val_rmse: 0.0598 - val_mse: 0.0054 - val_r_square: 0.9715\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0049 - acc: 0.9557 - rmse: 0.0300 - mse: 0.0049 - r_square: 0.9415 - val_loss: 0.0052 - val_acc: 0.9288 - val_rmse: 0.0594 - val_mse: 0.0052 - val_r_square: 0.9723\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0049 - acc: 0.9547 - rmse: 0.0307 - mse: 0.0049 - r_square: 0.9414 - val_loss: 0.0050 - val_acc: 0.9272 - val_rmse: 0.0574 - val_mse: 0.0050 - val_r_square: 0.9736\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0051 - acc: 0.9479 - rmse: 0.0323 - mse: 0.0051 - r_square: 0.9397 - val_loss: 0.0041 - val_acc: 0.9420 - val_rmse: 0.0527 - val_mse: 0.0041 - val_r_square: 0.9780\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0050 - acc: 0.9550 - rmse: 0.0323 - mse: 0.0050 - r_square: 0.9395 - val_loss: 0.0045 - val_acc: 0.9000 - val_rmse: 0.0544 - val_mse: 0.0045 - val_r_square: 0.9759\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0051 - acc: 0.9541 - rmse: 0.0324 - mse: 0.0051 - r_square: 0.9391 - val_loss: 0.0033 - val_acc: 0.9128 - val_rmse: 0.0456 - val_mse: 0.0033 - val_r_square: 0.9826\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 12s 2ms/step - loss: 0.0304 - acc: 0.5924 - rmse: 0.1476 - mse: 0.0304 - r_square: 0.5013 - val_loss: 0.0106 - val_acc: 0.8365 - val_rmse: 0.0940 - val_mse: 0.0106 - val_r_square: 0.9441\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0177 - acc: 0.7874 - rmse: 0.1029 - mse: 0.0177 - r_square: 0.7616 - val_loss: 0.0102 - val_acc: 0.8365 - val_rmse: 0.0960 - val_mse: 0.0102 - val_r_square: 0.9461\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0135 - acc: 0.8683 - rmse: 0.0837 - mse: 0.0135 - r_square: 0.8253 - val_loss: 0.0055 - val_acc: 0.8365 - val_rmse: 0.0656 - val_mse: 0.0055 - val_r_square: 0.9709\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0085 - acc: 0.9218 - rmse: 0.0550 - mse: 0.0085 - r_square: 0.8903 - val_loss: 0.0031 - val_acc: 0.8828 - val_rmse: 0.0412 - val_mse: 0.0031 - val_r_square: 0.9839\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0072 - acc: 0.9245 - rmse: 0.0453 - mse: 0.0072 - r_square: 0.9082 - val_loss: 0.0024 - val_acc: 0.8713 - val_rmse: 0.0325 - val_mse: 0.0024 - val_r_square: 0.9872\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0067 - acc: 0.9278 - rmse: 0.0417 - mse: 0.0067 - r_square: 0.9164 - val_loss: 0.0023 - val_acc: 0.8365 - val_rmse: 0.0317 - val_mse: 0.0023 - val_r_square: 0.9877\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0065 - acc: 0.9230 - rmse: 0.0405 - mse: 0.0065 - r_square: 0.9192 - val_loss: 0.0024 - val_acc: 0.8365 - val_rmse: 0.0339 - val_mse: 0.0024 - val_r_square: 0.9873\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0063 - acc: 0.9243 - rmse: 0.0393 - mse: 0.0063 - r_square: 0.9216 - val_loss: 0.0023 - val_acc: 0.8389 - val_rmse: 0.0335 - val_mse: 0.0023 - val_r_square: 0.9877\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0061 - acc: 0.9330 - rmse: 0.0377 - mse: 0.0061 - r_square: 0.9237 - val_loss: 0.0022 - val_acc: 0.8400 - val_rmse: 0.0311 - val_mse: 0.0022 - val_r_square: 0.9886\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0060 - acc: 0.9344 - rmse: 0.0371 - mse: 0.0060 - r_square: 0.9250 - val_loss: 0.0022 - val_acc: 0.8405 - val_rmse: 0.0318 - val_mse: 0.0022 - val_r_square: 0.9885\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0059 - acc: 0.9404 - rmse: 0.0368 - mse: 0.0059 - r_square: 0.9260 - val_loss: 0.0023 - val_acc: 0.8408 - val_rmse: 0.0339 - val_mse: 0.0023 - val_r_square: 0.9881\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0058 - acc: 0.9427 - rmse: 0.0362 - mse: 0.0058 - r_square: 0.9269 - val_loss: 0.0023 - val_acc: 0.8414 - val_rmse: 0.0340 - val_mse: 0.0023 - val_r_square: 0.9881\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 337us/step - loss: 0.0057 - acc: 0.9439 - rmse: 0.0353 - mse: 0.0057 - r_square: 0.9285 - val_loss: 0.0022 - val_acc: 0.8528 - val_rmse: 0.0334 - val_mse: 0.0022 - val_r_square: 0.9884\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0056 - acc: 0.9457 - rmse: 0.0344 - mse: 0.0056 - r_square: 0.9303 - val_loss: 0.0022 - val_acc: 0.8414 - val_rmse: 0.0330 - val_mse: 0.0022 - val_r_square: 0.9886\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0055 - acc: 0.9475 - rmse: 0.0336 - mse: 0.0055 - r_square: 0.9316 - val_loss: 0.0021 - val_acc: 0.8407 - val_rmse: 0.0324 - val_mse: 0.0021 - val_r_square: 0.9889\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0055 - acc: 0.9486 - rmse: 0.0333 - mse: 0.0055 - r_square: 0.9322 - val_loss: 0.0021 - val_acc: 0.8398 - val_rmse: 0.0312 - val_mse: 0.0021 - val_r_square: 0.9893\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0054 - acc: 0.9499 - rmse: 0.0334 - mse: 0.0054 - r_square: 0.9323 - val_loss: 0.0021 - val_acc: 0.8385 - val_rmse: 0.0317 - val_mse: 0.0021 - val_r_square: 0.9891\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0055 - acc: 0.9489 - rmse: 0.0340 - mse: 0.0055 - r_square: 0.9313 - val_loss: 0.0020 - val_acc: 0.8388 - val_rmse: 0.0304 - val_mse: 0.0020 - val_r_square: 0.9895\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0055 - acc: 0.9497 - rmse: 0.0346 - mse: 0.0055 - r_square: 0.9291 - val_loss: 0.0021 - val_acc: 0.8378 - val_rmse: 0.0329 - val_mse: 0.0021 - val_r_square: 0.9888\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0058 - acc: 0.9486 - rmse: 0.0359 - mse: 0.0058 - r_square: 0.9225 - val_loss: 0.0020 - val_acc: 0.8387 - val_rmse: 0.0309 - val_mse: 0.0020 - val_r_square: 0.9895\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0054 - acc: 0.9503 - rmse: 0.0346 - mse: 0.0054 - r_square: 0.9325 - val_loss: 0.0021 - val_acc: 0.8381 - val_rmse: 0.0331 - val_mse: 0.0021 - val_r_square: 0.9888\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 336us/step - loss: 0.0053 - acc: 0.9532 - rmse: 0.0333 - mse: 0.0053 - r_square: 0.9346 - val_loss: 0.0023 - val_acc: 0.8392 - val_rmse: 0.0359 - val_mse: 0.0023 - val_r_square: 0.9879\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0052 - acc: 0.9505 - rmse: 0.0318 - mse: 0.0052 - r_square: 0.9360 - val_loss: 0.0021 - val_acc: 0.8391 - val_rmse: 0.0324 - val_mse: 0.0021 - val_r_square: 0.9891\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0052 - acc: 0.9508 - rmse: 0.0316 - mse: 0.0052 - r_square: 0.9364 - val_loss: 0.0020 - val_acc: 0.8378 - val_rmse: 0.0307 - val_mse: 0.0020 - val_r_square: 0.9896\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0052 - acc: 0.9514 - rmse: 0.0327 - mse: 0.0052 - r_square: 0.9358 - val_loss: 0.0020 - val_acc: 0.8374 - val_rmse: 0.0315 - val_mse: 0.0020 - val_r_square: 0.9894\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0053 - acc: 0.9504 - rmse: 0.0345 - mse: 0.0053 - r_square: 0.9335 - val_loss: 0.0020 - val_acc: 0.8371 - val_rmse: 0.0309 - val_mse: 0.0020 - val_r_square: 0.9896\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0053 - acc: 0.9500 - rmse: 0.0355 - mse: 0.0053 - r_square: 0.9332 - val_loss: 0.0019 - val_acc: 0.8377 - val_rmse: 0.0290 - val_mse: 0.0019 - val_r_square: 0.9901\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0053 - acc: 0.9514 - rmse: 0.0353 - mse: 0.0053 - r_square: 0.9354 - val_loss: 0.0019 - val_acc: 0.8379 - val_rmse: 0.0294 - val_mse: 0.0019 - val_r_square: 0.9898\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0053 - acc: 0.9505 - rmse: 0.0351 - mse: 0.0053 - r_square: 0.9367 - val_loss: 0.0020 - val_acc: 0.8374 - val_rmse: 0.0292 - val_mse: 0.0020 - val_r_square: 0.9898\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0053 - acc: 0.9522 - rmse: 0.0337 - mse: 0.0053 - r_square: 0.9368 - val_loss: 0.0022 - val_acc: 0.8365 - val_rmse: 0.0336 - val_mse: 0.0022 - val_r_square: 0.9883\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0055 - acc: 0.9496 - rmse: 0.0358 - mse: 0.0055 - r_square: 0.9321 - val_loss: 0.0025 - val_acc: 0.8365 - val_rmse: 0.0366 - val_mse: 0.0025 - val_r_square: 0.9871\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0054 - acc: 0.9523 - rmse: 0.0367 - mse: 0.0054 - r_square: 0.9330 - val_loss: 0.0024 - val_acc: 0.8365 - val_rmse: 0.0358 - val_mse: 0.0024 - val_r_square: 0.9876\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0055 - acc: 0.9508 - rmse: 0.0383 - mse: 0.0055 - r_square: 0.9292 - val_loss: 0.0023 - val_acc: 0.8365 - val_rmse: 0.0354 - val_mse: 0.0023 - val_r_square: 0.9878\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0054 - acc: 0.9499 - rmse: 0.0391 - mse: 0.0054 - r_square: 0.9325 - val_loss: 0.0023 - val_acc: 0.8369 - val_rmse: 0.0351 - val_mse: 0.0023 - val_r_square: 0.9882\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0055 - acc: 0.9503 - rmse: 0.0399 - mse: 0.0055 - r_square: 0.9319 - val_loss: 0.0022 - val_acc: 0.8366 - val_rmse: 0.0343 - val_mse: 0.0022 - val_r_square: 0.9884\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0058 - acc: 0.9477 - rmse: 0.0445 - mse: 0.0058 - r_square: 0.9266 - val_loss: 0.0025 - val_acc: 0.8365 - val_rmse: 0.0390 - val_mse: 0.0025 - val_r_square: 0.9867\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0062 - acc: 0.9468 - rmse: 0.0484 - mse: 0.0062 - r_square: 0.9222 - val_loss: 0.0031 - val_acc: 0.8368 - val_rmse: 0.0461 - val_mse: 0.0031 - val_r_square: 0.9838\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0063 - acc: 0.9455 - rmse: 0.0501 - mse: 0.0063 - r_square: 0.9217 - val_loss: 0.0027 - val_acc: 0.9738 - val_rmse: 0.0414 - val_mse: 0.0027 - val_r_square: 0.9856\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0062 - acc: 0.9173 - rmse: 0.0495 - mse: 0.0062 - r_square: 0.9240 - val_loss: 0.0024 - val_acc: 0.9660 - val_rmse: 0.0369 - val_mse: 0.0024 - val_r_square: 0.9873\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0067 - acc: 0.9174 - rmse: 0.0520 - mse: 0.0067 - r_square: 0.9194 - val_loss: 0.0036 - val_acc: 0.9937 - val_rmse: 0.0506 - val_mse: 0.0036 - val_r_square: 0.9809\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0064 - acc: 0.9371 - rmse: 0.0488 - mse: 0.0064 - r_square: 0.9237 - val_loss: 0.0033 - val_acc: 0.9893 - val_rmse: 0.0475 - val_mse: 0.0033 - val_r_square: 0.9827\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0065 - acc: 0.9439 - rmse: 0.0505 - mse: 0.0065 - r_square: 0.9203 - val_loss: 0.0033 - val_acc: 0.9126 - val_rmse: 0.0482 - val_mse: 0.0033 - val_r_square: 0.9825\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0062 - acc: 0.9419 - rmse: 0.0489 - mse: 0.0062 - r_square: 0.9218 - val_loss: 0.0021 - val_acc: 0.8857 - val_rmse: 0.0314 - val_mse: 0.0021 - val_r_square: 0.9890\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0060 - acc: 0.9451 - rmse: 0.0459 - mse: 0.0060 - r_square: 0.9275 - val_loss: 0.0026 - val_acc: 0.9123 - val_rmse: 0.0387 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0057 - acc: 0.9401 - rmse: 0.0424 - mse: 0.0057 - r_square: 0.9304 - val_loss: 0.0022 - val_acc: 0.8847 - val_rmse: 0.0334 - val_mse: 0.0022 - val_r_square: 0.9886\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0055 - acc: 0.9375 - rmse: 0.0387 - mse: 0.0055 - r_square: 0.9327 - val_loss: 0.0022 - val_acc: 0.8611 - val_rmse: 0.0331 - val_mse: 0.0022 - val_r_square: 0.9886\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0054 - acc: 0.9430 - rmse: 0.0362 - mse: 0.0054 - r_square: 0.9347 - val_loss: 0.0021 - val_acc: 0.8365 - val_rmse: 0.0318 - val_mse: 0.0021 - val_r_square: 0.9890\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0055 - acc: 0.9428 - rmse: 0.0362 - mse: 0.0055 - r_square: 0.9307 - val_loss: 0.0022 - val_acc: 0.8732 - val_rmse: 0.0329 - val_mse: 0.0022 - val_r_square: 0.9887\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0052 - acc: 0.9473 - rmse: 0.0350 - mse: 0.0052 - r_square: 0.9377 - val_loss: 0.0021 - val_acc: 0.8615 - val_rmse: 0.0323 - val_mse: 0.0021 - val_r_square: 0.9889\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0052 - acc: 0.9508 - rmse: 0.0346 - mse: 0.0052 - r_square: 0.9383 - val_loss: 0.0021 - val_acc: 0.8735 - val_rmse: 0.0328 - val_mse: 0.0021 - val_r_square: 0.9888\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0052 - acc: 0.9540 - rmse: 0.0348 - mse: 0.0052 - r_square: 0.9384 - val_loss: 0.0022 - val_acc: 0.8857 - val_rmse: 0.0332 - val_mse: 0.0022 - val_r_square: 0.9886\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0052 - acc: 0.9544 - rmse: 0.0346 - mse: 0.0052 - r_square: 0.9388 - val_loss: 0.0022 - val_acc: 0.8863 - val_rmse: 0.0335 - val_mse: 0.0022 - val_r_square: 0.9885\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0051 - acc: 0.9545 - rmse: 0.0344 - mse: 0.0051 - r_square: 0.9391 - val_loss: 0.0022 - val_acc: 0.8993 - val_rmse: 0.0339 - val_mse: 0.0022 - val_r_square: 0.9884\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0051 - acc: 0.9548 - rmse: 0.0343 - mse: 0.0051 - r_square: 0.9393 - val_loss: 0.0023 - val_acc: 0.9003 - val_rmse: 0.0345 - val_mse: 0.0023 - val_r_square: 0.9882\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0051 - acc: 0.9544 - rmse: 0.0342 - mse: 0.0051 - r_square: 0.9393 - val_loss: 0.0023 - val_acc: 0.9010 - val_rmse: 0.0349 - val_mse: 0.0023 - val_r_square: 0.9880\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0051 - acc: 0.9550 - rmse: 0.0341 - mse: 0.0051 - r_square: 0.9394 - val_loss: 0.0023 - val_acc: 0.9134 - val_rmse: 0.0356 - val_mse: 0.0023 - val_r_square: 0.9878\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0051 - acc: 0.9547 - rmse: 0.0343 - mse: 0.0051 - r_square: 0.9389 - val_loss: 0.0024 - val_acc: 0.9142 - val_rmse: 0.0359 - val_mse: 0.0024 - val_r_square: 0.9876\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0052 - acc: 0.9559 - rmse: 0.0341 - mse: 0.0052 - r_square: 0.9382 - val_loss: 0.0024 - val_acc: 0.9144 - val_rmse: 0.0367 - val_mse: 0.0024 - val_r_square: 0.9873\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0053 - acc: 0.9549 - rmse: 0.0350 - mse: 0.0053 - r_square: 0.9348 - val_loss: 0.0024 - val_acc: 0.9147 - val_rmse: 0.0367 - val_mse: 0.0024 - val_r_square: 0.9873\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0051 - acc: 0.9561 - rmse: 0.0338 - mse: 0.0051 - r_square: 0.9389 - val_loss: 0.0025 - val_acc: 0.9148 - val_rmse: 0.0373 - val_mse: 0.0025 - val_r_square: 0.9871\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0051 - acc: 0.9590 - rmse: 0.0339 - mse: 0.0051 - r_square: 0.9390 - val_loss: 0.0024 - val_acc: 0.9142 - val_rmse: 0.0373 - val_mse: 0.0024 - val_r_square: 0.9871\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0051 - acc: 0.9584 - rmse: 0.0332 - mse: 0.0051 - r_square: 0.9397 - val_loss: 0.0025 - val_acc: 0.9151 - val_rmse: 0.0375 - val_mse: 0.0025 - val_r_square: 0.9870\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0051 - acc: 0.9587 - rmse: 0.0331 - mse: 0.0051 - r_square: 0.9397 - val_loss: 0.0025 - val_acc: 0.9144 - val_rmse: 0.0373 - val_mse: 0.0025 - val_r_square: 0.9871\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0050 - acc: 0.9589 - rmse: 0.0323 - mse: 0.0050 - r_square: 0.9404 - val_loss: 0.0025 - val_acc: 0.9151 - val_rmse: 0.0374 - val_mse: 0.0025 - val_r_square: 0.9870\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0050 - acc: 0.9575 - rmse: 0.0321 - mse: 0.0050 - r_square: 0.9401 - val_loss: 0.0025 - val_acc: 0.9145 - val_rmse: 0.0371 - val_mse: 0.0025 - val_r_square: 0.9871\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0050 - acc: 0.9590 - rmse: 0.0311 - mse: 0.0050 - r_square: 0.9407 - val_loss: 0.0025 - val_acc: 0.9151 - val_rmse: 0.0373 - val_mse: 0.0025 - val_r_square: 0.9870\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0050 - acc: 0.9576 - rmse: 0.0311 - mse: 0.0050 - r_square: 0.9400 - val_loss: 0.0025 - val_acc: 0.9148 - val_rmse: 0.0369 - val_mse: 0.0025 - val_r_square: 0.9870\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0049 - acc: 0.9588 - rmse: 0.0299 - mse: 0.0049 - r_square: 0.9409 - val_loss: 0.0025 - val_acc: 0.9152 - val_rmse: 0.0371 - val_mse: 0.0025 - val_r_square: 0.9869\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0050 - acc: 0.9577 - rmse: 0.0299 - mse: 0.0050 - r_square: 0.9400 - val_loss: 0.0025 - val_acc: 0.9152 - val_rmse: 0.0368 - val_mse: 0.0025 - val_r_square: 0.9870\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0049 - acc: 0.9579 - rmse: 0.0290 - mse: 0.0049 - r_square: 0.9412 - val_loss: 0.0025 - val_acc: 0.9154 - val_rmse: 0.0368 - val_mse: 0.0025 - val_r_square: 0.9869\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9590 - rmse: 0.0287 - mse: 0.0049 - r_square: 0.9415 - val_loss: 0.0025 - val_acc: 0.9406 - val_rmse: 0.0368 - val_mse: 0.0025 - val_r_square: 0.9868\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9579 - rmse: 0.0282 - mse: 0.0048 - r_square: 0.9424 - val_loss: 0.0025 - val_acc: 0.9403 - val_rmse: 0.0368 - val_mse: 0.0025 - val_r_square: 0.9868\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0048 - acc: 0.9573 - rmse: 0.0280 - mse: 0.0048 - r_square: 0.9424 - val_loss: 0.0025 - val_acc: 0.9545 - val_rmse: 0.0369 - val_mse: 0.0025 - val_r_square: 0.9867\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9566 - rmse: 0.0278 - mse: 0.0048 - r_square: 0.9424 - val_loss: 0.0025 - val_acc: 0.9539 - val_rmse: 0.0367 - val_mse: 0.0025 - val_r_square: 0.9867\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9567 - rmse: 0.0279 - mse: 0.0048 - r_square: 0.9418 - val_loss: 0.0025 - val_acc: 0.9550 - val_rmse: 0.0368 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0048 - acc: 0.9564 - rmse: 0.0276 - mse: 0.0048 - r_square: 0.9416 - val_loss: 0.0025 - val_acc: 0.9547 - val_rmse: 0.0368 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0048 - acc: 0.9551 - rmse: 0.0279 - mse: 0.0048 - r_square: 0.9418 - val_loss: 0.0025 - val_acc: 0.9550 - val_rmse: 0.0367 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9566 - rmse: 0.0274 - mse: 0.0048 - r_square: 0.9430 - val_loss: 0.0025 - val_acc: 0.9668 - val_rmse: 0.0368 - val_mse: 0.0025 - val_r_square: 0.9865\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0048 - acc: 0.9571 - rmse: 0.0276 - mse: 0.0048 - r_square: 0.9427 - val_loss: 0.0025 - val_acc: 0.9666 - val_rmse: 0.0366 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0048 - acc: 0.9561 - rmse: 0.0275 - mse: 0.0048 - r_square: 0.9423 - val_loss: 0.0025 - val_acc: 0.9676 - val_rmse: 0.0366 - val_mse: 0.0025 - val_r_square: 0.9865\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9568 - rmse: 0.0280 - mse: 0.0049 - r_square: 0.9412 - val_loss: 0.0025 - val_acc: 0.9675 - val_rmse: 0.0365 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9564 - rmse: 0.0276 - mse: 0.0049 - r_square: 0.9414 - val_loss: 0.0026 - val_acc: 0.9676 - val_rmse: 0.0366 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0048 - acc: 0.9549 - rmse: 0.0279 - mse: 0.0048 - r_square: 0.9420 - val_loss: 0.0025 - val_acc: 0.9676 - val_rmse: 0.0363 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9569 - rmse: 0.0277 - mse: 0.0048 - r_square: 0.9430 - val_loss: 0.0026 - val_acc: 0.9680 - val_rmse: 0.0365 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0048 - acc: 0.9561 - rmse: 0.0278 - mse: 0.0048 - r_square: 0.9430 - val_loss: 0.0025 - val_acc: 0.9678 - val_rmse: 0.0363 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9564 - rmse: 0.0279 - mse: 0.0048 - r_square: 0.9428 - val_loss: 0.0026 - val_acc: 0.9683 - val_rmse: 0.0365 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0048 - acc: 0.9566 - rmse: 0.0283 - mse: 0.0048 - r_square: 0.9418 - val_loss: 0.0025 - val_acc: 0.9680 - val_rmse: 0.0362 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9565 - rmse: 0.0282 - mse: 0.0049 - r_square: 0.9406 - val_loss: 0.0026 - val_acc: 0.9683 - val_rmse: 0.0364 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0049 - acc: 0.9544 - rmse: 0.0287 - mse: 0.0049 - r_square: 0.9406 - val_loss: 0.0025 - val_acc: 0.9796 - val_rmse: 0.0361 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0048 - acc: 0.9569 - rmse: 0.0285 - mse: 0.0048 - r_square: 0.9423 - val_loss: 0.0026 - val_acc: 0.9797 - val_rmse: 0.0365 - val_mse: 0.0026 - val_r_square: 0.9864\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 321us/step - loss: 0.0048 - acc: 0.9561 - rmse: 0.0285 - mse: 0.0048 - r_square: 0.9424 - val_loss: 0.0025 - val_acc: 0.9793 - val_rmse: 0.0362 - val_mse: 0.0025 - val_r_square: 0.9866\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0048 - acc: 0.9571 - rmse: 0.0286 - mse: 0.0048 - r_square: 0.9425 - val_loss: 0.0026 - val_acc: 0.9906 - val_rmse: 0.0367 - val_mse: 0.0026 - val_r_square: 0.9863\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0048 - acc: 0.9573 - rmse: 0.0288 - mse: 0.0048 - r_square: 0.9421 - val_loss: 0.0026 - val_acc: 0.9797 - val_rmse: 0.0364 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0049 - acc: 0.9559 - rmse: 0.0288 - mse: 0.0049 - r_square: 0.9414 - val_loss: 0.0026 - val_acc: 0.9911 - val_rmse: 0.0366 - val_mse: 0.0026 - val_r_square: 0.9864\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0049 - acc: 0.9576 - rmse: 0.0294 - mse: 0.0049 - r_square: 0.9402 - val_loss: 0.0026 - val_acc: 0.9908 - val_rmse: 0.0364 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0049 - acc: 0.9561 - rmse: 0.0288 - mse: 0.0049 - r_square: 0.9416 - val_loss: 0.0026 - val_acc: 0.9912 - val_rmse: 0.0365 - val_mse: 0.0026 - val_r_square: 0.9864\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0048 - acc: 0.9573 - rmse: 0.0290 - mse: 0.0048 - r_square: 0.9421 - val_loss: 0.0026 - val_acc: 0.9906 - val_rmse: 0.0364 - val_mse: 0.0026 - val_r_square: 0.9865\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0048 - acc: 0.9563 - rmse: 0.0289 - mse: 0.0048 - r_square: 0.9425 - val_loss: 0.0026 - val_acc: 0.9905 - val_rmse: 0.0367 - val_mse: 0.0026 - val_r_square: 0.9864\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0048 - acc: 0.9576 - rmse: 0.0291 - mse: 0.0048 - r_square: 0.9421 - val_loss: 0.0026 - val_acc: 0.9797 - val_rmse: 0.0368 - val_mse: 0.0026 - val_r_square: 0.9863\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9563 - rmse: 0.0289 - mse: 0.0049 - r_square: 0.9409 - val_loss: 0.0026 - val_acc: 0.9791 - val_rmse: 0.0368 - val_mse: 0.0026 - val_r_square: 0.9863\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_15 (RepeatVect (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 9s 1ms/step - loss: 0.0219 - acc: 0.6293 - mse: 0.0219 - rmse: 0.1212 - r_square: 0.6725 - val_loss: 0.0222 - val_acc: 0.4442 - val_mse: 0.0222 - val_rmse: 0.1433 - val_r_square: 0.8812\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0127 - acc: 0.8787 - mse: 0.0127 - rmse: 0.0912 - r_square: 0.7973 - val_loss: 0.0056 - val_acc: 0.9814 - val_mse: 0.0056 - val_rmse: 0.0670 - val_r_square: 0.9701\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0114 - acc: 0.9318 - mse: 0.0114 - rmse: 0.0732 - r_square: 0.8293 - val_loss: 0.0106 - val_acc: 0.8365 - val_mse: 0.0106 - val_rmse: 0.0987 - val_r_square: 0.9436\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0113 - acc: 0.7080 - mse: 0.0113 - rmse: 0.0842 - r_square: 0.8190 - val_loss: 0.0076 - val_acc: 0.8365 - val_mse: 0.0076 - val_rmse: 0.0817 - val_r_square: 0.9596\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0088 - acc: 0.8660 - mse: 0.0088 - rmse: 0.0663 - r_square: 0.8639 - val_loss: 0.0043 - val_acc: 0.8366 - val_mse: 0.0043 - val_rmse: 0.0585 - val_r_square: 0.9772\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0089 - acc: 0.9193 - mse: 0.0089 - rmse: 0.0669 - r_square: 0.8729 - val_loss: 0.0035 - val_acc: 0.8378 - val_mse: 0.0035 - val_rmse: 0.0469 - val_r_square: 0.9818\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0103 - acc: 0.7944 - mse: 0.0103 - rmse: 0.0739 - r_square: 0.8293 - val_loss: 0.0077 - val_acc: 0.8366 - val_mse: 0.0077 - val_rmse: 0.0822 - val_r_square: 0.9592\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0103 - acc: 0.9107 - mse: 0.0103 - rmse: 0.0720 - r_square: 0.8407 - val_loss: 0.0030 - val_acc: 0.8507 - val_mse: 0.0030 - val_rmse: 0.0458 - val_r_square: 0.9841\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0082 - acc: 0.7422 - mse: 0.0082 - rmse: 0.0667 - r_square: 0.8714 - val_loss: 0.0041 - val_acc: 0.8365 - val_mse: 0.0041 - val_rmse: 0.0564 - val_r_square: 0.9782\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0096 - acc: 0.9423 - mse: 0.0096 - rmse: 0.0684 - r_square: 0.8657 - val_loss: 0.0044 - val_acc: 0.8352 - val_mse: 0.0044 - val_rmse: 0.0505 - val_r_square: 0.9772\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0116 - acc: 0.7463 - mse: 0.0116 - rmse: 0.0789 - r_square: 0.8211 - val_loss: 0.0074 - val_acc: 0.8490 - val_mse: 0.0074 - val_rmse: 0.0808 - val_r_square: 0.9603\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0081 - acc: 0.9426 - mse: 0.0081 - rmse: 0.0620 - r_square: 0.8735 - val_loss: 0.0116 - val_acc: 0.8368 - val_mse: 0.0116 - val_rmse: 0.1024 - val_r_square: 0.9378\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0070 - acc: 0.9215 - mse: 0.0070 - rmse: 0.0544 - r_square: 0.9030 - val_loss: 0.0045 - val_acc: 0.9013 - val_mse: 0.0045 - val_rmse: 0.0602 - val_r_square: 0.9760\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0075 - acc: 0.9355 - mse: 0.0075 - rmse: 0.0597 - r_square: 0.8943 - val_loss: 0.0134 - val_acc: 0.9138 - val_mse: 0.0134 - val_rmse: 0.1089 - val_r_square: 0.9285\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0076 - acc: 0.9133 - mse: 0.0076 - rmse: 0.0598 - r_square: 0.8985 - val_loss: 0.0128 - val_acc: 0.9911 - val_mse: 0.0128 - val_rmse: 0.1070 - val_r_square: 0.9316\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0078 - acc: 0.9276 - mse: 0.0078 - rmse: 0.0607 - r_square: 0.9023 - val_loss: 0.0270 - val_acc: 0.8365 - val_mse: 0.0270 - val_rmse: 0.1567 - val_r_square: 0.8554\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0078 - acc: 0.8225 - mse: 0.0078 - rmse: 0.0613 - r_square: 0.9014 - val_loss: 0.0124 - val_acc: 0.9419 - val_mse: 0.0124 - val_rmse: 0.1052 - val_r_square: 0.9340\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0060 - acc: 0.9434 - mse: 0.0060 - rmse: 0.0479 - r_square: 0.9188 - val_loss: 0.0030 - val_acc: 0.8365 - val_mse: 0.0030 - val_rmse: 0.0409 - val_r_square: 0.9845\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0082 - acc: 0.9433 - mse: 0.0082 - rmse: 0.0646 - r_square: 0.8903 - val_loss: 0.0039 - val_acc: 0.8365 - val_mse: 0.0039 - val_rmse: 0.0544 - val_r_square: 0.9795\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0068 - acc: 0.9326 - mse: 0.0068 - rmse: 0.0547 - r_square: 0.9017 - val_loss: 0.0050 - val_acc: 0.8365 - val_mse: 0.0050 - val_rmse: 0.0626 - val_r_square: 0.9734\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0061 - acc: 0.9538 - mse: 0.0061 - rmse: 0.0469 - r_square: 0.9196 - val_loss: 0.0026 - val_acc: 0.9383 - val_mse: 0.0026 - val_rmse: 0.0399 - val_r_square: 0.9862\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0064 - acc: 0.9476 - mse: 0.0064 - rmse: 0.0514 - r_square: 0.9150 - val_loss: 0.0030 - val_acc: 0.9011 - val_mse: 0.0030 - val_rmse: 0.0445 - val_r_square: 0.9842\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0076 - acc: 0.9356 - mse: 0.0076 - rmse: 0.0592 - r_square: 0.8956 - val_loss: 0.0030 - val_acc: 0.9928 - val_mse: 0.0030 - val_rmse: 0.0441 - val_r_square: 0.9844\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0063 - acc: 0.8433 - mse: 0.0063 - rmse: 0.0504 - r_square: 0.9173 - val_loss: 0.0045 - val_acc: 0.9904 - val_mse: 0.0045 - val_rmse: 0.0580 - val_r_square: 0.9760\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0059 - acc: 0.7700 - mse: 0.0059 - rmse: 0.0483 - r_square: 0.9154 - val_loss: 0.0033 - val_acc: 0.9919 - val_mse: 0.0033 - val_rmse: 0.0463 - val_r_square: 0.9827\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0065 - acc: 0.9409 - mse: 0.0065 - rmse: 0.0527 - r_square: 0.9149 - val_loss: 0.0040 - val_acc: 0.9424 - val_mse: 0.0040 - val_rmse: 0.0537 - val_r_square: 0.9791\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0071 - acc: 0.9154 - mse: 0.0071 - rmse: 0.0583 - r_square: 0.9039 - val_loss: 0.0022 - val_acc: 0.9942 - val_mse: 0.0022 - val_rmse: 0.0310 - val_r_square: 0.9887\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0068 - acc: 0.9470 - mse: 0.0068 - rmse: 0.0517 - r_square: 0.9177 - val_loss: 0.0050 - val_acc: 0.9928 - val_mse: 0.0050 - val_rmse: 0.0627 - val_r_square: 0.9732\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0063 - acc: 0.8751 - mse: 0.0063 - rmse: 0.0498 - r_square: 0.9164 - val_loss: 0.0042 - val_acc: 0.9942 - val_mse: 0.0042 - val_rmse: 0.0557 - val_r_square: 0.9776\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0065 - acc: 0.9179 - mse: 0.0065 - rmse: 0.0536 - r_square: 0.9128 - val_loss: 0.0057 - val_acc: 0.9942 - val_mse: 0.0057 - val_rmse: 0.0674 - val_r_square: 0.9699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0065 - acc: 0.9410 - mse: 0.0065 - rmse: 0.0536 - r_square: 0.9082 - val_loss: 0.0027 - val_acc: 0.9940 - val_mse: 0.0027 - val_rmse: 0.0408 - val_r_square: 0.9860\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0078 - acc: 0.9206 - mse: 0.0078 - rmse: 0.0609 - r_square: 0.9018 - val_loss: 0.0045 - val_acc: 0.8864 - val_mse: 0.0045 - val_rmse: 0.0592 - val_r_square: 0.9760\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0071 - acc: 0.8964 - mse: 0.0071 - rmse: 0.0565 - r_square: 0.8986 - val_loss: 0.0050 - val_acc: 0.9656 - val_mse: 0.0050 - val_rmse: 0.0629 - val_r_square: 0.9732\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0063 - acc: 0.9370 - mse: 0.0063 - rmse: 0.0529 - r_square: 0.9154 - val_loss: 0.0035 - val_acc: 0.9941 - val_mse: 0.0035 - val_rmse: 0.0500 - val_r_square: 0.9814\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0062 - acc: 0.9578 - mse: 0.0062 - rmse: 0.0485 - r_square: 0.9193 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0285 - val_r_square: 0.9901\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0068 - acc: 0.9344 - mse: 0.0068 - rmse: 0.0544 - r_square: 0.9134 - val_loss: 0.0074 - val_acc: 0.8844 - val_mse: 0.0074 - val_rmse: 0.0790 - val_r_square: 0.9606\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0068 - acc: 0.9168 - mse: 0.0068 - rmse: 0.0544 - r_square: 0.9053 - val_loss: 0.0031 - val_acc: 0.8365 - val_mse: 0.0031 - val_rmse: 0.0450 - val_r_square: 0.9838\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0065 - acc: 0.9381 - mse: 0.0065 - rmse: 0.0526 - r_square: 0.9130 - val_loss: 0.0053 - val_acc: 0.9942 - val_mse: 0.0053 - val_rmse: 0.0659 - val_r_square: 0.9721\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0070 - acc: 0.9605 - mse: 0.0070 - rmse: 0.0557 - r_square: 0.9069 - val_loss: 0.0100 - val_acc: 0.3378 - val_mse: 0.0100 - val_rmse: 0.0913 - val_r_square: 0.9468\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0068 - acc: 0.9245 - mse: 0.0068 - rmse: 0.0540 - r_square: 0.9015 - val_loss: 0.0042 - val_acc: 0.9370 - val_mse: 0.0042 - val_rmse: 0.0558 - val_r_square: 0.9776\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0065 - acc: 0.9459 - mse: 0.0065 - rmse: 0.0492 - r_square: 0.9158 - val_loss: 0.0055 - val_acc: 0.8365 - val_mse: 0.0055 - val_rmse: 0.0675 - val_r_square: 0.9706\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0072 - acc: 0.8601 - mse: 0.0072 - rmse: 0.0595 - r_square: 0.8888 - val_loss: 0.0042 - val_acc: 0.8592 - val_mse: 0.0042 - val_rmse: 0.0563 - val_r_square: 0.9777\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0077 - acc: 0.9160 - mse: 0.0077 - rmse: 0.0598 - r_square: 0.8941 - val_loss: 0.0082 - val_acc: 0.9109 - val_mse: 0.0082 - val_rmse: 0.0813 - val_r_square: 0.9563\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0073 - acc: 0.8497 - mse: 0.0073 - rmse: 0.0609 - r_square: 0.9003 - val_loss: 0.0060 - val_acc: 0.9938 - val_mse: 0.0060 - val_rmse: 0.0710 - val_r_square: 0.9680\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0065 - acc: 0.9546 - mse: 0.0065 - rmse: 0.0529 - r_square: 0.9132 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0370 - val_r_square: 0.9877\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0072 - acc: 0.8785 - mse: 0.0072 - rmse: 0.0595 - r_square: 0.8874 - val_loss: 0.0060 - val_acc: 0.8365 - val_mse: 0.0060 - val_rmse: 0.0707 - val_r_square: 0.9679\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0065 - acc: 0.9329 - mse: 0.0065 - rmse: 0.0525 - r_square: 0.9131 - val_loss: 0.0038 - val_acc: 0.9937 - val_mse: 0.0038 - val_rmse: 0.0516 - val_r_square: 0.9798\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0063 - acc: 0.9155 - mse: 0.0063 - rmse: 0.0495 - r_square: 0.9193 - val_loss: 0.0045 - val_acc: 0.9937 - val_mse: 0.0045 - val_rmse: 0.0601 - val_r_square: 0.9762\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0066 - acc: 0.9252 - mse: 0.0066 - rmse: 0.0532 - r_square: 0.9051 - val_loss: 0.0025 - val_acc: 0.9678 - val_mse: 0.0025 - val_rmse: 0.0387 - val_r_square: 0.9867\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0058 - acc: 0.9346 - mse: 0.0058 - rmse: 0.0434 - r_square: 0.9258 - val_loss: 0.0031 - val_acc: 0.9909 - val_mse: 0.0031 - val_rmse: 0.0450 - val_r_square: 0.9835\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0064 - acc: 0.9397 - mse: 0.0064 - rmse: 0.0524 - r_square: 0.9125 - val_loss: 0.0031 - val_acc: 0.9922 - val_mse: 0.0031 - val_rmse: 0.0455 - val_r_square: 0.9836\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0058 - acc: 0.9471 - mse: 0.0058 - rmse: 0.0450 - r_square: 0.9234 - val_loss: 0.0031 - val_acc: 0.8470 - val_mse: 0.0031 - val_rmse: 0.0457 - val_r_square: 0.9836\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0064 - acc: 0.8911 - mse: 0.0064 - rmse: 0.0510 - r_square: 0.9068 - val_loss: 0.0025 - val_acc: 0.9937 - val_mse: 0.0025 - val_rmse: 0.0386 - val_r_square: 0.9868\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0063 - acc: 0.9048 - mse: 0.0063 - rmse: 0.0494 - r_square: 0.9129 - val_loss: 0.0034 - val_acc: 0.9937 - val_mse: 0.0034 - val_rmse: 0.0485 - val_r_square: 0.9821\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0058 - acc: 0.9389 - mse: 0.0058 - rmse: 0.0467 - r_square: 0.9238 - val_loss: 0.0038 - val_acc: 0.9927 - val_mse: 0.0038 - val_rmse: 0.0528 - val_r_square: 0.9798\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0067 - acc: 0.8723 - mse: 0.0067 - rmse: 0.0555 - r_square: 0.9010 - val_loss: 0.0053 - val_acc: 0.9374 - val_mse: 0.0053 - val_rmse: 0.0650 - val_r_square: 0.9718\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0068 - acc: 0.9243 - mse: 0.0068 - rmse: 0.0556 - r_square: 0.8995 - val_loss: 0.0045 - val_acc: 0.8883 - val_mse: 0.0045 - val_rmse: 0.0600 - val_r_square: 0.9759\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 236us/step - loss: 0.0061 - acc: 0.9097 - mse: 0.0061 - rmse: 0.0472 - r_square: 0.9234 - val_loss: 0.0062 - val_acc: 0.9935 - val_mse: 0.0062 - val_rmse: 0.0699 - val_r_square: 0.9668\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0058 - acc: 0.8098 - mse: 0.0058 - rmse: 0.0459 - r_square: 0.9195 - val_loss: 0.0062 - val_acc: 0.9937 - val_mse: 0.0062 - val_rmse: 0.0714 - val_r_square: 0.9671\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0066 - acc: 0.9467 - mse: 0.0066 - rmse: 0.0530 - r_square: 0.9042 - val_loss: 0.0025 - val_acc: 0.9057 - val_mse: 0.0025 - val_rmse: 0.0390 - val_r_square: 0.9867\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0059 - acc: 0.9367 - mse: 0.0059 - rmse: 0.0462 - r_square: 0.9223 - val_loss: 0.0031 - val_acc: 0.8371 - val_mse: 0.0031 - val_rmse: 0.0456 - val_r_square: 0.9838\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0057 - acc: 0.9482 - mse: 0.0057 - rmse: 0.0440 - r_square: 0.9273 - val_loss: 0.0054 - val_acc: 0.9417 - val_mse: 0.0054 - val_rmse: 0.0647 - val_r_square: 0.9714\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0061 - acc: 0.9284 - mse: 0.0061 - rmse: 0.0484 - r_square: 0.9211 - val_loss: 0.0059 - val_acc: 0.9868 - val_mse: 0.0059 - val_rmse: 0.0678 - val_r_square: 0.9686\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0063 - acc: 0.9428 - mse: 0.0063 - rmse: 0.0506 - r_square: 0.9161 - val_loss: 0.0026 - val_acc: 0.9929 - val_mse: 0.0026 - val_rmse: 0.0393 - val_r_square: 0.9865\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0068 - acc: 0.9509 - mse: 0.0068 - rmse: 0.0547 - r_square: 0.9042 - val_loss: 0.0035 - val_acc: 0.9931 - val_mse: 0.0035 - val_rmse: 0.0504 - val_r_square: 0.9812\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0056 - acc: 0.9472 - mse: 0.0056 - rmse: 0.0425 - r_square: 0.9256 - val_loss: 0.0044 - val_acc: 0.9397 - val_mse: 0.0044 - val_rmse: 0.0567 - val_r_square: 0.9768\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0058 - acc: 0.9535 - mse: 0.0058 - rmse: 0.0452 - r_square: 0.9195 - val_loss: 0.0068 - val_acc: 0.9934 - val_mse: 0.0068 - val_rmse: 0.0748 - val_r_square: 0.9639\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0058 - acc: 0.9526 - mse: 0.0058 - rmse: 0.0455 - r_square: 0.9172 - val_loss: 0.0054 - val_acc: 0.9937 - val_mse: 0.0054 - val_rmse: 0.0647 - val_r_square: 0.9713\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0058 - acc: 0.9531 - mse: 0.0058 - rmse: 0.0448 - r_square: 0.9212 - val_loss: 0.0032 - val_acc: 0.9931 - val_mse: 0.0032 - val_rmse: 0.0453 - val_r_square: 0.9832\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0054 - acc: 0.9562 - mse: 0.0054 - rmse: 0.0404 - r_square: 0.9269 - val_loss: 0.0047 - val_acc: 0.9557 - val_mse: 0.0047 - val_rmse: 0.0586 - val_r_square: 0.9752\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0056 - acc: 0.9477 - mse: 0.0056 - rmse: 0.0429 - r_square: 0.9247 - val_loss: 0.0047 - val_acc: 0.9159 - val_mse: 0.0047 - val_rmse: 0.0588 - val_r_square: 0.9749\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0054 - acc: 0.9545 - mse: 0.0054 - rmse: 0.0409 - r_square: 0.9289 - val_loss: 0.0062 - val_acc: 0.9937 - val_mse: 0.0062 - val_rmse: 0.0692 - val_r_square: 0.9672\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0055 - acc: 0.9545 - mse: 0.0055 - rmse: 0.0407 - r_square: 0.9303 - val_loss: 0.0045 - val_acc: 0.9937 - val_mse: 0.0045 - val_rmse: 0.0593 - val_r_square: 0.9762\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0057 - acc: 0.9472 - mse: 0.0057 - rmse: 0.0432 - r_square: 0.9221 - val_loss: 0.0041 - val_acc: 0.8984 - val_mse: 0.0041 - val_rmse: 0.0544 - val_r_square: 0.9781\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0057 - acc: 0.9440 - mse: 0.0057 - rmse: 0.0446 - r_square: 0.9187 - val_loss: 0.0029 - val_acc: 0.8369 - val_mse: 0.0029 - val_rmse: 0.0435 - val_r_square: 0.9845\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0055 - acc: 0.9531 - mse: 0.0055 - rmse: 0.0406 - r_square: 0.9288 - val_loss: 0.0042 - val_acc: 0.9116 - val_mse: 0.0042 - val_rmse: 0.0543 - val_r_square: 0.9779\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0057 - acc: 0.9521 - mse: 0.0057 - rmse: 0.0418 - r_square: 0.9286 - val_loss: 0.0082 - val_acc: 0.9937 - val_mse: 0.0082 - val_rmse: 0.0835 - val_r_square: 0.9564\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0055 - acc: 0.8029 - mse: 0.0055 - rmse: 0.0432 - r_square: 0.9248 - val_loss: 0.0045 - val_acc: 0.9512 - val_mse: 0.0045 - val_rmse: 0.0577 - val_r_square: 0.9761\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0061 - acc: 0.9375 - mse: 0.0061 - rmse: 0.0494 - r_square: 0.9186 - val_loss: 0.0055 - val_acc: 0.8951 - val_mse: 0.0055 - val_rmse: 0.0658 - val_r_square: 0.9706\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0060 - acc: 0.9294 - mse: 0.0060 - rmse: 0.0472 - r_square: 0.9209 - val_loss: 0.0042 - val_acc: 0.8369 - val_mse: 0.0042 - val_rmse: 0.0563 - val_r_square: 0.9779\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0060 - acc: 0.9454 - mse: 0.0060 - rmse: 0.0475 - r_square: 0.9158 - val_loss: 0.0049 - val_acc: 0.9666 - val_mse: 0.0049 - val_rmse: 0.0608 - val_r_square: 0.9739\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0062 - acc: 0.8309 - mse: 0.0062 - rmse: 0.0492 - r_square: 0.9168 - val_loss: 0.0071 - val_acc: 0.9419 - val_mse: 0.0071 - val_rmse: 0.0748 - val_r_square: 0.9622\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0059 - acc: 0.8850 - mse: 0.0059 - rmse: 0.0476 - r_square: 0.9228 - val_loss: 0.0064 - val_acc: 0.9931 - val_mse: 0.0064 - val_rmse: 0.0723 - val_r_square: 0.9659\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0059 - acc: 0.9502 - mse: 0.0059 - rmse: 0.0463 - r_square: 0.9189 - val_loss: 0.0039 - val_acc: 0.9106 - val_mse: 0.0039 - val_rmse: 0.0533 - val_r_square: 0.9794\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0057 - acc: 0.9412 - mse: 0.0057 - rmse: 0.0441 - r_square: 0.9280 - val_loss: 0.0023 - val_acc: 0.8374 - val_mse: 0.0023 - val_rmse: 0.0354 - val_r_square: 0.9879\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0060 - acc: 0.9462 - mse: 0.0060 - rmse: 0.0443 - r_square: 0.9252 - val_loss: 0.0048 - val_acc: 0.8863 - val_mse: 0.0048 - val_rmse: 0.0589 - val_r_square: 0.9745\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0056 - acc: 0.9200 - mse: 0.0056 - rmse: 0.0430 - r_square: 0.9295 - val_loss: 0.0082 - val_acc: 0.9937 - val_mse: 0.0082 - val_rmse: 0.0840 - val_r_square: 0.9561\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0062 - acc: 0.9527 - mse: 0.0062 - rmse: 0.0491 - r_square: 0.9146 - val_loss: 0.0031 - val_acc: 0.9309 - val_mse: 0.0031 - val_rmse: 0.0460 - val_r_square: 0.9838\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0062 - acc: 0.9367 - mse: 0.0062 - rmse: 0.0487 - r_square: 0.9225 - val_loss: 0.0043 - val_acc: 0.8497 - val_mse: 0.0043 - val_rmse: 0.0572 - val_r_square: 0.9775\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0062 - acc: 0.9522 - mse: 0.0062 - rmse: 0.0472 - r_square: 0.9189 - val_loss: 0.0035 - val_acc: 0.8366 - val_mse: 0.0035 - val_rmse: 0.0500 - val_r_square: 0.9815\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0054 - acc: 0.9500 - mse: 0.0054 - rmse: 0.0399 - r_square: 0.9333 - val_loss: 0.0042 - val_acc: 0.9034 - val_mse: 0.0042 - val_rmse: 0.0551 - val_r_square: 0.9776\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0058 - acc: 0.9428 - mse: 0.0058 - rmse: 0.0436 - r_square: 0.9283 - val_loss: 0.0075 - val_acc: 0.9941 - val_mse: 0.0075 - val_rmse: 0.0805 - val_r_square: 0.9600\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0059 - acc: 0.9416 - mse: 0.0059 - rmse: 0.0480 - r_square: 0.9197 - val_loss: 0.0023 - val_acc: 0.9111 - val_mse: 0.0023 - val_rmse: 0.0362 - val_r_square: 0.9877\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0054 - acc: 0.9484 - mse: 0.0054 - rmse: 0.0406 - r_square: 0.9307 - val_loss: 0.0030 - val_acc: 0.9914 - val_mse: 0.0030 - val_rmse: 0.0431 - val_r_square: 0.9844\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0053 - acc: 0.9538 - mse: 0.0053 - rmse: 0.0392 - r_square: 0.9300 - val_loss: 0.0047 - val_acc: 0.8641 - val_mse: 0.0047 - val_rmse: 0.0593 - val_r_square: 0.9750\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0057 - acc: 0.9478 - mse: 0.0057 - rmse: 0.0443 - r_square: 0.9252 - val_loss: 0.0027 - val_acc: 0.9049 - val_mse: 0.0027 - val_rmse: 0.0408 - val_r_square: 0.9860\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0052 - acc: 0.9470 - mse: 0.0052 - rmse: 0.0356 - r_square: 0.9359 - val_loss: 0.0048 - val_acc: 0.9895 - val_mse: 0.0048 - val_rmse: 0.0596 - val_r_square: 0.9744\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0054 - acc: 0.8912 - mse: 0.0054 - rmse: 0.0401 - r_square: 0.9311 - val_loss: 0.0051 - val_acc: 0.9937 - val_mse: 0.0051 - val_rmse: 0.0629 - val_r_square: 0.9729\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0051 - acc: 0.9460 - mse: 0.0051 - rmse: 0.0377 - r_square: 0.9329 - val_loss: 0.0038 - val_acc: 0.9292 - val_mse: 0.0038 - val_rmse: 0.0516 - val_r_square: 0.9800\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0058 - acc: 0.9229 - mse: 0.0058 - rmse: 0.0466 - r_square: 0.9207 - val_loss: 0.0023 - val_acc: 0.8516 - val_mse: 0.0023 - val_rmse: 0.0366 - val_r_square: 0.9877\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed_x',\n",
       "       'Deaths', 'Recovered', 'Confirmed_y', 'Country', 'Region', 'Population',\n",
       "       'Area (sq. mi.)', 'Pop. Density (per sq. mi.)',\n",
       "       'Coastline (coast/area ratio)', 'Net migration',\n",
       "       'Infant mortality (per 1000 births)', 'GDP ($ per capita)',\n",
       "       'Literacy (%)', 'Phones (per 1000)', 'Arable (%)', 'Crops (%)',\n",
       "       'Climate', 'Birthrate', 'Deathrate', 'Agriculture', 'Industry',\n",
       "       'Service', 'Month', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Crops (%)','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 13s 2ms/step - loss: 0.0415 - acc: 0.6453 - rmse: 0.1677 - mse: 0.0415 - r_square: 0.2009 - val_loss: 0.0315 - val_acc: 0.8365 - val_rmse: 0.1624 - val_mse: 0.0315 - val_r_square: 0.7812\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 3s 376us/step - loss: 0.0254 - acc: 0.8806 - rmse: 0.1289 - mse: 0.0254 - r_square: 0.5352 - val_loss: 0.0200 - val_acc: 0.8365 - val_rmse: 0.1313 - val_mse: 0.0200 - val_r_square: 0.8633\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0201 - acc: 0.9108 - rmse: 0.1068 - mse: 0.0201 - r_square: 0.6667 - val_loss: 0.0137 - val_acc: 0.8365 - val_rmse: 0.1078 - val_mse: 0.0137 - val_r_square: 0.9065\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 339us/step - loss: 0.0159 - acc: 0.9016 - rmse: 0.0905 - mse: 0.0159 - r_square: 0.7398 - val_loss: 0.0098 - val_acc: 0.8365 - val_rmse: 0.0909 - val_mse: 0.0098 - val_r_square: 0.9341\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0121 - acc: 0.8845 - rmse: 0.0732 - mse: 0.0121 - r_square: 0.7919 - val_loss: 0.0062 - val_acc: 0.8365 - val_rmse: 0.0680 - val_mse: 0.0062 - val_r_square: 0.9586\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 294us/step - loss: 0.0094 - acc: 0.9013 - rmse: 0.0581 - mse: 0.0094 - r_square: 0.8263 - val_loss: 0.0048 - val_acc: 0.8365 - val_rmse: 0.0531 - val_mse: 0.0048 - val_r_square: 0.9675\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 296us/step - loss: 0.0084 - acc: 0.9103 - rmse: 0.0540 - mse: 0.0084 - r_square: 0.8411 - val_loss: 0.0036 - val_acc: 0.8369 - val_rmse: 0.0446 - val_mse: 0.0036 - val_r_square: 0.9761\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0078 - acc: 0.9198 - rmse: 0.0496 - mse: 0.0078 - r_square: 0.8532 - val_loss: 0.0033 - val_acc: 0.8412 - val_rmse: 0.0450 - val_mse: 0.0033 - val_r_square: 0.9780\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0074 - acc: 0.9255 - rmse: 0.0476 - mse: 0.0074 - r_square: 0.8587 - val_loss: 0.0030 - val_acc: 0.8407 - val_rmse: 0.0441 - val_mse: 0.0030 - val_r_square: 0.9810\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0071 - acc: 0.9280 - rmse: 0.0461 - mse: 0.0071 - r_square: 0.8640 - val_loss: 0.0024 - val_acc: 0.8401 - val_rmse: 0.0368 - val_mse: 0.0024 - val_r_square: 0.9850\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0069 - acc: 0.9292 - rmse: 0.0447 - mse: 0.0069 - r_square: 0.8663 - val_loss: 0.0024 - val_acc: 0.8389 - val_rmse: 0.0375 - val_mse: 0.0024 - val_r_square: 0.9854\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0068 - acc: 0.9359 - rmse: 0.0452 - mse: 0.0068 - r_square: 0.8665 - val_loss: 0.0026 - val_acc: 0.8379 - val_rmse: 0.0410 - val_mse: 0.0026 - val_r_square: 0.9839\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0067 - acc: 0.9368 - rmse: 0.0451 - mse: 0.0067 - r_square: 0.8689 - val_loss: 0.0024 - val_acc: 0.8395 - val_rmse: 0.0392 - val_mse: 0.0024 - val_r_square: 0.9850\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0065 - acc: 0.9378 - rmse: 0.0430 - mse: 0.0065 - r_square: 0.8726 - val_loss: 0.0025 - val_acc: 0.8377 - val_rmse: 0.0401 - val_mse: 0.0025 - val_r_square: 0.9846\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0064 - acc: 0.9387 - rmse: 0.0431 - mse: 0.0064 - r_square: 0.8771 - val_loss: 0.0025 - val_acc: 0.8365 - val_rmse: 0.0381 - val_mse: 0.0025 - val_r_square: 0.9850\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 287us/step - loss: 0.0064 - acc: 0.9396 - rmse: 0.0437 - mse: 0.0064 - r_square: 0.8797 - val_loss: 0.0022 - val_acc: 0.8369 - val_rmse: 0.0342 - val_mse: 0.0022 - val_r_square: 0.9868\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 285us/step - loss: 0.0065 - acc: 0.9415 - rmse: 0.0450 - mse: 0.0065 - r_square: 0.8784 - val_loss: 0.0031 - val_acc: 0.8365 - val_rmse: 0.0468 - val_mse: 0.0031 - val_r_square: 0.9806\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0067 - acc: 0.9397 - rmse: 0.0470 - mse: 0.0067 - r_square: 0.8803 - val_loss: 0.0034 - val_acc: 0.8379 - val_rmse: 0.0515 - val_mse: 0.0034 - val_r_square: 0.9774\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 299us/step - loss: 0.0067 - acc: 0.9299 - rmse: 0.0484 - mse: 0.0067 - r_square: 0.8745 - val_loss: 0.0037 - val_acc: 0.9434 - val_rmse: 0.0535 - val_mse: 0.0037 - val_r_square: 0.9744\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0066 - acc: 0.9406 - rmse: 0.0473 - mse: 0.0066 - r_square: 0.8788 - val_loss: 0.0020 - val_acc: 0.9406 - val_rmse: 0.0338 - val_mse: 0.0020 - val_r_square: 0.9871\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0073 - acc: 0.9385 - rmse: 0.0505 - mse: 0.0073 - r_square: 0.8659 - val_loss: 0.0034 - val_acc: 0.9426 - val_rmse: 0.0497 - val_mse: 0.0034 - val_r_square: 0.9768\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0068 - acc: 0.9435 - rmse: 0.0475 - mse: 0.0068 - r_square: 0.8764 - val_loss: 0.0036 - val_acc: 0.9423 - val_rmse: 0.0521 - val_mse: 0.0036 - val_r_square: 0.9754\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 298us/step - loss: 0.0073 - acc: 0.9300 - rmse: 0.0532 - mse: 0.0073 - r_square: 0.8735 - val_loss: 0.0063 - val_acc: 0.9447 - val_rmse: 0.0733 - val_mse: 0.0063 - val_r_square: 0.9554\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0075 - acc: 0.8886 - rmse: 0.0569 - mse: 0.0075 - r_square: 0.8698 - val_loss: 0.0044 - val_acc: 0.9437 - val_rmse: 0.0601 - val_mse: 0.0044 - val_r_square: 0.9692\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 281us/step - loss: 0.0077 - acc: 0.9254 - rmse: 0.0580 - mse: 0.0077 - r_square: 0.8682 - val_loss: 0.0028 - val_acc: 0.8365 - val_rmse: 0.0422 - val_mse: 0.0028 - val_r_square: 0.9828\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 282us/step - loss: 0.0084 - acc: 0.9218 - rmse: 0.0616 - mse: 0.0084 - r_square: 0.8470 - val_loss: 0.0026 - val_acc: 0.8365 - val_rmse: 0.0396 - val_mse: 0.0026 - val_r_square: 0.9842\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 278us/step - loss: 0.0084 - acc: 0.9301 - rmse: 0.0624 - mse: 0.0084 - r_square: 0.8594 - val_loss: 0.0045 - val_acc: 0.8365 - val_rmse: 0.0614 - val_mse: 0.0045 - val_r_square: 0.9699\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 269us/step - loss: 0.0094 - acc: 0.9431 - rmse: 0.0674 - mse: 0.0094 - r_square: 0.8412 - val_loss: 0.0035 - val_acc: 0.8365 - val_rmse: 0.0521 - val_mse: 0.0035 - val_r_square: 0.9771\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0088 - acc: 0.9422 - rmse: 0.0634 - mse: 0.0088 - r_square: 0.8566 - val_loss: 0.0065 - val_acc: 0.8365 - val_rmse: 0.0755 - val_mse: 0.0065 - val_r_square: 0.9547\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0073 - acc: 0.9380 - rmse: 0.0550 - mse: 0.0073 - r_square: 0.8742 - val_loss: 0.0030 - val_acc: 0.8365 - val_rmse: 0.0472 - val_mse: 0.0030 - val_r_square: 0.9799\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0063 - acc: 0.9390 - rmse: 0.0461 - mse: 0.0063 - r_square: 0.8862 - val_loss: 0.0020 - val_acc: 0.8378 - val_rmse: 0.0332 - val_mse: 0.0020 - val_r_square: 0.9879\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0056 - acc: 0.9443 - rmse: 0.0380 - mse: 0.0056 - r_square: 0.8954 - val_loss: 0.0016 - val_acc: 0.8769 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0055 - acc: 0.9444 - rmse: 0.0375 - mse: 0.0055 - r_square: 0.8939 - val_loss: 0.0015 - val_acc: 0.8515 - val_rmse: 0.0258 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0054 - acc: 0.9464 - rmse: 0.0333 - mse: 0.0054 - r_square: 0.8984 - val_loss: 0.0016 - val_acc: 0.8653 - val_rmse: 0.0283 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0054 - acc: 0.9448 - rmse: 0.0334 - mse: 0.0054 - r_square: 0.8964 - val_loss: 0.0015 - val_acc: 0.8659 - val_rmse: 0.0257 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0051 - acc: 0.9504 - rmse: 0.0315 - mse: 0.0051 - r_square: 0.9031 - val_loss: 0.0017 - val_acc: 0.8801 - val_rmse: 0.0297 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9512 - rmse: 0.0313 - mse: 0.0050 - r_square: 0.9041 - val_loss: 0.0015 - val_acc: 0.8659 - val_rmse: 0.0267 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0050 - acc: 0.9514 - rmse: 0.0305 - mse: 0.0050 - r_square: 0.9049 - val_loss: 0.0017 - val_acc: 0.8788 - val_rmse: 0.0293 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9518 - rmse: 0.0305 - mse: 0.0050 - r_square: 0.9055 - val_loss: 0.0016 - val_acc: 0.8785 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0049 - acc: 0.9521 - rmse: 0.0298 - mse: 0.0049 - r_square: 0.9062 - val_loss: 0.0017 - val_acc: 0.8798 - val_rmse: 0.0291 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0049 - acc: 0.9525 - rmse: 0.0298 - mse: 0.0049 - r_square: 0.9067 - val_loss: 0.0016 - val_acc: 0.8915 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9529 - rmse: 0.0295 - mse: 0.0049 - r_square: 0.9070 - val_loss: 0.0017 - val_acc: 0.8915 - val_rmse: 0.0289 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9530 - rmse: 0.0294 - mse: 0.0049 - r_square: 0.9073 - val_loss: 0.0016 - val_acc: 0.9041 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9535 - rmse: 0.0295 - mse: 0.0049 - r_square: 0.9065 - val_loss: 0.0017 - val_acc: 0.8916 - val_rmse: 0.0287 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0050 - acc: 0.9537 - rmse: 0.0293 - mse: 0.0050 - r_square: 0.9060 - val_loss: 0.0016 - val_acc: 0.9413 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0050 - acc: 0.9536 - rmse: 0.0296 - mse: 0.0050 - r_square: 0.9041 - val_loss: 0.0017 - val_acc: 0.9034 - val_rmse: 0.0289 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9541 - rmse: 0.0287 - mse: 0.0048 - r_square: 0.9084 - val_loss: 0.0015 - val_acc: 0.9046 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9541 - rmse: 0.0285 - mse: 0.0048 - r_square: 0.9090 - val_loss: 0.0017 - val_acc: 0.9427 - val_rmse: 0.0291 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0048 - acc: 0.9548 - rmse: 0.0284 - mse: 0.0048 - r_square: 0.9096 - val_loss: 0.0015 - val_acc: 0.9292 - val_rmse: 0.0265 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0048 - acc: 0.9545 - rmse: 0.0280 - mse: 0.0048 - r_square: 0.9098 - val_loss: 0.0017 - val_acc: 0.9545 - val_rmse: 0.0290 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0048 - acc: 0.9555 - rmse: 0.0282 - mse: 0.0048 - r_square: 0.9101 - val_loss: 0.0016 - val_acc: 0.9302 - val_rmse: 0.0269 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0048 - acc: 0.9544 - rmse: 0.0280 - mse: 0.0048 - r_square: 0.9096 - val_loss: 0.0017 - val_acc: 0.9544 - val_rmse: 0.0289 - val_mse: 0.0017 - val_r_square: 0.9891\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9559 - rmse: 0.0285 - mse: 0.0049 - r_square: 0.9081 - val_loss: 0.0016 - val_acc: 0.9420 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0050 - acc: 0.9537 - rmse: 0.0286 - mse: 0.0050 - r_square: 0.9054 - val_loss: 0.0017 - val_acc: 0.9547 - val_rmse: 0.0290 - val_mse: 0.0017 - val_r_square: 0.9890\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9562 - rmse: 0.0280 - mse: 0.0048 - r_square: 0.9104 - val_loss: 0.0016 - val_acc: 0.9542 - val_rmse: 0.0277 - val_mse: 0.0016 - val_r_square: 0.9896\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0047 - acc: 0.9567 - rmse: 0.0277 - mse: 0.0047 - r_square: 0.9109 - val_loss: 0.0017 - val_acc: 0.9429 - val_rmse: 0.0283 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9564 - rmse: 0.0278 - mse: 0.0047 - r_square: 0.9111 - val_loss: 0.0016 - val_acc: 0.9544 - val_rmse: 0.0276 - val_mse: 0.0016 - val_r_square: 0.9896\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9568 - rmse: 0.0277 - mse: 0.0047 - r_square: 0.9115 - val_loss: 0.0017 - val_acc: 0.9430 - val_rmse: 0.0278 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9566 - rmse: 0.0276 - mse: 0.0047 - r_square: 0.9116 - val_loss: 0.0016 - val_acc: 0.9550 - val_rmse: 0.0276 - val_mse: 0.0016 - val_r_square: 0.9896\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9570 - rmse: 0.0277 - mse: 0.0047 - r_square: 0.9119 - val_loss: 0.0017 - val_acc: 0.9433 - val_rmse: 0.0277 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9563 - rmse: 0.0278 - mse: 0.0047 - r_square: 0.9118 - val_loss: 0.0016 - val_acc: 0.9554 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9896\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9567 - rmse: 0.0280 - mse: 0.0047 - r_square: 0.9118 - val_loss: 0.0017 - val_acc: 0.9434 - val_rmse: 0.0280 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0047 - acc: 0.9559 - rmse: 0.0282 - mse: 0.0047 - r_square: 0.9114 - val_loss: 0.0016 - val_acc: 0.9555 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9897\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0048 - acc: 0.9577 - rmse: 0.0286 - mse: 0.0048 - r_square: 0.9105 - val_loss: 0.0017 - val_acc: 0.9434 - val_rmse: 0.0284 - val_mse: 0.0017 - val_r_square: 0.9891\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0049 - acc: 0.9548 - rmse: 0.0292 - mse: 0.0049 - r_square: 0.9095 - val_loss: 0.0016 - val_acc: 0.9547 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9898\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0049 - acc: 0.9565 - rmse: 0.0291 - mse: 0.0049 - r_square: 0.9072 - val_loss: 0.0017 - val_acc: 0.9436 - val_rmse: 0.0282 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9545 - rmse: 0.0292 - mse: 0.0048 - r_square: 0.9114 - val_loss: 0.0017 - val_acc: 0.9427 - val_rmse: 0.0286 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9572 - rmse: 0.0287 - mse: 0.0047 - r_square: 0.9123 - val_loss: 0.0017 - val_acc: 0.9557 - val_rmse: 0.0279 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9564 - rmse: 0.0290 - mse: 0.0048 - r_square: 0.9122 - val_loss: 0.0018 - val_acc: 0.9430 - val_rmse: 0.0297 - val_mse: 0.0018 - val_r_square: 0.9887\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0047 - acc: 0.9575 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9127 - val_loss: 0.0017 - val_acc: 0.9555 - val_rmse: 0.0285 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9576 - rmse: 0.0293 - mse: 0.0048 - r_square: 0.9124 - val_loss: 0.0018 - val_acc: 0.9430 - val_rmse: 0.0304 - val_mse: 0.0018 - val_r_square: 0.9885\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9567 - rmse: 0.0296 - mse: 0.0048 - r_square: 0.9126 - val_loss: 0.0017 - val_acc: 0.9431 - val_rmse: 0.0286 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0048 - acc: 0.9568 - rmse: 0.0298 - mse: 0.0048 - r_square: 0.9118 - val_loss: 0.0018 - val_acc: 0.9430 - val_rmse: 0.0303 - val_mse: 0.0018 - val_r_square: 0.9887\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0048 - acc: 0.9556 - rmse: 0.0302 - mse: 0.0048 - r_square: 0.9105 - val_loss: 0.0016 - val_acc: 0.9427 - val_rmse: 0.0275 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0049 - acc: 0.9536 - rmse: 0.0305 - mse: 0.0049 - r_square: 0.9084 - val_loss: 0.0017 - val_acc: 0.9308 - val_rmse: 0.0294 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0049 - acc: 0.9516 - rmse: 0.0308 - mse: 0.0049 - r_square: 0.9087 - val_loss: 0.0015 - val_acc: 0.9161 - val_rmse: 0.0259 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0048 - acc: 0.9528 - rmse: 0.0300 - mse: 0.0048 - r_square: 0.9109 - val_loss: 0.0016 - val_acc: 0.9039 - val_rmse: 0.0283 - val_mse: 0.0016 - val_r_square: 0.9897\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9541 - rmse: 0.0300 - mse: 0.0047 - r_square: 0.9112 - val_loss: 0.0015 - val_acc: 0.8767 - val_rmse: 0.0251 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9521 - rmse: 0.0296 - mse: 0.0047 - r_square: 0.9114 - val_loss: 0.0017 - val_acc: 0.8764 - val_rmse: 0.0287 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0047 - acc: 0.9532 - rmse: 0.0298 - mse: 0.0047 - r_square: 0.9115 - val_loss: 0.0015 - val_acc: 0.8509 - val_rmse: 0.0251 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9511 - rmse: 0.0294 - mse: 0.0047 - r_square: 0.9116 - val_loss: 0.0017 - val_acc: 0.8509 - val_rmse: 0.0289 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0047 - acc: 0.9526 - rmse: 0.0298 - mse: 0.0047 - r_square: 0.9112 - val_loss: 0.0015 - val_acc: 0.8381 - val_rmse: 0.0254 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0048 - acc: 0.9512 - rmse: 0.0295 - mse: 0.0048 - r_square: 0.9097 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0290 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9526 - rmse: 0.0309 - mse: 0.0050 - r_square: 0.9048 - val_loss: 0.0015 - val_acc: 0.8378 - val_rmse: 0.0262 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9505 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9088 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0291 - val_mse: 0.0017 - val_r_square: 0.9897\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0048 - acc: 0.9508 - rmse: 0.0299 - mse: 0.0048 - r_square: 0.9089 - val_loss: 0.0015 - val_acc: 0.8378 - val_rmse: 0.0264 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0047 - acc: 0.9535 - rmse: 0.0293 - mse: 0.0047 - r_square: 0.9105 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0297 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0047 - acc: 0.9560 - rmse: 0.0292 - mse: 0.0047 - r_square: 0.9113 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0270 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9552 - rmse: 0.0288 - mse: 0.0047 - r_square: 0.9118 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0300 - val_mse: 0.0017 - val_r_square: 0.9891\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 256us/step - loss: 0.0047 - acc: 0.9561 - rmse: 0.0286 - mse: 0.0047 - r_square: 0.9122 - val_loss: 0.0015 - val_acc: 0.8378 - val_rmse: 0.0268 - val_mse: 0.0015 - val_r_square: 0.9904\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0047 - acc: 0.9543 - rmse: 0.0283 - mse: 0.0047 - r_square: 0.9125 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0298 - val_mse: 0.0017 - val_r_square: 0.9891\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 257us/step - loss: 0.0046 - acc: 0.9555 - rmse: 0.0280 - mse: 0.0046 - r_square: 0.9130 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0271 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0046 - acc: 0.9547 - rmse: 0.0278 - mse: 0.0046 - r_square: 0.9131 - val_loss: 0.0017 - val_acc: 0.8378 - val_rmse: 0.0298 - val_mse: 0.0017 - val_r_square: 0.9890\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0046 - acc: 0.9547 - rmse: 0.0277 - mse: 0.0046 - r_square: 0.9133 - val_loss: 0.0016 - val_acc: 0.8378 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0047 - acc: 0.9553 - rmse: 0.0277 - mse: 0.0047 - r_square: 0.9110 - val_loss: 0.0018 - val_acc: 0.8513 - val_rmse: 0.0302 - val_mse: 0.0018 - val_r_square: 0.9887\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0048 - acc: 0.9548 - rmse: 0.0286 - mse: 0.0048 - r_square: 0.9080 - val_loss: 0.0016 - val_acc: 0.8519 - val_rmse: 0.0268 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 259us/step - loss: 0.0047 - acc: 0.9545 - rmse: 0.0277 - mse: 0.0047 - r_square: 0.9115 - val_loss: 0.0018 - val_acc: 0.8638 - val_rmse: 0.0316 - val_mse: 0.0018 - val_r_square: 0.9881\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0046 - acc: 0.9571 - rmse: 0.0273 - mse: 0.0046 - r_square: 0.9130 - val_loss: 0.0016 - val_acc: 0.8767 - val_rmse: 0.0263 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0046 - acc: 0.9555 - rmse: 0.0266 - mse: 0.0046 - r_square: 0.9139 - val_loss: 0.0018 - val_acc: 0.8761 - val_rmse: 0.0301 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 258us/step - loss: 0.0046 - acc: 0.9575 - rmse: 0.0267 - mse: 0.0046 - r_square: 0.9143 - val_loss: 0.0017 - val_acc: 0.9036 - val_rmse: 0.0286 - val_mse: 0.0017 - val_r_square: 0.9891\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 13s 2ms/step - loss: 0.0227 - acc: 0.7472 - rmse: 0.1206 - mse: 0.0227 - r_square: 0.5424 - val_loss: 0.0058 - val_acc: 0.9823 - val_rmse: 0.0680 - val_mse: 0.0058 - val_r_square: 0.9608\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0134 - acc: 0.8575 - rmse: 0.0879 - mse: 0.0134 - r_square: 0.7160 - val_loss: 0.0051 - val_acc: 0.8365 - val_rmse: 0.0645 - val_mse: 0.0051 - val_r_square: 0.9664\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0094 - acc: 0.8985 - rmse: 0.0617 - mse: 0.0094 - r_square: 0.8310 - val_loss: 0.0031 - val_acc: 0.8365 - val_rmse: 0.0453 - val_mse: 0.0031 - val_r_square: 0.9806\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0077 - acc: 0.9034 - rmse: 0.0528 - mse: 0.0077 - r_square: 0.8560 - val_loss: 0.0026 - val_acc: 0.8365 - val_rmse: 0.0398 - val_mse: 0.0026 - val_r_square: 0.9840\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0069 - acc: 0.9051 - rmse: 0.0442 - mse: 0.0069 - r_square: 0.8732 - val_loss: 0.0021 - val_acc: 0.8365 - val_rmse: 0.0331 - val_mse: 0.0021 - val_r_square: 0.9874\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0063 - acc: 0.9308 - rmse: 0.0395 - mse: 0.0063 - r_square: 0.8827 - val_loss: 0.0018 - val_acc: 0.8381 - val_rmse: 0.0286 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0059 - acc: 0.9375 - rmse: 0.0352 - mse: 0.0059 - r_square: 0.8897 - val_loss: 0.0018 - val_acc: 0.8408 - val_rmse: 0.0290 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0058 - acc: 0.9401 - rmse: 0.0345 - mse: 0.0058 - r_square: 0.8909 - val_loss: 0.0017 - val_acc: 0.8420 - val_rmse: 0.0290 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0056 - acc: 0.9414 - rmse: 0.0337 - mse: 0.0056 - r_square: 0.8925 - val_loss: 0.0017 - val_acc: 0.8421 - val_rmse: 0.0283 - val_mse: 0.0017 - val_r_square: 0.9899\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0055 - acc: 0.9417 - rmse: 0.0330 - mse: 0.0055 - r_square: 0.8934 - val_loss: 0.0018 - val_acc: 0.8421 - val_rmse: 0.0307 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0054 - acc: 0.9433 - rmse: 0.0324 - mse: 0.0054 - r_square: 0.8951 - val_loss: 0.0017 - val_acc: 0.8425 - val_rmse: 0.0295 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0053 - acc: 0.9457 - rmse: 0.0315 - mse: 0.0053 - r_square: 0.8970 - val_loss: 0.0016 - val_acc: 0.8418 - val_rmse: 0.0286 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0052 - acc: 0.9469 - rmse: 0.0309 - mse: 0.0052 - r_square: 0.8982 - val_loss: 0.0016 - val_acc: 0.8418 - val_rmse: 0.0283 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0052 - acc: 0.9481 - rmse: 0.0305 - mse: 0.0052 - r_square: 0.8991 - val_loss: 0.0016 - val_acc: 0.8411 - val_rmse: 0.0279 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0051 - acc: 0.9488 - rmse: 0.0303 - mse: 0.0051 - r_square: 0.8997 - val_loss: 0.0016 - val_acc: 0.8404 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0053 - acc: 0.9494 - rmse: 0.0311 - mse: 0.0053 - r_square: 0.8962 - val_loss: 0.0016 - val_acc: 0.8400 - val_rmse: 0.0279 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0057 - acc: 0.9470 - rmse: 0.0321 - mse: 0.0057 - r_square: 0.8858 - val_loss: 0.0017 - val_acc: 0.8520 - val_rmse: 0.0306 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0052 - acc: 0.9509 - rmse: 0.0327 - mse: 0.0052 - r_square: 0.8968 - val_loss: 0.0017 - val_acc: 0.8915 - val_rmse: 0.0296 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0051 - acc: 0.9511 - rmse: 0.0305 - mse: 0.0051 - r_square: 0.9004 - val_loss: 0.0018 - val_acc: 0.9290 - val_rmse: 0.0321 - val_mse: 0.0018 - val_r_square: 0.9881\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0050 - acc: 0.9512 - rmse: 0.0295 - mse: 0.0050 - r_square: 0.9032 - val_loss: 0.0016 - val_acc: 0.8909 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0049 - acc: 0.9544 - rmse: 0.0286 - mse: 0.0049 - r_square: 0.9047 - val_loss: 0.0014 - val_acc: 0.8771 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0049 - acc: 0.9526 - rmse: 0.0283 - mse: 0.0049 - r_square: 0.9057 - val_loss: 0.0013 - val_acc: 0.8394 - val_rmse: 0.0208 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0049 - acc: 0.9549 - rmse: 0.0282 - mse: 0.0049 - r_square: 0.9061 - val_loss: 0.0013 - val_acc: 0.8389 - val_rmse: 0.0209 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0049 - acc: 0.9545 - rmse: 0.0284 - mse: 0.0049 - r_square: 0.9065 - val_loss: 0.0013 - val_acc: 0.8388 - val_rmse: 0.0207 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0049 - acc: 0.9550 - rmse: 0.0289 - mse: 0.0049 - r_square: 0.9061 - val_loss: 0.0013 - val_acc: 0.8385 - val_rmse: 0.0214 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0049 - acc: 0.9550 - rmse: 0.0291 - mse: 0.0049 - r_square: 0.9057 - val_loss: 0.0014 - val_acc: 0.8384 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9921\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0049 - acc: 0.9551 - rmse: 0.0304 - mse: 0.0049 - r_square: 0.9042 - val_loss: 0.0015 - val_acc: 0.8384 - val_rmse: 0.0261 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0050 - acc: 0.9541 - rmse: 0.0312 - mse: 0.0050 - r_square: 0.9028 - val_loss: 0.0017 - val_acc: 0.8646 - val_rmse: 0.0310 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0050 - acc: 0.9536 - rmse: 0.0315 - mse: 0.0050 - r_square: 0.9019 - val_loss: 0.0018 - val_acc: 0.8900 - val_rmse: 0.0319 - val_mse: 0.0018 - val_r_square: 0.9887\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0053 - acc: 0.9526 - rmse: 0.0332 - mse: 0.0053 - r_square: 0.8941 - val_loss: 0.0015 - val_acc: 0.8644 - val_rmse: 0.0257 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0049 - acc: 0.9536 - rmse: 0.0299 - mse: 0.0049 - r_square: 0.9058 - val_loss: 0.0013 - val_acc: 0.8382 - val_rmse: 0.0228 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9565 - rmse: 0.0285 - mse: 0.0048 - r_square: 0.9070 - val_loss: 0.0013 - val_acc: 0.8512 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9544 - rmse: 0.0292 - mse: 0.0048 - r_square: 0.9078 - val_loss: 0.0012 - val_acc: 0.8381 - val_rmse: 0.0197 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0048 - acc: 0.9573 - rmse: 0.0292 - mse: 0.0048 - r_square: 0.9077 - val_loss: 0.0013 - val_acc: 0.8379 - val_rmse: 0.0209 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9561 - rmse: 0.0290 - mse: 0.0048 - r_square: 0.9079 - val_loss: 0.0012 - val_acc: 0.8379 - val_rmse: 0.0199 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9576 - rmse: 0.0287 - mse: 0.0048 - r_square: 0.9082 - val_loss: 0.0013 - val_acc: 0.8379 - val_rmse: 0.0215 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0048 - acc: 0.9573 - rmse: 0.0287 - mse: 0.0048 - r_square: 0.9087 - val_loss: 0.0012 - val_acc: 0.8377 - val_rmse: 0.0184 - val_mse: 0.0012 - val_r_square: 0.9931\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0048 - acc: 0.9577 - rmse: 0.0288 - mse: 0.0048 - r_square: 0.9093 - val_loss: 0.0012 - val_acc: 0.8372 - val_rmse: 0.0190 - val_mse: 0.0012 - val_r_square: 0.9930\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0048 - acc: 0.9569 - rmse: 0.0289 - mse: 0.0048 - r_square: 0.9097 - val_loss: 0.0013 - val_acc: 0.8371 - val_rmse: 0.0183 - val_mse: 0.0013 - val_r_square: 0.9930\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 302us/step - loss: 0.0048 - acc: 0.9578 - rmse: 0.0294 - mse: 0.0048 - r_square: 0.9098 - val_loss: 0.0013 - val_acc: 0.8366 - val_rmse: 0.0190 - val_mse: 0.0013 - val_r_square: 0.9928\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0048 - acc: 0.9560 - rmse: 0.0303 - mse: 0.0048 - r_square: 0.9093 - val_loss: 0.0013 - val_acc: 0.8366 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0049 - acc: 0.9577 - rmse: 0.0311 - mse: 0.0049 - r_square: 0.9079 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0217 - val_mse: 0.0014 - val_r_square: 0.9922\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0049 - acc: 0.9563 - rmse: 0.0317 - mse: 0.0049 - r_square: 0.9069 - val_loss: 0.0014 - val_acc: 0.8365 - val_rmse: 0.0224 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0051 - acc: 0.9567 - rmse: 0.0335 - mse: 0.0051 - r_square: 0.9025 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0287 - val_mse: 0.0017 - val_r_square: 0.9901\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0050 - acc: 0.9559 - rmse: 0.0344 - mse: 0.0050 - r_square: 0.9054 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0285 - val_mse: 0.0017 - val_r_square: 0.9900\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0051 - acc: 0.9575 - rmse: 0.0362 - mse: 0.0051 - r_square: 0.9022 - val_loss: 0.0020 - val_acc: 0.8365 - val_rmse: 0.0338 - val_mse: 0.0020 - val_r_square: 0.9879\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0053 - acc: 0.9545 - rmse: 0.0399 - mse: 0.0053 - r_square: 0.8942 - val_loss: 0.0022 - val_acc: 0.8368 - val_rmse: 0.0378 - val_mse: 0.0022 - val_r_square: 0.9861\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0054 - acc: 0.9550 - rmse: 0.0408 - mse: 0.0054 - r_square: 0.8922 - val_loss: 0.0024 - val_acc: 0.9293 - val_rmse: 0.0401 - val_mse: 0.0024 - val_r_square: 0.9842\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0054 - acc: 0.9545 - rmse: 0.0408 - mse: 0.0054 - r_square: 0.8969 - val_loss: 0.0017 - val_acc: 0.9430 - val_rmse: 0.0286 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0053 - acc: 0.9577 - rmse: 0.0381 - mse: 0.0053 - r_square: 0.9028 - val_loss: 0.0018 - val_acc: 0.8892 - val_rmse: 0.0320 - val_mse: 0.0018 - val_r_square: 0.9885\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0054 - acc: 0.9579 - rmse: 0.0391 - mse: 0.0054 - r_square: 0.9005 - val_loss: 0.0021 - val_acc: 0.9283 - val_rmse: 0.0365 - val_mse: 0.0021 - val_r_square: 0.9863\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0058 - acc: 0.9564 - rmse: 0.0437 - mse: 0.0058 - r_square: 0.8900 - val_loss: 0.0028 - val_acc: 0.9419 - val_rmse: 0.0455 - val_mse: 0.0028 - val_r_square: 0.9811\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0064 - acc: 0.9549 - rmse: 0.0492 - mse: 0.0064 - r_square: 0.8828 - val_loss: 0.0039 - val_acc: 0.9562 - val_rmse: 0.0562 - val_mse: 0.0039 - val_r_square: 0.9728\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0061 - acc: 0.9516 - rmse: 0.0475 - mse: 0.0061 - r_square: 0.8833 - val_loss: 0.0031 - val_acc: 0.9430 - val_rmse: 0.0477 - val_mse: 0.0031 - val_r_square: 0.9787\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0059 - acc: 0.9571 - rmse: 0.0448 - mse: 0.0059 - r_square: 0.8979 - val_loss: 0.0044 - val_acc: 0.9426 - val_rmse: 0.0607 - val_mse: 0.0044 - val_r_square: 0.9691\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0056 - acc: 0.9145 - rmse: 0.0440 - mse: 0.0056 - r_square: 0.8966 - val_loss: 0.0030 - val_acc: 0.9561 - val_rmse: 0.0466 - val_mse: 0.0030 - val_r_square: 0.9794\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0059 - acc: 0.9270 - rmse: 0.0474 - mse: 0.0059 - r_square: 0.8902 - val_loss: 0.0017 - val_acc: 0.8365 - val_rmse: 0.0275 - val_mse: 0.0017 - val_r_square: 0.9902\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0061 - acc: 0.9373 - rmse: 0.0458 - mse: 0.0061 - r_square: 0.8790 - val_loss: 0.0021 - val_acc: 0.8368 - val_rmse: 0.0357 - val_mse: 0.0021 - val_r_square: 0.9870\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0054 - acc: 0.9498 - rmse: 0.0420 - mse: 0.0054 - r_square: 0.8995 - val_loss: 0.0016 - val_acc: 0.9299 - val_rmse: 0.0268 - val_mse: 0.0016 - val_r_square: 0.9905\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0052 - acc: 0.9512 - rmse: 0.0360 - mse: 0.0052 - r_square: 0.9062 - val_loss: 0.0019 - val_acc: 0.9306 - val_rmse: 0.0324 - val_mse: 0.0019 - val_r_square: 0.9882\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0052 - acc: 0.9506 - rmse: 0.0381 - mse: 0.0052 - r_square: 0.9067 - val_loss: 0.0018 - val_acc: 0.8371 - val_rmse: 0.0305 - val_mse: 0.0018 - val_r_square: 0.9892\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0053 - acc: 0.9368 - rmse: 0.0383 - mse: 0.0053 - r_square: 0.9044 - val_loss: 0.0019 - val_acc: 0.8368 - val_rmse: 0.0334 - val_mse: 0.0019 - val_r_square: 0.9880\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0053 - acc: 0.9337 - rmse: 0.0398 - mse: 0.0053 - r_square: 0.9022 - val_loss: 0.0018 - val_acc: 0.8365 - val_rmse: 0.0303 - val_mse: 0.0018 - val_r_square: 0.9894\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0054 - acc: 0.9270 - rmse: 0.0391 - mse: 0.0054 - r_square: 0.9015 - val_loss: 0.0019 - val_acc: 0.8365 - val_rmse: 0.0321 - val_mse: 0.0019 - val_r_square: 0.9886\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0053 - acc: 0.9310 - rmse: 0.0393 - mse: 0.0053 - r_square: 0.9030 - val_loss: 0.0019 - val_acc: 0.8365 - val_rmse: 0.0333 - val_mse: 0.0019 - val_r_square: 0.9881\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0053 - acc: 0.9333 - rmse: 0.0392 - mse: 0.0053 - r_square: 0.9027 - val_loss: 0.0021 - val_acc: 0.8365 - val_rmse: 0.0358 - val_mse: 0.0021 - val_r_square: 0.9869\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0054 - acc: 0.9356 - rmse: 0.0394 - mse: 0.0054 - r_square: 0.9034 - val_loss: 0.0023 - val_acc: 0.8365 - val_rmse: 0.0385 - val_mse: 0.0023 - val_r_square: 0.9856\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0054 - acc: 0.9371 - rmse: 0.0397 - mse: 0.0054 - r_square: 0.9023 - val_loss: 0.0024 - val_acc: 0.8365 - val_rmse: 0.0408 - val_mse: 0.0024 - val_r_square: 0.9843\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0054 - acc: 0.9478 - rmse: 0.0395 - mse: 0.0054 - r_square: 0.9040 - val_loss: 0.0026 - val_acc: 0.8365 - val_rmse: 0.0426 - val_mse: 0.0026 - val_r_square: 0.9832\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0054 - acc: 0.9481 - rmse: 0.0393 - mse: 0.0054 - r_square: 0.9034 - val_loss: 0.0025 - val_acc: 0.8366 - val_rmse: 0.0421 - val_mse: 0.0025 - val_r_square: 0.9834\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0053 - acc: 0.9521 - rmse: 0.0373 - mse: 0.0053 - r_square: 0.9066 - val_loss: 0.0023 - val_acc: 0.8368 - val_rmse: 0.0395 - val_mse: 0.0023 - val_r_square: 0.9848\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0051 - acc: 0.9540 - rmse: 0.0357 - mse: 0.0051 - r_square: 0.9073 - val_loss: 0.0020 - val_acc: 0.8375 - val_rmse: 0.0343 - val_mse: 0.0020 - val_r_square: 0.9874\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0050 - acc: 0.9526 - rmse: 0.0325 - mse: 0.0050 - r_square: 0.9105 - val_loss: 0.0017 - val_acc: 0.8379 - val_rmse: 0.0293 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0049 - acc: 0.9536 - rmse: 0.0314 - mse: 0.0049 - r_square: 0.9109 - val_loss: 0.0015 - val_acc: 0.8646 - val_rmse: 0.0252 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0048 - acc: 0.9522 - rmse: 0.0298 - mse: 0.0048 - r_square: 0.9125 - val_loss: 0.0014 - val_acc: 0.8906 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0047 - acc: 0.9543 - rmse: 0.0289 - mse: 0.0047 - r_square: 0.9132 - val_loss: 0.0013 - val_acc: 0.9034 - val_rmse: 0.0226 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0047 - acc: 0.9530 - rmse: 0.0278 - mse: 0.0047 - r_square: 0.9137 - val_loss: 0.0013 - val_acc: 0.8912 - val_rmse: 0.0223 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9566 - rmse: 0.0272 - mse: 0.0046 - r_square: 0.9139 - val_loss: 0.0013 - val_acc: 0.9282 - val_rmse: 0.0221 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9580 - rmse: 0.0268 - mse: 0.0046 - r_square: 0.9137 - val_loss: 0.0013 - val_acc: 0.9033 - val_rmse: 0.0220 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9587 - rmse: 0.0264 - mse: 0.0046 - r_square: 0.9138 - val_loss: 0.0013 - val_acc: 0.9301 - val_rmse: 0.0222 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9585 - rmse: 0.0263 - mse: 0.0046 - r_square: 0.9144 - val_loss: 0.0013 - val_acc: 0.9036 - val_rmse: 0.0222 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9589 - rmse: 0.0260 - mse: 0.0046 - r_square: 0.9150 - val_loss: 0.0014 - val_acc: 0.9299 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0046 - acc: 0.9593 - rmse: 0.0261 - mse: 0.0046 - r_square: 0.9150 - val_loss: 0.0013 - val_acc: 0.9288 - val_rmse: 0.0225 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9588 - rmse: 0.0259 - mse: 0.0046 - r_square: 0.9149 - val_loss: 0.0014 - val_acc: 0.9542 - val_rmse: 0.0229 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9596 - rmse: 0.0260 - mse: 0.0046 - r_square: 0.9141 - val_loss: 0.0014 - val_acc: 0.9295 - val_rmse: 0.0227 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0046 - acc: 0.9589 - rmse: 0.0258 - mse: 0.0046 - r_square: 0.9145 - val_loss: 0.0014 - val_acc: 0.9552 - val_rmse: 0.0233 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9599 - rmse: 0.0259 - mse: 0.0046 - r_square: 0.9154 - val_loss: 0.0014 - val_acc: 0.9419 - val_rmse: 0.0230 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0046 - acc: 0.9590 - rmse: 0.0256 - mse: 0.0046 - r_square: 0.9157 - val_loss: 0.0014 - val_acc: 0.9557 - val_rmse: 0.0235 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9599 - rmse: 0.0258 - mse: 0.0046 - r_square: 0.9150 - val_loss: 0.0014 - val_acc: 0.9436 - val_rmse: 0.0232 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0046 - acc: 0.9589 - rmse: 0.0258 - mse: 0.0046 - r_square: 0.9148 - val_loss: 0.0014 - val_acc: 0.9564 - val_rmse: 0.0238 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0046 - acc: 0.9599 - rmse: 0.0258 - mse: 0.0046 - r_square: 0.9146 - val_loss: 0.0014 - val_acc: 0.9550 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9590 - rmse: 0.0256 - mse: 0.0046 - r_square: 0.9154 - val_loss: 0.0014 - val_acc: 0.9564 - val_rmse: 0.0241 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0045 - acc: 0.9599 - rmse: 0.0257 - mse: 0.0045 - r_square: 0.9160 - val_loss: 0.0014 - val_acc: 0.9555 - val_rmse: 0.0237 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 305us/step - loss: 0.0045 - acc: 0.9590 - rmse: 0.0256 - mse: 0.0045 - r_square: 0.9159 - val_loss: 0.0014 - val_acc: 0.9564 - val_rmse: 0.0242 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9599 - rmse: 0.0257 - mse: 0.0046 - r_square: 0.9145 - val_loss: 0.0014 - val_acc: 0.9562 - val_rmse: 0.0239 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0046 - acc: 0.9589 - rmse: 0.0257 - mse: 0.0046 - r_square: 0.9153 - val_loss: 0.0014 - val_acc: 0.9564 - val_rmse: 0.0244 - val_mse: 0.0014 - val_r_square: 0.9911\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0045 - acc: 0.9602 - rmse: 0.0257 - mse: 0.0045 - r_square: 0.9163 - val_loss: 0.0014 - val_acc: 0.9562 - val_rmse: 0.0241 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0045 - acc: 0.9590 - rmse: 0.0255 - mse: 0.0045 - r_square: 0.9163 - val_loss: 0.0015 - val_acc: 0.9564 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0046 - acc: 0.9599 - rmse: 0.0256 - mse: 0.0046 - r_square: 0.9148 - val_loss: 0.0014 - val_acc: 0.9562 - val_rmse: 0.0244 - val_mse: 0.0014 - val_r_square: 0.9911\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 303us/step - loss: 0.0046 - acc: 0.9588 - rmse: 0.0257 - mse: 0.0046 - r_square: 0.9156 - val_loss: 0.0015 - val_acc: 0.9565 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9910\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_17 (GRU)                 (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_17 (RepeatVect (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 11s 2ms/step - loss: 0.0137 - acc: 0.8773 - mse: 0.0137 - rmse: 0.0916 - r_square: 0.6812 - val_loss: 0.0054 - val_acc: 0.9927 - val_mse: 0.0054 - val_rmse: 0.0681 - val_r_square: 0.9625\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0131 - acc: 0.9111 - mse: 0.0131 - rmse: 0.0904 - r_square: 0.5735 - val_loss: 0.0054 - val_acc: 0.9018 - val_mse: 0.0054 - val_rmse: 0.0689 - val_r_square: 0.9626\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0108 - acc: 0.8435 - mse: 0.0108 - rmse: 0.0758 - r_square: 0.6428 - val_loss: 0.0031 - val_acc: 0.9942 - val_mse: 0.0031 - val_rmse: 0.0484 - val_r_square: 0.9798\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0094 - acc: 0.9153 - mse: 0.0094 - rmse: 0.0700 - r_square: 0.8015 - val_loss: 0.0068 - val_acc: 0.8365 - val_mse: 0.0068 - val_rmse: 0.0771 - val_r_square: 0.9544\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0110 - acc: 0.8830 - mse: 0.0110 - rmse: 0.0767 - r_square: 0.7404 - val_loss: 0.0075 - val_acc: 0.8365 - val_mse: 0.0075 - val_rmse: 0.0820 - val_r_square: 0.9492\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0099 - acc: 0.8296 - mse: 0.0099 - rmse: 0.0669 - r_square: 0.7593 - val_loss: 0.0041 - val_acc: 0.8369 - val_mse: 0.0041 - val_rmse: 0.0579 - val_r_square: 0.9716\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0095 - acc: 0.9461 - mse: 0.0095 - rmse: 0.0644 - r_square: 0.7532 - val_loss: 0.0047 - val_acc: 0.9691 - val_mse: 0.0047 - val_rmse: 0.0633 - val_r_square: 0.9679\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0101 - acc: 0.9490 - mse: 0.0101 - rmse: 0.0739 - r_square: 0.7137 - val_loss: 0.0050 - val_acc: 0.9430 - val_mse: 0.0050 - val_rmse: 0.0653 - val_r_square: 0.9648\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0106 - acc: 0.9351 - mse: 0.0106 - rmse: 0.0790 - r_square: 0.6518 - val_loss: 0.0038 - val_acc: 0.8369 - val_mse: 0.0038 - val_rmse: 0.0553 - val_r_square: 0.9750\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0093 - acc: 0.9302 - mse: 0.0093 - rmse: 0.0694 - r_square: 0.7779 - val_loss: 0.0031 - val_acc: 0.8365 - val_mse: 0.0031 - val_rmse: 0.0483 - val_r_square: 0.9797\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0089 - acc: 0.9218 - mse: 0.0089 - rmse: 0.0614 - r_square: 0.7603 - val_loss: 0.0025 - val_acc: 0.8365 - val_mse: 0.0025 - val_rmse: 0.0400 - val_r_square: 0.9845\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0107 - acc: 0.9363 - mse: 0.0107 - rmse: 0.0707 - r_square: 0.7689 - val_loss: 0.0059 - val_acc: 0.8365 - val_mse: 0.0059 - val_rmse: 0.0709 - val_r_square: 0.9605\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0082 - acc: 0.9005 - mse: 0.0082 - rmse: 0.0631 - r_square: 0.8061 - val_loss: 0.0051 - val_acc: 0.8368 - val_mse: 0.0051 - val_rmse: 0.0662 - val_r_square: 0.9644\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0068 - acc: 0.9513 - mse: 0.0068 - rmse: 0.0491 - r_square: 0.8617 - val_loss: 0.0025 - val_acc: 0.8366 - val_mse: 0.0025 - val_rmse: 0.0412 - val_r_square: 0.9839\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0077 - acc: 0.9439 - mse: 0.0077 - rmse: 0.0539 - r_square: 0.8483 - val_loss: 0.0035 - val_acc: 0.8365 - val_mse: 0.0035 - val_rmse: 0.0474 - val_r_square: 0.9792\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0076 - acc: 0.9027 - mse: 0.0076 - rmse: 0.0578 - r_square: 0.8443 - val_loss: 0.0034 - val_acc: 0.8365 - val_mse: 0.0034 - val_rmse: 0.0494 - val_r_square: 0.9787\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0095 - acc: 0.9448 - mse: 0.0095 - rmse: 0.0569 - r_square: 0.7710 - val_loss: 0.0028 - val_acc: 0.8368 - val_mse: 0.0028 - val_rmse: 0.0456 - val_r_square: 0.9814\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0076 - acc: 0.9316 - mse: 0.0076 - rmse: 0.0515 - r_square: 0.8454 - val_loss: 0.0025 - val_acc: 0.9548 - val_mse: 0.0025 - val_rmse: 0.0412 - val_r_square: 0.9842\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0077 - acc: 0.8923 - mse: 0.0077 - rmse: 0.0609 - r_square: 0.8292 - val_loss: 0.0024 - val_acc: 0.9942 - val_mse: 0.0024 - val_rmse: 0.0374 - val_r_square: 0.9853\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0068 - acc: 0.9500 - mse: 0.0068 - rmse: 0.0524 - r_square: 0.8463 - val_loss: 0.0038 - val_acc: 0.9942 - val_mse: 0.0038 - val_rmse: 0.0542 - val_r_square: 0.9741\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0075 - acc: 0.9455 - mse: 0.0075 - rmse: 0.0573 - r_square: 0.8332 - val_loss: 0.0041 - val_acc: 0.9419 - val_mse: 0.0041 - val_rmse: 0.0575 - val_r_square: 0.9711\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0079 - acc: 0.8563 - mse: 0.0079 - rmse: 0.0612 - r_square: 0.8232 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0276 - val_r_square: 0.9902\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0072 - acc: 0.9220 - mse: 0.0072 - rmse: 0.0559 - r_square: 0.8408 - val_loss: 0.0022 - val_acc: 0.8365 - val_mse: 0.0022 - val_rmse: 0.0374 - val_r_square: 0.9864\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0064 - acc: 0.8869 - mse: 0.0064 - rmse: 0.0515 - r_square: 0.8516 - val_loss: 0.0039 - val_acc: 0.9424 - val_mse: 0.0039 - val_rmse: 0.0553 - val_r_square: 0.9724\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0077 - acc: 0.9220 - mse: 0.0077 - rmse: 0.0568 - r_square: 0.8433 - val_loss: 0.0029 - val_acc: 0.9942 - val_mse: 0.0029 - val_rmse: 0.0455 - val_r_square: 0.9814\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0077 - acc: 0.9430 - mse: 0.0077 - rmse: 0.0539 - r_square: 0.8271 - val_loss: 0.0026 - val_acc: 0.9942 - val_mse: 0.0026 - val_rmse: 0.0418 - val_r_square: 0.9831\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0066 - acc: 0.9013 - mse: 0.0066 - rmse: 0.0527 - r_square: 0.8243 - val_loss: 0.0033 - val_acc: 0.9934 - val_mse: 0.0033 - val_rmse: 0.0486 - val_r_square: 0.9777\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0076 - acc: 0.9546 - mse: 0.0076 - rmse: 0.0626 - r_square: 0.7822 - val_loss: 0.0017 - val_acc: 0.9424 - val_mse: 0.0017 - val_rmse: 0.0294 - val_r_square: 0.9895\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0068 - acc: 0.9558 - mse: 0.0068 - rmse: 0.0521 - r_square: 0.8546 - val_loss: 0.0031 - val_acc: 0.9430 - val_mse: 0.0031 - val_rmse: 0.0485 - val_r_square: 0.9793\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0064 - acc: 0.9349 - mse: 0.0064 - rmse: 0.0511 - r_square: 0.8315 - val_loss: 0.0022 - val_acc: 0.9259 - val_mse: 0.0022 - val_rmse: 0.0362 - val_r_square: 0.9858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0059 - acc: 0.9580 - mse: 0.0059 - rmse: 0.0469 - r_square: 0.8774 - val_loss: 0.0016 - val_acc: 0.9027 - val_mse: 0.0016 - val_rmse: 0.0269 - val_r_square: 0.9906\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.9543 - mse: 0.0057 - rmse: 0.0438 - r_square: 0.8588 - val_loss: 0.0032 - val_acc: 0.8777 - val_mse: 0.0032 - val_rmse: 0.0485 - val_r_square: 0.9777\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0063 - acc: 0.9563 - mse: 0.0063 - rmse: 0.0489 - r_square: 0.8647 - val_loss: 0.0027 - val_acc: 0.9424 - val_mse: 0.0027 - val_rmse: 0.0435 - val_r_square: 0.9819\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0058 - acc: 0.9577 - mse: 0.0058 - rmse: 0.0455 - r_square: 0.8829 - val_loss: 0.0021 - val_acc: 0.9567 - val_mse: 0.0021 - val_rmse: 0.0352 - val_r_square: 0.9862\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0068 - acc: 0.9596 - mse: 0.0068 - rmse: 0.0512 - r_square: 0.8605 - val_loss: 0.0021 - val_acc: 0.9927 - val_mse: 0.0021 - val_rmse: 0.0370 - val_r_square: 0.9865\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0058 - acc: 0.9478 - mse: 0.0058 - rmse: 0.0461 - r_square: 0.8671 - val_loss: 0.0031 - val_acc: 0.9942 - val_mse: 0.0031 - val_rmse: 0.0467 - val_r_square: 0.9788\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0071 - acc: 0.9555 - mse: 0.0071 - rmse: 0.0568 - r_square: 0.8385 - val_loss: 0.0023 - val_acc: 0.8365 - val_mse: 0.0023 - val_rmse: 0.0376 - val_r_square: 0.9857\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0062 - acc: 0.9252 - mse: 0.0062 - rmse: 0.0480 - r_square: 0.8774 - val_loss: 0.0014 - val_acc: 0.8372 - val_mse: 0.0014 - val_rmse: 0.0230 - val_r_square: 0.9918\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0080 - acc: 0.8963 - mse: 0.0080 - rmse: 0.0592 - r_square: 0.8361 - val_loss: 0.0107 - val_acc: 0.9942 - val_mse: 0.0107 - val_rmse: 0.0985 - val_r_square: 0.9219\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0061 - acc: 0.9121 - mse: 0.0061 - rmse: 0.0505 - r_square: 0.8345 - val_loss: 0.0033 - val_acc: 0.9660 - val_mse: 0.0033 - val_rmse: 0.0479 - val_r_square: 0.9772\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0057 - acc: 0.9230 - mse: 0.0057 - rmse: 0.0401 - r_square: 0.8898 - val_loss: 0.0017 - val_acc: 0.9895 - val_mse: 0.0017 - val_rmse: 0.0291 - val_r_square: 0.9894\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0060 - acc: 0.9272 - mse: 0.0060 - rmse: 0.0428 - r_square: 0.8795 - val_loss: 0.0029 - val_acc: 0.8366 - val_mse: 0.0029 - val_rmse: 0.0468 - val_r_square: 0.9801\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0052 - acc: 0.8887 - mse: 0.0052 - rmse: 0.0398 - r_square: 0.8862 - val_loss: 0.0019 - val_acc: 0.8365 - val_mse: 0.0019 - val_rmse: 0.0334 - val_r_square: 0.9877\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0051 - acc: 0.9596 - mse: 0.0051 - rmse: 0.0353 - r_square: 0.8995 - val_loss: 0.0013 - val_acc: 0.8365 - val_mse: 0.0013 - val_rmse: 0.0212 - val_r_square: 0.9924\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0053 - acc: 0.9574 - mse: 0.0053 - rmse: 0.0380 - r_square: 0.8743 - val_loss: 0.0017 - val_acc: 0.9049 - val_mse: 0.0017 - val_rmse: 0.0302 - val_r_square: 0.9892\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0059 - acc: 0.9025 - mse: 0.0059 - rmse: 0.0455 - r_square: 0.8797 - val_loss: 0.0020 - val_acc: 0.8365 - val_mse: 0.0020 - val_rmse: 0.0352 - val_r_square: 0.9870\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0054 - acc: 0.9608 - mse: 0.0054 - rmse: 0.0414 - r_square: 0.8761 - val_loss: 0.0015 - val_acc: 0.8365 - val_mse: 0.0015 - val_rmse: 0.0256 - val_r_square: 0.9908\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0061 - acc: 0.8679 - mse: 0.0061 - rmse: 0.0491 - r_square: 0.7966 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0294 - val_r_square: 0.9896\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0058 - acc: 0.9450 - mse: 0.0058 - rmse: 0.0454 - r_square: 0.8575 - val_loss: 0.0045 - val_acc: 0.9942 - val_mse: 0.0045 - val_rmse: 0.0604 - val_r_square: 0.9680\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0056 - acc: 0.9657 - mse: 0.0056 - rmse: 0.0434 - r_square: 0.8549 - val_loss: 0.0020 - val_acc: 0.8735 - val_mse: 0.0020 - val_rmse: 0.0347 - val_r_square: 0.9870\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0052 - acc: 0.9622 - mse: 0.0052 - rmse: 0.0385 - r_square: 0.8863 - val_loss: 0.0022 - val_acc: 0.9942 - val_mse: 0.0022 - val_rmse: 0.0373 - val_r_square: 0.9853\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0053 - acc: 0.9583 - mse: 0.0053 - rmse: 0.0404 - r_square: 0.8752 - val_loss: 0.0012 - val_acc: 0.9741 - val_mse: 0.0012 - val_rmse: 0.0164 - val_r_square: 0.9934\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0054 - acc: 0.9569 - mse: 0.0054 - rmse: 0.0403 - r_square: 0.8938 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0266 - val_r_square: 0.9903\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.9594 - mse: 0.0057 - rmse: 0.0446 - r_square: 0.8540 - val_loss: 0.0030 - val_acc: 0.9942 - val_mse: 0.0030 - val_rmse: 0.0467 - val_r_square: 0.9796\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0060 - acc: 0.9644 - mse: 0.0060 - rmse: 0.0478 - r_square: 0.8694 - val_loss: 0.0018 - val_acc: 0.9542 - val_mse: 0.0018 - val_rmse: 0.0314 - val_r_square: 0.9884\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0061 - acc: 0.9529 - mse: 0.0061 - rmse: 0.0471 - r_square: 0.8577 - val_loss: 0.0015 - val_acc: 0.8866 - val_mse: 0.0015 - val_rmse: 0.0242 - val_r_square: 0.9913\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0062 - acc: 0.9531 - mse: 0.0062 - rmse: 0.0444 - r_square: 0.8671 - val_loss: 0.0028 - val_acc: 0.9941 - val_mse: 0.0028 - val_rmse: 0.0433 - val_r_square: 0.9810\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0056 - acc: 0.9279 - mse: 0.0056 - rmse: 0.0441 - r_square: 0.8615 - val_loss: 0.0025 - val_acc: 0.9424 - val_mse: 0.0025 - val_rmse: 0.0414 - val_r_square: 0.9838\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0063 - acc: 0.9525 - mse: 0.0063 - rmse: 0.0499 - r_square: 0.8412 - val_loss: 0.0021 - val_acc: 0.9942 - val_mse: 0.0021 - val_rmse: 0.0355 - val_r_square: 0.9863\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0056 - acc: 0.9460 - mse: 0.0056 - rmse: 0.0414 - r_square: 0.8886 - val_loss: 0.0018 - val_acc: 0.9881 - val_mse: 0.0018 - val_rmse: 0.0302 - val_r_square: 0.9888\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0057 - acc: 0.9431 - mse: 0.0057 - rmse: 0.0434 - r_square: 0.8775 - val_loss: 0.0017 - val_acc: 0.9404 - val_mse: 0.0017 - val_rmse: 0.0292 - val_r_square: 0.9895\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0057 - acc: 0.9370 - mse: 0.0057 - rmse: 0.0447 - r_square: 0.8695 - val_loss: 0.0037 - val_acc: 0.9942 - val_mse: 0.0037 - val_rmse: 0.0535 - val_r_square: 0.9755\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0060 - acc: 0.9553 - mse: 0.0060 - rmse: 0.0488 - r_square: 0.8432 - val_loss: 0.0035 - val_acc: 0.9547 - val_mse: 0.0035 - val_rmse: 0.0505 - val_r_square: 0.9758\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0060 - acc: 0.9389 - mse: 0.0060 - rmse: 0.0488 - r_square: 0.8482 - val_loss: 0.0017 - val_acc: 0.8371 - val_mse: 0.0017 - val_rmse: 0.0293 - val_r_square: 0.9894\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0054 - acc: 0.9155 - mse: 0.0054 - rmse: 0.0401 - r_square: 0.8907 - val_loss: 0.0018 - val_acc: 0.8610 - val_mse: 0.0018 - val_rmse: 0.0306 - val_r_square: 0.9890\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0062 - acc: 0.9489 - mse: 0.0062 - rmse: 0.0500 - r_square: 0.8631 - val_loss: 0.0027 - val_acc: 0.9942 - val_mse: 0.0027 - val_rmse: 0.0448 - val_r_square: 0.9822\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0060 - acc: 0.9499 - mse: 0.0060 - rmse: 0.0491 - r_square: 0.8618 - val_loss: 0.0033 - val_acc: 0.9942 - val_mse: 0.0033 - val_rmse: 0.0495 - val_r_square: 0.9775\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 1s 214us/step - loss: 0.0062 - acc: 0.9433 - mse: 0.0062 - rmse: 0.0482 - r_square: 0.8549 - val_loss: 0.0027 - val_acc: 0.8374 - val_mse: 0.0027 - val_rmse: 0.0436 - val_r_square: 0.9821\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0068 - acc: 0.9245 - mse: 0.0068 - rmse: 0.0548 - r_square: 0.8362 - val_loss: 0.0017 - val_acc: 0.8374 - val_mse: 0.0017 - val_rmse: 0.0290 - val_r_square: 0.9899\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0061 - acc: 0.9270 - mse: 0.0061 - rmse: 0.0481 - r_square: 0.8473 - val_loss: 0.0041 - val_acc: 0.9426 - val_mse: 0.0041 - val_rmse: 0.0567 - val_r_square: 0.9712\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0059 - acc: 0.9207 - mse: 0.0059 - rmse: 0.0471 - r_square: 0.8729 - val_loss: 0.0027 - val_acc: 0.9426 - val_mse: 0.0027 - val_rmse: 0.0433 - val_r_square: 0.9820\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0061 - acc: 0.9187 - mse: 0.0061 - rmse: 0.0491 - r_square: 0.8350 - val_loss: 0.0017 - val_acc: 0.9505 - val_mse: 0.0017 - val_rmse: 0.0298 - val_r_square: 0.9895\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0063 - acc: 0.9466 - mse: 0.0063 - rmse: 0.0509 - r_square: 0.8381 - val_loss: 0.0028 - val_acc: 0.9905 - val_mse: 0.0028 - val_rmse: 0.0440 - val_r_square: 0.9809\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0056 - acc: 0.9272 - mse: 0.0056 - rmse: 0.0454 - r_square: 0.8754 - val_loss: 0.0018 - val_acc: 0.9430 - val_mse: 0.0018 - val_rmse: 0.0307 - val_r_square: 0.9886\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0056 - acc: 0.9217 - mse: 0.0056 - rmse: 0.0437 - r_square: 0.8657 - val_loss: 0.0019 - val_acc: 0.9430 - val_mse: 0.0019 - val_rmse: 0.0310 - val_r_square: 0.9881\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 1s 206us/step - loss: 0.0056 - acc: 0.9500 - mse: 0.0056 - rmse: 0.0424 - r_square: 0.8863 - val_loss: 0.0025 - val_acc: 0.9942 - val_mse: 0.0025 - val_rmse: 0.0416 - val_r_square: 0.9833\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0056 - acc: 0.9190 - mse: 0.0056 - rmse: 0.0436 - r_square: 0.8654 - val_loss: 0.0025 - val_acc: 0.9421 - val_mse: 0.0025 - val_rmse: 0.0407 - val_r_square: 0.9831\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0056 - acc: 0.9597 - mse: 0.0056 - rmse: 0.0425 - r_square: 0.8760 - val_loss: 0.0013 - val_acc: 0.8374 - val_mse: 0.0013 - val_rmse: 0.0199 - val_r_square: 0.9926\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0055 - acc: 0.9432 - mse: 0.0055 - rmse: 0.0399 - r_square: 0.8855 - val_loss: 0.0019 - val_acc: 0.8885 - val_mse: 0.0019 - val_rmse: 0.0324 - val_r_square: 0.9876\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0057 - acc: 0.8901 - mse: 0.0057 - rmse: 0.0437 - r_square: 0.8739 - val_loss: 0.0029 - val_acc: 0.9942 - val_mse: 0.0029 - val_rmse: 0.0458 - val_r_square: 0.9811\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0056 - acc: 0.9652 - mse: 0.0056 - rmse: 0.0439 - r_square: 0.8698 - val_loss: 0.0023 - val_acc: 0.8876 - val_mse: 0.0023 - val_rmse: 0.0387 - val_r_square: 0.9847\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0069 - acc: 0.9230 - mse: 0.0069 - rmse: 0.0542 - r_square: 0.7982 - val_loss: 0.0022 - val_acc: 0.8365 - val_mse: 0.0022 - val_rmse: 0.0346 - val_r_square: 0.9866\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 1s 213us/step - loss: 0.0058 - acc: 0.9066 - mse: 0.0058 - rmse: 0.0443 - r_square: 0.8697 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0290 - val_r_square: 0.9897\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0062 - acc: 0.9455 - mse: 0.0062 - rmse: 0.0488 - r_square: 0.8667 - val_loss: 0.0031 - val_acc: 0.9545 - val_mse: 0.0031 - val_rmse: 0.0484 - val_r_square: 0.9791\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0058 - acc: 0.9536 - mse: 0.0058 - rmse: 0.0453 - r_square: 0.8715 - val_loss: 0.0045 - val_acc: 0.9937 - val_mse: 0.0045 - val_rmse: 0.0603 - val_r_square: 0.9680\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0056 - acc: 0.9619 - mse: 0.0056 - rmse: 0.0421 - r_square: 0.8699 - val_loss: 0.0013 - val_acc: 0.8366 - val_mse: 0.0013 - val_rmse: 0.0223 - val_r_square: 0.9921\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0061 - acc: 0.9048 - mse: 0.0061 - rmse: 0.0482 - r_square: 0.8617 - val_loss: 0.0024 - val_acc: 0.9942 - val_mse: 0.0024 - val_rmse: 0.0394 - val_r_square: 0.9851\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0056 - acc: 0.9587 - mse: 0.0056 - rmse: 0.0439 - r_square: 0.8805 - val_loss: 0.0026 - val_acc: 0.9554 - val_mse: 0.0026 - val_rmse: 0.0424 - val_r_square: 0.9823\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0061 - acc: 0.9352 - mse: 0.0061 - rmse: 0.0471 - r_square: 0.8580 - val_loss: 0.0014 - val_acc: 0.9031 - val_mse: 0.0014 - val_rmse: 0.0212 - val_r_square: 0.9916\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0059 - acc: 0.9286 - mse: 0.0059 - rmse: 0.0454 - r_square: 0.8653 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0380 - val_r_square: 0.9858\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0060 - acc: 0.9503 - mse: 0.0060 - rmse: 0.0476 - r_square: 0.8554 - val_loss: 0.0031 - val_acc: 0.8369 - val_mse: 0.0031 - val_rmse: 0.0477 - val_r_square: 0.9791\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0059 - acc: 0.9543 - mse: 0.0059 - rmse: 0.0473 - r_square: 0.8478 - val_loss: 0.0022 - val_acc: 0.8382 - val_mse: 0.0022 - val_rmse: 0.0364 - val_r_square: 0.9861\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 1s 211us/step - loss: 0.0056 - acc: 0.9074 - mse: 0.0056 - rmse: 0.0432 - r_square: 0.8788 - val_loss: 0.0028 - val_acc: 0.9942 - val_mse: 0.0028 - val_rmse: 0.0449 - val_r_square: 0.9816\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 1s 208us/step - loss: 0.0056 - acc: 0.9551 - mse: 0.0056 - rmse: 0.0447 - r_square: 0.8780 - val_loss: 0.0019 - val_acc: 0.8372 - val_mse: 0.0019 - val_rmse: 0.0326 - val_r_square: 0.9882\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 1s 207us/step - loss: 0.0062 - acc: 0.9447 - mse: 0.0062 - rmse: 0.0464 - r_square: 0.8752 - val_loss: 0.0017 - val_acc: 0.8377 - val_mse: 0.0017 - val_rmse: 0.0277 - val_r_square: 0.9900\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0061 - acc: 0.9326 - mse: 0.0061 - rmse: 0.0456 - r_square: 0.8579 - val_loss: 0.0025 - val_acc: 0.9430 - val_mse: 0.0025 - val_rmse: 0.0414 - val_r_square: 0.9831\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 210us/step - loss: 0.0065 - acc: 0.9253 - mse: 0.0065 - rmse: 0.0477 - r_square: 0.8668 - val_loss: 0.0033 - val_acc: 0.9942 - val_mse: 0.0033 - val_rmse: 0.0494 - val_r_square: 0.9780\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 212us/step - loss: 0.0060 - acc: 0.9523 - mse: 0.0060 - rmse: 0.0428 - r_square: 0.8705 - val_loss: 0.0016 - val_acc: 0.9722 - val_mse: 0.0016 - val_rmse: 0.0269 - val_r_square: 0.9904\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0070 - acc: 0.9480 - mse: 0.0070 - rmse: 0.0499 - r_square: 0.8417 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0301 - val_r_square: 0.9892\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 209us/step - loss: 0.0061 - acc: 0.9509 - mse: 0.0061 - rmse: 0.0459 - r_square: 0.8576 - val_loss: 0.0015 - val_acc: 0.8372 - val_mse: 0.0015 - val_rmse: 0.0254 - val_r_square: 0.9912\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birthrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Outbreak', 'Province/State', 'Country/Region', 'Date', 'Confirmed_x',\n",
       "       'Deaths', 'Recovered', 'Confirmed_y', 'Country', 'Region', 'Population',\n",
       "       'Area (sq. mi.)', 'Pop. Density (per sq. mi.)',\n",
       "       'Coastline (coast/area ratio)', 'Net migration',\n",
       "       'Infant mortality (per 1000 births)', 'GDP ($ per capita)',\n",
       "       'Literacy (%)', 'Phones (per 1000)', 'Arable (%)', 'Crops (%)',\n",
       "       'Climate', 'Birthrate', 'Deathrate', 'Agriculture', 'Industry',\n",
       "       'Service', 'Month', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  (8683, 18, 6)\n",
      "train data:  (6946, 14, 6) (6946, 4, 6)\n",
      "validate data:  (1737, 14, 6) (1737, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "col=['Outbreak','Country/Region','Birthrate','Confirmed_x','Deaths','Recovered']\n",
    "df=new_df[col]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = normalize_data(df, scaler,df.shape[1])\n",
    "x_train, y_train, x_validate, y_validate = load_data(data,time_step=14, after_day=4, validate_percent=0.8)\n",
    "print('train data: ', x_train.shape, y_train.shape)\n",
    "print('validate data: ', x_validate.shape, y_validate.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 13s 2ms/step - loss: 0.0467 - acc: 0.6804 - rmse: 0.1854 - mse: 0.0467 - r_square: 0.3127 - val_loss: 0.0259 - val_acc: 0.8365 - val_rmse: 0.1451 - val_mse: 0.0259 - val_r_square: 0.8188\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 3s 368us/step - loss: 0.0330 - acc: 0.7067 - rmse: 0.1494 - mse: 0.0330 - r_square: 0.5435 - val_loss: 0.0217 - val_acc: 0.8876 - val_rmse: 0.1366 - val_mse: 0.0217 - val_r_square: 0.8449\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0234 - acc: 0.7890 - rmse: 0.1224 - mse: 0.0234 - r_square: 0.6703 - val_loss: 0.0127 - val_acc: 0.8483 - val_rmse: 0.1010 - val_mse: 0.0127 - val_r_square: 0.9107\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0170 - acc: 0.8777 - rmse: 0.0997 - mse: 0.0170 - r_square: 0.7645 - val_loss: 0.0107 - val_acc: 0.8365 - val_rmse: 0.0961 - val_mse: 0.0107 - val_r_square: 0.9248\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 355us/step - loss: 0.0127 - acc: 0.8953 - rmse: 0.0803 - mse: 0.0127 - r_square: 0.8189 - val_loss: 0.0063 - val_acc: 0.8365 - val_rmse: 0.0705 - val_mse: 0.0063 - val_r_square: 0.9563\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0102 - acc: 0.9019 - rmse: 0.0667 - mse: 0.0102 - r_square: 0.8510 - val_loss: 0.0040 - val_acc: 0.8369 - val_rmse: 0.0498 - val_mse: 0.0040 - val_r_square: 0.9733\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 289us/step - loss: 0.0092 - acc: 0.9045 - rmse: 0.0622 - mse: 0.0092 - r_square: 0.8631 - val_loss: 0.0033 - val_acc: 0.8365 - val_rmse: 0.0387 - val_mse: 0.0033 - val_r_square: 0.9798\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0086 - acc: 0.9100 - rmse: 0.0595 - mse: 0.0086 - r_square: 0.8722 - val_loss: 0.0033 - val_acc: 0.8365 - val_rmse: 0.0390 - val_mse: 0.0033 - val_r_square: 0.9805\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 294us/step - loss: 0.0089 - acc: 0.8963 - rmse: 0.0628 - mse: 0.0089 - r_square: 0.8684 - val_loss: 0.0033 - val_acc: 0.8385 - val_rmse: 0.0494 - val_mse: 0.0033 - val_r_square: 0.9779\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 295us/step - loss: 0.0087 - acc: 0.8808 - rmse: 0.0609 - mse: 0.0087 - r_square: 0.8726 - val_loss: 0.0064 - val_acc: 0.9902 - val_rmse: 0.0733 - val_mse: 0.0064 - val_r_square: 0.9540\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 300us/step - loss: 0.0080 - acc: 0.9080 - rmse: 0.0555 - mse: 0.0080 - r_square: 0.8884 - val_loss: 0.0021 - val_acc: 0.8660 - val_rmse: 0.0323 - val_mse: 0.0021 - val_r_square: 0.9869\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 301us/step - loss: 0.0077 - acc: 0.9130 - rmse: 0.0521 - mse: 0.0077 - r_square: 0.8923 - val_loss: 0.0021 - val_acc: 0.8418 - val_rmse: 0.0325 - val_mse: 0.0021 - val_r_square: 0.9871\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 304us/step - loss: 0.0076 - acc: 0.9051 - rmse: 0.0534 - mse: 0.0076 - r_square: 0.8933 - val_loss: 0.0029 - val_acc: 0.8377 - val_rmse: 0.0427 - val_mse: 0.0029 - val_r_square: 0.9813\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 306us/step - loss: 0.0073 - acc: 0.9166 - rmse: 0.0526 - mse: 0.0073 - r_square: 0.8956 - val_loss: 0.0020 - val_acc: 0.8423 - val_rmse: 0.0316 - val_mse: 0.0020 - val_r_square: 0.9876\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0071 - acc: 0.9075 - rmse: 0.0493 - mse: 0.0071 - r_square: 0.9018 - val_loss: 0.0021 - val_acc: 0.8382 - val_rmse: 0.0345 - val_mse: 0.0021 - val_r_square: 0.9867\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0074 - acc: 0.9160 - rmse: 0.0516 - mse: 0.0074 - r_square: 0.9003 - val_loss: 0.0028 - val_acc: 0.8381 - val_rmse: 0.0437 - val_mse: 0.0028 - val_r_square: 0.9818\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0073 - acc: 0.9144 - rmse: 0.0517 - mse: 0.0073 - r_square: 0.9016 - val_loss: 0.0028 - val_acc: 0.8384 - val_rmse: 0.0437 - val_mse: 0.0028 - val_r_square: 0.9817\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0077 - acc: 0.8922 - rmse: 0.0567 - mse: 0.0077 - r_square: 0.8957 - val_loss: 0.0039 - val_acc: 0.9548 - val_rmse: 0.0540 - val_mse: 0.0039 - val_r_square: 0.9726\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0084 - acc: 0.8792 - rmse: 0.0615 - mse: 0.0084 - r_square: 0.8877 - val_loss: 0.0056 - val_acc: 0.9921 - val_rmse: 0.0680 - val_mse: 0.0056 - val_r_square: 0.9592\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 292us/step - loss: 0.0077 - acc: 0.8589 - rmse: 0.0580 - mse: 0.0077 - r_square: 0.8959 - val_loss: 0.0028 - val_acc: 0.8512 - val_rmse: 0.0424 - val_mse: 0.0028 - val_r_square: 0.9817\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 291us/step - loss: 0.0075 - acc: 0.8988 - rmse: 0.0559 - mse: 0.0075 - r_square: 0.8931 - val_loss: 0.0024 - val_acc: 0.8372 - val_rmse: 0.0374 - val_mse: 0.0024 - val_r_square: 0.9847\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 288us/step - loss: 0.0066 - acc: 0.9237 - rmse: 0.0483 - mse: 0.0066 - r_square: 0.9058 - val_loss: 0.0019 - val_acc: 0.9052 - val_rmse: 0.0301 - val_mse: 0.0019 - val_r_square: 0.9884\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0065 - acc: 0.9233 - rmse: 0.0459 - mse: 0.0065 - r_square: 0.9094 - val_loss: 0.0018 - val_acc: 0.8792 - val_rmse: 0.0296 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0063 - acc: 0.9308 - rmse: 0.0441 - mse: 0.0063 - r_square: 0.9136 - val_loss: 0.0018 - val_acc: 0.9184 - val_rmse: 0.0287 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 292us/step - loss: 0.0063 - acc: 0.9297 - rmse: 0.0448 - mse: 0.0063 - r_square: 0.9137 - val_loss: 0.0018 - val_acc: 0.9180 - val_rmse: 0.0299 - val_mse: 0.0018 - val_r_square: 0.9884\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 293us/step - loss: 0.0062 - acc: 0.9343 - rmse: 0.0443 - mse: 0.0062 - r_square: 0.9151 - val_loss: 0.0018 - val_acc: 0.9178 - val_rmse: 0.0299 - val_mse: 0.0018 - val_r_square: 0.9885\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0063 - acc: 0.9323 - rmse: 0.0458 - mse: 0.0063 - r_square: 0.9134 - val_loss: 0.0019 - val_acc: 0.9190 - val_rmse: 0.0318 - val_mse: 0.0019 - val_r_square: 0.9877\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0064 - acc: 0.9325 - rmse: 0.0470 - mse: 0.0064 - r_square: 0.9121 - val_loss: 0.0020 - val_acc: 0.9195 - val_rmse: 0.0329 - val_mse: 0.0020 - val_r_square: 0.9872\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0067 - acc: 0.9322 - rmse: 0.0499 - mse: 0.0067 - r_square: 0.9069 - val_loss: 0.0022 - val_acc: 0.9178 - val_rmse: 0.0367 - val_mse: 0.0022 - val_r_square: 0.9855\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0069 - acc: 0.9323 - rmse: 0.0517 - mse: 0.0069 - r_square: 0.9044 - val_loss: 0.0025 - val_acc: 0.9197 - val_rmse: 0.0404 - val_mse: 0.0025 - val_r_square: 0.9835\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 260us/step - loss: 0.0073 - acc: 0.9225 - rmse: 0.0550 - mse: 0.0073 - r_square: 0.8971 - val_loss: 0.0025 - val_acc: 0.8660 - val_rmse: 0.0396 - val_mse: 0.0025 - val_r_square: 0.9841\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 286us/step - loss: 0.0073 - acc: 0.9101 - rmse: 0.0561 - mse: 0.0073 - r_square: 0.9011 - val_loss: 0.0026 - val_acc: 0.8395 - val_rmse: 0.0415 - val_mse: 0.0026 - val_r_square: 0.9831\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0076 - acc: 0.9137 - rmse: 0.0578 - mse: 0.0076 - r_square: 0.8984 - val_loss: 0.0023 - val_acc: 0.8377 - val_rmse: 0.0370 - val_mse: 0.0023 - val_r_square: 0.9856\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0074 - acc: 0.9165 - rmse: 0.0565 - mse: 0.0074 - r_square: 0.9007 - val_loss: 0.0020 - val_acc: 0.8374 - val_rmse: 0.0339 - val_mse: 0.0020 - val_r_square: 0.9872\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0070 - acc: 0.9247 - rmse: 0.0536 - mse: 0.0070 - r_square: 0.9054 - val_loss: 0.0018 - val_acc: 0.8371 - val_rmse: 0.0296 - val_mse: 0.0018 - val_r_square: 0.9890\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0065 - acc: 0.9360 - rmse: 0.0485 - mse: 0.0065 - r_square: 0.9120 - val_loss: 0.0016 - val_acc: 0.8384 - val_rmse: 0.0269 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0060 - acc: 0.9333 - rmse: 0.0429 - mse: 0.0060 - r_square: 0.9179 - val_loss: 0.0014 - val_acc: 0.8643 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0058 - acc: 0.9304 - rmse: 0.0402 - mse: 0.0058 - r_square: 0.9197 - val_loss: 0.0015 - val_acc: 0.9430 - val_rmse: 0.0251 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0056 - acc: 0.9336 - rmse: 0.0364 - mse: 0.0056 - r_square: 0.9223 - val_loss: 0.0015 - val_acc: 0.9548 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0057 - acc: 0.9320 - rmse: 0.0374 - mse: 0.0057 - r_square: 0.9208 - val_loss: 0.0016 - val_acc: 0.9666 - val_rmse: 0.0265 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0054 - acc: 0.9356 - rmse: 0.0345 - mse: 0.0054 - r_square: 0.9262 - val_loss: 0.0014 - val_acc: 0.9542 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0054 - acc: 0.9354 - rmse: 0.0344 - mse: 0.0054 - r_square: 0.9264 - val_loss: 0.0015 - val_acc: 0.9551 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0054 - acc: 0.9363 - rmse: 0.0343 - mse: 0.0054 - r_square: 0.9266 - val_loss: 0.0015 - val_acc: 0.9550 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0055 - acc: 0.9364 - rmse: 0.0338 - mse: 0.0055 - r_square: 0.9248 - val_loss: 0.0015 - val_acc: 0.9535 - val_rmse: 0.0233 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0055 - acc: 0.9350 - rmse: 0.0351 - mse: 0.0055 - r_square: 0.9240 - val_loss: 0.0015 - val_acc: 0.9794 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0054 - acc: 0.9374 - rmse: 0.0340 - mse: 0.0054 - r_square: 0.9257 - val_loss: 0.0015 - val_acc: 0.9426 - val_rmse: 0.0233 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0054 - acc: 0.9350 - rmse: 0.0344 - mse: 0.0054 - r_square: 0.9266 - val_loss: 0.0015 - val_acc: 0.9794 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0053 - acc: 0.9381 - rmse: 0.0331 - mse: 0.0053 - r_square: 0.9288 - val_loss: 0.0015 - val_acc: 0.9550 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9343 - rmse: 0.0334 - mse: 0.0053 - r_square: 0.9283 - val_loss: 0.0015 - val_acc: 0.9784 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9374 - rmse: 0.0327 - mse: 0.0052 - r_square: 0.9294 - val_loss: 0.0015 - val_acc: 0.9773 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0053 - acc: 0.9343 - rmse: 0.0330 - mse: 0.0053 - r_square: 0.9288 - val_loss: 0.0015 - val_acc: 0.9784 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9335 - rmse: 0.0333 - mse: 0.0053 - r_square: 0.9276 - val_loss: 0.0015 - val_acc: 0.9775 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0055 - acc: 0.9346 - rmse: 0.0344 - mse: 0.0055 - r_square: 0.9239 - val_loss: 0.0016 - val_acc: 0.9786 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9288 - rmse: 0.0340 - mse: 0.0053 - r_square: 0.9280 - val_loss: 0.0015 - val_acc: 0.9777 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9350 - rmse: 0.0336 - mse: 0.0053 - r_square: 0.9288 - val_loss: 0.0016 - val_acc: 0.9888 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0053 - acc: 0.9265 - rmse: 0.0340 - mse: 0.0053 - r_square: 0.9288 - val_loss: 0.0016 - val_acc: 0.9786 - val_rmse: 0.0264 - val_mse: 0.0016 - val_r_square: 0.9900\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9316 - rmse: 0.0341 - mse: 0.0053 - r_square: 0.9293 - val_loss: 0.0016 - val_acc: 0.9904 - val_rmse: 0.0271 - val_mse: 0.0016 - val_r_square: 0.9898\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 274us/step - loss: 0.0053 - acc: 0.9268 - rmse: 0.0344 - mse: 0.0053 - r_square: 0.9292 - val_loss: 0.0016 - val_acc: 0.9898 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9897\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0053 - acc: 0.9264 - rmse: 0.0348 - mse: 0.0053 - r_square: 0.9291 - val_loss: 0.0016 - val_acc: 0.9902 - val_rmse: 0.0273 - val_mse: 0.0016 - val_r_square: 0.9897\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9241 - rmse: 0.0352 - mse: 0.0053 - r_square: 0.9290 - val_loss: 0.0017 - val_acc: 0.9899 - val_rmse: 0.0278 - val_mse: 0.0017 - val_r_square: 0.9895\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0054 - acc: 0.9228 - rmse: 0.0359 - mse: 0.0054 - r_square: 0.9285 - val_loss: 0.0017 - val_acc: 0.9899 - val_rmse: 0.0280 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0054 - acc: 0.9219 - rmse: 0.0364 - mse: 0.0054 - r_square: 0.9277 - val_loss: 0.0017 - val_acc: 0.9899 - val_rmse: 0.0279 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0056 - acc: 0.9209 - rmse: 0.0382 - mse: 0.0056 - r_square: 0.9237 - val_loss: 0.0016 - val_acc: 0.9906 - val_rmse: 0.0262 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0058 - acc: 0.9208 - rmse: 0.0396 - mse: 0.0058 - r_square: 0.9202 - val_loss: 0.0015 - val_acc: 0.9904 - val_rmse: 0.0249 - val_mse: 0.0015 - val_r_square: 0.9905\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0057 - acc: 0.9181 - rmse: 0.0398 - mse: 0.0057 - r_square: 0.9240 - val_loss: 0.0015 - val_acc: 0.9898 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0056 - acc: 0.9210 - rmse: 0.0392 - mse: 0.0056 - r_square: 0.9254 - val_loss: 0.0014 - val_acc: 0.9886 - val_rmse: 0.0224 - val_mse: 0.0014 - val_r_square: 0.9914\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0056 - acc: 0.9184 - rmse: 0.0395 - mse: 0.0056 - r_square: 0.9249 - val_loss: 0.0014 - val_acc: 0.9655 - val_rmse: 0.0218 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0056 - acc: 0.9144 - rmse: 0.0399 - mse: 0.0056 - r_square: 0.9238 - val_loss: 0.0014 - val_acc: 0.9413 - val_rmse: 0.0224 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0055 - acc: 0.9107 - rmse: 0.0396 - mse: 0.0055 - r_square: 0.9231 - val_loss: 0.0014 - val_acc: 0.9293 - val_rmse: 0.0216 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0055 - acc: 0.9090 - rmse: 0.0391 - mse: 0.0055 - r_square: 0.9226 - val_loss: 0.0014 - val_acc: 0.8777 - val_rmse: 0.0220 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0057 - acc: 0.9233 - rmse: 0.0406 - mse: 0.0057 - r_square: 0.9188 - val_loss: 0.0015 - val_acc: 0.8638 - val_rmse: 0.0248 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0056 - acc: 0.9377 - rmse: 0.0384 - mse: 0.0056 - r_square: 0.9224 - val_loss: 0.0015 - val_acc: 0.8492 - val_rmse: 0.0246 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0054 - acc: 0.9435 - rmse: 0.0369 - mse: 0.0054 - r_square: 0.9242 - val_loss: 0.0014 - val_acc: 0.9293 - val_rmse: 0.0234 - val_mse: 0.0014 - val_r_square: 0.9912\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 271us/step - loss: 0.0052 - acc: 0.9440 - rmse: 0.0343 - mse: 0.0052 - r_square: 0.9281 - val_loss: 0.0014 - val_acc: 0.8767 - val_rmse: 0.0217 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0052 - acc: 0.9423 - rmse: 0.0332 - mse: 0.0052 - r_square: 0.9290 - val_loss: 0.0014 - val_acc: 0.9431 - val_rmse: 0.0212 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 262us/step - loss: 0.0052 - acc: 0.9422 - rmse: 0.0329 - mse: 0.0052 - r_square: 0.9295 - val_loss: 0.0014 - val_acc: 0.9018 - val_rmse: 0.0210 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 263us/step - loss: 0.0052 - acc: 0.9424 - rmse: 0.0324 - mse: 0.0052 - r_square: 0.9287 - val_loss: 0.0014 - val_acc: 0.9547 - val_rmse: 0.0203 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0053 - acc: 0.9374 - rmse: 0.0330 - mse: 0.0053 - r_square: 0.9281 - val_loss: 0.0013 - val_acc: 0.9024 - val_rmse: 0.0207 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0052 - acc: 0.9435 - rmse: 0.0324 - mse: 0.0052 - r_square: 0.9299 - val_loss: 0.0014 - val_acc: 0.9421 - val_rmse: 0.0206 - val_mse: 0.0014 - val_r_square: 0.9918\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9377 - rmse: 0.0328 - mse: 0.0051 - r_square: 0.9305 - val_loss: 0.0013 - val_acc: 0.9043 - val_rmse: 0.0202 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9433 - rmse: 0.0329 - mse: 0.0052 - r_square: 0.9301 - val_loss: 0.0014 - val_acc: 0.9406 - val_rmse: 0.0214 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0052 - acc: 0.9415 - rmse: 0.0335 - mse: 0.0052 - r_square: 0.9297 - val_loss: 0.0013 - val_acc: 0.9057 - val_rmse: 0.0194 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0053 - acc: 0.9437 - rmse: 0.0344 - mse: 0.0053 - r_square: 0.9286 - val_loss: 0.0014 - val_acc: 0.9018 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 265us/step - loss: 0.0053 - acc: 0.9419 - rmse: 0.0352 - mse: 0.0053 - r_square: 0.9263 - val_loss: 0.0013 - val_acc: 0.9050 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0054 - acc: 0.9435 - rmse: 0.0362 - mse: 0.0054 - r_square: 0.9275 - val_loss: 0.0014 - val_acc: 0.8509 - val_rmse: 0.0223 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0053 - acc: 0.9430 - rmse: 0.0360 - mse: 0.0053 - r_square: 0.9279 - val_loss: 0.0013 - val_acc: 0.8385 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 264us/step - loss: 0.0054 - acc: 0.9437 - rmse: 0.0370 - mse: 0.0054 - r_square: 0.9273 - val_loss: 0.0014 - val_acc: 0.8378 - val_rmse: 0.0210 - val_mse: 0.0014 - val_r_square: 0.9920\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0054 - acc: 0.9367 - rmse: 0.0374 - mse: 0.0054 - r_square: 0.9272 - val_loss: 0.0013 - val_acc: 0.8375 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0054 - acc: 0.9438 - rmse: 0.0377 - mse: 0.0054 - r_square: 0.9260 - val_loss: 0.0013 - val_acc: 0.8375 - val_rmse: 0.0194 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0055 - acc: 0.9399 - rmse: 0.0383 - mse: 0.0055 - r_square: 0.9241 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0198 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0055 - acc: 0.9440 - rmse: 0.0375 - mse: 0.0055 - r_square: 0.9249 - val_loss: 0.0013 - val_acc: 0.8375 - val_rmse: 0.0193 - val_mse: 0.0013 - val_r_square: 0.9924\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 267us/step - loss: 0.0054 - acc: 0.9441 - rmse: 0.0364 - mse: 0.0054 - r_square: 0.9268 - val_loss: 0.0013 - val_acc: 0.8374 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0053 - acc: 0.9443 - rmse: 0.0349 - mse: 0.0053 - r_square: 0.9286 - val_loss: 0.0013 - val_acc: 0.8375 - val_rmse: 0.0189 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 268us/step - loss: 0.0052 - acc: 0.9441 - rmse: 0.0334 - mse: 0.0052 - r_square: 0.9302 - val_loss: 0.0012 - val_acc: 0.8375 - val_rmse: 0.0179 - val_mse: 0.0012 - val_r_square: 0.9927\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 290us/step - loss: 0.0051 - acc: 0.9434 - rmse: 0.0322 - mse: 0.0051 - r_square: 0.9313 - val_loss: 0.0013 - val_acc: 0.8506 - val_rmse: 0.0186 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0051 - acc: 0.9445 - rmse: 0.0312 - mse: 0.0051 - r_square: 0.9321 - val_loss: 0.0013 - val_acc: 0.9024 - val_rmse: 0.0182 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0051 - acc: 0.9426 - rmse: 0.0307 - mse: 0.0051 - r_square: 0.9316 - val_loss: 0.0013 - val_acc: 0.9170 - val_rmse: 0.0182 - val_mse: 0.0013 - val_r_square: 0.9926\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 266us/step - loss: 0.0052 - acc: 0.9433 - rmse: 0.0310 - mse: 0.0052 - r_square: 0.9295 - val_loss: 0.0013 - val_acc: 0.9407 - val_rmse: 0.0194 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 270us/step - loss: 0.0051 - acc: 0.9430 - rmse: 0.0306 - mse: 0.0051 - r_square: 0.9316 - val_loss: 0.0013 - val_acc: 0.9416 - val_rmse: 0.0191 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 261us/step - loss: 0.0050 - acc: 0.9409 - rmse: 0.0303 - mse: 0.0050 - r_square: 0.9324 - val_loss: 0.0013 - val_acc: 0.9440 - val_rmse: 0.0192 - val_mse: 0.0013 - val_r_square: 0.9923\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = base_model(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=100, verbose=0, mode='max')\n",
    "history = model.fit(x_train, y_train, batch_size=256,epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 14s 2ms/step - loss: 0.0329 - acc: 0.6390 - rmse: 0.1510 - mse: 0.0329 - r_square: 0.4544 - val_loss: 0.0102 - val_acc: 0.9813 - val_rmse: 0.0956 - val_mse: 0.0102 - val_r_square: 0.9279\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 322us/step - loss: 0.0211 - acc: 0.6638 - rmse: 0.1158 - mse: 0.0211 - r_square: 0.6869 - val_loss: 0.0053 - val_acc: 0.8365 - val_rmse: 0.0663 - val_mse: 0.0053 - val_r_square: 0.9636\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0138 - acc: 0.6268 - rmse: 0.0894 - mse: 0.0138 - r_square: 0.7806 - val_loss: 0.0037 - val_acc: 0.8365 - val_rmse: 0.0511 - val_mse: 0.0037 - val_r_square: 0.9759\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 326us/step - loss: 0.0087 - acc: 0.9073 - rmse: 0.0588 - mse: 0.0087 - r_square: 0.8763 - val_loss: 0.0020 - val_acc: 0.8365 - val_rmse: 0.0285 - val_mse: 0.0020 - val_r_square: 0.9880\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 329us/step - loss: 0.0077 - acc: 0.8948 - rmse: 0.0514 - mse: 0.0077 - r_square: 0.8900 - val_loss: 0.0020 - val_acc: 0.9390 - val_rmse: 0.0286 - val_mse: 0.0020 - val_r_square: 0.9879\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 330us/step - loss: 0.0070 - acc: 0.9114 - rmse: 0.0444 - mse: 0.0070 - r_square: 0.9036 - val_loss: 0.0018 - val_acc: 0.8769 - val_rmse: 0.0261 - val_mse: 0.0018 - val_r_square: 0.9893\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0068 - acc: 0.9157 - rmse: 0.0436 - mse: 0.0068 - r_square: 0.9065 - val_loss: 0.0017 - val_acc: 0.9433 - val_rmse: 0.0257 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0066 - acc: 0.9219 - rmse: 0.0422 - mse: 0.0066 - r_square: 0.9084 - val_loss: 0.0018 - val_acc: 0.9449 - val_rmse: 0.0279 - val_mse: 0.0018 - val_r_square: 0.9889\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0064 - acc: 0.9243 - rmse: 0.0408 - mse: 0.0064 - r_square: 0.9119 - val_loss: 0.0016 - val_acc: 0.9067 - val_rmse: 0.0253 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0063 - acc: 0.9254 - rmse: 0.0399 - mse: 0.0063 - r_square: 0.9129 - val_loss: 0.0016 - val_acc: 0.8814 - val_rmse: 0.0245 - val_mse: 0.0016 - val_r_square: 0.9904\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0062 - acc: 0.9268 - rmse: 0.0398 - mse: 0.0062 - r_square: 0.9134 - val_loss: 0.0017 - val_acc: 0.8817 - val_rmse: 0.0266 - val_mse: 0.0017 - val_r_square: 0.9898\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0061 - acc: 0.9243 - rmse: 0.0386 - mse: 0.0061 - r_square: 0.9155 - val_loss: 0.0016 - val_acc: 0.8807 - val_rmse: 0.0245 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0060 - acc: 0.9250 - rmse: 0.0381 - mse: 0.0060 - r_square: 0.9163 - val_loss: 0.0015 - val_acc: 0.8549 - val_rmse: 0.0238 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0060 - acc: 0.9252 - rmse: 0.0378 - mse: 0.0060 - r_square: 0.9165 - val_loss: 0.0015 - val_acc: 0.8532 - val_rmse: 0.0228 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 334us/step - loss: 0.0061 - acc: 0.9264 - rmse: 0.0382 - mse: 0.0061 - r_square: 0.9140 - val_loss: 0.0015 - val_acc: 0.8410 - val_rmse: 0.0245 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 337us/step - loss: 0.0058 - acc: 0.9300 - rmse: 0.0374 - mse: 0.0058 - r_square: 0.9186 - val_loss: 0.0015 - val_acc: 0.8522 - val_rmse: 0.0237 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0058 - acc: 0.9282 - rmse: 0.0369 - mse: 0.0058 - r_square: 0.9192 - val_loss: 0.0015 - val_acc: 0.8528 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0057 - acc: 0.9314 - rmse: 0.0365 - mse: 0.0057 - r_square: 0.9203 - val_loss: 0.0014 - val_acc: 0.8395 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0057 - acc: 0.9302 - rmse: 0.0367 - mse: 0.0057 - r_square: 0.9196 - val_loss: 0.0014 - val_acc: 0.8394 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9915\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0057 - acc: 0.9322 - rmse: 0.0365 - mse: 0.0057 - r_square: 0.9205 - val_loss: 0.0014 - val_acc: 0.8382 - val_rmse: 0.0222 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0058 - acc: 0.9320 - rmse: 0.0378 - mse: 0.0058 - r_square: 0.9173 - val_loss: 0.0015 - val_acc: 0.8385 - val_rmse: 0.0254 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0056 - acc: 0.9324 - rmse: 0.0364 - mse: 0.0056 - r_square: 0.9220 - val_loss: 0.0015 - val_acc: 0.8379 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9913\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0056 - acc: 0.9327 - rmse: 0.0366 - mse: 0.0056 - r_square: 0.9220 - val_loss: 0.0015 - val_acc: 0.8507 - val_rmse: 0.0255 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0055 - acc: 0.9326 - rmse: 0.0358 - mse: 0.0055 - r_square: 0.9236 - val_loss: 0.0014 - val_acc: 0.8379 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 335us/step - loss: 0.0055 - acc: 0.9316 - rmse: 0.0358 - mse: 0.0055 - r_square: 0.9237 - val_loss: 0.0015 - val_acc: 0.8381 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 337us/step - loss: 0.0055 - acc: 0.9322 - rmse: 0.0355 - mse: 0.0055 - r_square: 0.9246 - val_loss: 0.0015 - val_acc: 0.8371 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0056 - acc: 0.9304 - rmse: 0.0366 - mse: 0.0056 - r_square: 0.9226 - val_loss: 0.0016 - val_acc: 0.8369 - val_rmse: 0.0252 - val_mse: 0.0016 - val_r_square: 0.9907\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 331us/step - loss: 0.0056 - acc: 0.9300 - rmse: 0.0374 - mse: 0.0056 - r_square: 0.9221 - val_loss: 0.0016 - val_acc: 0.8368 - val_rmse: 0.0252 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 338us/step - loss: 0.0058 - acc: 0.9314 - rmse: 0.0388 - mse: 0.0058 - r_square: 0.9181 - val_loss: 0.0017 - val_acc: 0.8375 - val_rmse: 0.0297 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 345us/step - loss: 0.0056 - acc: 0.9290 - rmse: 0.0373 - mse: 0.0056 - r_square: 0.9237 - val_loss: 0.0015 - val_acc: 0.8375 - val_rmse: 0.0230 - val_mse: 0.0015 - val_r_square: 0.9914\n",
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0056 - acc: 0.9288 - rmse: 0.0371 - mse: 0.0056 - r_square: 0.9245 - val_loss: 0.0016 - val_acc: 0.8374 - val_rmse: 0.0255 - val_mse: 0.0016 - val_r_square: 0.9906\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 332us/step - loss: 0.0056 - acc: 0.9282 - rmse: 0.0371 - mse: 0.0056 - r_square: 0.9254 - val_loss: 0.0015 - val_acc: 0.8368 - val_rmse: 0.0230 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 2s 333us/step - loss: 0.0056 - acc: 0.9235 - rmse: 0.0386 - mse: 0.0056 - r_square: 0.9243 - val_loss: 0.0016 - val_acc: 0.8368 - val_rmse: 0.0261 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0057 - acc: 0.9238 - rmse: 0.0402 - mse: 0.0057 - r_square: 0.9232 - val_loss: 0.0016 - val_acc: 0.8368 - val_rmse: 0.0265 - val_mse: 0.0016 - val_r_square: 0.9903\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0057 - acc: 0.9247 - rmse: 0.0406 - mse: 0.0057 - r_square: 0.9225 - val_loss: 0.0016 - val_acc: 0.8630 - val_rmse: 0.0274 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0057 - acc: 0.9298 - rmse: 0.0417 - mse: 0.0057 - r_square: 0.9217 - val_loss: 0.0013 - val_acc: 0.9397 - val_rmse: 0.0192 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 307us/step - loss: 0.0057 - acc: 0.9301 - rmse: 0.0418 - mse: 0.0057 - r_square: 0.9217 - val_loss: 0.0012 - val_acc: 0.9521 - val_rmse: 0.0156 - val_mse: 0.0012 - val_r_square: 0.9929\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0059 - acc: 0.9226 - rmse: 0.0428 - mse: 0.0059 - r_square: 0.9210 - val_loss: 0.0015 - val_acc: 0.9652 - val_rmse: 0.0250 - val_mse: 0.0015 - val_r_square: 0.9906\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0059 - acc: 0.9170 - rmse: 0.0419 - mse: 0.0059 - r_square: 0.9212 - val_loss: 0.0018 - val_acc: 0.9891 - val_rmse: 0.0302 - val_mse: 0.0018 - val_r_square: 0.9886\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0058 - acc: 0.9238 - rmse: 0.0418 - mse: 0.0058 - r_square: 0.9221 - val_loss: 0.0017 - val_acc: 0.9914 - val_rmse: 0.0281 - val_mse: 0.0017 - val_r_square: 0.9893\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0056 - acc: 0.9187 - rmse: 0.0393 - mse: 0.0056 - r_square: 0.9235 - val_loss: 0.0015 - val_acc: 0.9775 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 325us/step - loss: 0.0056 - acc: 0.9263 - rmse: 0.0387 - mse: 0.0056 - r_square: 0.9252 - val_loss: 0.0015 - val_acc: 0.9905 - val_rmse: 0.0247 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0055 - acc: 0.9142 - rmse: 0.0377 - mse: 0.0055 - r_square: 0.9257 - val_loss: 0.0015 - val_acc: 0.9542 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0054 - acc: 0.9354 - rmse: 0.0372 - mse: 0.0054 - r_square: 0.9264 - val_loss: 0.0015 - val_acc: 0.9544 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0054 - acc: 0.9400 - rmse: 0.0364 - mse: 0.0054 - r_square: 0.9273 - val_loss: 0.0015 - val_acc: 0.9420 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0053 - acc: 0.9428 - rmse: 0.0352 - mse: 0.0053 - r_square: 0.9284 - val_loss: 0.0015 - val_acc: 0.9679 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0053 - acc: 0.9423 - rmse: 0.0346 - mse: 0.0053 - r_square: 0.9281 - val_loss: 0.0015 - val_acc: 0.9680 - val_rmse: 0.0231 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0053 - acc: 0.9432 - rmse: 0.0342 - mse: 0.0053 - r_square: 0.9296 - val_loss: 0.0015 - val_acc: 0.9934 - val_rmse: 0.0239 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0053 - acc: 0.9426 - rmse: 0.0342 - mse: 0.0053 - r_square: 0.9292 - val_loss: 0.0015 - val_acc: 0.9928 - val_rmse: 0.0229 - val_mse: 0.0015 - val_r_square: 0.9912\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0053 - acc: 0.9427 - rmse: 0.0347 - mse: 0.0053 - r_square: 0.9300 - val_loss: 0.0015 - val_acc: 0.9940 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9907\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 324us/step - loss: 0.0053 - acc: 0.9432 - rmse: 0.0346 - mse: 0.0053 - r_square: 0.9296 - val_loss: 0.0015 - val_acc: 0.9937 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 318us/step - loss: 0.0053 - acc: 0.9448 - rmse: 0.0359 - mse: 0.0053 - r_square: 0.9290 - val_loss: 0.0016 - val_acc: 0.9942 - val_rmse: 0.0258 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 317us/step - loss: 0.0053 - acc: 0.9452 - rmse: 0.0354 - mse: 0.0053 - r_square: 0.9281 - val_loss: 0.0015 - val_acc: 0.9937 - val_rmse: 0.0236 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0054 - acc: 0.9463 - rmse: 0.0376 - mse: 0.0054 - r_square: 0.9273 - val_loss: 0.0017 - val_acc: 0.9942 - val_rmse: 0.0276 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0053 - acc: 0.9463 - rmse: 0.0360 - mse: 0.0053 - r_square: 0.9267 - val_loss: 0.0015 - val_acc: 0.9932 - val_rmse: 0.0233 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0055 - acc: 0.9473 - rmse: 0.0392 - mse: 0.0055 - r_square: 0.9261 - val_loss: 0.0017 - val_acc: 0.9942 - val_rmse: 0.0285 - val_mse: 0.0017 - val_r_square: 0.9892\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0053 - acc: 0.9478 - rmse: 0.0361 - mse: 0.0053 - r_square: 0.9269 - val_loss: 0.0014 - val_acc: 0.9691 - val_rmse: 0.0225 - val_mse: 0.0014 - val_r_square: 0.9913\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0055 - acc: 0.9475 - rmse: 0.0407 - mse: 0.0055 - r_square: 0.9245 - val_loss: 0.0017 - val_acc: 0.9942 - val_rmse: 0.0280 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0053 - acc: 0.9479 - rmse: 0.0365 - mse: 0.0053 - r_square: 0.9260 - val_loss: 0.0014 - val_acc: 0.9430 - val_rmse: 0.0212 - val_mse: 0.0014 - val_r_square: 0.9917\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0056 - acc: 0.9482 - rmse: 0.0412 - mse: 0.0056 - r_square: 0.9231 - val_loss: 0.0016 - val_acc: 0.9695 - val_rmse: 0.0260 - val_mse: 0.0016 - val_r_square: 0.9902\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0054 - acc: 0.9478 - rmse: 0.0367 - mse: 0.0054 - r_square: 0.9256 - val_loss: 0.0013 - val_acc: 0.9423 - val_rmse: 0.0202 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0055 - acc: 0.9479 - rmse: 0.0409 - mse: 0.0055 - r_square: 0.9233 - val_loss: 0.0015 - val_acc: 0.9433 - val_rmse: 0.0242 - val_mse: 0.0015 - val_r_square: 0.9908\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0053 - acc: 0.9475 - rmse: 0.0370 - mse: 0.0053 - r_square: 0.9263 - val_loss: 0.0013 - val_acc: 0.9306 - val_rmse: 0.0196 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0055 - acc: 0.9479 - rmse: 0.0409 - mse: 0.0055 - r_square: 0.9229 - val_loss: 0.0015 - val_acc: 0.9427 - val_rmse: 0.0232 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0054 - acc: 0.9471 - rmse: 0.0389 - mse: 0.0054 - r_square: 0.9242 - val_loss: 0.0013 - val_acc: 0.9185 - val_rmse: 0.0203 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0056 - acc: 0.9480 - rmse: 0.0419 - mse: 0.0056 - r_square: 0.9206 - val_loss: 0.0015 - val_acc: 0.9312 - val_rmse: 0.0241 - val_mse: 0.0015 - val_r_square: 0.9909\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0056 - acc: 0.9470 - rmse: 0.0419 - mse: 0.0056 - r_square: 0.9202 - val_loss: 0.0014 - val_acc: 0.9185 - val_rmse: 0.0217 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0058 - acc: 0.9469 - rmse: 0.0442 - mse: 0.0058 - r_square: 0.9171 - val_loss: 0.0016 - val_acc: 0.9185 - val_rmse: 0.0266 - val_mse: 0.0016 - val_r_square: 0.9901\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0059 - acc: 0.9475 - rmse: 0.0460 - mse: 0.0059 - r_square: 0.9142 - val_loss: 0.0015 - val_acc: 0.9184 - val_rmse: 0.0240 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0063 - acc: 0.9485 - rmse: 0.0495 - mse: 0.0063 - r_square: 0.9102 - val_loss: 0.0019 - val_acc: 0.8889 - val_rmse: 0.0319 - val_mse: 0.0019 - val_r_square: 0.9881\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0065 - acc: 0.9466 - rmse: 0.0518 - mse: 0.0065 - r_square: 0.9041 - val_loss: 0.0016 - val_acc: 0.9054 - val_rmse: 0.0272 - val_mse: 0.0016 - val_r_square: 0.9899\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0068 - acc: 0.9475 - rmse: 0.0541 - mse: 0.0068 - r_square: 0.9005 - val_loss: 0.0017 - val_acc: 0.9030 - val_rmse: 0.0281 - val_mse: 0.0017 - val_r_square: 0.9896\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0070 - acc: 0.9488 - rmse: 0.0567 - mse: 0.0070 - r_square: 0.8991 - val_loss: 0.0023 - val_acc: 0.8898 - val_rmse: 0.0382 - val_mse: 0.0023 - val_r_square: 0.9851\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 309us/step - loss: 0.0066 - acc: 0.9520 - rmse: 0.0532 - mse: 0.0066 - r_square: 0.9027 - val_loss: 0.0014 - val_acc: 0.8500 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0075 - acc: 0.9412 - rmse: 0.0591 - mse: 0.0075 - r_square: 0.8980 - val_loss: 0.0028 - val_acc: 0.8377 - val_rmse: 0.0451 - val_mse: 0.0028 - val_r_square: 0.9813\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 308us/step - loss: 0.0074 - acc: 0.9454 - rmse: 0.0571 - mse: 0.0074 - r_square: 0.8968 - val_loss: 0.0015 - val_acc: 0.8375 - val_rmse: 0.0234 - val_mse: 0.0015 - val_r_square: 0.9910\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0065 - acc: 0.9225 - rmse: 0.0512 - mse: 0.0065 - r_square: 0.9095 - val_loss: 0.0018 - val_acc: 0.8377 - val_rmse: 0.0311 - val_mse: 0.0018 - val_r_square: 0.9885\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0071 - acc: 0.9498 - rmse: 0.0546 - mse: 0.0071 - r_square: 0.9080 - val_loss: 0.0019 - val_acc: 0.8377 - val_rmse: 0.0314 - val_mse: 0.0019 - val_r_square: 0.9884\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 319us/step - loss: 0.0067 - acc: 0.9440 - rmse: 0.0510 - mse: 0.0067 - r_square: 0.9111 - val_loss: 0.0017 - val_acc: 0.8377 - val_rmse: 0.0290 - val_mse: 0.0017 - val_r_square: 0.9894\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0059 - acc: 0.9429 - rmse: 0.0419 - mse: 0.0059 - r_square: 0.9221 - val_loss: 0.0014 - val_acc: 0.8644 - val_rmse: 0.0221 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 310us/step - loss: 0.0055 - acc: 0.9414 - rmse: 0.0362 - mse: 0.0055 - r_square: 0.9267 - val_loss: 0.0014 - val_acc: 0.9421 - val_rmse: 0.0219 - val_mse: 0.0014 - val_r_square: 0.9916\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0053 - acc: 0.9381 - rmse: 0.0337 - mse: 0.0053 - r_square: 0.9295 - val_loss: 0.0015 - val_acc: 0.9436 - val_rmse: 0.0235 - val_mse: 0.0015 - val_r_square: 0.9911\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0051 - acc: 0.9374 - rmse: 0.0309 - mse: 0.0051 - r_square: 0.9320 - val_loss: 0.0013 - val_acc: 0.9180 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0050 - acc: 0.9417 - rmse: 0.0301 - mse: 0.0050 - r_square: 0.9330 - val_loss: 0.0013 - val_acc: 0.9303 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0050 - acc: 0.9420 - rmse: 0.0292 - mse: 0.0050 - r_square: 0.9333 - val_loss: 0.0013 - val_acc: 0.9039 - val_rmse: 0.0197 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0050 - acc: 0.9424 - rmse: 0.0294 - mse: 0.0050 - r_square: 0.9329 - val_loss: 0.0013 - val_acc: 0.9296 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0050 - acc: 0.9415 - rmse: 0.0295 - mse: 0.0050 - r_square: 0.9325 - val_loss: 0.0013 - val_acc: 0.9034 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0051 - acc: 0.9419 - rmse: 0.0297 - mse: 0.0051 - r_square: 0.9326 - val_loss: 0.0013 - val_acc: 0.9295 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0050 - acc: 0.9416 - rmse: 0.0296 - mse: 0.0050 - r_square: 0.9331 - val_loss: 0.0013 - val_acc: 0.9036 - val_rmse: 0.0199 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0050 - acc: 0.9407 - rmse: 0.0300 - mse: 0.0050 - r_square: 0.9333 - val_loss: 0.0013 - val_acc: 0.9178 - val_rmse: 0.0205 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 312us/step - loss: 0.0050 - acc: 0.9414 - rmse: 0.0298 - mse: 0.0050 - r_square: 0.9332 - val_loss: 0.0013 - val_acc: 0.9034 - val_rmse: 0.0201 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 315us/step - loss: 0.0051 - acc: 0.9350 - rmse: 0.0306 - mse: 0.0051 - r_square: 0.9320 - val_loss: 0.0013 - val_acc: 0.9178 - val_rmse: 0.0206 - val_mse: 0.0013 - val_r_square: 0.9919\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0051 - acc: 0.9403 - rmse: 0.0310 - mse: 0.0051 - r_square: 0.9321 - val_loss: 0.0013 - val_acc: 0.9028 - val_rmse: 0.0207 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 313us/step - loss: 0.0051 - acc: 0.9322 - rmse: 0.0314 - mse: 0.0051 - r_square: 0.9326 - val_loss: 0.0014 - val_acc: 0.9164 - val_rmse: 0.0209 - val_mse: 0.0014 - val_r_square: 0.9919\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 314us/step - loss: 0.0051 - acc: 0.9379 - rmse: 0.0315 - mse: 0.0051 - r_square: 0.9321 - val_loss: 0.0013 - val_acc: 0.9027 - val_rmse: 0.0202 - val_mse: 0.0013 - val_r_square: 0.9921\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0052 - acc: 0.9296 - rmse: 0.0325 - mse: 0.0052 - r_square: 0.9305 - val_loss: 0.0013 - val_acc: 0.9168 - val_rmse: 0.0204 - val_mse: 0.0013 - val_r_square: 0.9920\n",
      "Epoch 97/100\n",
      "6946/6946 [==============================] - 2s 328us/step - loss: 0.0052 - acc: 0.9318 - rmse: 0.0329 - mse: 0.0052 - r_square: 0.9311 - val_loss: 0.0013 - val_acc: 0.9027 - val_rmse: 0.0200 - val_mse: 0.0013 - val_r_square: 0.9922\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 2s 320us/step - loss: 0.0052 - acc: 0.9292 - rmse: 0.0331 - mse: 0.0052 - r_square: 0.9317 - val_loss: 0.0013 - val_acc: 0.9157 - val_rmse: 0.0194 - val_mse: 0.0013 - val_r_square: 0.9923\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 2s 316us/step - loss: 0.0052 - acc: 0.9293 - rmse: 0.0335 - mse: 0.0052 - r_square: 0.9313 - val_loss: 0.0013 - val_acc: 0.9152 - val_rmse: 0.0184 - val_mse: 0.0013 - val_r_square: 0.9925\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 2s 311us/step - loss: 0.0052 - acc: 0.9239 - rmse: 0.0339 - mse: 0.0052 - r_square: 0.9309 - val_loss: 0.0013 - val_acc: 0.9165 - val_rmse: 0.0184 - val_mse: 0.0013 - val_r_square: 0.9925\n"
     ]
    }
   ],
   "source": [
    "input_shape = (14, data.shape[1])\n",
    "model = seq2seq(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['acc',rmse,mse,r_square])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_19 (GRU)                 (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "repeat_vector_19 (RepeatVect (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (None, 4, 50)             22650     \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 4, 6)              306       \n",
      "=================================================================\n",
      "Total params: 55,056\n",
      "Trainable params: 55,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6946 samples, validate on 1737 samples\n",
      "Epoch 1/100\n",
      "6946/6946 [==============================] - 12s 2ms/step - loss: 0.0179 - acc: 0.7083 - mse: 0.0179 - rmse: 0.1109 - r_square: 0.6880 - val_loss: 0.0104 - val_acc: 0.9924 - val_mse: 0.0104 - val_rmse: 0.0961 - val_r_square: 0.9275\n",
      "Epoch 2/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0202 - acc: 0.5369 - mse: 0.0202 - rmse: 0.1235 - r_square: 0.6032 - val_loss: 0.0093 - val_acc: 0.8365 - val_mse: 0.0093 - val_rmse: 0.0914 - val_r_square: 0.9358\n",
      "Epoch 3/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0153 - acc: 0.7572 - mse: 0.0153 - rmse: 0.1015 - r_square: 0.7377 - val_loss: 0.0042 - val_acc: 0.8755 - val_mse: 0.0042 - val_rmse: 0.0585 - val_r_square: 0.9715\n",
      "Epoch 4/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0102 - acc: 0.9342 - mse: 0.0102 - rmse: 0.0740 - r_square: 0.8308 - val_loss: 0.0035 - val_acc: 0.8365 - val_mse: 0.0035 - val_rmse: 0.0509 - val_r_square: 0.9772\n",
      "Epoch 5/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0126 - acc: 0.9436 - mse: 0.0126 - rmse: 0.0819 - r_square: 0.8009 - val_loss: 0.0034 - val_acc: 0.8368 - val_mse: 0.0034 - val_rmse: 0.0466 - val_r_square: 0.9788\n",
      "Epoch 6/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0153 - acc: 0.7761 - mse: 0.0153 - rmse: 0.1000 - r_square: 0.7192 - val_loss: 0.0050 - val_acc: 0.8368 - val_mse: 0.0050 - val_rmse: 0.0638 - val_r_square: 0.9667\n",
      "Epoch 7/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0108 - acc: 0.9075 - mse: 0.0108 - rmse: 0.0807 - r_square: 0.8023 - val_loss: 0.0032 - val_acc: 0.8372 - val_mse: 0.0032 - val_rmse: 0.0486 - val_r_square: 0.9788\n",
      "Epoch 8/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0102 - acc: 0.9423 - mse: 0.0102 - rmse: 0.0671 - r_square: 0.8368 - val_loss: 0.0034 - val_acc: 0.8374 - val_mse: 0.0034 - val_rmse: 0.0516 - val_r_square: 0.9769\n",
      "Epoch 9/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0091 - acc: 0.8851 - mse: 0.0091 - rmse: 0.0605 - r_square: 0.8631 - val_loss: 0.0035 - val_acc: 0.8365 - val_mse: 0.0035 - val_rmse: 0.0455 - val_r_square: 0.9787\n",
      "Epoch 10/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0081 - acc: 0.9390 - mse: 0.0081 - rmse: 0.0591 - r_square: 0.8789 - val_loss: 0.0026 - val_acc: 0.8647 - val_mse: 0.0026 - val_rmse: 0.0416 - val_r_square: 0.9827\n",
      "Epoch 11/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0064 - acc: 0.9376 - mse: 0.0064 - rmse: 0.0467 - r_square: 0.9025 - val_loss: 0.0021 - val_acc: 0.8375 - val_mse: 0.0021 - val_rmse: 0.0357 - val_r_square: 0.9866\n",
      "Epoch 12/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0078 - acc: 0.9432 - mse: 0.0078 - rmse: 0.0547 - r_square: 0.8947 - val_loss: 0.0021 - val_acc: 0.8371 - val_mse: 0.0021 - val_rmse: 0.0309 - val_r_square: 0.9876\n",
      "Epoch 13/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0080 - acc: 0.9368 - mse: 0.0080 - rmse: 0.0580 - r_square: 0.8720 - val_loss: 0.0037 - val_acc: 0.8371 - val_mse: 0.0037 - val_rmse: 0.0550 - val_r_square: 0.9741\n",
      "Epoch 14/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0080 - acc: 0.9397 - mse: 0.0080 - rmse: 0.0590 - r_square: 0.8807 - val_loss: 0.0029 - val_acc: 0.8372 - val_mse: 0.0029 - val_rmse: 0.0443 - val_r_square: 0.9814\n",
      "Epoch 15/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0069 - acc: 0.9438 - mse: 0.0069 - rmse: 0.0529 - r_square: 0.8992 - val_loss: 0.0018 - val_acc: 0.8512 - val_mse: 0.0018 - val_rmse: 0.0275 - val_r_square: 0.9894\n",
      "Epoch 16/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0080 - acc: 0.9260 - mse: 0.0080 - rmse: 0.0606 - r_square: 0.8920 - val_loss: 0.0034 - val_acc: 0.8926 - val_mse: 0.0034 - val_rmse: 0.0510 - val_r_square: 0.9762\n",
      "Epoch 17/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0063 - acc: 0.9311 - mse: 0.0063 - rmse: 0.0495 - r_square: 0.9061 - val_loss: 0.0017 - val_acc: 0.8366 - val_mse: 0.0017 - val_rmse: 0.0282 - val_r_square: 0.9896\n",
      "Epoch 18/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0063 - acc: 0.9332 - mse: 0.0063 - rmse: 0.0489 - r_square: 0.9102 - val_loss: 0.0023 - val_acc: 0.8368 - val_mse: 0.0023 - val_rmse: 0.0377 - val_r_square: 0.9852\n",
      "Epoch 19/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0071 - acc: 0.9371 - mse: 0.0071 - rmse: 0.0561 - r_square: 0.8966 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0269 - val_r_square: 0.9896\n",
      "Epoch 20/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0065 - acc: 0.9360 - mse: 0.0065 - rmse: 0.0495 - r_square: 0.9124 - val_loss: 0.0029 - val_acc: 0.8503 - val_mse: 0.0029 - val_rmse: 0.0456 - val_r_square: 0.9809\n",
      "Epoch 21/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0066 - acc: 0.9260 - mse: 0.0066 - rmse: 0.0516 - r_square: 0.9055 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0370 - val_r_square: 0.9851\n",
      "Epoch 22/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0065 - acc: 0.9304 - mse: 0.0065 - rmse: 0.0506 - r_square: 0.9049 - val_loss: 0.0013 - val_acc: 0.9813 - val_mse: 0.0013 - val_rmse: 0.0170 - val_r_square: 0.9924\n",
      "Epoch 23/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0061 - acc: 0.9304 - mse: 0.0061 - rmse: 0.0451 - r_square: 0.9200 - val_loss: 0.0027 - val_acc: 0.8371 - val_mse: 0.0027 - val_rmse: 0.0444 - val_r_square: 0.9817\n",
      "Epoch 24/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0059 - acc: 0.9300 - mse: 0.0059 - rmse: 0.0454 - r_square: 0.9128 - val_loss: 0.0020 - val_acc: 0.8366 - val_mse: 0.0020 - val_rmse: 0.0325 - val_r_square: 0.9876\n",
      "Epoch 25/100\n",
      "6946/6946 [==============================] - 2s 225us/step - loss: 0.0063 - acc: 0.9275 - mse: 0.0063 - rmse: 0.0490 - r_square: 0.9075 - val_loss: 0.0017 - val_acc: 0.9558 - val_mse: 0.0017 - val_rmse: 0.0267 - val_r_square: 0.9898\n",
      "Epoch 26/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0065 - acc: 0.9192 - mse: 0.0065 - rmse: 0.0495 - r_square: 0.9142 - val_loss: 0.0030 - val_acc: 0.9693 - val_mse: 0.0030 - val_rmse: 0.0464 - val_r_square: 0.9802\n",
      "Epoch 27/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0058 - acc: 0.9289 - mse: 0.0058 - rmse: 0.0441 - r_square: 0.9176 - val_loss: 0.0017 - val_acc: 0.8505 - val_mse: 0.0017 - val_rmse: 0.0279 - val_r_square: 0.9895\n",
      "Epoch 28/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0063 - acc: 0.9180 - mse: 0.0063 - rmse: 0.0493 - r_square: 0.9134 - val_loss: 0.0026 - val_acc: 0.8372 - val_mse: 0.0026 - val_rmse: 0.0399 - val_r_square: 0.9837\n",
      "Epoch 29/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0069 - acc: 0.9286 - mse: 0.0069 - rmse: 0.0535 - r_square: 0.9066 - val_loss: 0.0039 - val_acc: 0.8368 - val_mse: 0.0039 - val_rmse: 0.0536 - val_r_square: 0.9749\n",
      "Epoch 30/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0069 - acc: 0.9096 - mse: 0.0069 - rmse: 0.0518 - r_square: 0.9129 - val_loss: 0.0036 - val_acc: 0.8365 - val_mse: 0.0036 - val_rmse: 0.0500 - val_r_square: 0.9769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0067 - acc: 0.9063 - mse: 0.0067 - rmse: 0.0527 - r_square: 0.9015 - val_loss: 0.0018 - val_acc: 0.8507 - val_mse: 0.0018 - val_rmse: 0.0292 - val_r_square: 0.9889\n",
      "Epoch 32/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0066 - acc: 0.9390 - mse: 0.0066 - rmse: 0.0518 - r_square: 0.9110 - val_loss: 0.0024 - val_acc: 0.9922 - val_mse: 0.0024 - val_rmse: 0.0391 - val_r_square: 0.9845\n",
      "Epoch 33/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0064 - acc: 0.9155 - mse: 0.0064 - rmse: 0.0492 - r_square: 0.9084 - val_loss: 0.0024 - val_acc: 0.8365 - val_mse: 0.0024 - val_rmse: 0.0362 - val_r_square: 0.9855\n",
      "Epoch 34/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0069 - acc: 0.7945 - mse: 0.0069 - rmse: 0.0576 - r_square: 0.8928 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0327 - val_r_square: 0.9861\n",
      "Epoch 35/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0071 - acc: 0.9137 - mse: 0.0071 - rmse: 0.0583 - r_square: 0.8855 - val_loss: 0.0021 - val_acc: 0.9940 - val_mse: 0.0021 - val_rmse: 0.0335 - val_r_square: 0.9866\n",
      "Epoch 36/100\n",
      "6946/6946 [==============================] - 2s 216us/step - loss: 0.0074 - acc: 0.9098 - mse: 0.0074 - rmse: 0.0560 - r_square: 0.8875 - val_loss: 0.0016 - val_acc: 0.8365 - val_mse: 0.0016 - val_rmse: 0.0261 - val_r_square: 0.9903\n",
      "Epoch 37/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0068 - acc: 0.9357 - mse: 0.0068 - rmse: 0.0536 - r_square: 0.8842 - val_loss: 0.0015 - val_acc: 0.8489 - val_mse: 0.0015 - val_rmse: 0.0224 - val_r_square: 0.9914\n",
      "Epoch 38/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0067 - acc: 0.9272 - mse: 0.0067 - rmse: 0.0534 - r_square: 0.8884 - val_loss: 0.0024 - val_acc: 0.8381 - val_mse: 0.0024 - val_rmse: 0.0395 - val_r_square: 0.9840\n",
      "Epoch 39/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0071 - acc: 0.9392 - mse: 0.0071 - rmse: 0.0543 - r_square: 0.9008 - val_loss: 0.0043 - val_acc: 0.9820 - val_mse: 0.0043 - val_rmse: 0.0587 - val_r_square: 0.9696\n",
      "Epoch 40/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0060 - acc: 0.9327 - mse: 0.0060 - rmse: 0.0453 - r_square: 0.9121 - val_loss: 0.0023 - val_acc: 0.8368 - val_mse: 0.0023 - val_rmse: 0.0376 - val_r_square: 0.9853\n",
      "Epoch 41/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0074 - acc: 0.9058 - mse: 0.0074 - rmse: 0.0605 - r_square: 0.8948 - val_loss: 0.0027 - val_acc: 0.9942 - val_mse: 0.0027 - val_rmse: 0.0429 - val_r_square: 0.9823\n",
      "Epoch 42/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0067 - acc: 0.8189 - mse: 0.0067 - rmse: 0.0541 - r_square: 0.8933 - val_loss: 0.0029 - val_acc: 0.9937 - val_mse: 0.0029 - val_rmse: 0.0441 - val_r_square: 0.9804\n",
      "Epoch 43/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0064 - acc: 0.9175 - mse: 0.0064 - rmse: 0.0508 - r_square: 0.9073 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0332 - val_r_square: 0.9873\n",
      "Epoch 44/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0068 - acc: 0.9197 - mse: 0.0068 - rmse: 0.0544 - r_square: 0.9058 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0238 - val_r_square: 0.9907\n",
      "Epoch 45/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0063 - acc: 0.9277 - mse: 0.0063 - rmse: 0.0500 - r_square: 0.9053 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0330 - val_r_square: 0.9876\n",
      "Epoch 46/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0065 - acc: 0.9206 - mse: 0.0065 - rmse: 0.0503 - r_square: 0.9077 - val_loss: 0.0017 - val_acc: 0.8365 - val_mse: 0.0017 - val_rmse: 0.0295 - val_r_square: 0.9892\n",
      "Epoch 47/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0063 - acc: 0.9306 - mse: 0.0063 - rmse: 0.0477 - r_square: 0.9109 - val_loss: 0.0013 - val_acc: 0.8487 - val_mse: 0.0013 - val_rmse: 0.0177 - val_r_square: 0.9925\n",
      "Epoch 48/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0058 - acc: 0.9436 - mse: 0.0058 - rmse: 0.0445 - r_square: 0.9171 - val_loss: 0.0016 - val_acc: 0.9928 - val_mse: 0.0016 - val_rmse: 0.0267 - val_r_square: 0.9902\n",
      "Epoch 49/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0071 - acc: 0.7713 - mse: 0.0071 - rmse: 0.0586 - r_square: 0.8807 - val_loss: 0.0025 - val_acc: 0.9026 - val_mse: 0.0025 - val_rmse: 0.0395 - val_r_square: 0.9838\n",
      "Epoch 50/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0072 - acc: 0.8670 - mse: 0.0072 - rmse: 0.0585 - r_square: 0.8721 - val_loss: 0.0020 - val_acc: 0.8365 - val_mse: 0.0020 - val_rmse: 0.0342 - val_r_square: 0.9869\n",
      "Epoch 51/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0061 - acc: 0.9335 - mse: 0.0061 - rmse: 0.0459 - r_square: 0.9151 - val_loss: 0.0016 - val_acc: 0.9678 - val_mse: 0.0016 - val_rmse: 0.0254 - val_r_square: 0.9901\n",
      "Epoch 52/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0064 - acc: 0.9300 - mse: 0.0064 - rmse: 0.0477 - r_square: 0.9093 - val_loss: 0.0022 - val_acc: 0.9942 - val_mse: 0.0022 - val_rmse: 0.0363 - val_r_square: 0.9856\n",
      "Epoch 53/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0060 - acc: 0.9014 - mse: 0.0060 - rmse: 0.0457 - r_square: 0.9139 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0224 - val_r_square: 0.9912\n",
      "Epoch 54/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0060 - acc: 0.9293 - mse: 0.0060 - rmse: 0.0472 - r_square: 0.9104 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0245 - val_r_square: 0.9906\n",
      "Epoch 55/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0060 - acc: 0.9368 - mse: 0.0060 - rmse: 0.0475 - r_square: 0.9093 - val_loss: 0.0016 - val_acc: 0.8372 - val_mse: 0.0016 - val_rmse: 0.0257 - val_r_square: 0.9903\n",
      "Epoch 56/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0064 - acc: 0.9468 - mse: 0.0064 - rmse: 0.0504 - r_square: 0.8894 - val_loss: 0.0018 - val_acc: 0.9403 - val_mse: 0.0018 - val_rmse: 0.0296 - val_r_square: 0.9891\n",
      "Epoch 57/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0066 - acc: 0.9011 - mse: 0.0066 - rmse: 0.0525 - r_square: 0.8895 - val_loss: 0.0031 - val_acc: 0.9401 - val_mse: 0.0031 - val_rmse: 0.0461 - val_r_square: 0.9788\n",
      "Epoch 58/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0064 - acc: 0.9245 - mse: 0.0064 - rmse: 0.0517 - r_square: 0.8898 - val_loss: 0.0013 - val_acc: 0.9786 - val_mse: 0.0013 - val_rmse: 0.0186 - val_r_square: 0.9923\n",
      "Epoch 59/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0060 - acc: 0.9260 - mse: 0.0060 - rmse: 0.0472 - r_square: 0.9160 - val_loss: 0.0014 - val_acc: 0.9554 - val_mse: 0.0014 - val_rmse: 0.0203 - val_r_square: 0.9919\n",
      "Epoch 60/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0067 - acc: 0.9410 - mse: 0.0067 - rmse: 0.0518 - r_square: 0.8996 - val_loss: 0.0026 - val_acc: 0.9942 - val_mse: 0.0026 - val_rmse: 0.0422 - val_r_square: 0.9825\n",
      "Epoch 61/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0067 - acc: 0.9480 - mse: 0.0067 - rmse: 0.0535 - r_square: 0.8918 - val_loss: 0.0017 - val_acc: 0.9904 - val_mse: 0.0017 - val_rmse: 0.0279 - val_r_square: 0.9896\n",
      "Epoch 62/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0068 - acc: 0.9155 - mse: 0.0068 - rmse: 0.0551 - r_square: 0.8959 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0266 - val_r_square: 0.9902\n",
      "Epoch 63/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0065 - acc: 0.9183 - mse: 0.0065 - rmse: 0.0515 - r_square: 0.9025 - val_loss: 0.0032 - val_acc: 0.9934 - val_mse: 0.0032 - val_rmse: 0.0494 - val_r_square: 0.9785\n",
      "Epoch 64/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0067 - acc: 0.9449 - mse: 0.0067 - rmse: 0.0509 - r_square: 0.9030 - val_loss: 0.0014 - val_acc: 0.8371 - val_mse: 0.0014 - val_rmse: 0.0214 - val_r_square: 0.9917\n",
      "Epoch 65/100\n",
      "6946/6946 [==============================] - 2s 231us/step - loss: 0.0061 - acc: 0.9466 - mse: 0.0061 - rmse: 0.0467 - r_square: 0.9093 - val_loss: 0.0014 - val_acc: 0.8391 - val_mse: 0.0014 - val_rmse: 0.0215 - val_r_square: 0.9916\n",
      "Epoch 66/100\n",
      "6946/6946 [==============================] - 2s 224us/step - loss: 0.0075 - acc: 0.8946 - mse: 0.0075 - rmse: 0.0558 - r_square: 0.8880 - val_loss: 0.0023 - val_acc: 0.9942 - val_mse: 0.0023 - val_rmse: 0.0374 - val_r_square: 0.9852\n",
      "Epoch 67/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0060 - acc: 0.9435 - mse: 0.0060 - rmse: 0.0427 - r_square: 0.9157 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0352 - val_r_square: 0.9869\n",
      "Epoch 68/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0058 - acc: 0.9433 - mse: 0.0058 - rmse: 0.0438 - r_square: 0.9158 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0241 - val_r_square: 0.9909\n",
      "Epoch 69/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0059 - acc: 0.9521 - mse: 0.0059 - rmse: 0.0441 - r_square: 0.9159 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0300 - val_r_square: 0.9890\n",
      "Epoch 70/100\n",
      "6946/6946 [==============================] - 2s 217us/step - loss: 0.0062 - acc: 0.9439 - mse: 0.0062 - rmse: 0.0460 - r_square: 0.9075 - val_loss: 0.0020 - val_acc: 0.9942 - val_mse: 0.0020 - val_rmse: 0.0342 - val_r_square: 0.9869\n",
      "Epoch 71/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0060 - acc: 0.9431 - mse: 0.0060 - rmse: 0.0425 - r_square: 0.9121 - val_loss: 0.0013 - val_acc: 0.9653 - val_mse: 0.0013 - val_rmse: 0.0188 - val_r_square: 0.9923\n",
      "Epoch 72/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0058 - acc: 0.9431 - mse: 0.0058 - rmse: 0.0432 - r_square: 0.9133 - val_loss: 0.0015 - val_acc: 0.9544 - val_mse: 0.0015 - val_rmse: 0.0232 - val_r_square: 0.9913\n",
      "Epoch 73/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0058 - acc: 0.9436 - mse: 0.0058 - rmse: 0.0437 - r_square: 0.9088 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0278 - val_r_square: 0.9892\n",
      "Epoch 74/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0054 - acc: 0.9438 - mse: 0.0054 - rmse: 0.0361 - r_square: 0.9240 - val_loss: 0.0012 - val_acc: 0.8368 - val_mse: 0.0012 - val_rmse: 0.0142 - val_r_square: 0.9932\n",
      "Epoch 75/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0054 - acc: 0.9462 - mse: 0.0054 - rmse: 0.0397 - r_square: 0.9201 - val_loss: 0.0015 - val_acc: 0.9940 - val_mse: 0.0015 - val_rmse: 0.0240 - val_r_square: 0.9911\n",
      "Epoch 76/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0056 - acc: 0.9376 - mse: 0.0056 - rmse: 0.0426 - r_square: 0.9143 - val_loss: 0.0018 - val_acc: 0.8765 - val_mse: 0.0018 - val_rmse: 0.0300 - val_r_square: 0.9888\n",
      "Epoch 77/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0058 - acc: 0.9410 - mse: 0.0058 - rmse: 0.0444 - r_square: 0.9162 - val_loss: 0.0014 - val_acc: 0.9170 - val_mse: 0.0014 - val_rmse: 0.0223 - val_r_square: 0.9914\n",
      "Epoch 78/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0059 - acc: 0.9456 - mse: 0.0059 - rmse: 0.0464 - r_square: 0.9048 - val_loss: 0.0014 - val_acc: 0.8667 - val_mse: 0.0014 - val_rmse: 0.0213 - val_r_square: 0.9916\n",
      "Epoch 79/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0063 - acc: 0.9462 - mse: 0.0063 - rmse: 0.0486 - r_square: 0.9133 - val_loss: 0.0033 - val_acc: 0.9942 - val_mse: 0.0033 - val_rmse: 0.0504 - val_r_square: 0.9774\n",
      "Epoch 80/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0056 - acc: 0.9504 - mse: 0.0056 - rmse: 0.0400 - r_square: 0.9196 - val_loss: 0.0014 - val_acc: 0.9856 - val_mse: 0.0014 - val_rmse: 0.0225 - val_r_square: 0.9913\n",
      "Epoch 81/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0057 - acc: 0.9272 - mse: 0.0057 - rmse: 0.0433 - r_square: 0.9209 - val_loss: 0.0016 - val_acc: 0.9276 - val_mse: 0.0016 - val_rmse: 0.0259 - val_r_square: 0.9905\n",
      "Epoch 82/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0060 - acc: 0.9403 - mse: 0.0060 - rmse: 0.0461 - r_square: 0.9118 - val_loss: 0.0019 - val_acc: 0.9942 - val_mse: 0.0019 - val_rmse: 0.0312 - val_r_square: 0.9883\n",
      "Epoch 83/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0058 - acc: 0.9381 - mse: 0.0058 - rmse: 0.0436 - r_square: 0.9183 - val_loss: 0.0014 - val_acc: 0.9868 - val_mse: 0.0014 - val_rmse: 0.0212 - val_r_square: 0.9915\n",
      "Epoch 84/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0061 - acc: 0.9487 - mse: 0.0061 - rmse: 0.0479 - r_square: 0.9077 - val_loss: 0.0013 - val_acc: 0.9683 - val_mse: 0.0013 - val_rmse: 0.0174 - val_r_square: 0.9926\n",
      "Epoch 85/100\n",
      "6946/6946 [==============================] - 2s 218us/step - loss: 0.0058 - acc: 0.9409 - mse: 0.0058 - rmse: 0.0425 - r_square: 0.9166 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0292 - val_r_square: 0.9894\n",
      "Epoch 86/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0058 - acc: 0.9380 - mse: 0.0058 - rmse: 0.0435 - r_square: 0.9104 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0290 - val_r_square: 0.9892\n",
      "Epoch 87/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0057 - acc: 0.9102 - mse: 0.0057 - rmse: 0.0430 - r_square: 0.9188 - val_loss: 0.0014 - val_acc: 0.8365 - val_mse: 0.0014 - val_rmse: 0.0214 - val_r_square: 0.9917\n",
      "Epoch 88/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0063 - acc: 0.9429 - mse: 0.0063 - rmse: 0.0480 - r_square: 0.9014 - val_loss: 0.0017 - val_acc: 0.9942 - val_mse: 0.0017 - val_rmse: 0.0268 - val_r_square: 0.9896\n",
      "Epoch 89/100\n",
      "6946/6946 [==============================] - 2s 219us/step - loss: 0.0056 - acc: 0.9331 - mse: 0.0056 - rmse: 0.0415 - r_square: 0.9155 - val_loss: 0.0016 - val_acc: 0.9942 - val_mse: 0.0016 - val_rmse: 0.0262 - val_r_square: 0.9903\n",
      "Epoch 90/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0057 - acc: 0.9282 - mse: 0.0057 - rmse: 0.0432 - r_square: 0.9146 - val_loss: 0.0018 - val_acc: 0.8502 - val_mse: 0.0018 - val_rmse: 0.0310 - val_r_square: 0.9886\n",
      "Epoch 91/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0058 - acc: 0.9392 - mse: 0.0058 - rmse: 0.0424 - r_square: 0.9151 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0203 - val_r_square: 0.9916\n",
      "Epoch 92/100\n",
      "6946/6946 [==============================] - 2s 221us/step - loss: 0.0055 - acc: 0.9349 - mse: 0.0055 - rmse: 0.0394 - r_square: 0.9197 - val_loss: 0.0014 - val_acc: 0.9699 - val_mse: 0.0014 - val_rmse: 0.0212 - val_r_square: 0.9919\n",
      "Epoch 93/100\n",
      "6946/6946 [==============================] - 2s 223us/step - loss: 0.0059 - acc: 0.9286 - mse: 0.0059 - rmse: 0.0442 - r_square: 0.9102 - val_loss: 0.0016 - val_acc: 0.9020 - val_mse: 0.0016 - val_rmse: 0.0268 - val_r_square: 0.9899\n",
      "Epoch 94/100\n",
      "6946/6946 [==============================] - 2s 220us/step - loss: 0.0057 - acc: 0.9464 - mse: 0.0057 - rmse: 0.0403 - r_square: 0.9176 - val_loss: 0.0013 - val_acc: 0.8368 - val_mse: 0.0013 - val_rmse: 0.0193 - val_r_square: 0.9921\n",
      "Epoch 95/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0059 - acc: 0.9435 - mse: 0.0059 - rmse: 0.0432 - r_square: 0.9072 - val_loss: 0.0014 - val_acc: 0.9942 - val_mse: 0.0014 - val_rmse: 0.0211 - val_r_square: 0.9917\n",
      "Epoch 96/100\n",
      "6946/6946 [==============================] - 2s 222us/step - loss: 0.0069 - acc: 0.9411 - mse: 0.0069 - rmse: 0.0513 - r_square: 0.8984 - val_loss: 0.0029 - val_acc: 0.9941 - val_mse: 0.0029 - val_rmse: 0.0466 - val_r_square: 0.9802\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0068 - acc: 0.9346 - mse: 0.0068 - rmse: 0.0512 - r_square: 0.8907 - val_loss: 0.0013 - val_acc: 0.9902 - val_mse: 0.0013 - val_rmse: 0.0172 - val_r_square: 0.9927\n",
      "Epoch 98/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0060 - acc: 0.9379 - mse: 0.0060 - rmse: 0.0445 - r_square: 0.9135 - val_loss: 0.0014 - val_acc: 0.9650 - val_mse: 0.0014 - val_rmse: 0.0214 - val_r_square: 0.9917\n",
      "Epoch 99/100\n",
      "6946/6946 [==============================] - 1s 216us/step - loss: 0.0060 - acc: 0.9418 - mse: 0.0060 - rmse: 0.0441 - r_square: 0.9100 - val_loss: 0.0018 - val_acc: 0.9942 - val_mse: 0.0018 - val_rmse: 0.0296 - val_r_square: 0.9892\n",
      "Epoch 100/100\n",
      "6946/6946 [==============================] - 1s 215us/step - loss: 0.0060 - acc: 0.9459 - mse: 0.0060 - rmse: 0.0451 - r_square: 0.9106 - val_loss: 0.0015 - val_acc: 0.9942 - val_mse: 0.0015 - val_rmse: 0.0245 - val_r_square: 0.9906\n"
     ]
    }
   ],
   "source": [
    "def base_model2(feature_len=3, after_day=3, input_shape=(8, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    #model.add(LSTM(units=100, return_sequences=False, input_shape=input_shape))\n",
    "    # one to many\n",
    "    model.add(RepeatVector(after_day))\n",
    "    #model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(GRU(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=feature_len, activation='linear')))\n",
    "    return model\n",
    "opt = Adam(lr=0.01)\n",
    "input_shape = (14, data.shape[1])\n",
    "model = base_model2(data.shape[1], 4, input_shape)\n",
    "model.compile(loss='mse', optimizer=opt,metrics=['acc',mse,rmse,r_square])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100,shuffle=False ,validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report For All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model    Bithrate         DeatRate\n",
    "         _________\n",
    "         MSE|MAE|RS|ACC\n",
    "LSTM       95%     +\n",
    "Se2Se      42%     -\n",
    "GRU        75%     -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
